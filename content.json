{"meta":{"title":"CodingStudio","subtitle":"努力进步","description":"自己的创作及学习空间","author":"jay1060950003","url":"http://jay1060950003.github.io","root":"/"},"pages":[{"title":"所有标签","date":"2023-05-06T15:16:10.122Z","updated":"2023-05-06T15:16:10.122Z","comments":true,"path":"tags/index.html","permalink":"http://jay1060950003.github.io/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2023-05-06T15:13:13.597Z","updated":"2023-05-06T15:13:13.597Z","comments":true,"path":"categories/index.html","permalink":"http://jay1060950003.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-05-06T15:14:12.344Z","updated":"2023-05-06T15:14:12.344Z","comments":true,"path":"about/index.html","permalink":"http://jay1060950003.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"StableDiffusion食用指南","slug":"小工具记录/StableDiffusion食用指南","date":"2023-12-13T05:25:12.000Z","updated":"2023-12-13T12:20:29.989Z","comments":true,"path":"2023/12/13/小工具记录/StableDiffusion食用指南/","link":"","permalink":"http://jay1060950003.github.io/2023/12/13/%E5%B0%8F%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/StableDiffusion%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"引言 Stable Diffusion的食用指南","text":"引言 Stable Diffusion的食用指南 0 Windows安装 安装miniconda, 具体安装地址 默认安装 配置下载源 12345678910111213141516&lt;!-- 1. 设置阿里源为默认源 --&gt;pip config set global.index-url https://mirrors.aliyun.com/pypi/simple&lt;!-- 该源可解决tb-nightly的问题 --&gt;&lt;!-- 还原默认源 --&gt;pip config set global.index-url https://mirrors.ustc.edu.cn/pypi/web/simple&lt;!-- 其他源 --&gt;https://pypi.tuna.tsinghua.edu.cn/simplehttps://mirrors.aliyun.com/pypi/simple/https://mirrors.163.com/pypi/simple/ https://pypi.douban.com/simple/ https://mirror.baidu.com/pypi/simple/https://pypi.mirrors.ustc.edu.cn/simple/https://mirrors.huaweicloud.com/repository/pypi/simple/https://mirrors.cloud.tencent.com/pypi/simple/ 创建虚拟环境 1conda create --name sd-webui python=3.10.6 激活虚拟环境 1conda activate sd-webui 安装git 安装cuda及cuDNN, 详见Windows深度学习环境配置 git克隆Stable Diffusion WebUI项目至本地, 注意终端的地址为本地合适的地址 1git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git 进入项目文件夹，运行Stable Diffusion WebUI, 首次运行会安装对应的库 12345&lt;!-- 切换目录 --&gt;cd stable-diffusion-webui&lt;!-- 运行 --&gt;webui-user.bat 安装插件 插件源 https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui-extensions/master/index.json https://gitee.com/hmy394481125/stable-diffusion-webui-extensions/raw/master/index.json https://gitee.com/kalicyh/stable-diffusion-webui-extensions/raw/master/AUTOMATIC1111_stable-diffusion-webui-extensions_master_index.json https://gitee.com/ethanyu/stable-diffusion-webui-extensions/raw/master/index.json 操作 打开Stable Diffusion WebUI的Settings，找到Extensions，点击Install，输入插件源地址，点击Install即可 安装插件后，需要重启Stable Diffusion WebUI才能生效 推荐插件 [x] stable-diffusion-webui-localization-zh_Hans 简体中文语言包 [ ] Booru tag autocompletion 自动补全标签 [ ] Stable Diffusion WebUI EasyNegative 一键生成负面标签 [x] sd-webui-controlnet ControlNet插件 [x] openpose-editor 编辑自定义POSE [x] stable-diffusion-webui-wd14-tagger 提取tag提示词 [ ] clip-interrogator-ext [ ] sd-webui-lora-black-weight 1 Ubuntu安装 2 ControlNet使用方法 部分模型说明 canny主要是边缘检测，属于比较通用的模型 Openpose就是传说中的姿势控制专用模型 Scribble是手稿模型，适合随手涂鸦然后生成一个精美的画面，可玩性高 3 Ubuntu调教 在Ubuntu中可使用supervisord配置sd-webui进程实现开机自启动 帮助命令12345启动命令：supervisord ctl start stable-webui关闭命令：supervisord ctl stop stable-webui重启命令：supervisord ctl restart stable-webui查看状态：supervisord ctl status stable-webui查看日志：tail -f /var/log/stable-webui.log 安装方式 文件/etc/supervisor/conf.d/stable-webui.conf 1234567891011121314&lt;!-- 编辑文件 --&gt;vim /etc/supervisor/conf.d/stable-webui.conf&lt;!-- 文件内容 --&gt;[program:stable-webui]command=/usr/local/miniconda3/bin/python3 launch.py --xformers --no-half-vae --listen --port 8080 --api --enable-insecure-extension-access --opt-channelslast --administratorprocess_name=%(program_name)sautorestart=trueredirect_stderr=truestdout_logfile=/var/log/stable-webui.log,/dev/stdoutstdout_events_enabled=trueenvironment=SHELL=/bin/bashdirectory=/hy-tmp/stable-diffusion-webui/user=root 设置 supervisord开机自启动 cd /usr/lib/systemd/system/ which supervisord, which supervisorctl, vi supervisord.service建立supervisord.service文件内容 12345678910111213141516#supervisord.service [Unit]Description=Supervisor daemon[Service]Type=forkingExecStart=/usr/local/bin/supervisord -c /etc/supervisord.confExecStop=/usr/local/bin/supervisorctl shutdownExecReload=/usr/local/bin/supervisorctl reloadKillMode=processRestart=on-failureRestartSec=42s[Install]WantedBy=multi-user.target 启动服务 systemctl enable supervisord, systemctl start supervisord 查看服务状态 systemctl status supervisord 验证是否开机自启动 systemctl is-enabled supervisord 4 模型下载 国内使用镜像站下载 推荐使用huggingface-cli进行下载123456789101112131415161718&lt;!-- 安装依赖 python&gt;3.8 --&gt;pip install -U huggingface_hub hf-transfer&lt;!-- Windows设置环境变量 --&gt;setx HF_HUB_ENABLE_HF_TRANSFER 1setx HF_ENDPOINT https://hf-mirror.com&lt;!-- Linux设置环境变量 --&gt;export HF_HUB_ENABLE_HF_TRANSFER=1vim ~/.bashrc# 在打开文件中的最后一行添加export HF_ENDPOINT=&quot;https://hf-mirror.com&quot;&lt;!-- 下载模型 --&gt;huggingface-cli download --token [访问令牌] --resume-download --local-dir-use-symlinks False [模型名] --local-dir [保存位置] 使用git clone123456789&lt;!-- 安装 git lfs --&gt;git lfs install&lt;!-- 直接git clone --&gt;git clone ....&lt;!-- 不下载大的文件配置方法 --&gt;setx GIT_LFS_SKIP_SMUDGE 1export GIT_LFS_SKIP_SMUDGE=1 5 注意事项 注意事项 模型文件在stable-diffusion-webui\\models中, 首次运行需要下载模型文件 webui-user.bat修改说明12345678&lt;!-- 解决RuntimeError: &quot;LayerNormKernelImpl&quot; not implemented for &#x27;Half&#x27; --&gt;COMMANDLINE_ARGS=--skip-torch-cuda-test --precision full --no-half&lt;!-- torch.cuda.OutOfMemoryError: CUDA out of memory --&gt;COMMANDLINE_ARGS=--medvram 或者--lowvram&lt;!-- No module &#x27;xformers&#x27;. Proceeding without it. --&gt;COMMANDLINE_ARGS=--xformers 模型推荐 https://huggingface.co/gsdf/Counterfeit-V2.5 配合EasyNegative使用，上面的萝姬就是用这个模型，很好看，tag写起来也简单 https://huggingface.co/andite/anything-v4.0 祖师爷，出图质量稳定，插图风格很不错 https://huggingface.co/datasets/gsdf/EasyNegative 用这个负面tag就可以写很简单了 https://huggingface.co/TASUKU2023/Chilloutmix 真人模型，不过我没怎么用过，还是喜欢二次元的图，不过之后可能研究配合Lora玩赛博COS 插件推荐： https://github.com/DominikDoom/a1111-sd-webui-tagcomplete 可以自动补全标签，有助于写出更准确的tags","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"目标检测论文总结","slug":"目标检测论文总结","date":"2023-04-12T11:27:07.000Z","updated":"2023-05-19T03:30:57.313Z","comments":true,"path":"2023/04/12/目标检测论文总结/","link":"","permalink":"http://jay1060950003.github.io/2023/04/12/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/","excerpt":"论文总览 backbone Two-stage One-stage Anchor-Free Other VGG RCNN YOLO CornerNet PANet ResNet SPP Net YOLOv2 CenterNet DETR* ResNetv2 Fast RCNN YOLOv3 FCOS DenseNet Faster RCNN RetinaNet CSPNet FPN YOLOv5 Mask RCNN YOLOv8 Cascade RCNN","text":"论文总览 backbone Two-stage One-stage Anchor-Free Other VGG RCNN YOLO CornerNet PANet ResNet SPP Net YOLOv2 CenterNet DETR* ResNetv2 Fast RCNN YOLOv3 FCOS DenseNet Faster RCNN RetinaNet CSPNet FPN YOLOv5 Mask RCNN YOLOv8 Cascade RCNN backbone VGG 证明了增加网络的深度能够在一定程度上影响网络的性能 结构(VGG16) INPUT(224*224*3) -&gt; Conv(k3,s1,c64) -&gt; Conv(k3,s1,c64) -&gt; maxpool(s2) -&gt; Conv(k3,s1,c128) -&gt; Conv(k3,s1,c128) -&gt; maxpool(s2) -&gt; Conv(k3,s1,c256) -&gt; Conv(k3,s1,c256) -&gt; Conv(k3,s1,c256) -&gt; maxpool(s2) -&gt; Conv(k3,s1,c512) -&gt; Conv(k3,s1,c512) -&gt; Conv(k3,s1,c512) -&gt; maxpool(s2) -&gt; Conv(k3,s1,c512) -&gt; Conv(k3,s1,c512) -&gt; Conv(k3,s1,c512) -&gt; maxpool(s2) -&gt; FC(4096) -&gt; FC(4096) -&gt; FC(1000) -&gt; softmax 13个卷积层, 3个全连接层 通道输出64, 128, 256, 512, 512 5个Block中卷积层数量2,2,3,3,3 都是k3*3, s1的卷积与s2的最大池化层 原理 使用连续的几个3*3卷积代替较大的卷积核, 给定感受野下, 堆积的小卷积核优于大卷积核(多层非线性层可以增加网络的深度来保证学习更复杂的模式, 且参数更少) 2个3*3卷积核代替5*5卷积核, 3个3*3卷积核代替7*7卷积核 相较于其他方法, VGG的参数空间较大训练时间较长,但一般采用pretrained model训练 ResNet 目的: 为解决深度神经网络的优化问题 网络越深, 反传回来的梯度之间的相关性越来越差, 最后接近白噪声导致梯度消失,网络无法得到有效的训练 初衷: 让模型的内部结构至少有恒等映射的能力(什么都不做的能力, 保持初心的能力), 这样可以保证更深的卷积层不会因为网络更深而产生退化 原理： 假定block的输入为x, 期望输出H(x), block完成非线性映射的功能 如何实现恒等映射: 假定直连(plain)卷积的输入为x, 期望输出为H(x), 则学习H(x) = x即可实现恒等映射 但上述较难学习, 利用shortcut可以让H(x)学习其他的, 而直连block网络输出学习为0即可, 上述直连卷积block输出学习为0比学习成恒等映射更简单(可通过L2正则化, 无限趋近于0) 将H(x)=F(x)+x, 只需要F(x)=0即可实现恒等映射 两个不同的结构 不使用bottleneck结构, 2个输出通道相同的3*3卷积层构成 使用bottleneck结构, 使用1*1卷积层, 3*3卷积层, 1*1卷积层构成 使用1*1卷积层先减小后增加维度, 该方式使3*3卷积的通道数目下降, 降低参数量, 减少算力瓶颈 **使用两种不同的shortcut**对网络的性能提升不明显: 一种shortcut不添加1*1卷积层, 另一种添加1*1卷积层 ResNet18, ResNet34使用两层残差结构, 更深的网络采用三层残差结构 ResNet18中7*7卷积+池化层降采样至原尺寸的14\\frac{1}{4}41​, 随后4个残差块分别降采样至原尺寸的12\\frac{1}{2}21​ 残差块数量[2, 2, 2, 2], 再加上第一层和最后一层, 共计18层 ResNet的一个重要设计原则是：当feature map大小降低一半时,feature map的数量增加一倍,这保持了网络层的复杂度 ResNetV2 目的: 在更深的ResNet(&gt;110layers)网络中, 使用预激活残差单元的网络更易训练且精度更高 预激活: 将激活函数(ReLu和BN)移到权值层(Weight)之前, 形成预激活(pre-activation)方式 公式推导 原先ResNet的残差单元: yl=h(xl)+F(xl,Wl),xl+1=f(yl).\\begin{gathered}\\mathbf{y}_l=h\\left(\\mathbf{x}_l\\right)+\\mathcal{F}\\left(\\mathbf{x}_l, \\mathcal{W}_l\\right), \\mathbf{x}_{l+1}=f\\left(\\mathbf{y}_l\\right) .\\end{gathered}yl​=h(xl​)+F(xl​,Wl​),xl+1​=f(yl​).​, 其中hhh是恒等映射,h(xl)=xlh(x_l)=x_lh(xl​)=xl​ 若函数fff也是恒等映射, 则xl+1=xl+F(xl,Wl)x_{l+1} = x_l+\\mathcal{F}\\left(\\mathbf{x}_l, \\mathcal{W}_l\\right)xl+1​=xl​+F(xl​,Wl​), 任意深层的单元LLL与浅层单元lll之间的关系, xL=xl+∑i=lL−1F(xi,Wi)x_{L} = x_l+\\sum_{i=l}^{L-1} \\mathcal{F}\\left(\\mathbf{x}_i, \\mathcal{W}_i\\right)xL​=xl​+∑i=lL−1​F(xi​,Wi​) 深层单元的特征可以由浅层单元的特征和残差函数相加得到; 任意深度单元的特征可以由起始特征与先前的残差函数相加得到(残差网络是相加, 普通网络是连乘) 反向传播: ∂E∂xl=∂E∂xL∂xL∂xl=∂E∂xL(1+∂∂xl∑i=lL−1F(xi,Wi))\\frac{\\partial \\mathcal{E}}{\\partial \\mathbf{x}_l}=\\frac{\\partial \\mathcal{E}}{\\partial \\mathbf{x}_L} \\frac{\\partial \\mathbf{x}_L}{\\partial \\mathbf{x}_l}=\\frac{\\partial \\mathcal{E}}{\\partial \\mathbf{x}_L}\\left(1+\\frac{\\partial}{\\partial \\mathbf{x}_l} \\sum_{i=l}^{L-1} \\mathcal{F}\\left(\\mathbf{x}_i, \\mathcal{W}_i\\right)\\right)∂xl​∂E​=∂xL​∂E​∂xl​∂xL​​=∂xL​∂E​(1+∂xl​∂​∑i=lL−1​F(xi​,Wi​)) 反向传播也是两条路径, 其中之一将信息回传, 另一条经过所有的权重层,且回传的梯度不会消失 若h(xl)=λlxlh(x_l)=\\lambda_l x_lh(xl​)=λl​xl​, 反向传播时∂E∂xl=∂E∂xL((∏i=lL−1λi)+∂∂xl∑i=lL−1F^(xi,Wi))\\frac{\\partial \\mathcal{E}}{\\partial \\mathbf{x}_l}=\\frac{\\partial \\mathcal{E}}{\\partial \\mathbf{x}_L}\\left(\\left(\\prod_{i=l}^{L-1} \\lambda_i\\right)+\\frac{\\partial}{\\partial \\mathbf{x}_l} \\sum_{i=l}^{L-1} \\hat{\\mathcal{F}}\\left(\\mathbf{x}_i, \\mathcal{W}_i\\right)\\right)∂xl​∂E​=∂xL​∂E​((∏i=lL−1​λi​)+∂xl​∂​∑i=lL−1​F^(xi​,Wi​)), 若λ&gt;1\\lambda&gt;1λ&gt;1, 则这一项指数级增大, 若λ&lt;1\\lambda&lt;1λ&lt;1, 则这一项很小甚至消失, 阻断反向传播 文章中的实验分析 激活函数的使用 BN在addition之后: 较基准差, BN在相加之后阻碍信号传播, 训练初期误差下降缓慢 ReLU在addition之前: 输出保持非负, 影响模型表示能力 后激活(post-activation) RuLU-only pre-activation full pre-activation: 效果最好 使用预激活的优点 fff变成恒等映射, 网络更易优化 使用BN作为预激活可以加强模型正则化, 减小过拟合 DenseNet 目的: 建立前面所有层与后层的密集连接, 让网络的每一层都直接与前面层相连, 实现特征的重复利用; 同时把网络的每一层设计特别窄(特征图/滤波器数量少), 即只学习非常少的特征图(最极端情况就是每一层只学习一个特征图), 达到降低冗余性 网络结构: DenseNet模型主要是由DenseBlock(密集块)组成, 密集块中每一层都将前面层concate后作为输入, xl=Hl([x0,x1,...,xl−1])x_l=H_l([x_0, x_1, ..., x_{l-1}])xl​=Hl​([x0​,x1​,...,xl−1​]) 在DenseBlock中, 每个网络层的特征图大小是一样的. Hl(⋅)H_l(\\cdot)Hl​(⋅)是非线性转化函数, 由BN, ReLU, Conv组成 在DenseBlock中, 参数k为网络的增长率, 表示任何一个3×33 \\times 33×3卷积层的滤波器个数(输出通道数), 若每个Hl(⋅)H_l(\\cdot)Hl​(⋅)函数都输出kkk个特征图, 第lll层的输入特征图数量为k0+k×(l−1)k_0+k \\times (l-1)k0​+k×(l−1), k0k_0k0​是DenseBlock的输入特征图数量 在DenseBlock中, 为保持卷积层的feature map大小一致, 在两个DenseBlock中间插入transition层(其由BN + ReLU + 1*1 Conv + 2*2 Avgpooling) CNN网络一般通过Pooling层或Stride &gt; 1的卷积层来降低特征图大小 优点 省参数: DenseNet所需的参数量和计算量都不及ResNet的一半 省计算量: 工业界而言, 小模型可以显著节省带宽, 降低存储开销(参数量小的模型计算量肯定也小) 抗过拟合: 神经网络每一层提取的特征都相当于对输入数据进行非线性变换, 随着网络加深, 变换的复杂度逐渐增加(更多非线性函数的复合); 相比于一般神经网络的分类器直接依赖于网络最后一层(复杂度最高)的特征, DenseNet可以综合利用浅层复杂度低的特征, 因而更容易得到一个光滑的具有更好泛化性能的决策函数 缺点: 密集连接会导致中间层的很多特征冗余 DenseNet中去掉中间层的密集连接, 只有最后一层聚合前面所有层的特征, 结果表明最后一层的连接强度变得更好 CSPNet MobileNetv1/v2/v3和ShuffleNetv1/v2为移动端(CPU)设计的轻量级网络采用**深度可分离卷积技术(基础技术)**并不适用于 NPU 芯片 目的: 优化DenseNet中梯度信息重复, 通过将梯度的变化从头到尾地集成到特征图中, 在减少计算量的同时保证准确率. 可以减小模型计算量, 提高运算速度, 还不降低模型精度. CSPNet解决的三个问题: 增强CNN的学习能力, 能够在轻量化的同时保持准确性 降低计算瓶颈和DenseNet的梯度信息重复 降低内存成本 原理 DenseNet中大量的梯度信息被重用来更新不同密集层的权值, 导致无差异的密集层反复学习复制的梯度信息 CSPNet利用跨阶段特征融合策略和截断梯度流来增强不同层间学习特征的可变性 EFM结构结合Maxout操作来压缩从特征金字塔生成的特征映射, 大大降低了所需的内存带宽, 推理的效率可以与边缘计算设备兼容 跨级部分密集网: CSPDenseNet的一阶段由局部密集块和局部过渡层组成, 保留了DenseNet重用特征特性的优点, 但同时通过截断梯度流防止了过多的重复梯度信息, 设计了一种分层的特征融合策略实现并应用于局部过渡层 局部密集块: 增加梯度路径: 通过分块归并策略, 可以使梯度路径的数量增加一倍. 利用跨阶段策略, 可以减轻使用显式特征图copy进行拼接带来的弊端 每一层的平衡计算: 通常DenseNet基层的通道数远大于生长速率; 由于在局部稠密块中,参与密集层操作的基础层通道仅占原始数据的一半,可以有效解决近一半的计算瓶颈 减少内存流量 局部过渡层: 使梯度组合的差异最大 是一种层次化的特征融合机制, 利用梯度流的聚合策略来防止不同的层学习重复的梯度信息 局部过渡层说明: Transition layer的含义和DenseNet类似, 是一个1x1的卷积层(没有再使用average pool), Transition layer的位置决定了梯度的结构方式 c图: Fusion First先将两个部分进行concate然后输入到Transition中, 采用这种做法会使大量的梯度信息被重用, 有利于网络学习 d图: Fusion Last先将部分特征输入Transition然后进行concate, 采用这种做法会使梯度信息被截断, 损失了部分的梯度复用, 但由于Transition输入维度少, 大大减少计算复杂度 b图: CSPNet采用的, 结合了c图和d图特点, 提升了学习能力的同时也提高计算复杂度 Two-stage RCNN 将CNN方法引入目标检测领域, 大大提高了目标检测效果 基本流程: 候选框生成: 一张图像采用选择性搜索方法生成1K~2K个候选区域 特征提取: 对每个候选区域, 使用CNN网络提取特征 类别判断: 特征送入每一类的SVM分类器判别是否属于该类 位置精修: 使用回归其精细修正候选框位置 测试过程: 候选框生成: 采用选择性搜索方法提取2K个候选框 在每个候选框周围加上16个像素值为候选框像素平均值的边框, 在各向异性变换成277*277大小 将所有候选框像素值减该候选框像素平均值后(预处理), 将其送入AlexNet中获取4096维特征, 将2000个候选框组合成2000*4096维矩阵 将2000*4096维矩阵与20个SVM组成的权值矩阵相乘获得2000*20维矩阵表示每个建议框使某个物体类别的得分 分别对上述2000*20维矩阵每一类进行非极大值抑制剔除重叠建议框, 得到该类中得分最高的一些建议框 分别用20个回归器对上述20个类别中剩余的建议框进行回归操作, 最终得到每个类别的修正后得分最高的BBox 基础知识 重叠率(IOU): 定义了BBox的重叠率 非极大值抑制(NMS): 从最大概率的矩形框开始, 分别判断各个预测框与该矩形框的IOU是否大于某个设定的阈值 若大于阈值则舍弃该矩形框, 并标记第一个矩形框为保留下来的矩形框 从剩下的矩形框中选择概率最大的矩形框, 重复上述判断直至找到所有被保留下的矩形框 流程中各个阶段详解 选择性搜索: 需要将不同大小的候选区域处理成相同的大小 各向异性缩放: 不管图像的长宽比例直接缩放(实验效果好) 各向同性缩放 位置精修: 使用回归器进行位置精修 Pi=(Pxi,Pyi,Pwi,Phi)P^i=(P_x^i, P_y^i, P_w^i, P_h^i)Pi=(Pxi​,Pyi​,Pwi​,Phi​)表示Region Proposal, Gi=(Gxi,Gyi,Gwi,Ghi)G^i=(G_x^i, G_y^i, G_w^i, G_h^i)Gi=(Gxi​,Gyi​,Gwi​,Ghi​)表示Ground Truth, G^i=(G^xi,G^yi,G^wi,G^hi)\\hat{G}^i=(\\hat{G}_x^i, \\hat{G}_y^i, \\hat{G}_w^i, \\hat{G}_h^i)G^i=(G^xi​,G^yi​,G^wi​,G^hi​)表示Region Proposal经过回归后的预测框, 为找到PPP到G^\\hat{G}G^的线性变换, 使得G^\\hat{G}G^与GGG相近, 该问题为线性回归问题, 可使用最小二乘法进行解决 G^x=Pwdx(P)+Px,G^y=Phdy(P)+Py,G^w=Pwexp(dw(P)),G^h=Phexp(dh(P))\\hat{G}_x=P_w d_x(P)+P_x, \\hat{G}_y=P_h d_y(P)+P_y, \\hat{G}_w=P_w exp(d_w(P)), \\hat{G}_h=P_h exp(d_h(P))G^x​=Pw​dx​(P)+Px​,G^y​=Ph​dy​(P)+Py​,G^w​=Pw​exp(dw​(P)),G^h​=Ph​exp(dh​(P)), 其中d∗(P)=w∗Tϕ5(P)d_*(P)=w_*^T \\phi_5(P)d∗​(P)=w∗T​ϕ5​(P)为CNN输出特征的线性函数, w∗Tw_*^Tw∗T​为需要学习的回归参数, d∗(P)d_*(P)d∗​(P)为训练目标 损失函数为Loss=argmin∑i=0N(t∗i−w^∗Tϕ5(Pi))2+λ∣∣w^∗∣∣2Loss=argmin \\sum_{i=0}^N (t_*^i - \\hat{w}_*^T \\phi_5(P^i))^2 + \\lambda|| \\hat{w}_*||^2Loss=argmin∑i=0N​(t∗i​−w^∗T​ϕ5​(Pi))2+λ∣∣w^∗​∣∣2, 正则项λ∣∣w^∗∣∣2\\lambda|| \\hat{w}_*||^2λ∣∣w^∗​∣∣2为防止回归参数过大 而回归目标为tx=(Gx−Px)/pw,ty=(Gy−Py)/ph,tw=log(GwPw),th=log(GhPh)t_x=(G_x-P_x)/p_w, t_y=(G_y-P_y)/p_h, t_w=log(\\frac{G_w}{P_w}), t_h=log(\\frac{G_h}{P_h})tx​=(Gx​−Px​)/pw​,ty​=(Gy​−Py​)/ph​,tw​=log(Pw​Gw​​),th​=log(Ph​Gh​​) 训练过程: 首先使用Alexnet模型进行训练, 随后利用选择性搜索得到的候选框对模型进行fine-tuning训练, 随后训练SVM finetune中正负样本划分: ground truth和与ground truth的IOU大于0.5的BBox为正样本, 否则为背景类别(负样本) SVM中正负样本划分: ground truth为正样本, 与ground truth的IOU小于0.3的为负样本 位置回归中正负样本划分: 与Ground Truth相交, IoU最大且&gt;0.6的Region Proposal 问题总结: 进行finetune的必要性: 针对特定任务进行finetune可以使CNN更加针对特定的任务, 不仅仅知识得到共性特征 为什么finetune和SVM时采用的正负样本阈值不一致 微调阶段CNN对小样本容易过拟合, 需要大量训练数据, 故IOU限制较为宽松,为0.5 SVM适合小样本训练, 因此对IOU限制严格; GroundTruth为正样本, 与其IOU&lt;0.3的建议框为负样本 为什么不采用finetune后的AlexNet最后一层Softmax进行21分类 微调时和训练SVM时正负样本阈值不同, 导致最后采用CNN softmax输出比SVM精度低, 因此最后选用SVM进行21分类 SPPNet 解决的问题:卷积神经网络的全连接层需要固定的输入, 而候选区域存在尺寸差异; 将不同候选区域依次输入卷积神经网络中进行特征提取存在大量冗余计算 解决方法 SPPNet采用选择性搜索获取候选区域, 将整张图像送入网络获取特征图随后再特征图上获取候选区域的特征 空间金字塔池化: 将任意大小的特征图划分成若干数量的子块, 随后对这些子块计算最大池化, 将计算结果进行拼接得到固定大小的输出 论文中使用3个分支, 将特征图划分为1*1, 2*2,4*4子块, 对每个子块进行最大池化, 随后将其进行拼接成21维的输出 Fast-RCNN 解决的问题:RCNN和SPPNet需要多步训练, 步骤繁琐; 时间和内存消耗较大; 测试时较慢 Fast RCNN优点: 高精度检测, 单步训练, multi-loss 训练可以更新所有网络层, 且内存不需要太大 网络架构 网络具有两个输入, 图像和对应已框出来的Region Proposal, 其中Region Proposal是由选择性搜索方法得到, 对每个类别都训练一个回归其, 且只有非背景Region Proposal才需要进行回归 与SPPNet相似, 将整张图像作为CNN输入, 将选择性搜索得到的候选框映射到特征图上, 以此减少计算量 使用ROI池化层解决候选框大小不一的问题, 将其转换为相同的大小 使用卷积神经网络输出分类和预测框的位置大小, 不采用SVM分类器和回归器 为提高速度使用SVD代替全连接层 预测流程 使用选择性搜索获取候选框 将原始图像送入网络中得到特征图(最后一次池化前的卷积计算结果) 对每个建议框, 从特征图中找到对应位置, 截取出特征框 将特征框划分为H*W(7*7)个网格进行池化(ROI池化) 将矩阵拉成一个向量分别作为全连接层的输入 全连接层输出分类得分和BBox回归(20*4矩阵) 对输出结果使用NMS选出结果 训练流程 使用VGG16对模型进行改进, 将最后的池化层换成ROI池化层; 将最后一个全连接层和softmax分类器换成两个并行层用于输出分类得分和坐标回归; 双输入, 将图像和建议框信息输入 损失函数: 损失函数包括分类损失和位置损失:L(p,u,tu,v)=Lcls(p,u)+1[u≥1]Lbox(tu,v)\\mathcal{L}\\left(p, u, t^u, v\\right)=\\mathcal{L}_{\\mathrm{cls}}(p, u)+1[u \\geq 1] \\mathcal{L}_{\\mathrm{box}}\\left(t^u, v\\right)L(p,u,tu,v)=Lcls​(p,u)+1[u≥1]Lbox​(tu,v) 分类损失使用log损失: Lcls(p,u)=−log⁡pu\\mathcal{L}_{\\mathrm{cls}}(p, u)=-\\log p_uLcls​(p,u)=−logpu​ 回归损失使用smooth_L1损失, 与RCNN相似: Lbox(tu,v)=∑i∈{x,y,w,h}L1smooth (tiu−vi)\\mathcal{L}_{\\mathrm{box}}\\left(t^u, v\\right)=\\sum_{i \\in\\{x, y, w, h\\}} L_1^{\\text {smooth }}\\left(t_i^u-v_i\\right)Lbox​(tu,v)=∑i∈{x,y,w,h}​L1smooth ​(tiu​−vi​) L1smooth (x)={0.5x2 if ∣x∣&lt;1∣x∣−0.5 otherwise L_1^{\\text {smooth }}(x)= \\begin{cases}0.5 x^2 &amp; \\text { if }|x|&lt;1 \\\\ |x|-0.5 &amp; \\text { otherwise }\\end{cases}L1smooth ​(x)={0.5x2∣x∣−0.5​ if ∣x∣&lt;1 otherwise ​ Faster-RCNN 流程: 首先将图像缩放至固定大小后送入网络; 利用卷积神经网络得到特征图后, 在RPN网络中首先经过3*3卷积, 再分别产生positive anchors和对应BBox regression偏移量, 计算出proposals; 利用ROI Pooling从feature maps中提取proposal feature送入后续全连接和softmax网络做分类 网络结构详解 backbone: 使用VGG16等网络进行特征提取, 卷积层设置padding1, stride1(经卷积后大小不变), 只在池化层使输出长宽为输入的一半 RPN(Pegion Proposal Networks): 在feature maps上利用3*3卷积转换语义空间, 随后利用两个1*1卷积进行二分类和位置回归; 因此分为两条线,一条使用softmax分类anchor获得positive和negative; (卷积核的通道数9*2).第二条计算对于anchors的BBox regression偏移量获得proposals, 同时剔除太小和超出边界的proposals(卷积核的通道数9*4) 重点过程分析 Anchors生成: 在特征图的每一个像素点上生成9个(3种形状, 长宽比不同)矩形框, 每一个像素点对应原图上一个16*16大小(bakcbone下采样16倍)的区域; Softmax判定positive与negative: 由1*1卷积实现, 通道数为9*2(每个点9个anchor, 每个anchor二分类), 随后利用softmax分类获取positive anchors(有目标), 也就相当于初步提取了检测目标候选区域, 总共选取正负样本比1:1的256个anchor BBox Regression原理: 沿用RCNN的方法 Proposal Layer原理: 负责综合所有的BBox regression偏移量和positive anchors计算出精确的proposal, 其输入包含分类结果, BBox regression偏移量和im_info=[M, N, scale_fator](保留缩放的信息), 具体步骤如下 生成anchors, 利用BBox regression偏移量对所有anchors做回归 按照positive softmax scores对修正后的anchors进行排序, 提取前pre_nms_top 12000个anchors 限定超出图像边界的anchor为图像边界, 防止后续roi pooling时超出图像边界 剔除尺寸非常小的positive anchors 对剩下的positive anchors进行NMS选出概率大的2000个ROIS 输出proposal box()(这里是对应原图输入尺寸) 注：在推理时为加快速度12000和2000分别变为6000和300 ROI Head: ROI Head在给出的2000个候选框上继续进行分类和位置参数的回归, 包括ROI Pooling和Classification(全连接分类两部分); 首先挑选除128个sample_roi, 使用ROI Pooling将不同尺寸的区域池化到同一尺寸7*7, 随后送至后续的两个全连接层(FC21(20个类+背景), FC84(21个类, 每个类4个位置参数))分别完成类别分类和BBox回归 设定7*7的原因: 为了可以共享VGG后面两个全连接的权重, 512*7*7=4096, 可以利用VGG16预训练权重来初始化前两层全连接层 ROI Pooling: ROI Pooling 两次量化过程 proposals是对应M*N的原图尺寸,在原图上生成的region proposal需要映射到 feature map上(坐标值缩小 16 倍),需要除以16/32(下采样倍数), 边界会出现小数, 自然就需要量化 将proposals对应的 feature map 区域水平划分成k×kk\\times kk×k(7×77\\times 77×7)的 bins, 并对每个bin中均匀选取多少个采样点, 然后进行max pooling,也会出现小数,自然就产生了第二次量化 训练过程: 对RPN生成的2000个RoIs, 选出128个(正负比3:1)进行分类和位置参数回归. IoU&gt;0.5内选32个作为正样本, IoU&lt;=0或0.1内选96个作为负样本 测试过程: 对RPN生成的300个RoIs计算概率, 利用位置参数调节预测框位置, 随后使用NMS进行处理 注意点 两次NMS操作, RPN中使用一次, 测试时在ROI Head中使用一次 两次位置回归, RPN中使用一次, 测试时在ROI Head中再回归一次 RPN时为二分类, 在ROI Head中为21分类 四个损失: RPN 分类损失：anchor 是否为前景(二分类) RPN 位置回归损失：anchor 位置微调 RoI 分类损失：RoI 所属类别(21 分类,多了一个类作为背景) RoI 位置回归损失：继续对 RoI 位置微调 FPN 低层的特征语义信息比较少, 但目标位置准确; 高层的特征语义信息比较丰富, 但目标位置粗略; 大多数的算法采用多尺度特征融合方式, 但一般采用融合后的特征进行预测, 而本方法在不同特征层独立进行预测 特征金字塔网络(FPN): 包含自底向上和自顶向下的线路以及横向连接 自底向上: 卷积神经网络的前向过程, feature map经过某些层后大小发生变化 自顶向下: 采用上采样(最邻近插值)进行, 好处是即利用顶层较强的语义信息, 又利用率底层的高分辨率信息 横向连接: 将上采样的结果和自底向上生成的相同大小的feature map进行融合; 融合之后使用3*3卷积核进行卷积以消除混叠效应. 为修正通道数, 会使用1*1卷积进行调整 可以将高层的语义信息逐渐传播到低层 结合Faster-RCNN 由于此时RPN的输入为多尺度的输入, 因此不需要设置不同尺寸大小的anchor, 仅需要设置3种不同的宽高比即可 不同尺度的RoIs使用不同特征图作为RoI Pooling的输入, 为每个RoIs提取特征之后使用RoI Pooling输出相同结果 Mask-RCNN 在Faster-RCNN (FPN)基础上进行改进 ROI Pooling改成ROI Align 在RPN之后增加卷积分支以实现mask分割 ROI Align: 更加精准的RoI Pooling 在Faster RCNN中由于两次量化操作会影响精度, ROI Align采用双线性插值的方式解决该问题 取消取整操作, 保留小数 首先将ROI切分成N∗NN*NN∗N的单元格, 将每个单元格均匀分成4份, 每个小方格是一个采样点, 使用双线性插值计算出该采样点的像素值. 最终在每个单元格内进行maxpooling, 最终可以得到N∗NN*NN∗N维的结果 损失函数: L=Lcls+Lbox+LmaskL=L_{cls}+L_{box}+L_{mask}L=Lcls​+Lbox​+Lmask​ 其中分类损失和位置损失与Faster RCNN一致 分割的LmaskL_{mask}Lmask​ 假定共有k个类别, mask分割分支输出的维度是K∗m∗mK*m*mK∗m∗m, 对于m∗mm*mm∗m中的每个点, 都会输出kkk个二值Mask 计算损失时, 该像素属于哪个类, 哪个类的sigmoid输出才需要计算损失(可以避免类间竞争, 提升性能) 在推理时, 通过分类分支预测的类别选择对应的mask预测(mask预测与分类预测解耦) Cascade-RCNN IoU阈值被用来定义正负样本 阈值过低, 学习大量背景框, 产生大量噪声预测 阈值过高, 正样本数量减少, 容易产生过拟合; 解决mismatch问题: 训练时, 由于知道Ground Truth, 可以较自然地将IoU&gt;0.5的划分为正样本; 而推理时, 不知道Ground Truth, 只能将所有的proposal作为正样本; 因此BBox回归器的输入分布不一致, 训练阶段的proposal质量更高, 推理阶段的proposal质量较差 途径: 多阶段方法, 利用多个感知器通过递增的IOU阈值分级训练(一个感知器输出一个良好的数据分布作为输入训练下一个高质量感知器) 其中三个stage的IOU阈值分别为0.5, 0.6, 0.7 One-stage YOLO 核心思想: 利用深度学习的回归方法预测物体位置和物体类别 预测阶段(推理): 将输入图像分为S∗SS*SS∗S个网格grid cell, 如果某个物体的中心落在这个网格中, 这个网格就负责预测这个物体 每个网格需要预测B个BBox的位置信息(x,y,w,h)和置信度信息confidence. 其中x,y是BBox的中心点位置, w,h是BBox的宽高; 每个置信度包含两个方面, 一是该边界框含有目标的可能性大小Pr(object)Pr(object)Pr(object), 二是该边界框的置信度, 用预测框和实际框的IOU表示,记作IOUpredtruthIOU_{pred}^{truth}IOUpredtruth​. 因此confidence=Pr(object)∗IOUpredtruthconfidence = Pr(object) * IOU_{pred}^{truth}confidence=Pr(object)∗IOUpredtruth​ 中心坐标的预测值(x,y)是相对于每个单元格左上角坐标点的偏移量 对于具有C个类别, 输出的维度为S∗S∗(5∗B+C)S*S*(5*B+C)S∗S∗(5∗B+C), C表示由该单元格负责预测的两个边界框中属于各个类别的概率Pr(classi∣object)Pr(class_i | object)Pr(classi​∣object), 因此每个BBox的类别置信度为Pr(classi∣object)∗confidencePr(class_i | object) * confidencePr(classi​∣object)∗confidence 在得到每个BBox的类别置信度后, 设置阈值过滤掉的得分低的BBox, 对剩下的BBox使用NMS处理得到最终结果 训练过程 输入图像为448*448, S=7,B=2,C=20, 输出为7*7*30维张量, 对于每一个单元格, 前20个元素是类别概率, 然后2个元素是边界框置信度, 相乘可以得到类别置信度. 最后8个元素是边界框的(x,y,w,h) 7*7网格, 共98个边界框, 2个框对应一个类别, 因此单张图片最多预测49个目标 损失函数: YOLO算法将检测问题看作回归问题, 选用了容易优化的均方根误差作为损失函数 为了平衡定位误差和分类误差, 引入λcoord=5\\lambda_{coord}=5λcoord​=5来使定位误差具有较大的权重, 可以使含有目标的边界框具有较大的权重, λnoobj=0.5\\lambda_{noobj}=0.5λnoobj​=0.5使不包含目标的边界框具有较小的权重 对于大小不同的边界框, 小边界框的坐标误差更加敏感, 因此将网络的边界框的宽高预测改为对其平方根的预测(x,y,w,h)(x,y,\\sqrt{w},\\sqrt{h})(x,y,w​,h​) 总体损失函数: λcoord ∑i=0S2∑j=0B1ijobj [(xi−x^i)2+(yi−y^i)2]+λcoord ∑i=0S2∑j=0B1ijobj [(wi−w^i)2+(hi−h^i)2]+∑i=0S2∑j=0B1ijobj (Ci−C^i)2+λnoobj ∑i=0S2∑j=0B1ijnoobj (Ci−C^i)2+∑i=0S21iobj ∑c∈ classes (pi(c)−p^i(c))2\\begin{aligned} &amp; \\lambda_{\\text {coord }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_i-\\hat{x}_i\\right)^2+\\left(y_i-\\hat{y}_i\\right)^2\\right] \\\\ &amp;+\\lambda_{\\text {coord }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }} {\\left[\\left(\\sqrt{w_i}-\\sqrt{\\hat{w}_i}\\right)^2+\\left(\\sqrt{h_i}-\\sqrt{\\hat{h}_i}\\right)^2\\right] } \\\\ &amp;+ \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_i-\\hat{C}_i\\right)^2 \\\\ &amp;+\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_i-\\hat{C}_i\\right)^2 \\\\ &amp;+\\sum_{i=0}^{S^2} \\mathbb{1}_i^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_i(c)-\\hat{p}_i(c)\\right)^2\\end{aligned}​λcoord ​i=0∑S2​j=0∑B​1ijobj ​[(xi​−x^i​)2+(yi​−y^​i​)2]+λcoord ​i=0∑S2​j=0∑B​1ijobj ​[(wi​​−w^i​​)2+(hi​​−h^i​​)2]+i=0∑S2​j=0∑B​1ijobj ​(Ci​−C^i​)2+λnoobj ​i=0∑S2​j=0∑B​1ijnoobj ​(Ci​−C^i​)2+i=0∑S2​1iobj ​c∈ classes ∑​(pi​(c)−p^​i​(c))2​ IijobjI_{ij}^{obj}Iijobj​ 指的是第 iii 个单元格存在目标, 且该单元格中的第 jjj 个边界框负责预测该目标. IiobjI_{i}^{obj}Iiobj​ 指的是第 iii 个单元格存在目标. 前2行计算前景的geo_loss(定位loss) 第3行计算前景的confidence_loss(包含目标的边界框的置信度误差项) 第4行计算背景的confidence_loss 第5行计算分类损失class_loss 值得注意的是,对于不存在对应目标的边界框,其误差项就是只有置信度,坐标项误差是没法计算的.而只有当一个单元格内确实存在目标时,才计算分类误差项,否则该项也是无法计算的 YOLOv2 YOLOv1的缺点: 每个grid预测两个框, 但是只能对应一个目标, 对于同一个grid有两个目标的情况下, YOLOv1检测补全, 且模型最多检测7*7=49个目标, 查全率Recall较低 预测框不够准确, 回归(x,y,w,h)的方法不够精准, 模型精确率低 回归参数网络使用全连接层参数量太大, 模型检测头不够快 改进方法 添加BN层: 卷积层的组成从原先的线性卷积与激活函数组合改进为卷积三件套 新的backbone: 使用Darknet-19, 该网络与VGG相似, 使用3*3卷积, 并且在每个2*2池化操作之后通道数加倍 全卷积网络结构: 将YOLOv1最后的一个池化层和全部的全连接层修改为卷积层, 虽然mAP有所下降, 但召回率有所上升 中心坐标预测的改进: 参考两阶段网络anchor boxes来预测边界框相对先验框的偏移, 同时用YOLOv1的方法预测边界框中心相对于grid左上角的相对偏移量 各个字母的含义： bx,by,bw,bhb_x,b_y,b_w,b_hbx​,by​,bw​,bh​ ：模型预测结果转化为 box 中心坐标和宽高后的值(归一化之后的值) tx,ty,tw,tht_x,t_y,t_w,t_htx​,ty​,tw​,th​ ：模型要预测的偏移量 cx,cyc_x,c_ycx​,cy​ ：grid 的左上角坐标 pw,php_w,p_hpw​,ph​ ：anchor 的宽和高，这里的 anchor 是人为定好的一个框，宽和高是固定的 location prediction: 利用上述定义, 可以从直接预测位置改为预测偏移量, 即基于anchor的宽高和grid的先验位置偏移, 位置上使用grid, 宽高上使用anchor框, 得到最终目标的位置 预测偏移而不直接预测位置, 可以使神经网络训练时更加稳定, 性能提升5% 使用σ\\sigmaσ函数可以将边界框的中心坐标限制在grid内部, 防止偏移过多 在解码过程中, 使用边界框的偏移量(tx,ty,tw,th)(t_x,t_y,t_w,t_h)(tx​,ty​,tw​,th​)可计算出边界框的位置和大小 在模型推理的时候，还需将对应的值乘以图片的宽度和长度(像素点值)才可得到边界框的实际中心坐标和大小 一个grid只能对应一个目标的改进 将7*7区域改为13*13, 每个区域内5个anchor, 且每个anchor对应一个类别. 因此输出的尺寸为[N, 13, 13, 125], 125=5*(5+20) YOLOv11个grid只能预测一个目标的分类概率, 两个boxes共享这个置信度概率; YOLOv2每个grid的每个anchor都单独预测一个目标的分类概率值 每个grid取5个anchor使因为k-means聚类实验后, 当k=5时, 模型mAP与复杂度可以较好的平衡 聚类分析时, 选用box与聚类中心box之间的IOU作为距离指标d(box, centroid)=1-IOU(box, centroid) 与Faster RCNN的不同: 利用数据集聚类统计得到anchor, 而不是手动设置anchor的大小和宽高 多尺度训练: 增加鲁棒性 在训练过程中每间隔一定的iterations之后改变模型输入图片的大小 由于YOLOv2下采样总步长为32, 输入图像大小选择为32倍数的值&#123;320, 352,...,608&#125;, 在训练过程中每隔10个iterations随机选择一种输入图像大小 损失函数 loss⁡t=∑i=0W∑j=0H∑k=0A1Max IOU &lt; Thresh λnoobj ∗(−bijko)2+1t&lt;12800λprior ∗∑r∈(x,y,w,h)( prior kr−bijkr)2+1ktruth (λcoord ∗∑r∈(x,y,w,h)( truth r−bijkr)2+λobj ∗(IOUtruth k−bijko)2+λclass ∗(∑c=1c(truthc−bijkc)2))\\begin{aligned} \\operatorname{loss}_t=\\sum_{i=0}^W \\sum_{j=0}^H \\sum_{k=0}^A &amp; 1_{\\text {Max IOU }&lt;\\text { Thresh }} \\lambda_{\\text {noobj }} *\\left(-b_{i j k}^o\\right)^2 \\\\ + &amp; 1_{t&lt;12800} \\lambda_{\\text {prior }} * \\sum_{r \\in(x, y, w, h)}\\left(\\text { prior }_k^r-b_{i j k}^r\\right)^2 \\\\ +1_k^{\\text {truth }}\\left(\\lambda_{\\text {coord }} *\\right. &amp; \\sum_{r \\in(x, y, w, h)}\\left(\\text { truth }^r-b_{i j k}^r\\right)^2 \\\\ &amp; +\\lambda_{\\text {obj }} *\\left(I O U_{\\text {truth }}^k-b_{i j k}^o\\right)^2 \\\\ &amp; \\left.+\\lambda_{\\text {class }} *\\left(\\sum_{c=1}^c\\left(t r u t h^c-b_{i j k}^c\\right)^2\\right)\\right)\\end{aligned}losst​=i=0∑W​j=0∑H​k=0∑A​++1ktruth ​(λcoord ​∗​1Max IOU &lt; Thresh ​λnoobj ​∗(−bijko​)21t&lt;12800​λprior ​∗r∈(x,y,w,h)∑​( prior kr​−bijkr​)2r∈(x,y,w,h)∑​( truth r−bijkr​)2+λobj ​∗(IOUtruth k​−bijko​)2+λclass ​∗(c=1∑c​(truthc−bijkc​)2))​ 第 2,3 行：ttt 是迭代次数，即前 12800 步我们计算这个损失，后面不计算了 前12800步优化预测的(x,y,w,h)(x,y,w,h)(x,y,w,h)与anchor的(x,y,w,h)(x,y,w,h)(x,y,w,h)的距离+预测的(x,y,w,h)(x,y,w,h)(x,y,w,h)与GT的(x,y,w,h)(x,y,w,h)(x,y,w,h)的距离, 12800步之后就只优化预测的(x,y,w,h)(x,y,w,h)(x,y,w,h)与GT的(x,y,w,h)(x,y,w,h)(x,y,w,h)的距离, 原因是这时的预测结果已经较为准确了, anchor已经满足检测系统的需要, 而在一开始预测不准的时候, 用上anchor可以加速训练 使用passthrough技术将融合特征 YOLOv3 改进总结: 结合前人的工作, 同时训练了一个更好的分类器网络 改进方法 新的backbone 使用Darknet53, 引入残差模块, 使用53个卷积层; 使用平均池化替换最大池化, 较少信息损失; 总体卷积核个数减少, 模型参数减小 引入特征金字塔网络(FPN)与多级检测 浅层网络负责检测较小的目标, 深度网络负责检测较大的目标 YOLOv3在3个尺度上进行预测, 分别在经过8倍降采样的特征图, 16倍降采样的特征图, 32倍降采样的特征图上进行多级检测 边界框预测: 更加细致, 阈值的取值有所改进 使用逻辑回归预测每个边界框是否存在检测目标.如果边界框先前与真实目标重叠超过任何其他边界框, 则该值为1. 如果候选的边界框不是最好的但是与真实目标重叠超过某个阈值(0.5)则忽略预测 与Faster-RCNN不同, 只为每个真实目标分配一个边界框, 若先前的边界框未分配给真实目标, 则不会导致坐标或类预测的损失, 只会导致是否存在目标的损失 类别预测 不适用softmax, 而只是使用独立logistic分类器. 在训练期间, 使用二元交叉熵损失进行类别预测 对复杂场景有帮助, 具有较多重叠标签时, softmax输出只有一个类, 多标签的方法可以更好的拟合数据 损失函数 YOLOv3使用多标签分类, 用多个独立的logistic分类器代替softmax函数以计算输入属于特定标签的可能性 计算分类损失时, 对每个类别使用二元交叉熵损失 正负样本确定 正样本：与GT的IOU最大的框 负样本：与GT的IOU&lt;0.5的框 忽略的样本：与GT的IOU&gt;0.5但不是最大的框 使用 txt_xtx​和tyt_yty​(不是bxb_xbx​和byb_yby​)来计算损失 注意：每个GT目标仅与一个先验边界框相关联. 如果没有分配先验边界框, 则不会导致分类和定位损失, 只会有目标的置信度损失 RetinaNet 目的: 为了解决one-stage算法中正负样本比例严重失衡的问题 网络结构特征 Neck部分采用FPN结构 Head部分分为两路, 一路为分类预测, 一路为BBox预测, 但Head采用共享权重, 可以较好的控制参数量 在4次通道数256的1*1卷积后, channel数分别为anchor数*类别数和anchor数* 4 与YOLOv3和RCNN系列结构不同的是, 类别的预测没有背景预测. 在类别分支输出后只能加sigmoid(归一化)函数, 而不能加softmax函数, 当前位置所有anchor类别预测值都很小时, 预测背景 改进方法: 使用新的损失函数Focal Loss CE(pt)=−log(pt)CE(p_t)=-log(p_t)CE(pt​)=−log(pt​) FL(pt)=−(1−pt)γlog(pt),pt为预测类别的概率FL(p_t)=-(1-p_t)^\\gamma log(p_t), p_t为预测类别的概率FL(pt​)=−(1−pt​)γlog(pt​),pt​为预测类别的概率 对于确定的类别, ptp_tpt​较大, 则认为这是一个简单样本, 将其对整体loss权重降低, 因此前面乘上1−pt1-p_t1−pt​; 为了泛化公式, 可以增加一个指数函数的超参数γ\\gammaγ调节整个公式力度 Anchor-Free CornerNet 先验问题: 什么是一对关键点: 只需要预测物体包围框的左上角坐标和右下角坐标就可以完成对物体的检测 如何匹配同一物体BBox的左上角和右下角: 会为每个点分配一个embeding vector, 属于同一个物体的点的vector的距离较小 什么是corner pooling: 目的: 为了建立点corner和目标的位置关系 一般而言, 知道了bbox的左上角和bbox的右下角就可以确定目标所在的范围和区域; 若从bbox左上角看物体.横着看,物体在视线的下方.竖着看, 物体在视线的右边; 当求解一个点的top left corner pooling时, 就是以该点为起点, 水平向右看遇到的最大值以及竖直向下看遇到的最大值之和 快速实现方法: 方向进行颠倒, 每次都将沿着该方向上遇到的最大值作为填充值即可实现. 网络输出: heatmaps, embeddings, offsets heatmap表示不同类别的左上corner和右下corner的位置信息以及位置置信度信息 embedding用于衡量左上corner和右下corner的距离, 从而判断某一对角点是否属于同一物体的两个角点 offsets为heatmap被downsample至原来1/n后, 想继续upsample回去时精度损失的补偿值 embeding vector corner pooling corner pooling快速实现 网络结构 backbone: Hourglass Network, 两个沙漏模块头尾相接. 使用两个Hourglass进行堆叠以提高特征提取能力 Head: 二分支输出Top-left corners和Bottom-right corners 经过backbone之后需要各自再通过一个3*3卷积才能获得两个corners分支, 每个corners进行corner pooling操作和三分支的输出 网络整体框架图 PredictionModule结构图 将标签映射为监督信息(类似网络的输出格式): 输入图像为511*511, 输出的特征图宽高均为128*128 heatmaps的大小(batch_size, 128, 128, 80), embedding的大小(batch_size, 128, 128, 1), offsets的大小(batch_size, 128, 128, 2) heatmaps反映不同类别(80个类)左上角或右下角的角点的位置范围. 将物体bbox的一个角点映射到heatmap中对应的一个小型的圆形区域(使用高斯分布获取其邻域, 越靠近真实角点的值越大, 越远离的越小), 又称真实框角点的邻近区域(positive location) offset和embedding offset为精确映射位置与真实映射位置相减的值 embedding: 相当于将二维平面铺平成一维向量, 然后求解再二维平面上坐标为(x,y)的点在一维向量中的索引 损失函数 以输出的heatmap和监督的heatmap为输入计算focal loss: Ldet=−1N∑c=1C∑i=1H∑j=1W{(1−pcij)αlog⁡(pcij) if ycij=1(1−ycij)β(pcij)αlog⁡(1−pcij) otherwise L_{d e t}=\\frac{-1}{N} \\sum_{c=1}^C \\sum_{i=1}^H \\sum_{j=1}^W\\left\\{\\begin{array}{cc}\\left(1-p_{c i j}\\right)^\\alpha \\log \\left(p_{c i j}\\right) &amp; \\text { if } y_{c i j}=1 \\\\ \\left(1-y_{c i j}\\right)^\\beta\\left(p_{c i j}\\right)^\\alpha \\log \\left(1-p_{c i j}\\right) &amp; \\text { otherwise }\\end{array}\\right.Ldet​=N−1​∑c=1C​∑i=1H​∑j=1W​{(1−pcij​)αlog(pcij​)(1−ycij​)β(pcij​)αlog(1−pcij​)​ if ycij​=1 otherwise ​ embedding损失: 该损失用于减小同一物体bbox左上角和右下角embedding的距离, 增大不同物体bbox左上角和右下角的距离 Lpull =1N∑k=1N[(etk−ek)2+(ebk−ek)2],Lpush =1N(N−1)∑k=1N∑j=1j≠kNmax⁡(0,Δ−∣ek−ej∣),\\begin{gathered}L_{\\text {pull }}=\\frac{1}{N} \\sum_{k=1}^N\\left[\\left(e_{t_k}-e_k\\right)^2+\\left(e_{b_k}-e_k\\right)^2\\right], \\\\ L_{\\text {push }}=\\frac{1}{N(N-1)} \\sum_{k=1}^N \\sum_{\\substack{j=1 \\\\ j \\neq k}}^N \\max \\left(0, \\Delta-\\left|e_k-e_j\\right|\\right),\\end{gathered}Lpull ​=N1​k=1∑N​[(etk​​−ek​)2+(ebk​​−ek​)2],Lpush ​=N(N−1)1​k=1∑N​j=1j=k​∑N​max(0,Δ−∣ek​−ej​∣),​ 修正损失: Loff=1N∑k=1NSmoothL1Loss⁡(ok,o^k)L_{o f f}=\\frac{1}{N} \\sum_{k=1}^N \\operatorname{SmoothL1Loss}\\left(\\boldsymbol{o}_k, \\hat{\\boldsymbol{o}}_k\\right)Loff​=N1​∑k=1N​SmoothL1Loss(ok​,o^k​), ok=(xkn−⌊xkn⌋,ykn−⌊ykn⌋)\\boldsymbol{o}_k=\\left(\\frac{x_k}{n}-\\left\\lfloor\\frac{x_k}{n}\\right\\rfloor, \\frac{y_k}{n}-\\left\\lfloor\\frac{y_k}{n}\\right\\rfloor\\right)ok​=(nxk​​−⌊nxk​​⌋,nyk​​−⌊nyk​​⌋) 总的损失函数: L=Ldet+Lpull+Lpush+LoffL = L_{det}+L_{pull}+L_{push}+L_{off}L=Ldet​+Lpull​+Lpush​+Loff​ CenterNet CenterNet只需要进行一个关键点的检测来判断物体位置, 故网络结构只需要一个大的分支, 该分支包含3个小分支. 3个小分支分别输出heatmap, offset, Height&amp;Weight HeatMap: 输出不同类别(80个类)物体中心点的位置([W/4, H/4, 80]) Offset: 对HeatMap的输出进行精练, 提高定位准确度([W/4, H/4, 2]) Height&amp;Width: 预测以关键点为中心的检测框的宽和高([W/4, H/4, 2]) 与CornerNet区别 将embedding分支替换成Height&amp;Width 删除了Corner Pooling Decode过程: 主要通过NMS在heatmap上寻找topk个最大值(可能成为物体中心的索引), 然后根据这topK个中心点, 寻找其对应的类别,宽高和offset信息 NMS过程: 寻找某点与周围的八个点之间最大值, 作为其NMS极大值 Encode过程: 将原图中的某关键点映射到Heatmap中的某一高斯核区域内 根据获得的Heatmap可以将GT Box的偏移信息和宽高信息按照该映射关系等同地映射到Offset和Height&amp;Weight特征图中 损失函数 Heatmap对应的损失(Focal Loss):Lk=−1N∑xyc{(1−Y^xyc)αlog⁡(Y^xyc) if Yxyc=1(1−Yxyc)β(Y^xyc)α otherwise log⁡(1−Y^xyc)L_k=\\frac{-1}{N} \\sum_{x y c}\\left\\{\\begin{array}{cl}\\left(1-\\hat{Y}_{x y c}\\right)^\\alpha \\log \\left(\\hat{Y}_{x y c}\\right) &amp; \\text { if } Y_{x y c}=1 \\\\ \\left(1-Y_{x y c}\\right)^\\beta\\left(\\hat{Y}_{x y c}\\right)^\\alpha &amp; \\text { otherwise } \\\\ \\log \\left(1-\\hat{Y}_{x y c}\\right) &amp; \\end{array}\\right.Lk​=N−1​∑xyc​⎩⎪⎪⎪⎪⎨⎪⎪⎪⎪⎧​(1−Y^xyc​)αlog(Y^xyc​)(1−Yxyc​)β(Y^xyc​)αlog(1−Y^xyc​)​ if Yxyc​=1 otherwise ​ Offset对应的loss： Loff=1N∑p∣O^p~−(pR−p~)∣L_{o f f}=\\frac{1}{N} \\sum_p\\left|\\hat{O}_{\\tilde{p}}-\\left(\\frac{p}{R}-\\tilde{p}\\right)\\right|Loff​=N1​∑p​∣∣∣∣​O^p~​​−(Rp​−p~​)∣∣∣∣​, p~=⌊pR⌋\\tilde{p}=\\left\\lfloor\\frac{p}{R}\\right\\rfloorp~​=⌊Rp​⌋ ppp是检测框中心点(原图)的真实坐标, pR\\frac{p}{R}Rp​是理论上该中心点映射到特征图的准确位置区域. 实际上经取整后坐标ppp在特征图的位置是p~=⌊pR⌋\\tilde{p}=\\left\\lfloor\\frac{p}{R}\\right\\rfloorp~​=⌊Rp​⌋, Op~^\\hat{O_{\\tilde{p}}}Op~​​^​是网络的Offset输出特征图, p~\\tilde{p}p~​指关键点实际落入的区域 Height&amp;Weight损失: Lsize=1N∑k=1N∣S^pk−sk∣,sk=(x2(k),x1(k),y2(k),y1(k))L_{s i z e}=\\frac{1}{N} \\sum_{k=1}^N\\left|\\hat{S}_{p_k}-s_k\\right|, s_k=(x_2^{(k)}, x_1^{(k)}, y_2^{(k)}, y_1^{(k)})Lsize​=N1​∑k=1N​∣∣∣∣​S^pk​​−sk​∣∣∣∣​,sk​=(x2(k)​,x1(k)​,y2(k)​,y1(k)​) 总损失: Ldet=Lk+λsizeLsize+λoffLoffL_{det} = L_{k}+\\lambda_{size}L_{size}+\\lambda_{off}L_{off}Ldet​=Lk​+λsize​Lsize​+λoff​Loff​ FCOS FCOS为逐像素预测的范式, 在每个像素点位置都产生预测结果. 当一个像素点位于多个重叠部分的GT Boxes内时, 容易产生歧义, FCOS使用FCN能很大程度上解决该问题. 使用centerness分支用来预测像素点位置与物体中心点的远近关系. 在推理时, 可以用该分数乘上分类得分, 以此降低低质量预测框的得分, 从而使其在NMS时排在后面以过滤掉低质量的边界框 FCOS的思想 假定FiF_iFi​是CNN Backbone的第i层特征图, s是到这一层的总步长. 输入图像GT BBox定义为Bi=(x0(i),y0(i),x1(i),y1(i),c(i))B_i=(x_0(i),y_0(i),x_1(i),y_1(i),c(i))Bi​=(x0​(i),y0​(i),x1​(i),y1​(i),c(i)) 对于FiF_iFi​上的每个像素(x,y)(x,y)(x,y), 可以将其映射到原输入图像(⌊s2⌋+xs,⌊s2⌋+ys)\\left(\\left\\lfloor\\frac{s}{2}\\right\\rfloor+x s,\\left\\lfloor\\frac{s}{2}\\right\\rfloor+y s\\right)(⌊2s​⌋+xs,⌊2s​⌋+ys). 在映射后的该点直接回归目标框, 而不是把这个点看成目标框的中心点.(FCOS相当于把每个点看成训练的样本) 对于每个(x,y)(x,y)(x,y), 若其落在GT的框内, 并且类别和GT框的类别一致, 那么就将其看成正样本, 否则看成负样本. 因此FCOS可以利用更多的前景样本, 而不是只有和GT框有高IOU的Anchor当作正样本 每个点都有一个4为向量t∗=(l∗,t∗,r∗,b∗)t^*=(l^*,t^*,r^*,b^*)t∗=(l∗,t∗,r∗,b∗), 分别对应(x,y)到左, 上, 右, 下的距离. 因为这个距离总是正值, 故会使用exp()保证得到的都是正值 检测流程 对每一层的feature map上的每一个点, 可以将其映射回原图的(⌊s2⌋+xs,⌊s2⌋+ys)\\left(\\left\\lfloor\\frac{s}{2}\\right\\rfloor+x s,\\left\\lfloor\\frac{s}{2}\\right\\rfloor+y s\\right)(⌊2s​⌋+xs,⌊2s​⌋+ys)位置上 如果该点落在一个GT Box内部, 则该店为正样本, 否则为负样本. 正样本回归的目标为上下左右四条边的距离.(若该点落在多个GT Box内, 回归面积最小的GT Box, 在结合FPN之后出现这种情况的概率减小) 可以利用更多的前景样本来训练回归器(FCOS效果好的原因之一) 使用C个二分类器进行分类, 而不是一个多分类器(和Focal loss一致) 损失函数: L({px,y},{tx,y})=1Npos∑x,yLcls(px,y,cx,y∗)+λNpos∑x,y1{cx,y∗&gt;0}Lreg(tx,y,tx,y∗)\\begin{aligned} L\\left(\\left\\{\\boldsymbol{p}_{x, y}\\right\\},\\left\\{\\boldsymbol{t}_{x, y}\\right\\}\\right) &amp; =\\frac{1}{N_{\\mathrm{pos}}} \\sum_{x, y} L_{\\mathrm{cls}}\\left(\\boldsymbol{p}_{x, y}, c_{x, y}^*\\right) \\\\ &amp; +\\frac{\\lambda}{N_{\\mathrm{pos}}} \\sum_{x, y} 1_{\\left\\{c_{x, y}^*&gt;0\\right\\}} L_{\\mathrm{reg}}\\left(\\boldsymbol{t}_{x, y}, \\boldsymbol{t}_{x, y}^*\\right)\\end{aligned}L({px,y​},{tx,y​})​=Npos​1​x,y∑​Lcls​(px,y​,cx,y∗​)+Npos​λ​x,y∑​1{cx,y∗​&gt;0}​Lreg​(tx,y​,tx,y∗​)​, LregL_{reg}Lreg​使用IOU损失 推理阶段, 对每一层feature map上的每一个点, 都预测一个分类分数和四个回归值, 将分类分数大于0.05的作为正样本 网络结构 和FPN结合的问题 通过设定每个层级上BBox回归大小的范围来将不同尺寸的物体约束在不同层级的feature map上 不同层的Head共享权重, 但不同层需要回归的数值大小不一致, 通过在回归偏移量上加上一个可训练的scaler参数用exp(sx)来代替exp(x)作为输出 重点解决低召回率和重叠目标情况下的歧义性问题 低召回率问题: 使用多层感受野不同的特征, 不同层可以对应分配给不同尺寸的物体, 为不同尺寸的物体提供了合适的样本去负责召回 重叠目标歧义性问题: 假设大部分重叠目标的尺寸存在一定程度的差异, 处于重叠Boxes内的一个特征点, 因为不同特征层会负责预测不同尺度的物体, 只需要看其属于哪个特征层就可以解决重叠目标的问题. 当两个重叠目标的尺度水平一致, 哪个物体的面积小就负责预测哪个. 检测头: Classification, Regression, Centerness Classification 先经过4个卷积块(3*3卷积-&gt;Group Normalization-&gt;ReLu), 随后利用1个3*3卷积将输出通道映射成物体类别数(将多分类当作多个二分类处理,损失函数使用Focal Loss) Regression 与Classification几乎一样, 先经过4个卷积块(与上述相同), 最后使用1个独立的3*3卷积进行预测, 不同的是最后卷积输出通道数为4, 代表回归的四个量l,t,r,bl,t,r,bl,t,r,b, 分别是像素点位置距离GT Box左边, 上边, 右边和下边的距离 使用exp()函数将回归量的值域调节到正值 不同层的Head共享权重, 但不同层需要回归的数值大小不一致, 通过在回归偏移量上加上一个可训练的scaler参数用exp(sx)来代替exp(x)作为输出 Loss使用IoU Loss Centerness 原因: 只要x,y落入到GT Box中就进行训练. 位置太多, 会存在一些低质量或较难学习的位置, 学习这些位置之后, 模型会产生较大的偏差. 加入centerness可以修正这种问题 在分类并行的位置上添加一个一层卷积来预测当前位置上的&quot;中心程度&quot;, 以此来过滤低质量的偏差很远的预测框. 推理时, 分类分数会乘上centerness的数值 centerness∗=min⁡(l∗,r∗)max⁡(l∗,r∗)×min⁡(t∗,b∗)max⁡(t∗,b∗)centerness^*=\\sqrt{\\frac{\\min \\left(l^*, r^*\\right)}{\\max \\left(l^*, r^*\\right)} \\times \\frac{\\min \\left(t^*, b^*\\right)}{\\max \\left(t^*, b^*\\right)}}centerness∗=max(l∗,r∗)min(l∗,r∗)​×max(t∗,b∗)min(t∗,b∗)​​ 开根号让centerness下降慢一些, 由于centerness值域为[0-1]故可以直接用BCE LOSS进行训练 标签分配策略 流程 将各层特征点位置映射回输入图像 位于物体框内的位置点作为正样本筛选, 只有min()l,t,r,b&gt;0min()l,t,r,b&gt;0min()l,t,r,b&gt;0的为支点才可以作为正样本候选 某位置点到物体边框的距离只有位于一定范围内才可作为正样本 对于第iii层的特征点, 只有当mi−1&lt;=max(l,t,r,b)&lt;=mim_{i-1} &lt;= max(l,t,r,b) &lt;= m_imi−1​&lt;=max(l,t,r,b)&lt;=mi​时, 该点才可以作为相应物体的正样本 该条件代表第iii层特征负责预测的GT Box的边长在[mi−1,mi][m_{i-1}, m_i][mi−1​,mi​]范围内, 实际上就是要让不同层的特征负责不同尺寸的物体 选择物体框面积最小的作为目标(标签) Other PANet 只针对YOLO中出现得点进行总结 自底向上Bottom-up Path Augmentation 原始Mask RCNN没有很好的利用低层信息. 高层的Feature maps关注物体整体, 低层的Feature maps关注物体纹理图案, 使用低层信息可以更好的对物体进行定位. 因此将低层信息传导到高层中, 可以减少高层到低层的信息流通需要穿过的卷积层数 PANet融合时, 通过一个更浅层的NiN_iNi​和更深层的$$P_{i+1}融合的方式得到下一层Ni+1N_{i+1}Ni+1​ 首先通过一个步长为2的3*3卷积进行降采样, 再通过单位加的方式对特征进行融合, 接着再使用一个3*3卷积对特征进行融合, 增加融合之后的特征表征能力, 再使用ReLu激活函数进行非线性化 此外还在自顶向下模块和自底向上模块间各添加了一个跨越多层的shortcut","categories":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"}],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"}]},{"title":"isp_pipeline练习实录","slug":"isp_pipeline练习实录","date":"2023-04-07T08:18:39.000Z","updated":"2023-10-16T07:33:11.294Z","comments":true,"path":"2023/04/07/isp_pipeline练习实录/","link":"","permalink":"http://jay1060950003.github.io/2023/04/07/isp_pipeline%E7%BB%83%E4%B9%A0%E5%AE%9E%E5%BD%95/","excerpt":"0 前言 记录自己使用C++和Python练习ISP Pipeline开发 设备: iphone 11 软件: ProCam 8 电脑环境: VS 2019, miniconda, opencv4","text":"0 前言 记录自己使用C++和Python练习ISP Pipeline开发 设备: iphone 11 软件: ProCam 8 电脑环境: VS 2019, miniconda, opencv4 1 读取raw文件 1.1 Adobe DNG SDK 使用Adobe DNG SDK处理DNG RAW数据 准备工作 下载Adobe DNG SDK 下载直链： 跳转至下载页面 默认已经安装好VS2019，另外安装cmake(跳转至下载页面) 注意在安装时将cmake添加进系统变量 将下载的Adobe DNG SDK解压缩到自己的dng_path 下载项目构建需要使用的libjpeg、zlib、expat 下载libjpeg(跳转至下载页面)，随后将压缩文件里的文件解压至dng_path\\libjpeg， 将该文件夹内的jconfig.h删除, 并将jconfig.vc重命名为jconfig.h 下载zlib(跳转至下载页面)，随后将**压缩文件内根目录下的.c和.h**文件解压到dng_path\\xmp\\toolkit\\third-party\\zlib目录内 下载expat(跳转至下载页面, github链接)，随后将压缩文件内的lib文件夹解压到dng_path\\xmp\\toolkit\\XMPCore\\third-party\\expat\\public文件夹内 构建xmp 打开dng_path\\xmp\\toolkit\\XMPCore\\build\\CMake64Static_VC16\\XMPCore64.sln 选择Debug或Release模式下ARM64或x64进行生成 打开dng_path\\xmp\\toolkit\\XMPFiles\\build\\CMake64Static_VC16\\XMPFiles64.sln 选择Debug或Release模式下ARM64或x64进行生成 打开dng_path\\dng_sdk\\projects\\win\\dng_validate.sln, 选择合适的平台(ARM64或X64)即可生成 为了方便调试,可将链接器的输出目录(OutputFile)和项目的输出路径(TargetPath)设置一致, 打开项目解决方案的属性，找到链接器-&gt;常规-&gt;输出文件, 将属性值设置为$(TargetPath) 1.2 libraw 使用LibRaw处理DNG文件 准备工作 下载LibRaw文件 跳转至下载页面 解压至LibRaw文件夹 在该文件夹下打开命令行，输入nmake -f Makefile.msvc进行编译 注意已经安装好VS2019 编译得到的动态链接库文件在bin/libraw.dll，而链接库在lib/libraw.lib中，头文件在libraw文件夹中 静态链接库为lib/libraw_static.lib 推荐使用动态链接库进行项目开发 1.3 C++项目构建 本教程使用LibRaw构建ISP-pipeline处理流程 需配置好opencv4(C++)环境 项目属性配置 配置属性 常规：输出目录$(SolutionDir)build 常规：中间目录$(SolutionDir)build\\dist\\$(Configuration)\\ C/C++ 常规：附加包含目录：C:\\Program Files\\opencv\\build\\include\\opencv2,C:\\Program Files\\opencv\\build\\include,$(SolutionDir)include 链接器 常规：附加库目录：C:\\Program Files\\opencv\\build\\x64\\vc15\\lib,$(SolutionDir)lib 输入：附加依赖项：libraw.lib,opencv_world460d.lib 将libraw.dll文件放在输出目录中 项目结构 123456789101112├─ isp_pipeline│ ├─build│ │ ├─dist│ │ ├─libraw.dll│ ├─include│ │ ├─libraw│ │ ├─Raw.cpp│ │ ├─Raw.h│ ├─lib│ │ ├─libraw.lib│ ├─res│ ├─demo.cpp 1234567891011121314151617181920212223242526272829// main.cpp#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;ctime&gt;#include &quot;libraw.h&quot;#include &quot;module.h&quot;int main() &#123; cv::utils::logging::setLogLevel(cv::utils::logging::LOG_LEVEL_ERROR); // 只输出错误日志 clock_t begin = clock(); const char* file = &quot;IMG_1.dng&quot;; // open dng file LibRaw* iProcessor = new LibRaw; iProcessor-&gt;open_file(file); iProcessor-&gt;unpack(); // raw2Mat and cut2roi cv::Mat raw = cv::Mat(iProcessor-&gt;imgdata.sizes.raw_height, iProcessor-&gt;imgdata.sizes.raw_width, CV_16UC1, iProcessor-&gt;imgdata.rawdata.raw_image); raw = raw(cv::Rect(iProcessor-&gt;imgdata.sizes.left_margin, iProcessor-&gt;imgdata.sizes.top_margin, iProcessor-&gt;imgdata.sizes.width, iProcessor-&gt;imgdata.sizes.height)); clock_t end = clock(); std::cout &lt;&lt; &quot;-------------------------------------------&quot; &lt;&lt; std::endl; std::cout &lt;&lt; &quot;ISP Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC &lt;&lt; &quot; s.&quot; &lt;&lt; std::endl; // recycle LibRaw and delete ptr iProcessor-&gt;recycle(); delete iProcessor;&#125; 注意事项： 上述程序中获取raw数据在iProcessor-&gt;imgdata.rawdata.raw_image字段中，且在构建cv::Mat矩阵时，需要注意范围为raw_height到raw_width 因为在CMOS中存在OB区，当获取的尺寸不对时，获取不到正确的数据。同时可以看出此时的图像存在黑边 故需要使用cv::Rect进行截取，截取的参数为left_margin,top_margin,width,height 在保存时，opencv会自动将CV_16UC1转换为CV_8UC1进行保存，而三通道的16位的数据(CV_16UC3)需要自己手动进行转换为(CV_8UC3)才可以正确保存 2 DPC 原因: CMOS器件自身工艺瑕疵造成 光线采集器件存在缺陷 解决方法 简单方法: 在5×5邻域内同一颜色通道相对中心像素有8个邻近像素, 计算中心像素与临近像素的差值, 若差值有正有负则正常; 否则利用阈值进行判断, 差值的绝对值都超过阈值则为坏点则用中位数替换 梯度方法: 计算四个方向的梯度: δ=(xi,0+xi,2−2∗xi,1)\\delta = (x_{i,0}+x_{i,2}-2*x{i,1})δ=(xi,0​+xi,2​−2∗xi,1), 得到12个梯度值 求各个方向梯度的绝对值的中值, 利用四个中值的最小值作为边缘方向 若边缘为水平(竖直方向) 中心点的梯度大于同方向梯度绝对值和的4倍，则中心点为坏点 若∣P4−Pc∣&lt;∣Pc−P5∣|P_4-P_c| &lt; |P_c -P_5|∣P4​−Pc​∣&lt;∣Pc​−P5​∣, 则中心像素值更靠近P4P_4P4​, 则Pc=P4+(P2+P7−P1−P6)/2P_c = P_4+(P_2+P_7-P_1-P_6)/2Pc​=P4​+(P2​+P7​−P1​−P6​)/2 若边缘为45度(135度方向) 计算135度方向梯度两两之差的绝对值的和, 若和大于100且45度中心梯度大于两边梯度的3倍且135度中心梯度大于两边梯度的3倍, 则为坏点; 若和小于100且45度中心梯度大于两边梯度的3倍, 则为坏点 若∣P3−Pc∣&lt;∣Pc−P6∣|P_3-P_c| &lt; |P_c -P_6|∣P3​−Pc​∣&lt;∣Pc​−P6​∣, 则中心像素值更靠近P3P_3P3​, 则Pc=P3+(P4+P7−P2−P5)/2P_c = P_3+(P_4+P_7-P_2-P_5)/2Pc​=P3​+(P4​+P7​−P2​−P5​)/2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132// 使用梯度法进行校正int median(int a, int b, int c) &#123; return a &gt;= b ? (b &gt;= c ? b : (a &gt;= c ? c : a)) : (a &gt;= c ? a : (b &gt;= c ? c : b));&#125;cv::Mat padding(cv::Mat&amp; img, uchar* pads)&#123; cv::Mat img_pad = cv::Mat(cv::Size(img.cols + pads[2] + pads[3], img.rows + pads[0] + pads[1]), img.type()); cv::copyMakeBorder(img, img_pad, pads[0], pads[1], pads[2], pads[3], cv::BORDER_REFLECT); return img_pad;&#125;void dpc(cv::Mat&amp; src, uchar thres)&#123; clock_t begin = clock(); uchar pads[4] = &#123; 2, 2, 2, 2 &#125;; cv::Mat src_p = padding(src, pads); ushort* p0, * p1, * p2, * p3, * p4, * p5, * p6, * p7, * p8, * p; int grad_h1 = 0, grad_h2 = 0, grad_h3 = 0, grad_v1 = 0, grad_v2 = 0, grad_v3 = 0; int grad_45_1 = 0, grad_45_2 = 0, grad_45_3 = 0, grad_135_1 = 0, grad_135_2 = 0, grad_135_3 = 0; int grad_h = 0, grad_v = 0, grad_45 = 0, grad_135 = 0; std::vector&lt;int&gt; gradient(4, 0); int grad_sum = 0; for (int i = 0; i &lt; src_p.rows - 4; ++i) &#123; std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;DPC: &quot;; std::cout &lt;&lt; std::setw(6) &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; (float)i / (src_p.rows - 2) * 100 &lt;&lt; &quot;%&quot;; p0 = src_p.ptr&lt;ushort&gt;(i + 2); p1 = src_p.ptr&lt;ushort&gt;(i); p2 = src_p.ptr&lt;ushort&gt;(i); p3 = src_p.ptr&lt;ushort&gt;(i); p4 = src_p.ptr&lt;ushort&gt;(i + 2); p5 = src_p.ptr&lt;ushort&gt;(i + 2); p6 = src_p.ptr&lt;ushort&gt;(i + 4); p7 = src_p.ptr&lt;ushort&gt;(i + 4); p8 = src_p.ptr&lt;ushort&gt;(i + 4); p = src.ptr&lt;ushort&gt;(i); for (int j = 0; j &lt; src_p.cols - 4; j++) &#123; grad_h1 = abs(p1[j] + p3[j + 4] - 2 * p2[j + 2]); grad_h2 = abs(p4[j] + p5[j + 4] - 2 * p0[j + 2]); grad_h3 = abs(p6[j] + p8[j + 4] - 2 * p7[j + 2]); grad_v1 = abs(p1[j] + p4[j] - 2 * p6[j]); grad_v2 = abs(p2[j + 2] + p7[j + 2] - 2 * p0[j + 2]); grad_v3 = abs(p3[j + 4] + p8[j + 4] - 2 * p5[j + 4]); grad_45_1 = 2 * abs(p2[j + 2] - p4[j]); grad_45_2 = abs(p3[j + 4] + p6[j] - 2 * p0[j + 2]); grad_45_3 = 2 * abs(p5[j + 4] - p7[j + 2]); grad_135_1 = 2 * abs(p2[j + 2] -p5[j + 4]); grad_135_2 = abs(p1[j] + p8[j + 4] - 2 * p0[j + 2]); grad_135_3 = 2 * abs(p4[j] - p7[j + 2]); grad_h = median(grad_h1, grad_h2, grad_h3); grad_v = median(grad_v1, grad_v2, grad_v3); grad_45 = median(grad_45_1, grad_45_2, grad_45_3); grad_135 = median(grad_135_1, grad_135_2, grad_135_3); gradient = &#123; grad_h, grad_v, grad_45, grad_135 &#125;; auto minPosition = std::min_element(gradient.begin(), gradient.end()); if (minPosition == gradient.begin() &amp;&amp; grad_h2 &gt; 4*(grad_h1+grad_h3)) &#123; if (abs(p4[j] - p0[j + 2]) &lt; abs(p0[j + 2] - p5[j + 4])) &#123; p[j] = p4[j] + (p2[j + 2] + p7[j + 2] - p1[j] - p6[j]) / 2; &#125; else &#123; p[j] = p5[j + 4] + (p2[j + 2] + p7[j + 2] - p3[j + 4] - p8[j + 4]) / 2; &#125; &#125; if (minPosition == gradient.begin()+1 &amp;&amp; grad_v2 &gt; 4 * (grad_v1 + grad_v3)) &#123; if (abs(p2[j + 2] - p0[j + 2]) &lt; abs(p0[j + 2] - p7[j + 2])) &#123; p[j] = p2[j + 2] + (p4[j] + p5[j + 4] - p1[j] - p3[j + 4]) / 2; &#125; else &#123; p[j] = p7[j + 2] + (p4[j] + p5[j + 4] - p6[j] - p8[j + 4]) / 2; &#125; &#125; if (minPosition == gradient.begin()+2) &#123; grad_sum = abs(grad_135_1 - grad_135_2) + abs(grad_135_1 - grad_135_3) + abs(grad_135_2 - grad_135_3); if (grad_sum &gt; 100) &#123; if (grad_45_2 &gt; 3 * (grad_45_1 + grad_45_3) &amp;&amp; grad_135_2 &gt; 3 * (grad_135_1 + grad_135_3)) &#123; if (abs(p3[j + 4] - p0[j + 2]) &lt; abs(p0[j + 2] - p6[j])) &#123; p[j] = p3[j + 4] + (p4[j] + p7[j + 2] - p2[j + 2] - p5[j + 4]) / 2; &#125; else &#123; p[j] = p6[j] - (p4[j] + p7[j + 2] - p2[j + 2] - p5[j + 4]) / 2; &#125; &#125; &#125; else &#123; if (grad_45_2 &gt; 3 * (grad_45_1 + grad_45_3)) &#123; if (abs(p3[j + 4] - p0[j + 2]) &lt; abs(p0[j + 2] - p6[j])) &#123; p[j] = p3[j + 4] + (p4[j] + p7[j + 2] - p2[j + 2] - p5[j + 4]) / 2; &#125; else &#123; p[j] = p6[j] - (p4[j] + p7[j + 2] - p2[j + 2] - p5[j + 4]) / 2; &#125; &#125; &#125; &#125; if (minPosition == gradient.begin()+3) &#123; grad_sum = abs(grad_45_1 - grad_45_2) + abs(grad_45_1 - grad_45_3) + abs(grad_45_2 - grad_45_3); if (grad_sum &gt; 100) &#123; if (grad_135_2 &gt; 3 * (grad_135_1 + grad_135_3) &amp;&amp; grad_45_2 &gt; 3 * (grad_45_1 + grad_45_3)) &#123; if (abs(p1[j] - p0[j + 2]) &lt; abs(p0[j + 2] - p8[j + 4])) &#123; p[j] = p1[j] + (p5[j + 4] + p6[j] - p2[j + 2] - p4[j]) / 2; &#125; else &#123; p[j] = p8[j + 4] - (p5[j + 4] + p6[j] - p2[j + 2] - p4[j]) / 2; &#125; &#125; &#125; else &#123; if (grad_135_2 &gt; 3 * (grad_135_1 + grad_135_3)) &#123; if (abs(p1[j] - p0[j + 2]) &lt; abs(p0[j + 2] - p8[j + 4])) &#123; p[j] = p1[j] + (p5[j + 4] + p6[j] - p2[j + 2] - p4[j]) / 2; &#125; else &#123; p[j] = p8[j + 4] - (p5[j + 4] + p6[j] - p2[j + 2] - p4[j]) / 2; &#125; &#125; &#125; &#125; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;DPC Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;uchar dpc_thres = 30;dpc(raw, dpc_thres); //DPC，坏点矫正，使用梯度进行解决 3 BLC 原因： 常用的光电器件在没有光照时仍然有电压输出 CMOS内部为PN结, 工作在反向电压下, 没有光照时依然有微小电流为暗电流 sensor到isp中有AD转换，但AD存在灵敏度问题, 通常认为添加一个固定值, 使低于AD阈值时也可以进行转换, 保留更多暗部细节 校正方法 sensor端算法: 利用OB区的像素值(取平均, 曲线拟合)进行较准 isp端算法: 扣除暗电流: 利用黑帧RAW图每个通道的平均值进行校正, 并对GrG_rGr​和GbG_bGb​进行归一化(R和B通道不进行归一化, 后续使用AWB进行校正) ISO联动: 暗电流与Gain值和温度相关, 简历ISO与暗电流之间的关系, 每次查表校正 曲线拟合: 在黑帧中选取部分位置和校正值存储, 后续其他像素校正值通过线性插值进行精准校正 练习实录 在dng文件中包含该文件的暗电平校正值和白电平值, 包含在imgdata.color.dng_levels.dng_black与imgdata.color.dng_levels.dng_whitelevel[0]字段中 利用上述两个字段, 使用简单的扣除暗电流方法即可校正暗电流 注:在该方案中, 并不对GGG通道进行归一化，发现对该通道归一化, 会导致偏色, 原因未知 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122std::vector&lt;cv::Mat&gt; split_bayer(cv::Mat&amp; bayer_array, std::string&amp; bayer_pattern) &#123; cv::Mat R = cv::Mat(bayer_array.size() / 2, bayer_array.type()); cv::Mat Gr = cv::Mat(bayer_array.size() / 2, bayer_array.type()); cv::Mat Gb = cv::Mat(bayer_array.size() / 2, bayer_array.type()); cv::Mat B = cv::Mat(bayer_array.size() / 2, bayer_array.type()); ushort* p_R, * p_Gr, * p_Gb, * p_B, * p_bayer1, * p_bayer2; for (int i = 0; i &lt; bayer_array.rows / 2; ++i) &#123; p_R = R.ptr&lt;ushort&gt;(i); p_Gr = Gr.ptr&lt;ushort&gt;(i); p_Gb = Gb.ptr&lt;ushort&gt;(i); p_B = B.ptr&lt;ushort&gt;(i); p_bayer1 = bayer_array.ptr&lt;ushort&gt;(2 * i); p_bayer2 = bayer_array.ptr&lt;ushort&gt;(2 * i + 1); for (int j = 0; j &lt; bayer_array.cols / 2; ++j) &#123; if (bayer_pattern == &quot;gbrg&quot;) &#123; p_R[j] = p_bayer1[2 * j + 1]; p_Gr[j] = p_bayer2[2 * j + 1]; p_Gb[j] = p_bayer1[2 * j]; p_B[j] = p_bayer2[2 * j]; &#125; else if (bayer_pattern == &quot;rggb&quot;) &#123; p_R[j] = p_bayer1[2 * j]; p_Gr[j] = p_bayer2[2 * j]; p_Gb[j] = p_bayer1[2 * j + 1]; p_B[j] = p_bayer2[2 * j + 1]; &#125; else if (bayer_pattern == &quot;bggr&quot;) &#123; p_R[j] = p_bayer2[2 * j + 1]; p_Gr[j] = p_bayer1[2 * j + 1]; p_Gb[j] = p_bayer2[2 * j]; p_B[j] = p_bayer1[2 * j]; &#125; else if (bayer_pattern == &quot;grbg&quot;) &#123; p_R[j] = p_bayer2[2 * j]; p_Gr[j] = p_bayer1[2 * j]; p_Gb[j] = p_bayer2[2 * j + 1]; p_B[j] = p_bayer1[2 * j + 1]; &#125; else &#123; throw &quot;bayer pattern is not declared!\\n&quot;; &#125; &#125; &#125; return std::vector&lt;cv::Mat&gt; &#123; R,Gr,Gb,B &#125;;&#125;cv::Mat reconstruct_bayer(std::vector&lt;cv::Mat&gt;&amp; sub_arrays, std::string&amp; bayer_pattern) &#123; cv::Mat bayer_array = cv::Mat(sub_arrays[0].size() * 2, sub_arrays[0].type()); ushort* p_R, * p_Gr, * p_Gb, * p_B, * p_bayer1, * p_bayer2; for (int i = 0; i &lt; sub_arrays[0].rows; ++i) &#123; p_R = sub_arrays[0].ptr&lt;ushort&gt;(i); p_Gr = sub_arrays[1].ptr&lt;ushort&gt;(i); p_Gb = sub_arrays[2].ptr&lt;ushort&gt;(i); p_B = sub_arrays[3].ptr&lt;ushort&gt;(i); p_bayer1 = bayer_array.ptr&lt;ushort&gt;(2 * i); p_bayer2 = bayer_array.ptr&lt;ushort&gt;(2 * i + 1); for (int j = 0; j &lt; sub_arrays[0].cols; ++j) &#123; if (bayer_pattern == &quot;gbrg&quot;) &#123; p_bayer1[2 * j + 1] = p_R[j]; p_bayer2[2 * j + 1] = p_Gr[j]; p_bayer1[2 * j] = p_Gb[j]; p_bayer2[2 * j] = p_B[j]; &#125; else if (bayer_pattern == &quot;rggb&quot;) &#123; p_bayer1[2 * j] = p_R[j]; p_bayer2[2 * j] = p_Gr[j]; p_bayer1[2 * j + 1] = p_Gb[j]; p_bayer2[2 * j + 1] = p_B[j]; &#125; else if (bayer_pattern == &quot;bggr&quot;) &#123; p_bayer2[2 * j + 1] = p_R[j]; p_bayer1[2 * j + 1] = p_Gr[j]; p_bayer2[2 * j] = p_Gb[j]; p_bayer1[2 * j] = p_B[j]; &#125; else if (bayer_pattern == &quot;grbg&quot;) &#123; p_bayer2[2 * j] = p_R[j]; p_bayer1[2 * j] = p_Gr[j]; p_bayer2[2 * j + 1] = p_Gb[j]; p_bayer1[2 * j + 1] = p_B[j]; &#125; else &#123; throw &quot;bayer pattern is not declared!\\n&quot;; &#125; &#125; &#125; return bayer_array;&#125;void blc(cv::Mat&amp; src, std::string bayer_pattern, float black_level, float white_level)&#123; clock_t begin = clock(); std::vector&lt;cv::Mat&gt; bayer4 = split_bayer(src, bayer_pattern); int pixel_R = 0, pixel_Gr = 0, pixel_Gb = 0, pixel_B = 0; ushort* p_R, * p_Gr, * p_Gb, * p_B; for (int i = 0; i &lt; bayer4[0].rows; ++i) &#123; p_R = bayer4[0].ptr&lt;ushort&gt;(i); p_Gr = bayer4[1].ptr&lt;ushort&gt;(i); p_Gb = bayer4[2].ptr&lt;ushort&gt;(i); p_B = bayer4[3].ptr&lt;ushort&gt;(i); for (int j = 0; j &lt; bayer4[0].cols; ++j) &#123; pixel_R = p_R[j] - black_level; pixel_B = p_B[j] - black_level; pixel_Gr = p_Gr[j] - black_level; pixel_Gb = p_Gb[j] - black_level; p_R[j] = ((pixel_R &lt; 0) ? 0 : (pixel_R &gt; white_level ? white_level : pixel_R)); p_Gr[j] = ((pixel_Gr &lt; 0) ? 0 : (pixel_Gr &gt; white_level ? white_level : pixel_Gr)); p_Gb[j] = ((pixel_Gb &lt; 0) ? 0 : (pixel_Gb &gt; white_level ? white_level : pixel_Gb)); p_B[j] = ((pixel_B &lt; 0) ? 0 : (pixel_B &gt; white_level ? white_level : pixel_B)); &#125; &#125; src = reconstruct_bayer(bayer4, bayer_pattern); clock_t end = clock(); std::cout &lt;&lt; &quot;BLC Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;std::string BAYER = &quot;rggb&quot;;float black = iProcessor-&gt;imgdata.color.dng_levels.dng_black;float white = iProcessor-&gt;imgdata.color.dng_levels.dng_whitelevel[0];blc(raw, BAYER, black, white); //BLC 4 AAF(抗混叠滤波) 混叠产生的原因 在后续的Demosaics会进行插值操作, 该操作可能会导致混叠 由于无法对一个函数无限地取样, 因此在数字图像中会出现混叠现象(空间混叠和时间混叠) 空间混叠, 由于欠采样导致, 会引入伪影 对图像放大视为过取样, 混叠不严重; 而对图像缩小视为欠取样, 混叠较为严重 根本原因：高频信息在采样过程中重叠到低频段 解决方法： 使用抗混叠滤波器进行滤波;(本质上使用低通滤波器进行滤波, 衰减高频分量, 使重新采样后的分辨率可以表示高频信息) 1234567891011121314151617void aaf(cv::Mat&amp; src, cv::Mat&amp; kernel)&#123; clock_t begin = clock(); cv::Mat origin_img = src.clone(); cv::filter2D(origin_img, src, CV_16UC1, kernel); clock_t end = clock(); std::cout &lt;&lt; &quot;AAF Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot;&lt;&lt; std::endl;&#125;cv::Mat aaf_kernel = (cv::Mat_&lt;float&gt;(5, 5) &lt;&lt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 8, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1) / 16;aaf(raw, aaf_kernel); //AAF, 抗混叠滤波，抑制频谱混叠 5 WBGC(白平衡校正) 产生原因: 传感器不具有人眼的不同光照色温下的色彩恒常性, 白平衡模块需要将人眼看来白色的物体进行色彩的还原, 使其在照片上呈现白色 校正方法: 灰度世界法: 任何一幅图像具有足够的色彩变化, 则RGB分量的均值会趋于0(一般选取G通道作为参考值计算RB通道的Gain值进行校正) 完美反射法: 图像中最亮的点就是白色或者镜面反射出来的, 最亮的点就是光源的属性, 但该点本身应该是白色, 以此为基础计算Gain值进行校正(计算图像RGB分别的最大值, 用三个最大值的最大值除以每个通道的最大值即可得到每个通道的Gain值) 基于色温的方法 不同色温环境下灰卡得到Gain值关系曲线与R/G与色温关系曲线 获取了一张图像的拍摄色温, 通过第二张图获取R/G的值随后可根据图一计算出B/G从而计算R和B的Gain值 练习实录 在dng文件中具有AWB矩阵, 该矩阵存放在imgdata.color.dng_levels.asshotneutral字段中 利用上述字段分别对图像的各个通道进行校正 12345678910111213141516171819202122232425void wbgc(cv::Mat&amp; src, std::string bayer_pattern, std::vector&lt;float&gt; gain, ushort clip)&#123; gain = &#123; 1 / gain[0] * 1024, 1 / gain[1] * 1024, 1 / gain[2] * 1024 &#125;; clock_t begin = clock(); std::vector&lt;cv::Mat&gt; rggb = split_bayer(src, bayer_pattern); rggb[0] *= (gain[0] / 1024); rggb[1] *= (gain[1] / 1024); rggb[2] *= (gain[1] / 1024); rggb[3] *= (gain[2] / 1024); src = reconstruct_bayer(rggb, bayer_pattern); ushort* p_img; for (int i = 0; i &lt; src.rows; ++i) &#123; p_img = src.ptr&lt;ushort&gt;(i); for (int j = 0; j &lt; src.cols; ++j) &#123; p_img[j] = (p_img[j] &lt; 0) ? 0 : (p_img[j] &gt; clip ? clip : p_img[j]); &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;AWB Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;std::vector&lt;float&gt; parameter(iProcessor-&gt;imgdata.color.dng_levels.asshotneutral, iProcessor-&gt;imgdata.color.dng_levels.asshotneutral + 3);ushort CLIP = 4095;wbgc(raw, BAYER, parameter, CLIP); //WBGC，白平衡较准 6 BNR 在RAW域进行降噪处理效果会更好, 此时的噪声没有经过各种模块的调节而导致变大 常用方法: 中值滤波 双边滤波 BM3D降噪 练习实录 在Raw数据分为4个通道, 在每个通道上应用中值滤波进行处理 1234567891011121314void bnr(cv::Mat&amp; src, std::string bayer_pattern, uchar ksize) &#123; clock_t begin = clock(); std::vector&lt;cv::Mat&gt; rggb = split_bayer(src, bayer_pattern); medianBlur(rggb[0], rggb[0], ksize); medianBlur(rggb[1], rggb[1], ksize); medianBlur(rggb[2], rggb[2], ksize); medianBlur(rggb[3], rggb[3], ksize); src = reconstruct_bayer(rggb, bayer_pattern); clock_t end = clock(); std::cout &lt;&lt; &quot;BNF Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;uchar bnr_size = 3;bnr(raw, BAYER, bnr_size); 7 Demosaics 原理：一般的CMOS为前照式CMOS, 使用CFA阵列将光线分解为RGB三个分量用感光器件接收 解决方法: 简单线性插值: 效果一般, 清晰度降低, 高频产生伪彩, 边缘产生伪像 色比法: 一个邻域内不同颜色通道的比值固定, 首先插值计算出G的缺失值, 随后根据比值恒定计算出其他的缺失值(清晰度变差, 产生伪彩和伪像) 练习实录 使用opencv自身的算法进行实现 123456789101112131415161718192021222324void cfa(cv::Mat&amp; src, std::string bayer_pattern)&#123; clock_t begin = clock(); if (bayer_pattern == &quot;gbrg&quot;) &#123; cv::cvtColor(src, src, cv::COLOR_BayerGB2RGB); &#125; else if (bayer_pattern == &quot;rggb&quot;) &#123; cv::cvtColor(src, src, cv::COLOR_BayerRG2RGB); &#125; else if (bayer_pattern == &quot;bggr&quot;) &#123; cv::cvtColor(src, src, cv::COLOR_BayerBG2RGB); &#125; else if (bayer_pattern == &quot;grbg&quot;) &#123; cv::cvtColor(src, src, cv::COLOR_BayerGR2RGB); &#125; else &#123; throw &quot;bayer pattern is not declared!\\n&quot;; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;CFA Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;cfa(raw, BAYER); //CFA 8 CCM 原因: sensor和人眼对颜色的感知存在差异, 且不同sensor之间的颜色感知也存在差异; 因此需要将sensor感光数据转换至人眼感光数据 解决方法 3D-LUT查表法 多项式拟合方法: 拟合颜色校正矩阵(CCM矩阵, 该矩阵的每个行相等,即r=g=br=g=br=g=b) 使用24色标准色卡(常规做法): 通常在CIE_LAB空间具有ΔE=ΔL2+ΔA2+ΔB2,L为亮度,AB为色相\\Delta E = \\sqrt{\\Delta L^2+ \\Delta A^2 + \\Delta B^2}, L为亮度, AB为色相ΔE=ΔL2+ΔA2+ΔB2​,L为亮度,AB为色相参数, 更精确表示人眼的特性 通常是求解最优点, 而不是直接计算出CCM矩阵 经过校正后, sensorRGB贴近sRGB, 且具有了负响应 练习实录 在dng文件中具有CCM矩阵,该字段在imgdata.color.cmatrix字段中 获取该字段后,使用矩阵相乘即可实现CCM校正 123456789101112131415161718192021void ccm(cv::Mat&amp; src, cv::Mat&amp; ccm)&#123; clock_t begin = clock(); cv::Mat img0 = src.clone(); cv::Vec3s* p, * p0; for (int i = 0; i &lt; src.rows; ++i) &#123; p0 = img0.ptr&lt;cv::Vec3s&gt;(i); p = src.ptr&lt;cv::Vec3s&gt;(i); for (int j = 0; j &lt; src.cols; ++j) &#123; for (int k = 0; k &lt; 3; ++k) &#123; p[j][k] = ccm.ptr&lt;float&gt;(k)[0] * p0[j][0] + ccm.ptr&lt;float&gt;(k)[1] * p0[j][1] + ccm.ptr&lt;float&gt;(k)[2] * p0[j][2]; &#125; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;CCM Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;cv::Mat ccmatrix = cv::Mat(3, 4, CV_32F, iProcessor-&gt;imgdata.color.cmatrix)(cv::Rect(0, 0, 3, 3));ccm(raw, ccmatrix); //CCM, sensor RGB转sRGB，转换到人眼相适应的颜色空间，颜色较准 9 Gamma校正 产生原因: 人眼视觉特征和显示器的视觉特性不一致导致，为了使人眼看起来更加舒服，对暗区加强以提高动态范围和暗区细节 解决方法 查表法 线性插值法: 在Gamma曲线上取一些采样点进行存储, 校正时插值获取校正值 练习实录 根据Gamma值建立表, 对每个像素进行查表解决 1234567891011121314151617181920212223242526void gc(cv::Mat&amp; src, float gamma, ushort clip)&#123; clock_t begin = clock(); std::vector&lt;int&gt; LUT&#123;&#125;; for (int i = 0; i &lt; clip + 1; ++i) &#123; float lx = std::pow(((float)i / clip), (float)gamma) * (float)sdr_max_value; LUT.push_back((int)lx); &#125; cv::Vec3s* p; for (int i = 0; i &lt; src.rows; ++i) &#123; p = src.ptr&lt;cv::Vec3s&gt;(i); for (int j = 0; j &lt; src.cols; ++j) &#123; for (int k = 0; k &lt; 3; ++k) &#123; p[j][k] = ((p[j][k] &lt; 0) ? ushort(LUT[0]) : (p[j][k] &gt; clip ? ushort(LUT[clip]) : ushort(LUT[p[j][k]]))); &#125; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;GaC Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;float gamma = 0.42;gc(raw, gamma, CLIP); //GC 10 CSC 原因: 将颜色从RGB空间转换至其他空间进行处理, 通常转换至YUV空间, 以便进一步对色度和饱和度进行处理 练习实录: 将颜色转换至YUV420颜色空间, 该颜色空间下YUV三个通道相互分离 1234567891011121314151617181920212223242526272829303132void csc(cv::Mat&amp; src, cv::Mat&amp; y, cv::Mat&amp; u, cv::Mat&amp; v, float YUV420[3][4])&#123; clock_t begin = clock(); cv::Vec3s* p; float* p_YUV420; ushort* p_y, * p_u, * p_v; for (int i = 0; i &lt; src.rows; ++i) &#123; p = src.ptr&lt;cv::Vec3s&gt;(i); p_y = y.ptr&lt;ushort&gt;(i); p_u = u.ptr&lt;ushort&gt;(i); p_v = v.ptr&lt;ushort&gt;(i); for (int j = 0; j &lt; src.cols; ++j) &#123; p_y[j] = (p[j][0] * YUV420[0][0] + p[j][1] * YUV420[0][1] + p[j][2] * YUV420[0][2] + YUV420[0][3]); p_u[j] = (p[j][0] * YUV420[1][0] + p[j][1] * YUV420[1][1] + p[j][2] * YUV420[1][2] + YUV420[1][3]); p_v[j] = (p[j][0] * YUV420[2][0] + p[j][1] * YUV420[2][1] + p[j][2] * YUV420[2][2] + YUV420[2][3]); &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;CSC Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;float RGB2YUV420[3][4] = &#123; &#123;0.257, 0.504, 0.098, 16&#125;, &#123;-.148, -.291, 0.439, 128 &#125;, &#123;0.439, -.368, -.071, 128&#125;, &#125;;cv::Mat y = cv::Mat(cv::Size(raw.cols, raw.rows), CV_16U);cv::Mat u = cv::Mat(cv::Size(raw.cols, raw.rows), CV_16U);cv::Mat v = cv::Mat(cv::Size(raw.cols, raw.rows), CV_16U);csc(raw, y, u, v, RGB2YUV420); //CSC 11 NLM 对Y通道进行保边降噪 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162void nlm(cv::Mat&amp; src, uchar ds, uchar Ds, uchar h, uchar clip)&#123; clock_t begin = clock(); ushort center_y = 0, center_x = 0, start_y = 0, start_x = 0, pixel_pad = 0; double sweight = .0, average = .0, wmax = .0, w = .0, dist = .0, pixel = 0; ushort* p_src, *p_p, *p_p0, * p_neighbor, * p_center_w; uchar pads[4] = &#123; Ds, Ds, Ds, Ds &#125;; cv::Mat src_p = padding(src, pads); for (int y = 0; y &lt; src_p.rows - 2 * Ds; ++y) &#123; std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;NLM: &quot;; std::cout &lt;&lt; std::setw(6) &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; (float)y / (src_p.rows - 2) * 100 &lt;&lt; &quot;%&quot;; center_y = y + Ds; p_src = src.ptr&lt;ushort&gt;(y); p_p0 = src_p.ptr&lt;ushort&gt;(center_y); for (int x = 0; x &lt; src_p.cols - 2 * Ds; ++x) &#123; center_x = x + Ds; //calWeights sweight = .0, average = .0, wmax = .0, dist = .0; for (int m = 0; m &lt; 2 * Ds + 1 - 2 * ds - 1; ++m) &#123; start_y = center_y - Ds + ds + m; p_p = src_p.ptr&lt;ushort&gt;(start_y); for (int n = 0; n &lt; 2 * Ds + 1 - 2 * ds - 1; ++n) &#123; start_x = center_x - Ds + ds + n; pixel_pad = p_p[start_x]; if (m != center_y || n != center_x) &#123; for (int i = 0; i &lt; 2 * ds + 1; ++i) &#123; p_neighbor = src_p.ptr&lt;ushort&gt;(start_y - ds + i); p_center_w = src_p.ptr&lt;ushort&gt;(center_y - ds + i); for (int j = 0; j &lt; 2 * ds + 1; ++j) &#123; dist += (((p_neighbor[start_x - ds + j] - p_center_w[center_x - ds + j]) ^ 2) / (2 * ds + 1) ^ 2); &#125; &#125; w = exp(-dist / (h ^ 2)); if (w &gt; wmax) wmax = w; sweight += w; average += (w * pixel_pad); &#125; &#125; &#125; average += (wmax * p_p0[center_x]); sweight += wmax; pixel = average / sweight; pixel = (pixel &lt;= 0) ? 0 : (pixel &gt;= clip ? clip : pixel); p_src[x] = (ushort)pixel; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;NLM Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;uchar nlm_dw = 1;uchar nlm_Dw = 3;uchar nlm_thres = 10;float bnf_dw[5][5] = &#123; &#123;0.5, 0.75, 2, 0.75, 0.5 &#125;, &#123;0.75, 4, 8, 4, 0.75&#125;, &#123;2, 4, 64, 4, 2&#125;, &#123;0.75, 4, 8, 4, 0.75&#125;, &#123;0.5, 0.75, 2, 0.75, 0.5 &#125;,&#125;;nlm(y, nlm_dw, nlm_Dw, nlm_thres, CLIP); //NLM 12 BNF 双边滤波：非线性滤波，结合图像的空间邻近度和像素相似度的折中处理，同时考虑空间与信息和灰度相似度，达到保边去噪的目的； 方法：使用两个滤波器（一个函数由几何空间距离决定滤波器系数，另一个由像素差值决定滤波器系数） g(i,j)=∑k,lf(k,l)w(i,j,k,l)∑k,lw(i,j,k,l)g(i, j)=\\frac{\\sum_{k, l} f(k, l) w(i, j, k, l)}{\\sum_{k, l} w(i, j, k, l)}g(i,j)=∑k,l​w(i,j,k,l)∑k,l​f(k,l)w(i,j,k,l)​ w(i,j,k,l)=exp⁡(−(i−k)2+(j−l)22σd2−∥f(i,j)−f(k,l)∥22σr2)w(i, j, k, l)=\\exp \\left(-\\frac{(i-k)^2+(j-l)^2}{2 \\sigma_d^2}-\\frac{\\|f(i, j)-f(k, l)\\|^2}{2 \\sigma_r^2}\\right)w(i,j,k,l)=exp(−2σd2​(i−k)2+(j−l)2​−2σr2​∥f(i,j)−f(k,l)∥2​). 简单来说双边滤波模板组合由两个模板生成：第一个为高斯模板，第二个为以灰度级的插值作为函数系数生成的模板，两模板点乘即可得到最终滤波模板 可以很好的保留图像边缘细节而滤除掉低频分量的噪声，但效率较低，花费时间较长 练习实录 使用双边滤波进一步保边降噪 1234567891011121314151617181920212223242526272829303132333435363738394041void bnf(cv::Mat&amp; src, uchar sigmoid_s, uchar sigmoid_p, ushort clip)&#123; clock_t begin = clock(); uchar pads[4] = &#123; 2, 2, 2, 2 &#125;; cv::Mat src_p = padding(src, pads); int sum_weight = 0, sum_imgA = 0; ushort pixel_center = 0; double dive = .0, w = .0; ushort* p, * p_p; for (int y = 0; y &lt; src_p.rows - 4; ++y) &#123; std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;BNF: &quot;; std::cout &lt;&lt; std::setw(6) &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; (float)y / (src_p.rows - 4) * 100 &lt;&lt; &quot;%&quot;; p = src.ptr&lt;ushort&gt;(y); for (int x = 0; x &lt; src_p.cols - 4; ++x) &#123; pixel_center = src_p.ptr&lt;ushort&gt;(y + 2)[x + 2]; sum_imgA = 0; sum_weight = 0; dive = .0; for (int i = 0; i &lt; 5; ++i) &#123; p_p = src_p.ptr&lt;ushort&gt;(y + i); for (int j = 0; j &lt; 5; ++j) &#123; w = exp(-((abs(p_p[x + j] - pixel_center)) ^ 2) / 2 / sigmoid_p ^ 2) * exp(-((2 - i) ^ 2 + (2 - j) ^ 2) / 2 / sigmoid_s); sum_imgA += p_p[x + j] * w; sum_weight += w; &#125; &#125; dive = sum_imgA / sum_weight; dive = (dive &lt; 0) ? 0 : (dive &gt; clip ? clip : dive); p[x] = (ushort)dive; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;BNF Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;uchar bnf_s_p = 5;uchar bnf_s_s = 5;bnf(y, bnf_s_s, bnf_s_p, CLIP); //BNF 13 EE 练习实录 使用边缘增强增强边缘 通过使用拉普拉斯算子提取出边缘信息, 使用Gain值将边缘增加到原图上 1234567891011121314151617181920212223242526272829303132333435363738void ee(cv::Mat&amp; src, cv::Mat&amp; edgemap, char edge_filter[3][5], ushort clip)&#123; clock_t begin = clock(); uchar pads[4] = &#123; 1,1,2,2 &#125;; cv::Mat src_p = padding(src, pads); double em_img, ee_img, tmp_em_img; ushort* p_src, * p_edgemap; for (int y = 0; y &lt; src_p.rows - 2; ++y) &#123; std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;EEH: &quot;; std::cout &lt;&lt; std::setw(6) &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; (float)y / (src_p.rows - 4) * 100 &lt;&lt; &quot;%&quot;; p_edgemap = edgemap.ptr&lt;ushort&gt;(y); p_src = src.ptr&lt;ushort&gt;(y); for (int x = 0; x &lt; src_p.cols - 4; ++x) &#123; em_img = 0.0; for (int i = 0; i &lt; 3; ++i) &#123; for (int j = 0; j &lt; 5; ++j) &#123; em_img += src_p.ptr&lt;ushort&gt;(y + i)[x + j] * edge_filter[i][j]; &#125; &#125; em_img = em_img / 8; ee_img = src_p.ptr&lt;ushort&gt;(y + 1)[x + 2] + em_img; ee_img = (ee_img &lt; 0) ? 0 : (ee_img &gt; clip ? clip : ee_img); p_edgemap[x] = (ushort)em_img; p_src[x] = (ushort)ee_img; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;\\r&quot; &lt;&lt; &quot;EEH Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;char edge_filter[3][5] = &#123; &#123;-1, 0, -1, 0, -1&#125;, &#123;-1, 0, 8, 0, -1&#125;, &#123;-1, 0, -1, 0, -1&#125; &#125;;cv::Mat edge_map = cv::Mat(cv::Size(y.cols, y.rows), CV_16U);ee(y, edge_map, edge_filter, CLIP); //EE 14 BCC 练习实录 调节y通道的亮度和对比度 算法流程: 对每个通道的值, 分别加上亮度增益 对比度调节时, 将像素值减一个中间值(255/2=127255/2=127255/2=127), 随后使用原像素值加乘以对比度的差值pixel+(pixel−127)∗contrastpixel+(pixel-127)*contrastpixel+(pixel−127)∗contrast 12345678910111213141516171819202122void bcc(cv::Mat&amp; src, uchar brightness, uchar contrast, ushort bcc_clip)&#123; clock_t begin = clock(); contrast = contrast / (2 ^ 5); ushort* p; int pixel; for (int y = 0; y &lt; src.rows; ++y) &#123; p = src.ptr&lt;ushort&gt;(y); for (int x = 0; x &lt; src.cols; ++x) &#123; pixel = p[x]; pixel = pixel + brightness + (pixel - 127) * contrast; pixel = (pixel &lt; 0) ? 0 : (pixel &gt; bcc_clip ? bcc_clip : pixel); p[x] = (ushort)pixel; &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;BCC Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;uchar brightness = 10;uchar contrast = 10;bcc(y, brightness, contrast, CLIP); //BCC 15 转换并存储 1234567891011121314151617181920212223void yuv2rgb(cv::Mat&amp; src, cv::Mat&amp; y, cv::Mat&amp; u, cv::Mat&amp; v)&#123; clock_t begin = clock(); ushort* p_y, * p_u, * p_v; cv::Vec3s* p; for (int i = 0; i &lt; src.rows; ++i)&#123; p = src.ptr&lt;cv::Vec3s&gt;(i); p_y = y.ptr&lt;ushort&gt;(i); p_u = u.ptr&lt;ushort&gt;(i); p_v = v.ptr&lt;ushort&gt;(i); for (int j = 0; j &lt; src.cols; ++j)&#123; p[j][0] = cv::saturate_cast&lt;ushort&gt;(p_y[j] + 1.402 * (p_v[j] - 128)); // R p[j][1] = cv::saturate_cast&lt;ushort&gt;(p_y[j] - 0.34413 * (p_u[j] - 128) - 0.71414 * (p_v[j] - 128)); // G p[j][2] = cv::saturate_cast&lt;ushort&gt;(p_y[j] + 1.772 * (p_u[j] - 128)); // B &#125; &#125; clock_t end = clock(); std::cout &lt;&lt; &quot;Y2R Done! Elapsed &quot; &lt;&lt; double(end - begin) / CLOCKS_PER_SEC * 1000 &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;&#125;yuv2rgb(raw, y, u, v);raw.convertTo(raw, CV_8UC3);cv::imwrite(&quot;result.png&quot;, raw);","categories":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"}],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"}]},{"title":"手撕代码篇","slug":"手撕代码篇","date":"2023-04-06T01:55:18.000Z","updated":"2023-05-06T16:12:51.054Z","comments":true,"path":"2023/04/06/手撕代码篇/","link":"","permalink":"http://jay1060950003.github.io/2023/04/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81%E7%AF%87/","excerpt":"引言 在准备面试时的手撕代码记录","text":"引言 在准备面试时的手撕代码记录 排序算法 冒泡排序 选择排序 插入排序 希尔排序 归并排序 快速排序 堆排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177#include &lt;iostream&gt;#include &lt;vector&gt;// 冒泡排序void bubble_sort(std::vector&lt;int&gt;&amp; array)&#123; int array_ = 0; bool exchange = false; for(int i=0;i&lt;array.size()-1;++i)&#123; exchange = false; for(int j=0;j&lt;array.size()-1-i;++j)&#123; if(array[j] &gt; array[j+1])&#123; array_ = array[j+1]; array[j+1] = array[j]; array[j] = array_; exchange = true; &#125; &#125; if(!exchange) break; // 如果没有进行交换, 提前结束 &#125;&#125;// 选择排序void select_sort(std::vector&lt;int&gt;&amp; array)&#123; int array_ = 0; for(int i=0;i&lt;array.size()-1;++i)&#123; for(int j=i;j&lt;array.size();++j)&#123; if(array[j] &lt; array[i])&#123; array_ = array[j]; array[j] = array[i]; array[i] = array_; &#125; &#125; &#125;&#125;// 插入排序void insert_sort(std::vector&lt;int&gt;&amp; array)&#123; int array_ = 0; for(int i=1;i&lt;array.size();++i)&#123; //从下标为1的元素开始进行 int array_ = array[i]; //记录待插入元素 int j; //从已排序序列的最右边开始查找, 找到比待插入元素最小的元素位置 for(j=i;j&gt;=1 &amp;&amp; array_&lt;array[j-1];j--)&#123; array[j] = array[j-1]; &#125; array[j] = array_; //插入 &#125;&#125;// 希尔排序void hill_sort(std::vector&lt;int&gt;&amp; array)&#123; int array_ = 0; for(int step = array.size()/2;step&gt;0;step/=2)&#123; for(int i=0;i&lt;step;i++)&#123; std::cout &lt;&lt; &quot;step: &quot; &lt;&lt; step &lt;&lt; &quot;&quot;; //使用直接插入排序进行 for(int j=i+step;j&lt;array.size();j+=step)&#123; array_ = array[j]; int m; for(m=j;m&gt;=step &amp;&amp; array_ &lt; array[m-step];m-=step) array[m] = array[m-step]; array[m] = array_; &#125; for(auto i : array) std::cout &lt;&lt; i &lt;&lt; &#x27; &#x27;; std::cout &lt;&lt; std::endl; &#125; &#125;&#125;void merge(std::vector&lt;int&gt;&amp; array, int left, int mid, int right)&#123; // 采用分治思想 std::vector&lt;int&gt; array_(array.size()); int i=left, j=mid+1,k=0; while(i&lt;=mid &amp;&amp; j&lt;=right)&#123; if(array[i] &lt;= array[j])&#123; // 从小到大存放在array_中 array_[k++] = array[i++]; &#125;else&#123; array_[k++] = array[j++]; &#125; &#125; // 剩余元素存放 while (i&lt;=mid) &#123; array_[k++] = array[i++]; &#125; while(j&lt;=right)&#123; array_[k++] = array[j++]; &#125; // 数据转移 k = 0; for(int i=left;i&lt;=right;i++)&#123; array[i] = array_[k++]; &#125;&#125;// 归并排序void merge_sort(std::vector&lt;int&gt;&amp; array, int left, int right)&#123; if(left &lt; right)&#123; int mid = left + (right-left)/2; merge_sort(array, left, mid); merge_sort(array, mid+1, right); merge(array, left, mid, right); &#125;&#125;// 快速排序void quick_sort(std::vector&lt;int&gt;&amp; array, int left, int right)&#123; if(left &gt;= right) return; int lp = left; int rp = right; int pivot = array[lp]; while(lp &lt; rp)&#123; // 寻找比基准小的值, 并交换 while(lp &lt; rp &amp;&amp; array[rp] &gt;= pivot)&#123; rp--; &#125; if(lp &lt; rp) array[lp] = array[rp]; // 寻找比基准大的值, 并交换 while(lp &lt; rp &amp;&amp; array[lp] &lt;= pivot)&#123; lp++; &#125; if(lp &lt; rp) array[rp] = array[lp]; // 重合, 赋值 if(lp == rp) array[lp] = pivot; &#125; quick_sort(array, left, lp-1); // 基准左侧 quick_sort(array, lp+1, right); // 基准右侧&#125;void heapify(std::vector&lt;int&gt;&amp; array, int n, int i)&#123; if(i&gt;=n) return; int largest = i; int lson = i*2+1; int rson = i*2+2; int array_ = 0; if(lson &lt; n &amp;&amp; array[largest] &lt; array[lson])&#123; largest = lson; &#125; if(rson &lt; n &amp;&amp; array[largest] &lt; array[rson])&#123; largest = rson; &#125; if(largest!=i)&#123; array_ = array[i]; array[i] = array[largest]; array[largest] = array_; heapify(array, n, largest); &#125;&#125;// 堆排序void heap_sort(std::vector&lt;int&gt;&amp; array)&#123; int lastNode = array.size()-1; int parent = (lastNode-1)/2; for(int i=parent;i&gt;=0;i--)&#123; heapify(array, array.size(), i); &#125; for(int i=array.size()-1;i&gt;=0;--i)&#123; heapify(array, i, 0); &#125;&#125;int main()&#123; std::vector&lt;int&gt; array&#123;3,4,2,5,6,1,7,9,8,0,0,1,30,20,0,-5&#125;; // int array[10] = &#123;3,4,2,5,6,1,7,9,8,0&#125;; std::cout &lt;&lt; &quot;original: &quot; &lt;&lt; std::endl; for(auto i : array) std::cout &lt;&lt; i &lt;&lt; &#x27; &#x27;; std::cout &lt;&lt; std::endl; // merge_sort(array, 0, array.size()-1); quick_sort(array, 0, array.size()-1); std::cout &lt;&lt; &quot;\\nafter:&quot; &lt;&lt; std::endl; for(auto i : array) std::cout &lt;&lt; i &lt;&lt; &#x27; &#x27;;&#125; 深度学习基础","categories":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"}],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"}]},{"title":"专业相关知识补缺","slug":"专业相关知识补缺","date":"2023-03-15T01:21:41.000Z","updated":"2023-05-07T08:19:33.273Z","comments":true,"path":"2023/03/15/专业相关知识补缺/","link":"","permalink":"http://jay1060950003.github.io/2023/03/15/%E4%B8%93%E4%B8%9A%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E8%A1%A5%E7%BC%BA/","excerpt":"引言 部分光学相关知识的补充 数字图像处理知识的补充 图像降噪算法专题","text":"引言 部分光学相关知识的补充 数字图像处理知识的补充 图像降噪算法专题 1 基础知识点 直方图处理 令 rk(k=0,1,2...L−1)r_k(k = 0,1,2...L-1)rk​(k=0,1,2...L−1) 表示一幅LLL级灰度数字图像 f(x,y)f(x,y)f(x,y) 的灰度. fff 的非归一化直方图定义为: h(rk)=nk,k=0,1,2...L−1h(r_{k}) = n_{k}, k = 0,1,2...L-1h(rk​)=nk​,k=0,1,2...L−1 式中,nkn_knk​是fff中灰度为rkr_krk​的像素的数量,并且细分的灰度级称为直方图容器 归一化直方图定义为 p(rk)=h(rk)MN=nkMNp(r_{k}) = \\frac{h(r_{k})}{MN} = \\frac{n_{k}}{MN}p(rk​)=MNh(rk​)​=MNnk​​ 式中, MMM和NNN分别是图像的行数和列数.对kkk的所有值, p(rk)p(r_{k})p(rk​)的和总是1 像素占据整个灰度级范围并且均匀分布的图像, 将具有高对比度的外观和多种灰色调 直方图均衡化 由像素累计概率确定对应的新像素值 直方图均衡化的目的: 为了生成一幅具有均匀直方图的输出图像 变换函数: sk=T(rk)=(L−1)∑j=0kpr(rj),k=0,1,2,⋯ ,L−1s_k=T\\left(r_k\\right)=(L-1) \\sum_{j=0}^k p_r\\left(r_j\\right), \\quad k=0,1,2, \\cdots, L-1sk​=T(rk​)=(L−1)∑j=0k​pr​(rj​),k=0,1,2,⋯,L−1 直方图均衡化改变的只是对比度并非内容 直方图匹配(规范化) 寻找累计概率密度最相近的像素值作为新像素值 定义: 用于生成具有规定直方图的图像的方法 局部直方图处理 目的: 解决增强图像中几个小区域的细节 解决方法: 设计基于像素邻域的灰度分布的变换函数 局部直方图的处理过程: 定义一个邻域, 并将其中心在水平方向或垂直方向上从一个像素移动到另一个像素 在每个位置, 计算邻域中的各点的直方图, 得到直方图均衡化或直方图规定化变换函数, 将这个函数映射于邻域中心点像素的灰度 然后将邻域的中心移到一个相邻像素位置, 并重复上述过程 图像均值和方差的含义 均值是平均灰度的测度 方差(或标准差)是图像对比度的测度 简单理解：均值越大, 图像越亮; 方差越大, 图像对比度越高 MTF的理解 MTF为调制传递函数, 为分辨率和对比度两者间的关系 分辨率单位为每毫米线对(lp/mm), 对比度定义为最小与最大强度值从物平面传输到像平面的程度 MTF是衡量其在特定分辨率下将对比度从物体转移到图像的能力, 随着测试目标上的线间距减小(频率增加), 镜头越来越难以有效地传递对比度,结果MTF下降 MTF会随着空间分辨率地增加而降低 刃边法SFR求MTF 对黑白斜边超采样得到ESF(边缘扩散函数) 对ESF求导得到直线的变化率LSF(线扩散函数) 对LSF进行FFT变换得到各个频率下MTF PSF,LSF,ESF PSF(点扩散函数): 为点光源成像后的亮度分布函数, 点扩散函数是中心圆对称 ESF(边缘扩散函数): 为一条由白到黑的线 LSF(线扩散函数) 当获取点光源的亮度分布函数PSF(x,y)后, 对其进行二维傅里叶变换即可得到MTF 但由于实际中点光源强度很弱, 一般较少采用 相对于PSF而言, LSF能量得到一定加强, 因此用LSF更好 膨胀, 腐蚀, 开运算, 闭运算 膨胀 利用卷积核B对图像A进行卷积操作, 卷积核可以是任意形状或大小 卷积核B通常有一个自定义的参考点, 一般位于中心位置 膨胀是求局部最大值的操作: 当卷积核B扫描图像A与其进行卷积操作时, 计算模板B覆盖的区域的最大值并将最大值赋给模板的参考点. 因为图像中亮点的灰度值大, 所以膨胀操作会使得图像中的高亮区域逐渐增长 腐蚀 膨胀的反操作, 腐蚀计算的是局部区域的最小值 将卷积核B与图像A进行卷积, 将B所覆盖区域的最小值赋给参考点 腐蚀操作会使得图像中亮的区域变小, 暗的区域变大 开运算: 先腐蚀再膨胀 开运算可以移除较小的明亮区域, 在较细的地方分离物体(假设小物体是亮色, 关注的前景是黑色, 可以使用开运算移出亮点) 闭操作: 先膨胀再腐蚀 闭运算可以填充五体内的细小空洞, 连接邻近的明亮物体 顶帽操作: 原图与开操作的差 局部亮度极大点被分割出来(可以分两步理解, 开操作移除了明亮的小区域, 当用原图减去开操作的结果之后, 之前被移除的明亮区域就会凸显出来, 因此看到的效果就是一些亮度较大的小区域) 黑帽操作: 闭操作与原图的差 局部黑色的洞被分割出来 边缘检测算子及其对比 绝大多数的边缘检测方法可以分为两类: 基于查找的方法和基于零穿越的方法 基于查找的方法: 通过寻找图像一阶导数中的最大和最小值来检测边缘, 通常是将边界定位在梯度最大的方向 基于零穿越的方法: 通过寻找图像二阶导数零穿越来寻找边界, Laplacian过零点或非线性差分表示的过零点 Canny算子 Roberts算子 利用局部交叉差分寻找边缘的算子, 常用来处理具有陡峭的低噪声图像, 当图像边缘接近于正45度或负45度时, 该算法处理效果更理想 优点: 从图像处理的实际效果看, 边缘定位较准, 对噪声敏感, 适用于边缘明显且噪声较小的图像分割 缺点: 提取的边缘线条较粗 gx=∂f∂x=P9−P5gy=∂f∂y=P8−P6g_x = \\frac{\\partial f}{\\partial x}=P9-P5 \\\\ g_y = \\frac{\\partial f}{\\partial y} =P8-P6gx​=∂x∂f​=P9−P5gy​=∂y∂f​=P8−P6 在代码实现方面, 便可以如同卷积一样构造两个滤波器矩阵对图像进行卷积, 假设使用第一个模板卷积后得到的结果为 fyf_yfy​ , 使用第二个模板卷积后得到的结果为 fxf_xfx​ , 那么最终的结果为这两个中间结果的加权平均, 例如 0.5∗fx+0.5∗fy0.5*f_x +0.5*f_y0.5∗fx​+0.5∗fy​ Prewitt算子 采用3*3模板对区域内的像素值进行计算, 在水平方向和垂直方向均比Roberts算子更加明显, 适合用来识别噪声较多灰度渐变的图像 优点: Prewitt算子对噪声有抑制作用, 抑制噪声的原理是通过像素平均 缺点: 该算子具有平滑的作用, 但是像素平均相当于对图像的低通滤波, 所以Prewitt算子对边缘的定位不如Roberts算子 gx=∂f∂x=(P7+P8+P9)−(P1+P2+P3)gy=∂f∂y=(P3+P6+P9)−(P1+P4+P7)g_x = \\frac{\\partial f}{\\partial x}=(P7+P8+P9)-(P1+P2+P3) \\\\ g_y = \\frac{\\partial f}{\\partial y}=(P3+P6+P9)-(P1+P4+P7)gx​=∂x∂f​=(P7+P8+P9)−(P1+P2+P3)gy​=∂y∂f​=(P3+P6+P9)−(P1+P4+P7) Sobel算子 Sobel算子在Prewitt算子的基础上增加了权重的概念, 认为相邻点的距离远近对当前像素点的影响是不同的, 距离越近的像素点对应当前像素的影响越大, 从而实现图像锐化并突出边缘轮廓 Sobel算子结合了高斯平滑和微分求导, 因此结果会具有更多的抗噪性, 当对精度要求不是很高时, Sobel算子是一种较为常用的边缘检测方法 优点：由于该算子中引入了类似局部平均的运算, 因此对噪声具有平滑作用, 能很好的消除噪声的影响, 边缘定位效果不错. Sobel算子对于象素的位置的影响做了加权, 与Prewitt算子、Roberts算子相比因此效果更好 缺点：但检测出的边缘容易出现多像素宽度 gx=∂f∂x=(P7+2∗P8+P9)−(P1+2∗P2+P3)gy=∂f∂y=(P3+2∗P6+P9)−(P1+2∗P4+P7)g_x = \\frac{\\partial f}{\\partial x}=(P7+2*P8+P9)-(P1+2*P2+P3) \\\\ g_y = \\frac{\\partial f}{\\partial y}=(P3+2*P6+P9)-(P1+2*P4+P7)gx​=∂x∂f​=(P7+2∗P8+P9)−(P1+2∗P2+P3)gy​=∂y∂f​=(P3+2∗P6+P9)−(P1+2∗P4+P7) Laplacian算子 各向同性算子, 不能检测出边的方向, 对孤立像素的响应要比对边缘或线的相应更强烈, 只适用于无噪声图像; 存在噪声的情况下, 使用Laplace算子检测之前需低通滤波 Laplacian算子一般不用于边的检测, 常用来判断边缘像素位于图像的明区或暗区 定义: Laplacian(f)=∂2f∂x2+∂2f∂y2Laplacian(f)=\\frac{\\partial^2f}{\\partial x^2}+\\frac{\\partial^2f}{\\partial y^2}Laplacian(f)=∂x2∂2f​+∂y2∂2f​ ∂2f∂x2=f(x+1)−f(x)∂x=[f(x+1)−f(x)]−[f(x)−f(x−1)]∂2f∂y2=f(y+1)−f(y)∂y=[f(y+1)−f(y)]−[f(y)−f(y−1)]\\frac{\\partial^2f}{\\partial x^2} = \\frac{f(x+1)-f(x)}{\\partial x} = [f(x+1)-f(x)]-[f(x)-f(x-1)] \\\\ \\frac{\\partial^2f}{\\partial y^2} = \\frac{f(y+1)-f(y)}{\\partial y} = [f(y+1)-f(y)]-[f(y)-f(y-1)]∂x2∂2f​=∂xf(x+1)−f(x)​=[f(x+1)−f(x)]−[f(x)−f(x−1)]∂y2∂2f​=∂yf(y+1)−f(y)​=[f(y+1)−f(y)]−[f(y)−f(y−1)] ∇2(f)=∂2f∂x2+∂2f∂y2=[f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)]−4f(x,y)\\nabla^2(f)=\\frac{\\partial^2f}{\\partial x^2}+\\frac{\\partial^2f}{\\partial y^2} =[f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)]-4f(x,y)∇2(f)=∂x2∂2f​+∂y2∂2f​=[f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)]−4f(x,y) 该算子对孤立点或端点更为敏感, 因此特别适用于以突出图像中的孤立点、孤立线或线端点为目的的场合. 同梯度算子一样, 拉普拉斯算子也会增强图像中的噪声, 有时用拉普拉斯算子进行边缘检测时, 可将图像先进行平滑处理 Laplacian算子进行边缘检测并没有像Sobel或Prewitt那样的平滑过程, 所以它会对噪声产生较大的响应, 并且无法分别得到水平方向、垂直方向或者其他固定方向的的边缘. 但是它只有一个卷积核, 所以计算成本会更低 Laplacian锐化 由于拉普拉斯是一种微分算子, 它的应用可增强图像中灰度突变的区域, 减弱灰度的缓慢变化区域. 因此, 锐化处理可选择拉普拉斯算子对原图像进行处理, 产生描述灰度突变的图像, 再将拉普拉斯图像与原始图像叠加而产生锐化图像 g(x,y)={f(x,y)−∇2f(x,y) 如果拉普拉斯掩模中心系数为负 f(x,y)+∇2f(x,y) 如果拉普拉斯掩模中心系数为正 g(x, y)= \\begin{cases}f(x, y)-\\nabla^2 f(x, y) &amp; \\text { 如果拉普拉斯掩模中心系数为负 } \\\\ f(x, y)+\\nabla^2 f(x, y) &amp; \\text { 如果拉普拉斯掩模中心系数为正 }\\end{cases}g(x,y)={f(x,y)−∇2f(x,y)f(x,y)+∇2f(x,y)​ 如果拉普拉斯掩模中心系数为负 如果拉普拉斯掩模中心系数为正 ​ Canny算子 是传统图像里被用的最多的边缘检测算子 Canny提出了一个对于边缘检测算法的评价标准, 包括： 以低的错误率检测边缘, 也即意味着需要尽可能准确的捕获图像中尽可能多的边缘 检测到的边缘应精确定位在真实边缘的中心 图像中给定的边缘应只被标记一次, 并且在可能的情况下, 图像的噪声不应产生假的边缘 检测算法要做到：**边缘要全, 位置要准, 抵抗噪声的能力要强. ** 该算子求边缘点的具体算法步骤如下 用高斯滤波器平滑图像：边缘检测算子受噪声的影响都很大. 那么, 我们第一步就是想到要先去除噪声, 因为噪声就是灰度变化很大的地方, 所以容易被识别为伪边缘 用一阶偏导有限差分计算梯度幅值和方向, 例如 Sobel 对梯度幅值进行非极大值抑制：sobel算子检测出来的边缘太粗了, 我们需要抑制那些梯度不够大的像素点, 只保留最大的梯度, 从而达到瘦边的目的. 通常灰度变化的地方都比较集中, 将局部范围内的梯度方向上, 灰度变化最大的保留下来, 其它的不保留, 这样可以剔除掉一大部分的点. 将有多个像素宽的边缘变成一个单像素宽的边缘. 即“胖边缘”变成“瘦边缘” 用双阈值算法检测和连接边缘：通过非极大值抑制后, 仍然有很多的可能边缘点, 进一步的设置一个双阈值, 即低阈值（low）, 高阈值（high）. 灰度变化大于high的, 设置为强边缘像素, 低于low的, 剔除. 在low和high之间的设置为弱边缘. 对每一个弱边缘进一步判断, 如果其领域内有强边缘像素, 保留, 如果没有, 剔除 2 空间滤波基础 基础知识的注意点: 低通滤波器可以消除噪声，高通滤波器可以提取边缘 为什么0表示黑色，255表示白色：可能是模拟人眼对光线的机理，黑色表示没有光线，白色相反 图像信息的高频信息 高频信息：图像中的边缘和其他急剧的灰度变化(如噪声) 基础滤波算法 平滑(低通)空间滤波器: 通过模糊图像来平滑图像, 使用积分运算实现 用于降低灰度的急剧过度, 因为随机噪声通常是由灰度的急剧过渡组成 均值滤波：实质是归一化之后地方框滤波, 不能很好地保护图像细节, 不能很好地去除噪声点, 但对周期性地干扰噪声有很好的抑制作用 低通高斯滤波核: 高斯核是唯一可分离的圆对称核, 对于抑制服从正态分布的噪声非常有效, 可以产生更加均匀的平滑结果 锐化(高通)空间滤波器:突出灰度中的过渡, 使用微分运算实现 拉普拉斯算子: Δf=∂2f∂x2+∂2f∂y2\\Delta f= \\frac{\\partial ^{2}f}{\\partial x^{2}}+ \\frac{\\partial ^{2}f}{\\partial y^{2}}Δf=∂x2∂2f​+∂y2∂2f​ Δf=f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)−4f(x,y)\\Delta f = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1)-4f(x,y)Δf=f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)−4f(x,y) 使用拉普拉斯算子锐化图像的基本方法: g(x,y)=f(x,y)+c[∇2f(x,y)]g(x, y)=f(x, y)+c\\left[\\nabla^2 f(x, y)\\right]g(x,y)=f(x,y)+c[∇2f(x,y)] 钝化遮掩: 从原图减去钝化(平滑后)图像, 可以用来锐化图像 步骤： 模糊原图像 从原图像减去模糊后的图像(产生的差称为模板) 将模板与原图像相加 使用罗伯特交叉梯度算子和Sobel算子 使用一阶梯度算子锐化图像咳用于工业缺陷检测 使用拉普拉斯算子来突出图像细节, 使用梯度来增强突出边缘 双边滤波与导向滤波 双边滤波和引导(导向)滤波都是保边滤波器, 能在滤波过程中有效的保留图像中的边缘信息 双边滤波器 同时考虑了像素空间的差异与强度差异的滤波器, 具有保持图像边缘的特征 与高斯滤波器相比, 在原有高斯函数基础上增加一项使权重与图像边缘梯度相关, 不仅仅与空间距离相关, 且与灰度距离相关 BF=1Wq∑p∈SGs(p)Gr(p)∗Ip=1Wq∑p∈Sexp⁡(−∥p−q∥22σs2)exp⁡(−∥Ip−Iq∥22σr2)∗Ip\\begin{aligned} B F &amp; =\\frac{1}{W_q} \\sum_{p \\in S} G_s(p) G_r(p) * I_p \\\\ &amp; =\\frac{1}{W_q} \\sum_{p \\in S} \\exp \\left(-\\frac{\\|p-q\\|^2}{2 \\sigma_s^2}\\right) \\exp \\left(-\\frac{\\left\\|I_p-I_q\\right\\|^2}{2 \\sigma_r^2}\\right) * I_p \\end{aligned}BF​=Wq​1​p∈S∑​Gs​(p)Gr​(p)∗Ip​=Wq​1​p∈S∑​exp(−2σs2​∥p−q∥2​)exp(−2σr2​∥Ip​−Iq​∥2​)∗Ip​​ 引导(导向)滤波器 引导滤波的思想用一张引导图像产生权重, 从而对输入图像进行处理 保边滤波后的结果和引导图像在滤波窗口内呈现线性关系: qi=akIi+bk,∀i∈ωkq_i=a_k I_i+b_k,\\forall i \\in \\omega_kqi​=ak​Ii​+bk​,∀i∈ωk​, III是引导图像, qqq是输出, ω\\omegaω是以kkk为中心像素的窗口, aaa和bbb都为该窗口对应的线性系数 期望aaa和bbb随着图像内容变化, 在边缘区域,aaa尽量大,保持梯度;在平滑区域aaa尽量小,以尽量平滑. 利用带有正则项的岭回归模型求解: E(ak,bk)=∑i∈ωk((akIi+bk−pi)2+ϵak2)E(a_k, b_k)=\\sum_{i \\in \\omega_k}((a_k I_i+b_k-p_i)^2+\\epsilon a_k^2)E(ak​,bk​)=∑i∈ωk​​((ak​Ii​+bk​−pi​)2+ϵak2​) 求解上述方程,可以得到: ak=1∣ω∣∑i∈ωkIipi−μkpˉkσk2+ϵa_k=\\frac{\\frac{1}{|\\omega|} \\sum_{i \\in \\omega_k} I_i p_i-\\mu_k \\bar{p}_k}{\\sigma_k^2+\\epsilon}ak​=σk2​+ϵ∣ω∣1​∑i∈ωk​​Ii​pi​−μk​pˉ​k​​, bk=pˉk−akμkb_k=\\bar{p}_k-a_k \\mu_kbk​=pˉ​k​−ak​μk​, qi=1∣ω∣∑k∣i∈ωk(akIi+bk)q_i=\\frac{1}{|\\omega|} \\sum_{k \\mid i \\in \\omega_k}(a_k I_i+b_k)qi​=∣ω∣1​∑k∣i∈ωk​​(ak​Ii​+bk​) 在公式中, μk\\mu_kμk​ 与 σk\\sigma_kσk​ 表示 IiI_iIi​ 在窗口内的均值、标准差, ∣w∣|w|∣w∣ 表示窗口内像素块的总数, pk‾\\overline{p_k}pk​​ 表示窗口内输入图像 ppp 的均值 最终算法: mean⁡I=fmean (I)mean⁡p=fmean (p)corr⁡I=fmean (I.∗I)corr⁡Ip=fmean (I.∗p)\\begin{aligned} &amp; \\operatorname{mean}_I=f_{\\text {mean }}(I) \\\\ &amp; \\operatorname{mean}_p=f_{\\text {mean }}(p) \\\\ &amp; \\operatorname{corr}_I=f_{\\text {mean }}(I . * I) \\\\ &amp; \\operatorname{corr}_{I p}=f_{\\text {mean }}(I . * p)\\end{aligned}​meanI​=fmean ​(I)meanp​=fmean ​(p)corrI​=fmean ​(I.∗I)corrIp​=fmean ​(I.∗p)​ var⁡I=corr⁡I−mean⁡I⋅mean⁡Icov⁡Ip=corr⁡Ip−mean⁡I⋅mean⁡p\\begin{aligned} &amp; \\operatorname{var}_I=\\operatorname{corr}_I-\\operatorname{mean}_I \\cdot \\operatorname{mean}_I \\\\ &amp; \\operatorname{cov}_{I p}=\\operatorname{corr}_{I p}-\\operatorname{mean}_I \\cdot \\operatorname{mean}_p\\end{aligned}​varI​=corrI​−meanI​⋅meanI​covIp​=corrIp​−meanI​⋅meanp​​ a=cov⁡Ip⋅/(var⁡I+ϵ)b=mean⁡p−a.∗mean⁡I\\begin{aligned} &amp; a=\\operatorname{cov}_{I p} \\cdot /\\left(\\operatorname{var}_I+\\epsilon\\right) \\\\ &amp; b=\\operatorname{mean}_p-a . * \\operatorname{mean}_I\\end{aligned}​a=covIp​⋅/(varI​+ϵ)b=meanp​−a.∗meanI​​ mean⁡a=fmean (a)mean⁡b=fmean (b)\\begin{aligned} \\operatorname{mean}_a &amp; =f_{\\text {mean }}(a) \\\\ \\operatorname{mean}_b &amp; =f_{\\text {mean }}(b)\\end{aligned}meana​meanb​​=fmean ​(a)=fmean ​(b)​ q=mean⁡a∗I+mean⁡bq=\\operatorname{mean}_a * I+\\operatorname{mean}_bq=meana​∗I+meanb​ fmeanf_{mean}fmean​为窗口半径为rrr的均值滤波 图像的抗混叠滤波 因为无法对图像无限地取样，因此在数字图像中总会出现混叠 混叠：空间混叠和时间混叠 空间混叠：由欠采样引起的，主要问题是引入伪影，即原始图像中未出现的线条锯齿、虚假高光和频率模式 时间混叠：与动态图像序列中图像的时间间隔相关，如车轮效应 在重取样之前使用低通滤波器进行平滑，以衰减图像的高频分量，可以有效地抑制混叠，但图像清晰度下降 常见的三种图像插值方法 最近邻插值: 在待求像素的四邻域中, 将距离待求像素最近的邻像素的灰度值赋给待求像素 双线性插值: 利用待求像素四个相邻像素的灰度在两个方向上做线性插值 三次内插法: 利用三次多项式求逼近理论上的最佳插值函数, 待求像素(x,y)的灰度值由其周围16个灰度值加权内插得到 图像降噪算法专题 空间域滤波降噪 该方法主要针对随机噪声 空间域滤波降噪的方法主要是通过分析在一定窗口大小内中心像素和其他相邻像素之间的直接联系，来获取新的中心像素值的方法 算术均值滤波 算术均值滤波：用像素邻域的平均值代替像素值，适用于脉冲噪声（灰度级一般与周围像素的灰度级不相关，且亮度高出其他像素值许多）；频域角度考虑，均值滤波器为低通滤波器，可以帮助消除图像尖锐噪声实现图像平滑模糊 方法：取待处理像素的L邻域计算平均灰度以替代其像素值；均值滤波效果随L的增大而变得模糊，图像对比度随之降低 优点：适用于具有一般随机干扰的信号（信号在平均值附近波动） 缺点：耗费RAM资源，计算速度较慢 1void cv::blur(InputArray src, OutputArray dst, Size ksize, Point anchor = Point(-1,-1), int borderType = BORDER_DEFAULT) 为提高均值滤波器的效果： 增加对边缘方向的判断，以提高锐度，但做均值的像素减少去噪效果下降； 提出NLM(none local mean)算法进行降噪 中值滤波 中值滤波器：使用像素邻域内的中值代替像素值。由于中值滤波不会处理最大值和最小值，故不会受到噪声的影响。也可用于处理边缘信息；但中值滤波器会清除掉某些区域的纹理信息 方法：取待处理像素的L邻域计算中值以替代其像素值；对椒盐噪声的消除效果好于均值滤波 优点：能克服偶然因素引起的波动干扰 缺点：当噪声像素个数大于窗口像素总数的一半时，由于中值仍为噪声像素灰度值，滤波效果较差；若加大窗口尺寸，会使得原边缘像素被其他区域像素代替使图像变得模糊加大运算量 由于窗口大小固定，中值滤波不能兼顾去噪和保护图像细节 自适应中值滤波(Adaptive Median Filter)，会自动调节窗口大小，并判断像素是否为噪声需要处理 1void medianBlur(InputArray src, OutputArray dst, int ksize); 高斯滤波器 高斯滤波与均值滤波的区别： 均值滤波中，滤波器的各个像素的权重相同，滤波器为线性滤波器；高斯滤波器中的像素的权重与其距中心的距离成比例，高斯滤波器为非线性滤波器 高斯滤波考虑了空间距离对中心像素的影响, 添加了空间权重, 因此边缘较均值滤波更锐利 高斯滤波：高斯滤波矩阵的权值，随着与中心像素点的距离增加，而呈现高斯衰减的变换特性；离算子中心很远的像素点的作用很小，从而能在一定程度上保持图像的边缘特征 方法：与均值滤波相似，生成L邻域的高斯滤波算子，计算L邻域内的像素与滤波算子的卷积结果代替像素值 GB[I]p=∑q∈SGσ(∥p−q∥)IqG B[I]_{\\mathrm{p}}=\\sum_{\\mathbf{q} \\in \\mathcal{S}} G_\\sigma(\\|\\mathbf{p}-\\mathbf{q}\\|) I_{\\mathbf{q}}GB[I]p​=∑q∈S​Gσ​(∥p−q∥)Iq​ Gσ(x)=12πσ2exp⁡(−x22σ2)G_\\sigma(x)=\\frac{1}{2 \\pi \\sigma^2} \\exp \\left(-\\frac{x^2}{2 \\sigma^2}\\right)Gσ​(x)=2πσ21​exp(−2σ2x2​) 其中ppp为中心像素位置, qqq为另一个像素位置, IqI_qIq​为qqq像素像素值, 两者之间的距离使用Gσ(∣∣p−q∣∣)G_\\sigma(||p-q||)Gσ​(∣∣p−q∣∣)获取, σ\\sigmaσ决定了高斯分布的宽度, 大小决定了以ppp为中心涵盖了多少临近像素用于参与计算 对高斯噪声的滤除效果较好 1void cv::GaussianBlur(InputArray src, OutputArray dst, Size ksize, double sigmaX, double sigmaY, int borderType = BORDER_DEFAULT) 双边滤波 上述高斯滤波仅仅考虑空间位置关系, 并没有考虑图像本身像素值的变化情况(图像边缘像素值变化剧烈, 非边缘区域变化平坦), 因此需要能够衡量像素变化剧烈程度的量 双边滤波：非线性滤波，结合图像的空间邻近度和像素相似度的折中处理，同时考虑空间信息和灰度相似度(可解决图像边缘问题)，达到保边去噪的目的； 方法：使用两个滤波器（一个函数由几何空间距离决定滤波器系数，另一个由像素差值决定滤波器系数） BF[I]p=1Wp∑q∈SGσs(∥p−q∥)Gσr(Ip−Iq)IqBF[I]_{\\mathrm{p}}=\\frac{1}{W_{\\mathbf{p}}} \\sum_{\\mathbf{q} \\in \\mathcal{S}} G_{\\sigma_s}(\\|\\mathbf{p}-\\mathbf{q}\\|) G_{\\sigma_r}\\left(I_{\\mathbf{p}}-I_{\\mathbf{q}}\\right) I_{\\mathbf{q}}BF[I]p​=Wp​1​∑q∈S​Gσs​​(∥p−q∥)Gσr​​(Ip​−Iq​)Iq​ Wp=∑q∈SGσs(∥p−q∥)Gσr(Ip−Iq)W_{\\mathrm{p}}=\\sum_{\\mathrm{q} \\in \\mathcal{S}} G_{\\sigma_s}(\\|\\mathrm{p}-\\mathrm{q}\\|) G_{\\sigma_{\\mathrm{r}}}\\left(I_{\\mathrm{p}}-I_{\\mathrm{q}}\\right)Wp​=∑q∈S​Gσs​​(∥p−q∥)Gσr​​(Ip​−Iq​) 简单来说双边滤波模板组合由两个模板生成：第一个为高斯模板(离中心点远的对中心点的贡献小)，第二个为以像素值的差值作为函数系数生成的模板(像素差值越大对中心点的贡献小)，两模板点乘即可得到最终滤波模板; 第一个高斯模板只要是进行滤波操作, 而第二个以像素值差值的模板主要是进行保边操作 参数讨论 单单考虑值域上的滤波不考虑空间上高斯滤波, 值域滤波可以看作直方图变换, 使图像的值域范围朝向峰值方向压缩 σs\\sigma_sσs​与σr\\sigma_rσr​, 值越大对双边滤波器的贡献就越小, 相反值越小则贡献越大, 得到强调; σs\\sigma_sσs​变小, 则更多的是利用邻域的值进行平滑, 说明空间上的信息更加重要; σr\\sigma_rσr​变小, 则更多的是利用相似的值进行保边, 说明值域上的信息更加重要; σs\\sigma_sσs​表示的是空间上的平滑, 对没有边缘的更加合适;而σr\\sigma_rσr​强调值域的差别, 对具有边缘的区域更加重要, 减小该值以更好的保边 σs\\sigma_sσs​变大, 图像每个区域的权重更多源于值域滤波的权重, 对空间邻域信息不敏感 σr\\sigma_rσr​变大, 图像每个区域的权重更多源于空间距离的权重, 相似于高斯滤波, 对空间邻域信息不敏感, 保边性能下降 需要去除平滑区域的噪声, 应提高σs\\sigma_sσs​, 而需要保持边缘, 应减小σr\\sigma_rσr​ 可以很好的保留图像边缘细节而滤除掉低频分量的噪声，但效率较低，花费时间较长 1void bilateralFilter(InputArray src, OutputArray dst, int d, double sigmaColor, double sigmaSpace, int borderType=BORDER_DEFAULT ) 引导滤波 引导滤波(导向滤波)是一种图像滤波技术，通过一张引导图对初始图像(输入图像)进行滤波处理，使得最后的输出图像大体上与初始图像相似，但是纹理部分与引导图相似 原理: 假设引导图像GGG, 输出图像为OOO, 则对应图像的任何一个位置kkk, 滤波窗口为wkw_kwk​, 则Oi=ak∗Gi+bk,i∈wkO_i = a_k * G_i + b_k, i \\in w_kOi​=ak​∗Gi​+bk​,i∈wk​; 该方式就可以保证滤波输出与引导图尽量一致 因此为使输入图像和输出图像在局部内容大致相同, 最优化目标为min∑i∈wk(Oi−Ii)2=min∑i∈wk(ak∗Gi+bk−Ii)2+ϵ∗ak2min \\sum_{i \\in w_k} (O_i - I_i)^2 = min \\sum_{i \\in w_k}(a_k*G_i+b_k-I_i)^2 + \\epsilon * a_k ^2min∑i∈wk​​(Oi​−Ii​)2=min∑i∈wk​​(ak​∗Gi​+bk​−Ii​)2+ϵ∗ak2​, ϵ∗ak2\\epsilon * a_k ^2ϵ∗ak2​为控制变量, 防止除0 上述公式进行求导并使其等于0以求极值, 可计算得: bk=mean(I)−ak∗mean(G)b_k=mean(I)-a_k*mean(G)bk​=mean(I)−ak​∗mean(G) ak=cov(G,I)var(G)+ϵa_k=\\frac{cov(G, I)}{var(G)+\\epsilon}ak​=var(G)+ϵcov(G,I)​ 去噪实验 去噪时O=∑(mean(I)+ak∗(G−mean(G)))O = \\sum (mean(I) + a_k * (G - mean(G)))O=∑(mean(I)+ak​∗(G−mean(G))), 考虑窗口内的I的均值滤波(低频分量)与引导图的高频细节的加权, 最终表现为I的平坦区域与G的梯度剧烈变化区域(I的低频分量与G的高频细节的结合) 平坦区域, var(I)→0,ak→0,bk→mean(I),O→mean(I)var(I) \\rightarrow 0, a_k \\rightarrow 0, b_k \\rightarrow mean(I), O \\rightarrow mean(I)var(I)→0,ak​→0,bk​→mean(I),O→mean(I)更多的是均值滤波, 反之输出引导图本身, 梯度得到保留 参数的影响 滤波核大小: 直接涉及均值滤波核大小, 核越大周围像素影响越大, 平滑越明显 ϵ\\epsilonϵ的影响: 控制aka_kak​, ϵ\\epsilonϵ越大, aka_kak​越小, 则更接近平滑滤波, 高频分量保留更少, 保边效果差, 降噪效果更好; 否则高频分量保留更多, 保边效果更好 若ϵ=0\\epsilon=0ϵ=0, 则滤波器没有作用, 将输入原封输出 若ϵ&gt;0\\epsilon&gt;0ϵ&gt;0, 在像素强度变化小的区域, 相当于加权平均滤波; 而变化大的区域, 滤波效果很弱, 有助于保持边缘 ϵ\\epsilonϵ的作用用于界定像素强度变化的大小, ϵ\\epsilonϵ越大滤波效果越明显 实际实现中, 对整幅图像同时求解(窗口内的值求和, 并不进行取平均操作), 随后进行一次均值滤波 典型应用：保边、图像平滑、抠图、图像增强、HDR压缩、图像抠图及图像去雾等场景 重要应用：去雾算法 随后提出快速导向滤波算法：通过下采样减少像素点后通过上采样恢复到原有的尺寸大小 1void cv::ximgproc::guidedFilter(InputArray guide, InputArray src, OutputArray dst, int radius, double eps, int dDepth = -1) 非局部均值去噪(NLM) NLM算法使用自然图像中普遍存在的冗余信息来去噪，利用整幅图像去噪，以图像块为单位在图像中寻找相似区域，再对区域求平均，能够较好的去掉图像中存在的高斯噪声 与高斯滤波的差异: 使用相似度计算权重, 相似度越大贡献越大 基本思想：当前像素的估计值由图像中与它具有相似邻域结构的像素加权平均得到 TV算法在平滑噪声的同时也把很多图像本身的纹理边缘细节去掉 各向异性滤波AD算法在保持细节信息的同时也保留很多的噪声 NL算法在去除噪声和保持纹理细节方面都具有较好的效果 算法执行过程： 对于图像中每个像素点, 建立两个窗口, 大窗口的为搜索窗, 小窗口为邻域窗口;其中邻域窗口分别建立在该像素点和搜索窗中. 通过滑动搜索窗中的邻域窗口计算两个邻域窗口的相似度进行赋值 权值计算 u^(x0,y0)=1C(x0,y0)∑(x,y)∈B(x0,y0,r)u(x,y)w((x0,y0),(x,y)),C(x0,y0)=∑(x,y)∈B(x0,y0,r)w((x0,y0),(x,y))\\hat{u}(x_0, y_0) = \\frac{1}{C(x_0, y_0)} \\sum_{(x, y) \\in B(x_0, y_0, r)} u(x, y) w((x_0, y_0),(x,y)), C(x_0, y_0) = \\sum_{(x, y) \\in B(x_0, y_0, r)} w((x_0, y_0),(x,y))u^(x0​,y0​)=C(x0​,y0​)1​∑(x,y)∈B(x0​,y0​,r)​u(x,y)w((x0​,y0​),(x,y)),C(x0​,y0​)=∑(x,y)∈B(x0​,y0​,r)​w((x0​,y0​),(x,y)) w((x0,y0),(x,y))=exp(−max(d2−2ϵ2,0.0)h2)w((x_0, y_0),(x,y)) = exp {(-\\frac{max(d^2-2\\epsilon^2, 0.0)}{h^2})}w((x0​,y0​),(x,y))=exp(−h2max(d2−2ϵ2,0.0)​) d=1(2f+1)2∑(x,y)∈(x0,y0,f)(u(x,y)−u(x0,y0))2d = \\frac{1}{(2f+1)^2} \\sum_{(x,y) \\in (x_0, y_0, f)}(u(x,y)-u(x_0,y_0))^2d=(2f+1)21​∑(x,y)∈(x0​,y0​,f)​(u(x,y)−u(x0​,y0​))2 其中rrr为搜索窗的大小, f为邻域大小; 即每个点的值为搜索窗每个点的加权和. 而该权重的计算是利用两个邻域对应像素点值的差值的平方(对应像素点的像素值欧式距离), 并将该值赋予高斯权重以形成权重 参数分析 当两块区域很相似度, 其差值就越小, 则权重就越大;而相似度很小时, 差值较大, 权重较小. 完全考虑了图像像素值变化对滤波的影响 h控制保边降噪效果：h越大时, 高斯曲线越平缓, 去噪效果越好, 但保边效果下降图像模糊; ϵ\\epsilonϵ表示噪声的标准差, 小于2ϵ2\\epsilon2ϵ的块设置为1, 而d较大的块权重较小, 贡献较少. 该参数主要用于将相似的块平均到噪声水平 考察不同大小的相似窗和搜索窗，在不同的噪声程度下，最后取得的去噪效果的PSNR值 当相似窗大小(2f+1)2(2f+1)^2(2f+1)2中的f取为4,即9×99 \\times 99×9时，对不同的噪声程度，最后的去噪效果都有较大的PSNR值 当搜索窗大小(2s+1)2(2s+1)^2(2s+1)2中的s取为6,即搜索窗大小为13×1313 \\times 1313×13时，对不同的噪声程度，最后的去噪效果都有最大的PSNR值 指标 MSE PSNR, 峰值信噪比,即峰值信号的能量与噪声的平均能量之比，通常表示的时候取对数变成分贝dB 由于MSE为真实图像与含噪图像之差的能量均值，两者的差为噪声，因此PSNR即峰值信号能量与MSE之比，定义为PSNR=10log⁡10 MaxValue 2MSE=10log⁡102bits −1MSEP S N R=10 \\log _{10} \\frac{\\text { MaxValue }^2}{M S E}=10 \\log _{10} \\frac{2^{\\text {bits }}-1}{M S E}PSNR=10log10​MSE MaxValue 2​=10log10​MSE2bits −1​ 1234void fastNlMeansDenoising( InputArray src, OutputArray dst, float h = 3, int templateWindowSize = 7, int searchWindowSize = 21);void fastNIMeansDenoisingColored( InputArray src, OutputArray dst, float h = 3, float hColor = 3, int templateWindowSize = 7, int searchWindowSize = 21);void fastNlMeansDenoisingMulti( InputArray Of Arrays srcImgs, OutputArray dst,int imgToDenoiseIndex, int temporalWindowSize, float h = 3, int templateWindowSize = 7, int searchWindowSize = 21);void fastNlMeansDenoisingColoredMulti( InputArray Of Arrays srcImgs, OutputArray dst, int imgToDenoiseIndex, int temporalWindowSize, float h = 3, float hColor = 3,int templateWindowSize = 7, int searchWindowSize = 21); BM3D去噪 维纳滤波(最小均方误差滤波) 该方法建立在图像和噪声都是随机变量的基础上, 为了寻找为未污染图像fff与一个估计f^\\hat{f}f^​, 使其均方误差最小, e2=E((x−f^)2)e^2 = E{((x-\\hat{f})^2)}e2=E((x−f^​)2) 频域推导过程 原始信号为X(ω)X(\\omega)X(ω), 噪声信号为V(ω)V(\\omega)V(ω), 观测到的信号Y(ω)=X(ω)+V(ω)Y(\\omega)=X(\\omega)+V(\\omega)Y(ω)=X(ω)+V(ω)$ 假定维纳滤波器为H(ω)H(\\omega)H(ω), 则滤波输出Z(ω)=H(ω)Y(ω)Z(\\omega) = H(\\omega) Y(\\omega)Z(ω)=H(ω)Y(ω) 频域的误差为e(ω)=X(ω)−Z(ω)e(\\omega) = X(\\omega)-Z(\\omega)e(ω)=X(ω)−Z(ω)， 代价函数为J(H)=E2(e(ω))=E2(X)−HPyx−H∗Pxy+H2PyyJ(H) = E^2(e(\\omega))=E^2(X)-H P_{yx} - H^{*}P_{xy}+H^2P_{yy}J(H)=E2(e(ω))=E2(X)−HPyx​−H∗Pxy​+H2Pyy​, 其中P表示功率谱和互功率谱 对上式求导可得维纳滤波器的最优解为H(ω)=Pxy(ω)Pyy(ω)H(\\omega) = \\frac{P_{xy}(\\omega)}{P_{yy}(\\omega)}H(ω)=Pyy​(ω)Pxy​(ω)​ 由于纯净信号无法得到, 在纯净信号和噪声不相关的假设, 可得Pxy=Pxx,Pyy=Pxx+PvvP_{xy} = P_{xx}, P_{yy} = P_{xx}+P_{vv}Pxy​=Pxx​,Pyy​=Pxx​+Pvv​, 于是H(ω)=PxxPxx+PvvH(\\omega)=\\frac{P_{xx}}{P_{xx}+P_{vv}}H(ω)=Pxx​+Pvv​Pxx​​ Kaiser窗 该窗可以同时调节主瓣和旁瓣的宽度, 具有更小的带外能量, 带外衰减大 可以低通滤波，同时可以降低高频 BM3D算法 2007年TIP的文章Image denoising by sparse 3D transform-domain collaborative ltering 变体：彩色图CBM3D, 时域VBM3D, 沿袭BM3D的基于块处理的思想BM4D和VBM4D只能应用于离线处理 算法总体流程: 一、基础估计 对于每个目标图块，在附近寻找最多MAXN1(超参数)个相似的图块,为了避免噪点的影响，将图块经过2D变换(代码中使用DCT变换)后再用欧式距离衡量相似程度。按距离从小到大排序后取最多前MAXN1个。叠成一个三维数组 d(ZxR,Zx)=∥Υ′(T2Dht(ZxR))−Υ′(T2Dht(Zx))∥22(N1ht)2d\\left(Z_{x_R}, Z_x\\right)=\\frac{\\left\\|\\Upsilon^{\\prime}\\left(\\mathcal{T}_{2 \\mathrm{D}}^{\\mathrm{ht}}\\left(Z_{x_R}\\right)\\right)-\\Upsilon^{\\prime}\\left(\\mathcal{T}_{2 \\mathrm{D}}^{\\mathrm{ht}}\\left(Z_x\\right)\\right)\\right\\|_2^2}{\\left(N_1^{\\mathrm{ht}}\\right)^2}d(ZxR​​,Zx​)=(N1ht​)2∥Υ′(T2Dht​(ZxR​​))−Υ′(T2Dht​(Zx​))∥22​​ 对3D数组的第三维,即图块叠起来后，每个图块同一个位置的像素点构成的数组，进行DCT变换后，采用硬阈值的方式将小于超参数的成分置为0.同时统计非零成分的数量作为后续权重的参考，后续将第三维进行逆变换 Y^SxRhtht=T3Dht−1(Υ(T3Dht(ZSxRhtt)))\\widehat{\\mathbf{Y}}_{S_{x_R}^{\\mathrm{ht}}}^{\\mathrm{ht}}=\\mathcal{T}_{3 \\mathrm{D}}^{\\mathrm{ht}{ }^{-1}}\\left(\\Upsilon\\left(\\mathcal{T}_{3 \\mathrm{D}}^{\\mathrm{ht}}\\left(\\mathbf{Z}_{S_{x_R}}^{\\mathrm{ht}^{\\mathrm{t}}}\\right)\\right)\\right)YSxR​ht​ht​=T3Dht−1​(Υ(T3Dht​(ZSxR​​htt​))) 为什么这么做？ 传统方法由空域得到近似块，然后对近似块的每个像素——对应去平均，作为目标块每个像素的值。但是该策略对部分场景并不合适 某些相似块拥有的噪声更小，相比其它相似块，该块的权重应更大，而不是简单取平均 相似块图像信息冗余，从空域上看，两个有重叠的相似块，简单平均会造成目标块信息重复 采用Collaborative ltering by shrinkage in transform domain能够加强相似块的稀疏性，同时降低相似块的噪声 将这些图块逆变换后放回原位，利用非零成分数量统计叠加权重，最后将叠放后的图除以每个点的权重就得到基础估计的图像，图像的噪声得到了较大的去除 y^basic (x)=∑xR∈X∑xm∈SxRhtwxRhtY^xmht,xR(x)∑xR∈X∑xm∈SxRht.wxRhtχxm(x),∀x∈X\\hat{y}^{\\text {basic }}(x)=\\frac{\\sum_{x_R \\in X} \\sum_{x_m \\in S_{x_R}^{\\mathrm{ht}}} w_{x_R}^{\\mathrm{ht}} \\widehat{Y}_{x_m}^{\\mathrm{ht}, x_R}(x)}{\\sum_{x_R \\in X} \\sum_{x_m \\in S_{x_R}^{\\mathrm{ht}} .} w_{x_R}^{\\mathrm{ht}} \\chi_{x_m}(x)}, \\forall x \\in Xy^​basic (x)=∑xR​∈X​∑xm​∈SxR​ht​.​wxR​ht​χxm​​(x)∑xR​∈X​∑xm​∈SxR​ht​​wxR​ht​Yxm​ht,xR​​(x)​,∀x∈X 二、最终估计：基于初步估计,进行改进的分组和协同维纳滤波 由于基础估计极大地消除了噪点，对于含噪原图的每个目标图块，可以直接用对应基础估计图块的欧氏距离衡量相似程度。按距离从小到大排序后取最多前MAXN1个。将基础估计图块、含噪原图图块分别叠成两个三维数组 SxRwie ={x∈X:∥Y^xRbasic −Y^xbasic ∥22&lt;τmatch wie (N1wie )2}S_{x_R}^{\\text {wie }}=\\left\\{x \\in X: \\frac{\\left\\|\\widehat{Y}_{x_R}^{\\text {basic }}-\\widehat{Y}_x^{\\text {basic }}\\right\\|_2^2&lt;\\tau_{\\text {match }}^{\\text {wie }}}{\\left(N_1^{\\text {wie }}\\right)^2}\\right\\}SxR​wie ​={x∈X:(N1wie ​)2∥YxR​basic ​−Yxbasic ​∥22​&lt;τmatch wie ​​} 对含基础估计3D数组的第三维，即图块叠起来后，每个图块同一个位置的像素点构成的数组，进行DCT变换，利用如下公式得到系数 WSxRwie =∣T3Dwie (Y^SxRbasic bus )∣2∣T3Dwie (Y^SxRwic basic )∣2+σ2\\mathbf{W}_{S_{x_R}^{\\text {wie }}}=\\frac{\\left|\\mathcal{T}_{3 \\mathrm{D}}^{\\text {wie }}\\left(\\widehat{\\mathbf{Y}}_{S_{x_R}^{\\text {basic }}}^{\\text {bus }}\\right)\\right|^2}{\\left|\\mathcal{T}_{3 \\mathrm{D}}^{\\text {wie }}\\left(\\widehat{\\mathbf{Y}}_{S_{x_R}^{\\text {wic }}}^{\\text {basic }}\\right)\\right|^2+\\sigma^2}WSxR​wie ​​=∣∣∣∣​T3Dwie ​(YSxR​wic ​basic ​)∣∣∣∣​2+σ2∣∣∣∣​T3Dwie ​(YSxR​basic ​bus ​)∣∣∣∣​2​ 将系数与含噪3D图块相乘放回原处，最后做加权平均调整即可得到最终估计图。相对于基础估计图，还原了更多原图的细节 算法实现:(见下方代码) 一、基础估计 参数定义: BLK_Size相似窗大小, window_size搜索窗大小, search_step扫描步长, Threshold相似搜索的阈值, max_matched最大堆叠数量, Threshold_hard变换域内三维组系数的阈值 首先取中心像素的的BLK_Size相似窗大小的邻域图像进行DCT变换, 将变换结果和中心点的位置进行保存 相似块搜索: 在搜索窗区域进行搜索, 取每个搜索的相似块进行DCT变换, 变换后的结果与原始搜索窗的相似度distance=(O−N)2BLK_Size2distance = \\frac{(O-N)^2}{BLK\\_Size^2}distance=BLK_Size2(O−N)2​, 保存大于阈值distance&gt;Thresholddistance &gt; Thresholddistance&gt;Threshold相似块的变换结果和坐标, 在排序后取相似度最大的max_matched个结果进行后续操作 3维滤波: 对于堆叠后的相似块, 其形状定义为[max_matched, BLK_size, BLK_size]. 我们在对每个像素点对应的max_matched矩阵进行DCT变换(即[:, i, j]), 在每次的变换结果中, 将对应像素值小于阈值(Threshold_Hard)的数值置零. 统计这一维的非零元素个数并将置零后的结果iDCT变换后放后对应位置. 聚合操作: 若非零元素个数小于1, 则将个数置1. 利用非零元素个数和Kaiser窗计算权重, 将上述保存的3维相似块矩阵取每张图像进行iDCT变换([i,:,:]), 随后放回原位置. 每次处理使用累加操作。 在一整张图像的所有像素处理后, 将处理后的结果与权重相除得到基础估计的结果 二、最终估计 相似块搜索: 与一相同, 但使用一处理后的基础估计结果进行搜索, 最终将基础估计结果的相似块(DCT结果)和含噪原始图像的相似块输出(DCT结果) 3D维纳协同滤波: 对基础估计图像, 取每个像素点进行DCT变换, 随后计算权重mweight=DCTT×DCTDCTT×DCT+σ2m_weight = \\frac{DCT^T \\times DCT}{DCT^T \\times DCT + \\sigma ^ 2}mw​eight=DCTT×DCT+σ2DCTT×DCT​, 若该权重不为0, 则反变换的权重为wiener=1m_weight2×σ2wiener = \\frac{1}{m\\_weight^2 \\times \\sigma^2}wiener=m_weight2×σ21​, 随后对含噪原始图像的相似块进行滤波操作, 将其每个像素点进行DCT变换, 利用m_weight进行滤波, 随后经iDCT变换后返回 聚合操作: 过程类似一, 利用Kaiser窗和反变换的权重对处理后的含噪原始图像的相似块进行iDCT操作后返回, 最终可得到最终结果 参数的选择 最大相似块的数量: 第一步硬阈值操作中设置为16, 第二步设置为32 相似块匹配时的阈值: 噪声的σ&lt;40,τhard=τwien=2500,else=4000\\sigma &lt; 40, \\tau_{hard}=\\tau_{wien}=2500, else =4000σ&lt;40,τhard​=τwien​=2500,else=4000. 该值对结果具有较小影响, 设置过小导致滤波性能下降, 过大导致假细节 相似块的大小: k_hard=8,kwien=12k\\_{hard}=8, k_{wien}=12k_hard=8,kwien​=12 硬阈值降噪时变换域内三维组系数的阈值λ3Dhard\\lambda_{3D}^{hard}λ3Dhard​, 该值对结果具有较大的影响, 最优解为2.7 加速方法 为了加快计算速度，在寻找相似块的步骤后，得到的块实际上已经进行了2D变换处理，然后再加上一个1D变换(使用1D-Haar离散小波变换),成为了3D变换, 使用2D+1D变换方法替代直接3D变换 难点 2D变换与各种超参数并没有一个确定值，需要大量实验积累参数的设置 若实际运用在图像降噪中，原始图像不会大量噪声，因此就不需要BM3D两步去噪 可以将BM3D的两步拆开，采用前步的硬阈值、2D变换寻找相似块、1D变换升至3D域再加权平均，或后步直接使用维纳滤波，或许就已经有很好的效果了 参考文章： 图像去噪：BM3D 去噪算法原理解析与代码实现 BM3D图像去噪算法原理及代码详解 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343# -*- coding: utf-8 -*-import cv2import numpycv2.setUseOptimized(True)# Parameters initializationsigma = 25Threshold_Hard3D = 2.7*sigma # Threshold for Hard ThresholdingFirst_Match_threshold = 2500 # 用于计算block之间相似度的阈值Step1_max_matched_cnt = 16 # 组最大匹配的块数Step1_Blk_Size = 8 # block_Size即块的大小，8*8Step1_Blk_Step = 3 # Rather than sliding by one pixel to every next reference block, use a step of Nstep pixels in both horizontal and vertical directions.Step1_Search_Step = 3 # 块的搜索stepStep1_Search_Window = 39 # Search for candidate matching blocks in a local neighborhood of restricted size NS*NS centeredSecond_Match_threshold = 400 # 用于计算block之间相似度的阈值Step2_max_matched_cnt = 32Step2_Blk_Size = 8Step2_Blk_Step = 3Step2_Search_Step = 3Step2_Search_Window = 39Beta_Kaiser = 2.0def init(img, _blk_size, _Beta_Kaiser): &quot;&quot;&quot;该函数用于初始化，返回用于记录过滤后图像以及权重的数组,还有构造凯撒窗&quot;&quot;&quot; m_shape = img.shape m_img = numpy.matrix(numpy.zeros(m_shape, dtype=float)) m_wight = numpy.matrix(numpy.zeros(m_shape, dtype=float)) K = numpy.matrix(numpy.kaiser(_blk_size, _Beta_Kaiser)) m_Kaiser = numpy.array(K.T * K) # 构造一个凯撒窗 return m_img, m_wight, m_Kaiserdef Locate_blk(i, j, blk_step, block_Size, width, height): &#x27;&#x27;&#x27;该函数用于保证当前的blk不超出图像范围&#x27;&#x27;&#x27; if i*blk_step+block_Size &lt; width: point_x = i*blk_step else: point_x = width - block_Size if j*blk_step+block_Size &lt; height: point_y = j*blk_step else: point_y = height - block_Size m_blockPoint = numpy.array((point_x, point_y), dtype=int) # 当前参考图像的顶点 return m_blockPointdef Define_SearchWindow(_noisyImg, _BlockPoint, _WindowSize, Blk_Size): &quot;&quot;&quot;该函数返回一个二元组（x,y）,用以界定_Search_Window顶点坐标&quot;&quot;&quot; point_x = _BlockPoint[0] # 当前坐标 point_y = _BlockPoint[1] # 当前坐标 # 获得SearchWindow四个顶点的坐标 LX = point_x+Blk_Size/2-_WindowSize/2 # 左上x LY = point_y+Blk_Size/2-_WindowSize/2 # 左上y RX = LX+_WindowSize # 右下x RY = LY+_WindowSize # 右下y # 判断一下是否越界 if LX &lt; 0: LX = 0 elif RX &gt; _noisyImg.shape[0]: LX = _noisyImg.shape[0]-_WindowSize if LY &lt; 0: LY = 0 elif RY &gt; _noisyImg.shape[0]: LY = _noisyImg.shape[0]-_WindowSize return numpy.array((LX, LY), dtype=int)def Step1_fast_match(_noisyImg, _BlockPoint): &quot;&quot;&quot;快速匹配&quot;&quot;&quot; &#x27;&#x27;&#x27; *返回邻域内寻找和当前_block相似度最高的几个block,返回的数组中包含本身 *_noisyImg:噪声图像 *_BlockPoint:当前block的坐标及大小 &#x27;&#x27;&#x27; (present_x, present_y) = _BlockPoint # 当前坐标 Blk_Size = Step1_Blk_Size Search_Step = Step1_Search_Step Threshold = First_Match_threshold max_matched = Step1_max_matched_cnt Window_size = Step1_Search_Window blk_positions = numpy.zeros((max_matched, 2), dtype=int) # 用于记录相似blk的位置 Final_similar_blocks = numpy.zeros((max_matched, Blk_Size, Blk_Size), dtype=float) img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size] dct_img = cv2.dct(img.astype(numpy.float64)) # 对目标作block作二维余弦变换 Final_similar_blocks[0, :, :] = dct_img blk_positions[0, :] = _BlockPoint Window_location = Define_SearchWindow(_noisyImg, _BlockPoint, Window_size, Blk_Size) blk_num = (Window_size-Blk_Size)/Search_Step # 确定最多可以找到多少相似blk blk_num = int(blk_num) (present_x, present_y) = Window_location similar_blocks = numpy.zeros((blk_num**2, Blk_Size, Blk_Size), dtype=float) m_Blkpositions = numpy.zeros((blk_num**2, 2), dtype=int) Distances = numpy.zeros(blk_num**2, dtype=float) # 记录各个blk与它的相似度 # 开始在_Search_Window中搜索,初始版本先采用遍历搜索策略,这里返回最相似的几块 matched_cnt = 0 for i in range(blk_num): for j in range(blk_num): tem_img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size] dct_Tem_img = cv2.dct(tem_img.astype(numpy.float64)) m_Distance = numpy.linalg.norm((dct_img-dct_Tem_img))**2 / (Blk_Size**2) # 下面记录数据自动不考虑自身(因为已经记录) if m_Distance &lt; Threshold and m_Distance &gt; 0: # 说明找到了一块符合要求的 similar_blocks[matched_cnt, :, :] = dct_Tem_img m_Blkpositions[matched_cnt, :] = (present_x, present_y) Distances[matched_cnt] = m_Distance matched_cnt += 1 present_y += Search_Step present_x += Search_Step present_y = Window_location[1] Distances = Distances[:matched_cnt] Sort = Distances.argsort() # 统计一下找到了多少相似的blk if matched_cnt &lt; max_matched: Count = matched_cnt + 1 else: Count = max_matched if Count &gt; 0: for i in range(1, Count): Final_similar_blocks[i, :, :] = similar_blocks[Sort[i-1], :, :] blk_positions[i, :] = m_Blkpositions[Sort[i-1], :] return Final_similar_blocks, blk_positions, Countdef Step1_3DFiltering(_similar_blocks): &#x27;&#x27;&#x27; *3D变换及滤波处理 *_similar_blocks:相似的一组block,这里已经是频域的表示 *要将_similar_blocks第三维依次取出,然在频域用阈值滤波之后,再作反变换 &#x27;&#x27;&#x27; statis_nonzero = 0 # 非零元素个数 m_Shape = _similar_blocks.shape # 下面这一段代码很耗时 for i in range(m_Shape[1]): for j in range(m_Shape[2]): tem_Vct_Trans = cv2.dct(_similar_blocks[:, i, j]) tem_Vct_Trans[numpy.abs(tem_Vct_Trans[:]) &lt; Threshold_Hard3D] = 0. statis_nonzero += tem_Vct_Trans.nonzero()[0].size _similar_blocks[:, i, j] = cv2.idct(tem_Vct_Trans)[0] return _similar_blocks, statis_nonzerodef Aggregation_hardthreshold(_similar_blocks, blk_positions, m_basic_img, m_wight_img, _nonzero_num, Count, Kaiser): &#x27;&#x27;&#x27; *对3D变换及滤波后输出的stack进行加权累加,得到初步滤波的图片 *_similar_blocks:相似的一组block,这里是频域的表示 *对于最后的数组，乘以凯撒窗之后再输出 &#x27;&#x27;&#x27; _shape = _similar_blocks.shape if _nonzero_num &lt; 1: _nonzero_num = 1 block_wight = (1./_nonzero_num) * Kaiser for i in range(Count): point = blk_positions[i, :] tem_img = (1./_nonzero_num)*cv2.idct(_similar_blocks[i, :, :]) * Kaiser m_basic_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += tem_img m_wight_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += block_wightdef BM3D_1st_step(_noisyImg): &quot;&quot;&quot;第一步,基本去噪&quot;&quot;&quot; # 初始化一些参数： (width, height) = _noisyImg.shape # 得到图像的长宽 block_Size = Step1_Blk_Size # 块大小 blk_step = Step1_Blk_Step # N块步长滑动 Width_num = (width - block_Size)/blk_step Height_num = (height - block_Size)/blk_step # 初始化几个数组 Basic_img, m_Wight, m_Kaiser = init(_noisyImg, Step1_Blk_Size, Beta_Kaiser) # 开始逐block的处理,+2是为了避免边缘上不够 for i in range(int(Width_num+2)): for j in range(int(Height_num+2)): # m_blockPoint当前参考图像的顶点 m_blockPoint = Locate_blk(i, j, blk_step, block_Size, width, height) # 该函数用于保证当前的blk不超出图像范围 Similar_Blks, Positions, Count = Step1_fast_match(_noisyImg, m_blockPoint) Similar_Blks, statis_nonzero = Step1_3DFiltering(Similar_Blks) Aggregation_hardthreshold(Similar_Blks, Positions, Basic_img, m_Wight, statis_nonzero, Count, m_Kaiser) Basic_img[:, :] /= m_Wight[:, :] basic = numpy.matrix(Basic_img, dtype=int) basic.astype(numpy.uint8) return basicdef Step2_fast_match(_Basic_img, _noisyImg, _BlockPoint): &#x27;&#x27;&#x27; *快速匹配算法,返回邻域内寻找和当前_block相似度最高的几个block,要同时返回basicImg和IMG *_Basic_img: 基础去噪之后的图像 *_noisyImg:噪声图像 *_BlockPoint:当前block的坐标及大小 &#x27;&#x27;&#x27; (present_x, present_y) = _BlockPoint # 当前坐标 Blk_Size = Step2_Blk_Size Threshold = Second_Match_threshold Search_Step = Step2_Search_Step max_matched = Step2_max_matched_cnt Window_size = Step2_Search_Window blk_positions = numpy.zeros((max_matched, 2), dtype=int) # 用于记录相似blk的位置 Final_similar_blocks = numpy.zeros((max_matched, Blk_Size, Blk_Size), dtype=float) Final_noisy_blocks = numpy.zeros((max_matched, Blk_Size, Blk_Size), dtype=float) img = _Basic_img[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size] dct_img = cv2.dct(img.astype(numpy.float32)) # 对目标作block作二维余弦变换 Final_similar_blocks[0, :, :] = dct_img n_img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size] dct_n_img = cv2.dct(n_img.astype(numpy.float32)) # 对目标作block作二维余弦变换 Final_noisy_blocks[0, :, :] = dct_n_img blk_positions[0, :] = _BlockPoint Window_location = Define_SearchWindow(_noisyImg, _BlockPoint, Window_size, Blk_Size) blk_num = (Window_size-Blk_Size)/Search_Step # 确定最多可以找到多少相似blk blk_num = int(blk_num) (present_x, present_y) = Window_location similar_blocks = numpy.zeros((blk_num**2, Blk_Size, Blk_Size), dtype=float) m_Blkpositions = numpy.zeros((blk_num**2, 2), dtype=int) Distances = numpy.zeros(blk_num**2, dtype=float) # 记录各个blk与它的相似度 # 开始在_Search_Window中搜索,初始版本先采用遍历搜索策略,这里返回最相似的几块 matched_cnt = 0 for i in range(blk_num): for j in range(blk_num): tem_img = _Basic_img[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size] dct_Tem_img = cv2.dct(tem_img.astype(numpy.float32)) m_Distance = numpy.linalg.norm((dct_img-dct_Tem_img))**2 / (Blk_Size**2) # 下面记录数据自动不考虑自身(因为已经记录) if m_Distance &lt; Threshold and m_Distance &gt; 0: similar_blocks[matched_cnt, :, :] = dct_Tem_img m_Blkpositions[matched_cnt, :] = (present_x, present_y) Distances[matched_cnt] = m_Distance matched_cnt += 1 present_y += Search_Step present_x += Search_Step present_y = Window_location[1] Distances = Distances[:matched_cnt] Sort = Distances.argsort() # 统计一下找到了多少相似的blk if matched_cnt &lt; max_matched: Count = matched_cnt + 1 else: Count = max_matched if Count &gt; 0: for i in range(1, Count): Final_similar_blocks[i, :, :] = similar_blocks[Sort[i-1], :, :] blk_positions[i, :] = m_Blkpositions[Sort[i-1], :] (present_x, present_y) = m_Blkpositions[Sort[i-1], :] n_img = _noisyImg[present_x: present_x+Blk_Size, present_y: present_y+Blk_Size] Final_noisy_blocks[i, :, :] = cv2.dct(n_img.astype(numpy.float64)) return Final_similar_blocks, Final_noisy_blocks, blk_positions, Countdef Step2_3DFiltering(_Similar_Bscs, _Similar_Imgs): &#x27;&#x27;&#x27; *3D维纳变换的协同滤波 *_similar_blocks:相似的一组block,这里是频域的表示 *要将_similar_blocks第三维依次取出,然后作dct,在频域进行维纳滤波之后,再作反变换 *返回的Wiener_wight用于后面Aggregation &#x27;&#x27;&#x27; m_Shape = _Similar_Bscs.shape Wiener_wight = numpy.zeros((m_Shape[1], m_Shape[2]), dtype=float) for i in range(m_Shape[1]): for j in range(m_Shape[2]): tem_vector = _Similar_Bscs[:, i, j] tem_Vct_Trans = numpy.matrix(cv2.dct(tem_vector)) Norm_2 = numpy.float64(tem_Vct_Trans.T * tem_Vct_Trans) m_weight = Norm_2/(Norm_2 + sigma**2) if m_weight != 0: Wiener_wight[i, j] = 1./(m_weight**2 * sigma**2) # else: # Wiener_wight[i, j] = 10000 tem_vector = _Similar_Imgs[:, i, j] tem_Vct_Trans = m_weight * cv2.dct(tem_vector) _Similar_Bscs[:, i, j] = cv2.idct(tem_Vct_Trans)[0] return _Similar_Bscs, Wiener_wightdef Aggregation_Wiener(_Similar_Blks, _Wiener_wight, blk_positions, m_basic_img, m_wight_img, Count, Kaiser): &#x27;&#x27;&#x27; *对3D变换及滤波后输出的stack进行加权累加,得到初步滤波的图片 *_similar_blocks:相似的一组block,这里是频域的表示 *对于最后的数组，乘以凯撒窗之后再输出 &#x27;&#x27;&#x27; _shape = _Similar_Blks.shape block_wight = _Wiener_wight # * Kaiser for i in range(Count): point = blk_positions[i, :] tem_img = _Wiener_wight * cv2.idct(_Similar_Blks[i, :, :]) # * Kaiser m_basic_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += tem_img m_wight_img[point[0]:point[0]+_shape[1], point[1]:point[1]+_shape[2]] += block_wightdef BM3D_2nd_step(_basicImg, _noisyImg): &#x27;&#x27;&#x27;Step 2. 最终的估计: 利用基本的估计，进行改进了的分组以及协同维纳滤波&#x27;&#x27;&#x27; # 初始化一些参数： (width, height) = _noisyImg.shape block_Size = Step2_Blk_Size blk_step = Step2_Blk_Step Width_num = (width - block_Size)/blk_step Height_num = (height - block_Size)/blk_step # 初始化几个数组 m_img, m_Wight, m_Kaiser = init(_noisyImg, block_Size, Beta_Kaiser) for i in range(int(Width_num+2)): for j in range(int(Height_num+2)): m_blockPoint = Locate_blk(i, j, blk_step, block_Size, width, height) Similar_Blks, Similar_Imgs, Positions, Count = Step2_fast_match(_basicImg, _noisyImg, m_blockPoint) Similar_Blks, Wiener_wight = Step2_3DFiltering(Similar_Blks, Similar_Imgs) Aggregation_Wiener(Similar_Blks, Wiener_wight, Positions, m_img, m_Wight, Count, m_Kaiser) m_img[:, :] /= m_Wight[:, :] Final = numpy.matrix(m_img, dtype=int) Final.astype(numpy.uint8) return Final 变换域去噪 基于频域的处理方法主要是用滤波器，把有用的信号和干扰信号分开，它在有用信号和干扰信号的频谱没有重叠的前提下，才能把有用信号和干扰信号完全分开，但实际上很难分开 主要方法：傅里叶变换，小波变换等","categories":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"}],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"}]},{"title":"计算机基础知识点补缺","slug":"计算机基础知识点补缺","date":"2023-03-14T02:49:42.000Z","updated":"2023-05-09T10:21:27.240Z","comments":true,"path":"2023/03/14/计算机基础知识点补缺/","link":"","permalink":"http://jay1060950003.github.io/2023/03/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E7%BC%BA/","excerpt":"引言 计算机基础知识和编程基础的查漏补缺以及高频面试题","text":"引言 计算机基础知识和编程基础的查漏补缺以及高频面试题 1 知识点 操作系统中堆和栈的区别 堆为按需申请、动态分配，例如 C++ 中的 new 操作（当然 C++ 的 new 不仅仅是申请内存这么简单） 堆可以简单理解为当前使用的空闲内存，其申请和释放需要程序员自己写代码管理 栈内存：由编译器自动分配释放，存放函数的参数值，局部变量。操作方式类似于数据结构中的栈，都是先进后出。使用一级缓存，通常都是被调用时处于存储空间中，调用完毕立即释放 堆内存：由程序员分配释放，若程序员不释放，程序结束时可能由OS回收。堆是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定 并发与并行区别 并发是指宏观上在一段时间内能同时运行多个程序, 指多个任务在逻辑上交织执行的程序设计(总线程数 &lt;= CPU数量) 单核CPU运行多任务, 并发技术：使用时间片轮转进程调度算法, CPU轮流为多个进程服务 并行则指在同一时刻能运行多个指令, 指物理上同时执行(总线程数 &gt; CPU数量) 多个CPU运行多任务, 并行技术：不同进程分配给不同CPU 2 C++编程题汇总 C++编译相关问题 编译过程: 预处理-&gt;编译-&gt;汇编-&gt;链接 宏定义的处理 宏在编译时候就处理完了，生成的可执行文件里面再没有宏，因此宏是不占内存的 在宏展开后，宏所定义的内容是否需要分配内存，就看宏的替换的结果了, 但这个就不算宏所占用的内存 Linux中C程序的生命周期 GCC 编译器将源程序文件 hello.c 编译为目标文件 hello 的过程分为四个阶段: 预处理器、编译器、汇编器和链接器, 一起构成了编译器系统 C++语言 C++语言的三个特征: 封装, 继承, 多态 多态的理解: 同一函数作用于不同的对象, 会实现不同的功能, 产生不同的执行结果. 运行时可以通过指向基类的指针或引用来调用派生类中的方法 在程序运行时的多态通过继承和虚函数体现； 在程序编译时的多态在函数和算数符的重载上体现 C++面向对象的特点: 数据抽象, 继承, 动态绑定 动态绑定的理解: 函数运行时的版本由实参决定自动选择函数的版本 使用基类的引用或指针调用一个虚函数时, 将会发生动态绑定 sizeof与strlen strlen: 为一个函数, 只能以char*作为参数, 用于计算指定字符串的长度, 但不包括结束字符串\\0 参数必须以\\0作为结束符才可以正确统计 sizeof: 单目运算符, 计算一个表达式或类型名称所占内存空间的字节数, 满足右结合律 统计结构体大小时涉及内存对齐问题: 结构变量中的成员按照4或8的倍数计算(加快CPU存取速度) 常见关键字的作用 extern 与&quot;C&quot;一起作用, 告诉编译器该函数或变量按照C的规则翻译, 如extern “C” void fun(int a,int b) 不与&quot;C&quot;一起作用, 声明函数或变量的作用范围, 作用范围为本模块或其他模块, 常用于声明在外部定义的变量 const: const类型的对象在程序执行期间不能被修改 常对象: 声明对象前加const 常对象只能调用常函数, 不能调用普通函数 常函数: 成员函数后加const 常函数不可以修改成员属性, 只能使用数据成员 成员属性声明前加mutable后, 在常函数中依然可以修改 顶层const与底层const 顶层const表示指针本身是常量(指针常量) int* const p, 指针指向的地址不可改变 底层const表示指针指向的是一个常量(常量指针)const int* p, 可以指向别的常量 优点: 便于类型检查, 保护实参 类似与宏定义, 方便参数的修改和调整 节省空间, 宏定义时会进行宏替换并为变量分配空间 为函数重载提供参考, 即可添加const进行重载 static: 修饰内置类型变量为静态变量 静态变量只初始化一次, 未初始化的静态变量初始化为0; 静态全局变量只在本文件可见, 外部无法访问 静态局部变量只在定义的作用域内可见, 但生存周期是整个程序运行时期 修饰函数为静态函数 只允许在当前文件中使用, 不可以被其他文件引用, 其不会与其他文件中的同名函数冲突 修饰成员变量为静态成员变量 所有对象(包括派生类)共享同一份数据 在编译期间分配内存 类内声明, 类外初始化(不可使用构造函数初始化) 修饰成员函数为静态成员函数 所有对象共享同一函数 不含this指针. 不需要通过对象便可直接访问 静态成员函数只能访问静态成员变量 关系 static和extern不能同时修饰一个变量, static即声明也定义, extern只能声明 const和static不能同时修饰成员函数 volatile: 防止对变量进行优化, 让编译器每次操作该变量时一定从内存中取出 override: 确保该成员函数为虚函数并且一定可以重写来自基类的虚函数 final: 虚函数加final, 任何覆盖该函数的行为会报错 new/delete与C中malloc/free的区别 new/delete 是C++的运算符, malloc/free是C++/C的标准库函数 new/delete会调用构造函数申请或析构函数释放内存 new/delete 更加灵活： malloc/free为库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加在malloc/free上 delete和delete[]的区别 通俗来讲 delete用来释放new申请的动态内存, 释放单个对象指针指向的内存 delete[]用来释放new[]申请的动态内存, 释放对象数组指针指向的内存 针对数据类型而言 对基本数据类型, delete和delete[]释放内存效果一样 对自定数据类型, delete只会调用第一个对象的析构函数;delete[]会逐个调用析构函数来释放数组的所有对象 include后使用&quot;&quot;和&lt;&gt;的区别 使用&lt;&gt;表明优先在环境变量中搜索头文件 使用&quot;&quot;表明优先在当前文件目录(或文件名指定的其他目录)中搜索文件, 随后再在标准位置搜索文件 动态库和静态库的区别 库文件是是一个代码仓库或代码组件的集合, 为目标文件提供可直接使用的变量, 函数, 类等 静态链接库和动态链接库的根本区别在程序编译过程中如何处理库文件和目标文件的链接关系 静态链接库：链接时, 静态库会完全复制到可执行文件中, 构建完成后不再依赖该静态库 动态链接库: 链接时仅将重要的信息, 如重定位和符号表信息复制到可执行文件中. 在程序执行时, 会根据信息从系统中寻找对于库文件 区别 静态库 动态库 可执行文件大小 较大动态库的内容会被完全复制 较小 占用磁盘大小 较大多个可执行文件使用同一个静态库, 会被多次复制 较小多个可可执行文件共用同一个动态库 扩展性与兼容性 全量更新库文件的更新, 可执行文件需重新编译及发布 增量更新只需发布动态库文件 依赖问题 无依赖问题已构建的可执行文件不依赖静态库文件 有依赖问题可执行文件需要依赖的动态库文件 复杂程度 简单 复杂会引起很多问题，例如如何在运行时确定地址，库文件版本管理等 加载速度 快 慢 C++指针和引用的区别 指针为一个变量, 存储一个指向原变量的地址; 引用为原变量的一个别名, 实质上为一个东西 指针可以有多级； 引用只可以有一级 指针可以在任何时间初始化; 引用必须在创建时被初始化 指针存在空指针，引用不存在空引用 指针初始化之后可以再改变; 引用初始化后不可改变 sizeof运算时, 引用为引用类型的大小,指针始终是地址空间所占字节个数 自增运算意义不同: 引用自增为实体加1, 指针自增为指针向后偏移 作为函数参数时, 传递指针会产生临时的指针变量, 传递指针变量的值(指针指向变量的地址值); 传递引用时传递的是变量的地址, 不会产生临时变量 指针, ++的优先级问题 *p++、*(p++)、(*p)++、*++p、++*p的区别 *p++与*(p++)相同，后缀++优先级更高，但后缀++先返回值（指针p），指针p与*结合之后，指针p再++，因此对应的结果是，输出指针p在自增前对应的值，指针p自增 (*p)++ 括号优先级最高，因此先对指针p取值，然后后缀++先返回值*p，再对*p这个整体自增，因此对应结果是输出*p的值，之后*p的值自增1，指针p指向的位置不变 *++p 即*(++p)，最左是*，但后面跟的是表达式 ++p 所以要先算++p ++*p 即++(*p)，最左是++ 但后面跟的是表达式*p 所以要先算*p （感谢@weixin_42004700更正） ++问题 前缀时, 先自增再返回 后缀时, 先返回后自增 优先级问题 后缀优先级高于前缀和* 后缀++结合律从左至右(先返回值后自增) 前缀++和*优先级相同, 结合律从右至左 谁靠近p就先计算谁 如果在p后面就先计算 类的static变量在什么时候初始化, 函数的static变量在什么时候初始化 类的静态成员变量在类实例化之前就已经存在并且分配了内存 函数的静态变量在执行此函数时初始化 常量指针和指针常量 记忆方法: 指针\\*和常量const谁在前先读谁 常量指针: 指向const对象的指针,指向的地址可以改变,但其指向的内容(即对象的值)不可以改变 指针常量: 指针本身是常量, 即指向的地址本身不可以改变, 但内容(即对象的值)可以改变 函数指针和指针函数 指针函数: 本质上为函数, 其返回值为指针int* func(int x, int y); 函数指针: 本质上为指针, 一个指向函数的指针变量 声明: int (*func)(int x, int y); 赋值: func = &amp;Function;或func = Function; 调用: a=(*func)();或a=func(); 区分方法: 函数名带括号的为函数指针, 不带括号的为指针函数 数组指针和指针数组 数组指针: 本质为指针, 指向一个数组, 数组中每个每个元素都是某种数据类型的值 定义: int (*p)[n] 也称行指针, 当指针p执行p+1时，指针会指向数组的下一行 指针数组: 本质为数组, 数组的元素为指针 定义: int *p[n] 指针数组是一个包含若干个指针的数组, p是数组名, 当执行p+1时, 则p会指向数组中的下一个元素 区分方法：数组名带括号的就是数组指针, 不带括号的就是指针数组 全局变量和局部变量在内存中的区别 全局变量存储在静态数据区 局部变量存储在堆栈中 #pragma与#ifndef #endif 相同点：都是防止头文件重复包含 不同点： 原理不同 #pragma once如果发现头文件被包含就不会打开头文件(更快) #ifndef #endif每次都要打开头文件去判断头文件宏 #pragma once在两个头文件名不同, 而内容相同时会把两个头文件都包含进来, 出现重定义的错误; 而后者打开头文件后发现宏名一样, 就不会重复包含, 也就避免率这个问题(更稳定) 如何在防止一个类被其他的类继承呢 使用友元实现, 借助友元来实现，因为友元是不可以被继承的 如果一个类的构造函数要借助它的友元类， 那么继承了这个类的类就无法构造自己的对象. 从而杜绝了被继承 C++11的新特性 初始化列表 auto关键字, 编译期间自动推导变量类型 decltype关键字, 从表达式中推断类型 范围for语句 nullptr关键字解决NULL二义性问题: nullptr是一种特殊类型的字面值，可以被转换成任意其他的指针类型，也可以初始化一个空指针 lambda表达式 智能指针: 更安全且更加容易地管理动态内存 右值引用 decltype和auto的区别 auto 是根据等号右边的初始值推导出变量的类型，且变量必须初始化，auto的使用更加简洁 decltype 是根据表达式推导出变量的类型，不要求初始化，decltype的使用更加灵活 使用场合 auto根据等号右侧表达式的值推导出变量类型，并使用表达式返回值初始化该变量。右侧表达是真实运行了的 decltype根据括号内表达式分析出变量的数据类型，不会初始化变量。表达式没有真实的运行，只是用于分析而已 顶层const与引用 auto会忽略顶层const和引用，直接将引用指向的数据类型作为推断出的类型(顶层const不会忽略) decltype不会忽略，完全一致 union union是一种节省空间的特殊的类, 一个union可以有多个数据成员, 但任意时刻只有一个数据成员有值, 当某个成员被赋值后, 其他成员为未定义状态 Union中的默认访问权限是public, 但可以为其成员设置权限 能够包含访问权限, 成员变量, 成员函数(可以包含构造函数和析构函数) 不能包含虚函数, 静态数据变量和引用类型的变量 不能被用作其他类的基类, 本身也不能有从某个基类派生而来 不允许存放带有构造函数、析够函数、复制拷贝操作符等的类, 因为他们共享内存，编译器无法保证这些对象不被破坏, 也无法保证离开时调用析够函数 （尽量不要让union带有对象） 当多个基本数据类型或复合数据结构要占用同一片内存时, 要使用联合体 当多种类型, 多个对象, 多个事物只取其一时，也可以使用联合体来发挥其长处 12345678910111213141516171819202122232425262728293031// 示例#include &lt;iostream&gt;using namespace std;union Test &#123; struct &#123; int x; int y; int z; &#125;s; int k;&#125;myUnion;int main()&#123; myUnion.s.x = 4; myUnion.s.y = 5; myUnion.s.z = 6; myUnion.k = 0; cout &lt;&lt; myUnion.s.x &lt;&lt; endl; //0 cout &lt;&lt; myUnion.s.y &lt;&lt; endl; //5 cout &lt;&lt; myUnion.s.z &lt;&lt; endl; //6 cout &lt;&lt; myUnion.k &lt;&lt; endl; //0 cout &lt;&lt; &amp;myUnion.s.x &lt;&lt; endl; //00DAA138 cout &lt;&lt; &amp;myUnion.s.y &lt;&lt; endl; //00DAA13C cout &lt;&lt; &amp;myUnion.s.z &lt;&lt; endl; //00DAA140 cout &lt;&lt; &amp;myUnion.k &lt;&lt; endl; //00DAA138 return 0;&#125;// 对k赋值时, 出于共享内存, 故从union的首地址开始放置 struct、class、union的区别 访问权限:struct, union的默认访问权限都是public, class的默认访问权限是private 内存大小: struct,class的内存大小为所有成员的内存之和; union的内存大小为最大的成员的内存大小，成员变量之间共享内存 继承: struct,class都可以进行继承与被继承,不过struct只能添加带参数的构造函数; union不可被继承或派生 成员：union不能包含虚函数, 静态数据变量, 也不能存放带有构造,析构,拷贝构造等函数的类 template模板: class可以使用模板，而struct不可以 深拷贝与浅拷贝的区别 浅拷贝: 通过拷贝构造函数实现, 编译器会以浅拷贝方式自动生成缺省的函数, 拷贝时简单复制某个对象的指针 引发问题: 假设String类有两个对象a和b，a.data的内容为“hello”，b.data为“world”，当将a的值赋给b时，可能会出现3个问题 b.data的内存没释放, 造成内存泄漏 b.data和a.data指向了同一块内存, a或b任何一方的值改变都会修改另一方的值 在对象被析构时，data被释放了两次 深拷贝: 必须显示地提供拷贝构造函数和赋值运算符，而且新旧对象不共享内存 使用情景: 一个对象以值传递的方式传入函数体 一个对象以值传递的方式从函数体返回 一个对象需要通过另外一个对象进行初始化 map和hashmap(unordered_map)区别 hashmap(unordered_map) 基础知识 使用hash table组织,数据 通过将键值key映射到hash表中的一个位置进行访问 对元素查找的时间复杂度可达到O(1), 但元素的排序无序 在最开始建立时比较耗时, 但查询速度较快 优点: 查找速度快 缺点: 哈希表建立比较耗费时间 适用处: 对于查找问题, unordered_map会更加高效一些 map 基础知识 使用红黑树组织数据, 默认实现了数据的排序 在存储上, map占用空间较大; 在红黑树中, 每一个节点都要额外保存父节点和子节点的连接, 因此使得每一个节点都占用较大空间来维护红黑树性质 优点: 有序性, 内部实现的红黑树使得map的很多操作在lg(n)lg(n)lg(n)的时间复杂度下就可以实现, 效率非常的高 缺点: 占用空间较大 适用处: 有顺序要求的问题, 使用map更高效 unordered map内存占用率高, 但执行效率高 vector的扩容机制和原理 vector存储的空间在内存中连续. 若vector现有空间已存满元素, 在push_back新增数据时需要更大的内存, 会将原来的数据copy过来, 释放之前的内存, 在新的内存空间中存入新增元素 不同编译器对vector的扩容方式实现不一致, vs中以1.5倍扩容(效果更好), gcc中以2倍扩容 2倍扩容时, 要申请的空间都比之前释放的空间合并起来大, 无法循环利用之前的空间; 1.5倍扩容时, 可以循环利用之前的空间, 内存碎片风险小 。空间和时间的权衡，空间分配地越多，平摊时间复杂度越低，但浪费空间也多。最好把增长因子设在 (1,2) 之间 vector初始扩容方式, 扩容效率低, 需要频繁增长, 需要频繁申请内存造成过多内存碎片. 需要合理使用resize()和reserve()提高效率减少内存碎片 对vector的任何操作, 一旦引起空间重新配置, 指向原vector的所有迭代器就都会失效 resize()和reserve()区别 size()：返回vector中的元素个数, 已用空间大小 capacity()：返回vector能存储元素的总数, 总空间大小 resize()：创建指定数量的的元素并指定vector的存储空间 既修改capacity的大小, 也修改size的大小, 即分配了空间的同时也创建了对象 reserve()：指定vector的元素总数 只修改capacity的大小, 不修改size大小 预先分配一块较大的指定大小的内存空间，这样当指定大小的内存空间未使用完时，是不会重新分配内存空间的，这样便提升了效率; 只有当n&gt;capacity()时，调用reserve(n)才会改变vector容量，不然保持 capacity() 不变 用reserve(size_type)只是扩大 capacity 值，内存空间可能是“野”的，若此时使用[ ]来访问,则可能会越界; resize(size_type new_size)会真正使容器具有new_size个对象, 可以使用[ ]来访问 push_back和emplace_back区别 push_back：构造函数+拷贝构造 emplace_back：构造函数+移动构造 emplace_back省去了拷贝构造的时间, 运行效率更高 构造函数与析构函数 析构函数 析构函数 一个类只能有一个析构函数, 不能重载 析构函数不能有任何参数, 无返回值 若没有写析构函数, 编译器会生成默认的析构函数 对象的生命周期结束, 系统会自动调用析构函数 析构函数为什么一般是虚函数 C++默认析构函数不是虚函数. 对于没有派生类的基类而言, 将析构函数定义为虚函数会浪费内存空间 若不声明为虚函数, 在析构一个指向派生类的基类指针时, 只会调用基类的析构函数, 不会调用派生类的析构函数, 造成内存泄漏 子类在析构时, 需要调用父类的析构函数吗 不需要显式调用基类的析构函数, 编译器会自动调用 析构时会先析构派生类再析构基类 构造函数 构造时: 先调用基类在调用子类 构造函数中的初始化列表成员只和类中定义变量的顺序相关, 与初始化列表中变量的排序无关(重要) 类中const, reference成员变量或属于某种未提供默认构造函数的类类型只能用初始化列表初始化或赋值一个默认参数, 不可二次修改 构造函数 当类中定义了其他构造函数后, 将不存在默认构造函数, 需要自己合成(在无参构造函数后加=default) 使用explicit修饰构造函数, 使其无法进行隐式类型转换 explicit只能对含有1个参数或含有n个参数, 但其中n-1个参数有默认值的构造函数有效, 其余构造函数无法约束 隐式转换就是=赋值, 禁止隐式转换后, 但其本身还可以进行doubel到int的显式类型转换 拷贝构造函数：Foo(const Foo &amp;), 一般发生在使用已有的对象初始化一个正在创建的对象: 包含使用等号, 传参, 返回值&lt;非引用&gt;等 处理类的静态变量或需要进行深拷贝时需要自定义拷贝构造函数 浅拷贝出错时, 需要定义自己的拷贝构造函数, 或禁止拷贝 使用=delete可以指定函数禁止使用, 如禁止拷贝(将拷贝构造函数, 赋值运算符=delete) 移动构造函数：Foo(const Foo &amp;&amp;):右值引用, 可以避免不必要的拷贝赋值, 提升速度 构造函数为什么一般不定义为虚函数 虚函数对应一个虚函数表, 类中存储一个虚指针(vptr)指向该虚函数表 若构造函数是虚函数, 就需要通过vptr调用, 但对象没有初始化就没有vptr, 无法找到vtable 详解: 创建对象时必须确定其类型, 类型规定了对象可以进行哪些操作 虚函数在运行时才确定对象类型; 构造函数声明为虚函数, 构造对象时对象没有创建, 编译器不知道对象的实际类型 虚函数调用需要虚表指针; 构造函数为虚函数, 对象还未创建没有内存空间, 因此没有虚表指针调用虚函数 123456789101112131415161718192021222324252627// 初始化列表成员顺序题class Base&#123;public: Base(int a) :m_a(a) &#123;&#125; ~Base() &#123;&#125; int m_a;&#125;;class Derive:public Base &#123;public: Derive(int a, int c) :m_c(c), Base(a), m_b(m_a + m_c) &#123;&#125; ~Derive() &#123;&#125; int m_b; int m_c;&#125;;int main() &#123; Derive a(1, 10); cout &lt;&lt; a.m_a &lt;&lt; &#x27;\\t&#x27; &lt;&lt; a.m_b &lt;&lt; &#x27;\\t&#x27; &lt;&lt; a.m_c &lt;&lt; endl; system(&quot;pause&quot;);&#125;// 输出// m_a=1// m_b=未知，因为m_c此时并未赋值// m_c=10 上面的赋值顺序: ma,mb,mc 初始化列表的赋值顺序是由成员变量的定义顺序决定的, 且基类先与子类 C++中的类型转换 static_cast: 可以更改一切非常量性质的, 具有明确定义的类型转换 一般是一些风险较低的转换, 比如void*转int*、char*转void*、int转double等常用的转换关系 在编译期转换, 转换失败会报编译错误 const_cast: 改变对象的底层const属性, 去掉const性质 但是对象本身如果就是一个常量, 执行类型转换后的写操作是未定义的 reinterpret_cast: 较为底层的转换, 可将int * -&gt; char *, 比较危险, 不建议使用 相当于是对static_cast的补充, static_cast不能完成的转换，reinterpret_cast都可以完成，比如int转char dynamic_cast: 转换包含虚函数的基类派生类间的相互转换, 将基类的指针或者引用安全地转化成派生类的指针和引用 为什么是安全的：如果子类含有父类不存在的函数或者变量就会返回一个空值, 说转换不成功 使用static_cast仍然会转换成功, 不过调用子类的成员变量时, 由于不存在这些变量, 不存在的变量就会是随机数 转换成功的条件: 父类指针指向了子类, 而需要将父类再转回子类时才能成功, 其实本质上还是向上转型 子类与父类的类型转换 子类实例指针转型为父类实例指针, 不需要显式转换 父类指针转换为子类指针是不建议的, 如果确实需要则建议使用dynamic_cast 只有父类指针指向子类, 再将父类转成子类可以成功, 直接将父类转换成子类会失败 左值与右值引用 左值与右值 左值：可以取地址的，有名字的，非临时的 本质上是用户创建的, 通过作用域规则可知道生存周期(包括函数返回的局部变量的应用以及const对象) 右值：不能取地址的，没有名字的，临时的 本质上, 创建和销毁由编译器控制 左值引用与右值引用 左值引用: 要求右边的值必须能够取地址, 如果无法取地址, 可以用常引用 使用常引用后, 只能通过引用来读取数据, 无法修改数据, 因为其被const修饰成常量引用 右值引用: 主要用于移动语义 生命周期: 绑定到右值以后, 本来会被销毁的右值的生存期会延长到与绑定到它的右值引用的生存期 资源调配: 拷贝构造函数是新开辟一个空间, 进行拷贝; 移动构造函数, 则直接将对象赋给新对象, 直接使用了已经申请的资源, 既能节省资源, 又能节省资源申请和释放的时间 内联函数(inline) inline函数作用: 提高函数执行效率, 在程序的每个调用点将函数体展开, 而不是采用通常的函数调用机制, 从而减少额外开销 定义在类内的成员函数默认是inline函数, 虚函数除外 通常只有函数非常短(10行以内)时才适合定义为inline函数, 否则会导致程序变慢 头文件中不仅要包含inline函数的声明, 还要包含其定义, 方便编译器查找 inline函数会增加执行文件大小 虚函数 虚函数的概念 虚函数: 指在基类内部声明的成员函数前添加virtual关键字指明的函数 存在意义: 实现多态, 让派生类能重写(override)基类的成员函数 虚函数一旦声明就一直是虚函数, 派生类也无法改变其属性 虚函数动态绑定, 在运行时才确定, 而非虚函数的调用在编译时确定 虚函数必须是非静态成员函数, (因为静态成员函数在编译时确定) 构造函数不能是虚函数, 析构函数一般是虚函数 静态函数与虚函数的区别 静态函数在编译时已经确定 虚函数在运行时动态绑定, 使用虚函数表机制, 调用时会增加一次内存开销 虚函数一般不能声明为inline函数 inline函数在编译期间将函数内容替换到函数调用处, 为静态编译 虚函数为动态调用, 编译器不知道虚函数绑定的是哪个对象 虚函数工作机制 使用虚函数表+虚表指针 编译器在含有虚函数的类中创建虚函数表(vtable, 存放虚函数的地址), 隐式设置虚表指针(vptr, 指向该类对象的虚函数表) 派生类继承基类时, 也会继承基类的虚函数表 派生类重写了基类的虚函数时, 会将重写后的虚函数地址替换掉由基类继承而来的虚函数表中对应的虚函数地址 派生类没有重写基类的虚函数, 基类继承而来的虚函数的地址直接保存在派生类的虚函数表中 每个类都有一个虚函数表, 一个类的所有对象共享一个虚函数表, 并不是每个实例化对象都分别有一个虚函数表 运行时多态 多态: 静态多态, 动态多态 静态多态: 通过重载, 在编译时已经确定 动态多态: 通过虚函数机制实现, 在运行时动态绑定 指基类的指针指向其派生类, 通过基类的指针来调用派生类的成员函数 若基类通过引用或指针调用非虚函数, 无论实际对象什么类型, 都调用基类的函数 C++类的多态性通过虚函数实现 基类通过引用或指针调用虚函数时, 只有在运行时才能确定调用的是基类的虚函数还是派生类的虚函数 纯虚函数 纯虚函数 只在基类中声明, 但没有定义, 没有函数体 声明时只需要在虚函数形参列表后添加=0即可 含有纯虚函数的类都是抽象类, 只含有纯虚函数的类是接口类 抽象类 抽象类不能实例化对象 抽象类的派生类可以是抽象类(会继承), 也可通过实现全部的虚函数变成非抽象类, 从而可以实例化对象 抽象类的指针可以指向其派生类对象, 并调用派生类对象的成员函数 接口类 接口类没有任何数据成员, 也没有构造函数和析构函数 接口类的指针可以指向其派生类对象 智能指针 使用智能指针: 为了更安全且更加容易地管理动态内存 智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数来会自动释放资源，不需要手动地释放内存 当然，这并不是说使用智能指针就不会发生内存泄漏，只是它在很大程度上可以防止由于程序员的疏忽造成的内存泄漏问题 四个智能指针: auto_ptr, unique_ptr, share_ptr, weak_ptr 后面3个为C++11的新特性 auto_ptr 定义在&lt;memory&gt;中, C++11中因为不够安全被弃用, 被unique_ptr代替 unique_ptr: 同auto_ptr一样也是采用所有权模式, 即同一时间只能有一个智能指针可以指向某个对象 unique_ptr相比auto_ptr其禁止了拷贝=操作(引起安全问题), 采用了移动赋值 std::move()函数来进行控制权的转移 不管是auto_ptr还是unique_ptr, 都可以调用函数release或reset将(非const)unique_ptr的控制权转移给另一个 unique_ptr 如果unique_ptr是个临时右值, 编译器允许拷贝操作 share_ptr: 可以共享所有权的智能指针 定义在&lt;memory&gt;中, 允许多个智能指针指向同一个对象, 并使用引用计数的方式来管理指向对象的指针(use_count()可以获得引用计数), 该对象和其相关资源在最后一个引用被销毁时释放 销毁时, 调用析构函数, 析构函数先使引用计数减1, 若减至0则delete对象 内存泄露问题: 当两个对象分别使用一个共享指针share_ptr指向对方 智能指针使用引用计数机制来管理着它所指对象的生命周期 若某个对象A的share_ptr 指向了对象B，那么对象A只能在对象B先销毁之后它才会销毁；同理，若对象B的share_ptr 也指向了对象A，则只有在对象A先销毁之后B才会被销毁。因此，当两个对象的share_ptr 相互指向对方时，两者的引用计数永远不会减至0，即两个对象都不会被销毁，就会造成内存泄漏的问题 weak_ptr: 弱指针, 不控制对象生命周期的智能指针 指向一个share_ptr管理的对象, weak_ptr不会修改引用计数, 只是提供访问其管理对象的方法 share_ptr 可以直接赋值给weak_ptr; weak_ptr可调用lock成员函数获得share_ptr 智能指针的一大优点: 在对象离开作用域时自动释放对象(需自定义析构对象) 使用可调用类：可调用类指重载了调用运算符()的类, 其也是一个类, 用于保存一些状态 使用lambda表达式: auto DeleterLambda=[](Connection *connection)&#123;close connection;delete connection;&#125; 3 Python编程题汇总 enumerate() 用在for循环中, 将可遍历的数据对象组合成一个索引序列, 同时列出数据和数据下标 global global实现定义全局变量 lambda匿名函数 精简代码, lambda省去了定义函数, map省去了写for循环过程 res = list(map(lambda x: &quot;填充值&quot; if x==&quot;&quot; else x, str_1)) Python错误处理 try-except-finally any()与all()方法 any(): 只要迭代器中有一个元素为真就为真 all(): 迭代器中所有的判断项返回都是真，结果才为真 提高 Python 运行效率的方法 使用生成器，因为可以节约大量内存; 循环代码优化，避免过多重复代码的执行; 核心模块用 Cython PyPy 等，提高效率; 多进程、多线程、协程; 多个 if elif 条件判断，可以把最有可能先发生的条件放到前面写，可以减少程序判断的次数，提高效率 Python为什么不提供函数重载 对可变参数类型：python可以接受任何类型的参数，不需要做成两个不同函数 对可变参数个数：使用缺省参数(默认参数) *args与**kargs, *与** args与kargs为名称, 可使用其他的代替 *args为可变位置参数, 传入的参数会被放进元组里 **kargs为可变关键字参数, 传入的参数以键值对的形式存放到字典里 *与**的区别 *将元组转换为多个单元素 **将字典去除key, 留下的value变成多个单元素 import与from import import: 导入包, 使用其成员时需指明是哪个库 from import导入时指明是哪个库的成员, 后续使用不需要再次指明 Python中实例方法/静态方法/类方法 区别： 实例方法只能被实例对象调用 静态方法(由@staticmethod装饰器来声明), 类方法(由@classmethod装饰器来声明)，可以被类或类的实例对象调用; 传参 实例方法，第一个参数必须要默认传实例对象，一般习惯用self 静态方法，参数没有要求 类方法，第一个参数必须要默认传类，一般习惯用 cls 12345678910111213class Foo(object): &quot;&quot;&quot;类三种方法语法形式 &quot;&quot;&quot; def instance_method(self): print(&quot;是类&#123;&#125;的实例方法，只能被实例对象调用&quot;.format(Foo)) @staticmethod def static_method(): print(&quot;是静态方法&quot;) @classmethod def class_method(cls): print(&quot;是类方法&quot;) 类方法和静态方法 大多数情况下, 类方法可以通过静态方法代替, 但在通过类调用时, 对调用者来说不可区分 区别: classmethod增加了一个对实际调用类的引用 方法可以判断自身是通过基类被调用还是通过某个子类被调用 通过子类调用时, 方法可以返回子类的实例而非基类的实例; 且可以调用子类其他classmethod staticmethod唯一的好处: 调用时返回的是真正的函数, 没有多态性 staticmethod可在子类上被重写为classmethod, 但反之不可以 __new__和 __init __方法的区别 __new__ 方法是静态方法, 是构造函数(在每次创建类得新对象时执行), 用于创建对象并返回对象，在返回对象时会自动调用__init__方法，执行较__init__方法早 __init__ 是实例方法, 并不是严格意义上的构造函数 __len__ len()函数返回多少个元素, 需要定义__len__()魔术方法返回元素个数 Python函数参数传递 将可变对象(列表list、字典dict、NumPy数组ndarray和用户定义的类型(类))，作为参数传递给函数，函数内部将其改变后，函数外部这个变量也会改变(对变量进行重新赋值除外) 函数传参方式是引用传递, 底层实现的是传递引用变量 将不可变对象(字符串string、元组tuple、数值numbers)作为参数传递给函数, 函数内部将其改变后, 函数外部这个变量不会改变 可以将数据包装成列表(字典)等可变对象, 通过列表(字典)的方式修改 Python实现对函参做类型检查 使用isinstance()实现 添加了参数检查后传入错误的参数类型，函数抛出TypeError错误 为什么说Python是动态语言 =是赋值语句，可以把任意数据类型赋值给变量,同样一个变量可以被不同类型的变量反复赋值 Python动态语言：变量本身类型不固定, 可以反复赋值不同类型的变量成为动态语言 迭代器 __getitem__ 类中实现了该方法, 其实例对象可以使用p[key]进行取值(会调用__getitem__方法) 一般若想使用索引访问元素, 需要在类中定义__getitem__方法 __iter__() 迭代器, 生成迭代对象时调用(只在生成对象时调用一次) 返回值必须是对象本身(self), 然后使用for循环调用next方法 若对同一个对象生成两个迭代器对象, 两个迭代器对象一个被修改, 另一个也会自动执行相应的修改 __next__() 每一次for循环都会调用该方法(优先级高于__getitem__()) 深度学习的应用 __getitem__：常用于数据加载类(Dataset)中，用于对象的迭代，每次迭代都执行一次__getitem__中的数据加载函数，以获取相应的数据 __len__：常用于数据加载类（Dataset）中，以便可以使用len()函数获取数据总数，方便计算训练一个epoch需要多个batch（更多的是显示作用） __iter__()：常用于数据加载类（Dataset）中，固定写法返回self __next()__和__getitem__很像，深度学习中一般只使用__getitem__不断读取数据，next()使用较少 三者的区别 都可以在for中使用, 进行迭代操作 __getitem__用于可迭代对象的索引（如p[key]），也可用于for的迭代（但优先级低于__next__） __iter__和__next__只用于对象的迭代（如for）（通过iter()/next()调用对应的创建迭代器、迭代操作函数） 可迭代对象必须包含__getitem__或者同时包含__iter__和__next__，或者同时包含。（同时包含时，在循环中__next__的优先级高于__getitem__，只会执行__next__） 生成器(yield) 生成器: 使用了yield函数 生成器返回迭代器对象, 只能用于迭代操作; 生成器就是一个迭代器 调用生成器的过程中, 每次遇到yield时函数会自动暂停并保存当前所有运行信息, 返回yield值, 并在下一次执行next()方法是从当前位置继续运行 map 与 reduce函数用法解释 map()函数接受两个参数,一个是函数,一个是Iterable map将传入的函数依次作用到序列的每个元素, 将结果作为新的Iterator返回 注意map()返回的是Iterator(惰性序列), 需要通过list()转换为常用列表结构 reduce()函数接受两个参数,一个是函数,一个是序列 与map()不同的是reduce()把结果继续和序列的下一个元素做累积计算 reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) Python赋值、深拷贝、浅拷贝区别 复制不可变数据类型 不管 copy 还是 deepcopy, 都是同一个地址, 对象的 id 值与浅复制原来的值相同 复制可变数据类型 直接赋值: 为对象的引用(别名) 浅拷贝(copy)：重新分配一块内存, 创建一个新的对象, 但里面的元素是原对象中各个子对象的引用(只拷贝地址, 但地址指向的仍然是同一个变量) 使用切片[:]操作 使用工厂函数 使用copy模块和copy()函数, 但是子对象还是指向统一对象(是引用) 深拷贝(deepcopy): 重新分配一块内存, 创建一个新的对象, 并且将原对象中的元素以递归的方式创建新的子对象拷贝到新对象中 使用copy模块和deepcopy()函数，完全拷贝了父对象及其子对象, 两者是完全独立. 深拷贝包含对象里面的子对象拷贝, 所以原始对象的改变不会造成深拷贝里任何子元素的改变 Python多态与继承的理解 多态是指对不同类型的变量进行相同的操作, 会根据对象(或类)类型的不同而表现处不同的行为 继承可以拿到父类的所有数据和方法, 子类可以重写父类的方法, 也可以新增自己特有的方法 先有继承后有多态, 不同类的对象对同一消息会做出不同的响应 super() 设计目的: 解决多重继承时父类的查找问题, 在子类需要调用父类的方法时使用 好处: 可以避免直接使用父类的名字, 主要用于多继承 list与np.array区别 list: 内置数据类型, list内的数据类型不必相同, 保存的是数据存放的地址(指针) np.array(ndarray): numpy中的函数, 元素必须同一类型 具有矢量运算能力和广播能力 array()方法可以将任何序列类型转换成ndarray数组 numpy堆叠数组函数 ravel(): 让将多维数组展平成一维数组.若不指定任何参数,ravel()将沿着行(第0维)展平/拉平输入数组 stack(): 沿给定轴连接数组序列, 两个数组必须有相同的形状,且输出的结果的维度比输入的数组多一维 vstack(): 垂直堆叠序列中的数组, 除了需要堆叠的轴外其他轴上具有相同的shape hstack(): 水平堆叠序列中的数组, 除了需要堆叠的轴外其他轴上具有相同的shape concatenate(): 可以实现stack(), vstack(), hstack()的功能, 根据指定的维度，对一个元组、列表中的list或者ndarray进行连接 注意：axis指定的维度（即拼接的维度）可以是不同的，但是axis之外的维度（其他维度）的长度必须是相同的 可调用类型__call__() 类中定义了__call__(self, param)函数, 则该类的对象就可以当作函数调用, 且默认调用的是__call__()函数 __init__.py作用 标识该目录是一个python的模块包(module package) 简化了模块导入操作; 本来需要按文件一级一级导入的程序, 现在可以将这些函数全部写入__init__.py中, 只需要导入这个模块包就可以导入这个模块包下的所有程序了 使用__all__关联一个模块列表, 在执行from xx import *时, 自动导入列表中的模块 __init__.py是在程序导入(import)时执行的 装饰器 实现的技术前提 高阶函数: 函数参数是一个函数名或返回的是函数名 函数嵌套: 在一个函数中定义另一个函数 闭包: 在函数嵌套中, 内部函数对外部函数作用域的引用, 称内部函数为闭包 装饰器: 增强函数或类的功能的一个函数(对函数进行功能更新, 主要是前后处理, 无法对函数进行修改) 装饰器本质上是一个Python函数或类，可以让其他函数或类在不需要做任何代码修改的前提下增加额外功能，装饰器的返回值也是一个函数/类对象 经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景，装饰器是解决这类问题的绝佳设计 使用装饰器可以抽离出大量与函数功能本身无关的雷同代码到装饰器中并继续重用 使用方法 不用@符号: f=decorator(函数名)或f=(decorator(参数))(函数名) 使用@符号: 本质上@就是装饰器用来装饰@下面的函数 自身不传入参数的装饰器使用两层函数定义装饰器, 自身传入参数的装饰器采用三层函数定义装饰器 123456789101112131415161718192021222324252627# 自身不传入参数的装饰器def login(func) : def wrapper(*args ,**kargs): print( &#x27;函数名:%s &#x27;% func. __name__) return func(*args,**kargs) return wrapper@logindef f(): print( &quot; inside decorator ! &#x27;) f()# 自身传入参数的装饰器def login(text): def decorator(func) : def wrapper(*args,**kargs ): print( &quot;%s%s &quot;%(text， func.__name__)) return func(*args ,**kargs) return wrapper return decorator# 等价于=-&gt;( login(text))(f)==&gt;返回wrapper@login( &#x27;this is a parameter of decorator&#x27; )def f(): print( &#x27; 2019-06-13&#x27;)#等价于-=&gt;(login(text))(f)()==&gt;调用wrapper()并返回f()f() 内置装饰器 @propert: 将类内方法当成属性使用, 必须有返回值, 相当于getter 假如没有定义@func.setter修饰方法, 就是只读属性, 不可修改 @classmethod: 类方法, 不需要self参数, 但第一个参数需要时表示自身类的cls参数 内部使用该类方法, 直接使用cls替代类名(相较@staticmethod方法更加方便, 不需要写类名) @staticmethod: 静态方法, 不需要表示自身对象的self和表示自身类的cls参数 不需要传入上述参数, 但内部使用类方法时, 需要把类名写上 123456789101112131415161718class Car: def __init__(self, name, price): self._name = name self._price = price @property def car_name(self): return self._name # car_name可以读写的属性，以下是固定写法，如果不加，car_name就是一个只读属性 @car_name.setter def car.name(self, value): self._name = value # car_price是只读属性 @property def car_price(self): return str(self._price) + &#x27;万&#x27; 4 Pytorch基础知识 为什么用model(input)而不是model.forward(input) pytorch中nn.Module内部定义了__call__()函数, 其内容调用self.forward() Pytorch维度变换 squeeze(): 对tensor进行维度压缩，去掉维数为1的维度 unsqueeze(): 对tensor进行维度扩充，给指定位置上加上维数为1的维度 Pytorch维度交换 .transpose: 只能交换两个维度 .permute: 可以交换任意位置 合并分割 合并 .cat()为连接, 不会增加维度 .stack()为堆叠, 会增加一个维度 分割 .split()将张量拆分为多个块，每个块都是原始张量的视图 .chunk(input, chunks, dim=0)将tensor按dim分割成chunks个tensor， 返回的是一个元组 上采样方法总结 基于线性插值的上采样: 最近邻算法(nearest), 双线性插值算法(bilinear), 双三次插值算法(bicubic) Pytorch老版本使用nn.Upsample()， 新版本使用torch.nn.functional.interpolate(可以实现定制化需求的上采样或下采样功能) 基于深度学习的上采样(转置卷积, Conv2dTranspose2d) 先padding来扩大图像尺寸，紧接着跟正向卷积一样，旋转卷积核180度，再进行卷积计算 Unpooling方法(简单的补零或扩充操作) tensor数据结构相关 参数requires_grad=True，torch.autograd会记录相关的运算结果实现自动求导 每一个tensor都有一个相应的torch.Storage保存其数据 view 和 reshape的区别 view只适合对满足连续性(contiguous)的tensor进行操作 reshape同时还可以对不满足连续性条件的tensor进行操作 当tensor满足连续性条件时,view和reshape返回的结果相同, 都不会开辟新的内存空间, 不满足时,直接调用view方法会失效, reshape方法会开辟新的内存空间并返回副本","categories":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"}],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"}]},{"title":"深度学习基础知识点补缺","slug":"深度学习基础知识点补缺","date":"2023-03-08T09:20:24.000Z","updated":"2023-05-19T03:30:54.801Z","comments":true,"path":"2023/03/08/深度学习基础知识点补缺/","link":"","permalink":"http://jay1060950003.github.io/2023/03/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E7%BC%BA/","excerpt":"引言 深度学习的基础知识查漏补缺以及高频面试题","text":"引言 深度学习的基础知识查漏补缺以及高频面试题 深度学习基础 基本概念 为什么使用深层表示 深度神经网络是一种特征递进式的学习方法, 浅层神经元学习低层次的简单特征, 深层的特征基于以学习到的浅层特征继续学习更高级的特征 深层的网络隐藏单元数量相对较少, 隐藏层数目较多, 若浅层的网络想达到相同的计算结果需要指数级增长的单元数量 神经网络更深的意义 前提: 一定范围内 在神经元数量相同的情况下, 深层网络结构具有更大容量, 分层组合带来的是指数级的表达空间, 更容易学习和表示各种特征 隐藏层增加意味着由激活函数带来的非线性变换的嵌套层数更多, 能构造更加复杂的映射 网络操作与计算 卷积神经网络中卷积操作和互相关操作的关系 实际上卷积神经网络中的卷积操作为互相关操作 严格卷积操作: 需要将卷积核上下左右翻转后再进行互相关操作 但图像处理中大部分的卷积核都是中心对称的, 互相关操作与卷积操作一致 池化层 种类：最大池化和平均池化 最大池化：前向传播时将最大值作为结果, 反向传播时通过最大值的位置传播梯度, 其他位置梯度为0 平均池化：前向传播时将平均值作为结果, 反向传播时将梯度均分给每个位置 选择与实际应用 最大池化：可以学到图像的边缘和纹理结构, 用于减小估计值的方差, 保留强激活值但容易过拟合 平均池化：减小估计值均值的偏移, 会弱化强激活值 池化层的作用 增加非线性 保留主要特征的同时减少参数(降维)和计算量, 防止过拟合, 提高模型泛化能力 利用max pooling可以引入平移不变性, 旋转不变性和尺度不变性, 从而可以增大感受野 但在降维过程中会损失一部分信息 其他池化方法: 重叠池化: 相邻池化窗口之间重叠 SPP(空间金字塔池化): 用大小不同的池化窗口作用域feature map CNN加入SPP层之后, CNN可以处理任意大小的输入, 模型更加灵活 卷积,池化尺寸及感受野计算 卷积：o=⌊i+2p−ks⌋+1o=\\left\\lfloor\\frac{i+2 p-k}{s}\\right\\rfloor+1o=⌊si+2p−k​⌋+1 池化：o=⌊i−ks⌋+1o=\\left\\lfloor\\frac{i-k}{s}\\right\\rfloor+1o=⌊si−k​⌋+1 感受野: RFN−2=(RFN−1−1)∗s+kRF_{N-2} = (RF_{N-1} -1)*s + kRFN−2​=(RFN−1​−1)∗s+k, s和k是第N-2层的 [ ] 代码实现卷积操作 激活函数 为什么需要非线性激活函数 为什么需要激活函数 激活函数对模型学习、理解非常复杂和非线性的函数具有非常重要的作用 激活函数可以引入非线性因素 激活函数可以把当前特征空间通过一定线性映射转换到另一个空间 为什么激活函数需要非线性函数 若网络全部为线性组件, 线性的组合还是线性, 与单独一个线性分类器无异. 不能用非线性来逼近任何函数 使用非线性激活函数, 网络会更加强大, 使用非线性激活函数, 能够从输入输出之间生成非线性映射 激活函数的性质 非线性: 非线性激活函数, 一个两层的神经网络基本就可以逼近所有函数 连续并可导(允许少数点上不可导) 单调性: 当激活函数单调时, 单层网络能保证是凸函数 激活函数及导函数要尽可能的简单, 有利于提高网络计算效率 f(x)≈xf(x)≈xf(x)≈x：当激活函数满足这个性质的时候, 如果参数的初始化是随机的较小值, 那么神经网络的训练将会很高效; 如果不满足这个性质, 那么就需要详细地去设置初始值; 激活函数的导函数的值域要在一个合适的区间内, 不能太大也不能太小, 否则会影响计算的效率和稳定性 激活函数详解 Sigmoid函数 函数公式: σ(x)=11+exp(−x)\\sigma(x) = \\frac{1}{1 + exp(-x)}σ(x)=1+exp(−x)1​ 导函数: ddxσ(x)=exp(−x)(1+exp(−x))2=σ(x)(1−σ(x))\\frac{\\mathrm{d} }{\\mathrm{d} x} \\sigma(x) = \\frac{exp(-x)}{(1+exp(-x))^2} = \\sigma(x)(1 - \\sigma(x))dxd​σ(x)=(1+exp(−x))2exp(−x)​=σ(x)(1−σ(x)) 软饱和性：当sigmoid函数的输入很大或很小时, 梯度会消失 导致sigmoid函数在隐藏层中使用较少, 使用更简单更容易训练的ReLu函数替代 在二分类与多分类多标签问题中, 损失函数为sigmoid+nn.BCELoss();多分类单标签问题损失函数nn.CrossEntropyLoss(), 无需手动做softmax nn.BCEWithLogitsLoss() 函数等效于 sigmoid + nn.BCELoss 优点: 函数平滑容易求导 缺点: 容易造成梯度消失 存在幂运算, 计算量大 输出不关于零点对称 Tanh函数 函数公式: tanh(x)=2σ(2x)−1=21+e−2x−1\\text{tanh}(x) = 2\\sigma(2x) - 1 = \\frac{2}{1 + e^{-2x}} - 1tanh(x)=2σ(2x)−1=1+e−2x2​−1 导函数: ddxtanh(x)=1−tanh2(x)\\frac{\\mathrm{d} }{\\mathrm{d} x} \\text{tanh}(x) = 1 - \\text{tanh}^{2}(x)dxd​tanh(x)=1−tanh2(x) 可以看作放大并平移的sigmoid函数 Tanh函数优缺点总结: 具有Sigmoid的所有优点 exp指数计算代价大, 梯度消失问题依然存在 优点: 函数平滑, 容易求导 输出关于零点对称 缺点: 容易造成梯度消失 计算量大 ReLu函数 公式:ReLU(x)=max(0,x)={xx≥00x&lt;0ReLU(x) = max(0, x) = \\left \\lbrace \\begin{matrix} x &amp; x \\geq 0 \\\\ 0 &amp; x&lt; 0 \\end{matrix}\\right.ReLU(x)=max(0,x)={x0​x≥0x&lt;0​ ReLu函数仅保留正元素并丢弃所有负元素 优点 ReLU 激活函数计算简单, 且运算速度较快 ReLu单侧抑制, 使一部分神经元输出为0, 使网络具有稀疏性, 且减少了参数的相互依存, 解决了过拟合的问题 函数在x &gt; 0时导数为1的性质(左饱和函数), 在一定程度上缓解了神经网络的梯度消失问题, 加速梯度下降的收敛速度 缺点 ReLU 神经元在训练时比较容易“死亡”(如果神经元参数值在一次不恰当的更新后, 其值小于 0, 那么这个神经元自身参数的梯度永远都会是 0, 在以后的训练过程中永远不能被激活, 这种现象被称作“死区”) ReLU 函数的输出是非零中心化的, 给后一层的神经网络引入偏置偏移, 会影响梯度下降的效率 Leaky ReLU函数 为了缓解“死区”现象, 研究者将 ReLU 函数中 x &lt; 0 的部分调整为 γ⋅x\\gamma \\cdot xγ⋅x, 其中 γ\\gammaγ 常设置为 0.01 或 0.001 数量级的较小正数. 这种新型的激活函数被称作带泄露的 ReLU(Leaky ReLU) 公式: Leaky ReLU(x)=max(0,𝑥)+γ min(0,x)={xx≥0γ⋅xx&lt;0\\text{Leaky ReLU}(x) = max(0, 𝑥) + \\gamma\\ min(0, x)= \\lbrace \\begin{matrix} x &amp; x\\geq 0 \\\\ \\gamma \\cdot x &amp; x&lt; 0 \\end{matrix}Leaky ReLU(x)=max(0,x)+γ min(0,x)={xγ⋅x​x≥0x&lt;0​ PReLU函数 为了解决 Leaky ReLU 中超参数 γ\\gammaγ 不易设定的问题, 有研究者提出了参数化 ReLU(Parametric ReLU,PReLU).参数化 ReLU 直接将 γ\\gammaγ 也作为一个网络中可学习的变量融入模型的整体训练过程 对于第 iii 个神经元,PReLU的定义为: Leaky ReLU(x)=max(0,𝑥)+γi min(0,x)={x≥0γi⋅xx&lt;0\\text{Leaky ReLU}(x) = max(0, 𝑥) + \\gamma_{i}\\ min(0, x) = \\lbrace\\begin{matrix} &amp; x\\geq 0 \\\\ \\gamma_{i} \\cdot x &amp; x&lt; 0 \\end{matrix}Leaky ReLU(x)=max(0,x)+γi​ min(0,x)={γi​⋅x​x≥0x&lt;0​ Swish函数 公式: swish(x)=xσ(βx)\\text{swish}(x) = x\\sigma(\\beta x)swish(x)=xσ(βx) 其中 σ(⋅)\\sigma(\\cdot)σ(⋅) 为 Logistic 函数, β\\betaβ 为可学习的参数或一个固定超参数. σ(⋅)∈(0,1)\\sigma(\\cdot) \\in (0, 1)σ(⋅)∈(0,1) 可以看作一种软性的门控机制 当 σ(βx)\\sigma(\\beta x)σ(βx) 接近于 1 时, 门处于“开”状态, 激活函数的输出近似于 xxx 本身 当 σ(βx)\\sigma(\\beta x)σ(βx) 接近于 0 时, 门的状态为“关”, 激活函数的输出近似于 0 Swish 函数可以看作线性函数和 ReLU 函数之间的非线性插值函数, 其程度由参数 β\\betaβ 控制 相对于sigmoid激活函数, tanh激活函数输出关于零点对称的好处 sigmoid函数其输出始终为正, 导致在深度网络训练中模型的收敛速度变慢, 因为在反向传播链式求导过程中, 权重更新的效率会降低 sigmoid函数的输出均大于0, 作为下层神经元的输入会导致下层输入不是0均值的, 随着网络的加深可能会使得原始数据的分布发生改变. 而在深度学习的网络训练中, 经常需要将数据处理成零均值分布的情况, 以提高收敛效率, 因此tanh函数更加符合这个要求 sigmoid函数的输出在[0,1]之间, 比较适合用于二分类问题 如何解决ReLu神经元死亡的问题 为什么ReLU会出现神经元死亡的问题 当学习率比较大, 而且梯度也很大时, 会导致权重更新太多, 有可能出现对于所有的训练样本, 该神经元输出都&lt;0, 那么该神经元的权值就不会再更新了 解决方法 采用Leaky ReLu等激活函数: 使其在该神经元的输出为负时, 仍然可以对该神经元进行梯度更新 设置较小的学习率进行训练: 尽可能避免因为梯度过大更新导致对于神经元的所有输入的输入都小于0 使用momentum优化算法动态调整学习率: 使用momentum优化算法, 利用惯性, 抑制异常数据的更新方向, 避免神经元死亡 softmax定义及作用 softmax是logistic函数的一种泛化, 是网络预测多分类问题的最佳激活函数 加入eee的幂函数可形成两极化, 正样本的结果趋近于1, 负样本的结果趋近于0 用于将分类结果归一化, 形成概率分布 softmax⁡(xi)=exp⁡(xi)∑jexp⁡(xj)\\operatorname{softmax}\\left(x_i\\right)=\\frac{\\exp \\left(x_i\\right)}{\\sum_j \\exp \\left(x_j\\right)}softmax(xi​)=∑j​exp(xj​)exp(xi​)​ 由于指数函数的方法作用过于明显, 直接使用公式容易导致数据溢出 12345678910import numpy as npdef softmax(x, axis=1)&#123; row_max = np.max(x, axis=axis) #计算最大值 row_max = row_max.reshape(-1, 1) #数据展开为m*1的形状, 方便使用广播做差 x = x-row_max #减最大值 x_exp = np.exp(x) #求exp s = x_exp/np.sum(x_exp, axis=axis, keepdim=True) return s&#125; Batch_Size 在合理的范围内, 增大Batch_Size的好处 增加内存利用率, 大矩阵乘法的并行化效率提高 对相同数据量的处理速度加快, 跑完一个epoch(全数据集)需要的迭代次数减少 一定范围内, Batch_Size越大, 其确定的下降方向越准, 引起的训练震荡越小 盲目增大Batch_Size的坏处 内存容量可能不够 跑完一次epoch(全数据集)所需的迭代次数减少, 要想达到相同的精度, 其所花费的时间大大增加了, 从而对参数的修正也就显得更加缓慢 Batch_Size 增大到一定程度, 其确定的下降方向已经基本不再变化 归一化 为什么要归一化 为了后面数据处理更加方便, 可以避免一些数值问题 为了程序运行时收敛加快 统一量纲 避免神经元饱和. 当神经元的激活在接近0或1时会饱和, 梯度几乎为0, 造成无法更新 保证输出数据中数值小的不被吞食 为什么归一化能提高求解最优解速度 在使用梯度下降法寻求最优解时, 很有可能走“之字型”路线(垂直等高线走)，从而导致需要迭代很多次才能收敛; 而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛 为什么对数值型特征做归一化 消除特征之间量纲的影响, 使得不同特征之间具有可比性 在使用随机梯度下降求解时, 能加快模型收敛速度 归一化之后, 损失函数等高线图大致为圆形的, 更新方向与等高线垂直更加平滑, 而未归一化等高线图为椭圆形, 更新方向为横向 归一化可能提高精度, 一些分类器需要计算样本之间的距离, 小的特征值域范围更加有利于计算 为什么输入网络前对图像进行归一化 灰度数据表示一种是uint8, 另一种是double. 当运算的类型为double是需要进行归一化 在使用随机梯度下降求解时, 未进行归一化输入分布差异很大, 各个参数的梯度数量级不同, 需要的学习速度不同, 归一化后可以方便的选择学习率 标准化后实现了数据中心化, 数据中心化符合数据分布规律, 能增加模型泛化能力 BN层的深入理解 BN介绍 不同层的数据分布会往激活函数的上限或下限偏移, 第一层数据分布改变会导致第二层分布改变, 模型拟合效果会降低, 收敛速度下降(对下一轮更新时数据陌生), BN将每一层数据标准化到高斯分布 核心公式 Input:B={x1...m};γ,β(这两个是可以训练的参数)Input:B=\\{x_{1...m}\\}; \\gamma, \\beta (这两个是可以训练的参数)Input:B={x1...m​};γ,β(这两个是可以训练的参数) Output:{yi=BNγ,β(xi)}Output : \\{y_i = BN_{\\gamma, \\beta}(x_i)\\}Output:{yi​=BNγ,β​(xi​)} μB←1m∑i=1mxiσB2←1m∑i=1m(xi−μB)2\\mu_{B} \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m}{x_i} \\\\ \\sigma_B^2 \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m}{(x_i - \\mu_B)^2}μB​←m1​∑i=1m​xi​σB2​←m1​∑i=1m​(xi​−μB​)2 x~i=xi−μBσB2+ε（分母加ε是为了防止方差为0）yi=γx~i+β\\tilde{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\varepsilon}} \\quad （分母加\\varepsilon是为了防止方差为0）\\\\ y_i = \\gamma \\tilde{x}_i + \\betax~i​=σB2​+ε​xi​−μB​​（分母加ε是为了防止方差为0）yi​=γx~i​+β BN对数据进行了变换重构, 引入可学习参数γ,β\\gamma, \\betaγ,β使网络可以恢复出原始网络所要学习的特征分布, 可以避免使用强制归一化, 大多数的数据无法激活, 学习特征被破坏 BN中的均值与方差通过哪些维度计算得到 神经网络中的张量数据维度为[N, C, H, W], BN在NHW维度做均值, 从而得到2C个训练参数(将每个通道的数据单独相加, 再除以N*H*W) 训练时: 均值和方差分别是该批次内数据相应维度的均值与方差 推理时: 均值为所有训练时batch的\\mu_B的平均值, 方差为训练时每个batch的σB2\\sigma_B^2σB2​的无偏估计 BN的优缺点 优点 防止网络梯度消失 加速训练, 且允许更大的学习率: 通过normalization数据分布在合适的范围, 经过激活函数可以得到不错的梯度, 训练更快 降低参数初始化敏感度: 随着网络层数的增加, 分布逐渐发生偏移, 之所以收敛慢, 是因为整体分布往非线性函数取值区间的上下限靠近. 这会导致反向传播时梯度消失. BN就是通过规范化的手段, 把每层神经网络任意神经元这个输入值的分布强行拉回到均值0方差1的标准正态分布, 使得激活函数输入值落入非线性函数中比较敏感的区域 提高网络泛化能力防止过拟合: 因为BN统计了一个batch内所有样本的信息, 从而引入了一定的噪声, 这个噪声也就起到了正则化的作用 可以把训练数据彻底打乱 缺点: 如果Batch Size太小, 则BN效果明显下降 对于有些像素级图片生成任务来说, BN效果不佳 RNN等动态网络使用BN效果不佳, 且使用起来不方便 其他的几种类似BN结构 LN: 在N通道归一化 IN: 在CN通道归一化 GN: 部分特征图在同一batch归一化 [ ] BN的代码实现 预训练与微调 什么是模型微调fine tuning 别人的参数、修改后的网络和自己的数据进行训练，使得参数适应自己的数据，这样一个过程，通常称之为微调 微调先冻结底层，训练顶层的原因？ ​ 首先冻结除了顶部改动层以外的所有层参数，对顶层进行训练，这个过程可以理解为顶层的域适应训练，主要用来训练适应模型的现有特征空间，防止顶层糟糕的初始化，对已经具备一定表达能力的层的干扰和破坏，影响最终的性能。之后，在很多深度学习框架教程中会使用放开顶层往下一半的层数，继续进行微调。这样的好处在于越底层的特征通常是越通用的特征，越往上其整体的高层次语义越完备，这通过感受野很容易理解。所以，若预训练模型的数据和微调训练的数据语义差异越大（例如ImageNet的预模型用于医学图像的训练），那越往顶层的特征语义差异就越大，因此通常也需要进行相应的调整 权重偏差初始化 为什么神经网络权重不能初始化为0 因为所有参数为0, 经过第一层网络后, 所有的输入为0, 因此从第二层网络开始, 所有的输入神经元均一样, 从而打破了&quot;非对称性&quot;原则. 因此每次反向传播每个神经元得到的更新都是相同的, 网络无法正常学习 结论 网络中不可以连续相邻两层及以上的权重全部置0, 否则会出现权值对称性问题 为什么神经网络权重不能设为相同的值 权重设为非0相同值, 本质上也是使第二层网络开始形成了近似的对称性, 从而使网络梯度更新的非常慢 为什神经网络的最后一层可以将所有权值初始化为0 因为最后一层网络的输入不相同（即a1≠a2≠0a_1\\neq a_2\\neq0a1​=a2​=0）, 所以最后一层的权值依然可以正常更新. （最后一层的偏置, 永远都可以正常更新, 无论是否全部初始化为0） 而其他层正常初始化, 依然可以正常更新, 所以整个网络都可以正常更新. 使用场景： 如注意力机制中, 一般只是为了学习特征的增量用于shortcut, 理论上这个增量不能太大, 因此, 将注意力模块的最后一层卷积设置为0, 使其在最优值附近, 方便收敛, 逻辑回归参数初始化为什么可以设置为0 如果w11,w21,bw_{11}, w_{21}, bw11​,w21​,b都初始化为0时, 由于输入x1,x2x_1, x_2x1​,x2​不一样, 所以最后他们的变化率dw11,dw21,dbdw_{11}, dw_{21}, dbdw11​,dw21​,db都不为0, 且都不相同, 所以权值可以正常更新 参数初始化方法 过大或过小的初始化：如果权值的初始值过大,则会导致梯度爆炸,使得网络不收敛; 过小的权值初始值,则会导致梯度消失,会导致网络收敛缓慢或者收敛到局部极小值 权值的初始值过大,则loss function相对于权值参数的梯度值很大,每次利用梯度下降更新参数的时,参数更新的幅度也会很大,导致loss function的值在其最小值附近震荡 + 过小的初值则相反,loss关于权值参数的梯度很小,每次更新参数时,更新的幅度也很小,导致loss的收敛很缓慢,或者在收敛到最小值前在某个局部的极小值收敛了 方法选择: 优先采用Pre-train初始化, 随机初始化带BN, He初始化 随机初始化带BN方法 BN可以将过大或过小的数据都归一化到0-1分布, 避免了梯度爆炸或梯度消失 Xavier初始化 基本思想: 保证输入和输出的数据分布(均值和方差)一致, 使网络具有更好的信息流动, 更易学习 Xavier初始化主要用于tanh, 不适用于ReLu, 适合关于0点对称的激活函数 根据输入和输出神经元的数量自动决定初始化的范围：定义参数所在的层的输入维度为 mmm, 输出维度为nnn, 那么参数将从(−6m+n,6m+n)(-\\sqrt{\\frac{6}{m+n}}, \\sqrt{\\frac{6}{m+n}})(−m+n6​​,m+n6​​)均匀分布中采样 为什么方差相等, 就可以使得网络有更好的信息流动 在考虑线性激活函数的情况下, 在初始化的时候使各层神经元的方差保持不变, 即使各层有着相同的分布. 如果每层都用N(0, 0.01)随机初始化的话, 各层的数据分布不一致, 随着层度的增加, 神经元将集中在很大的值或很小的值, 不利于传递信息. 很多初始化策略都是为了保持每层的分布不变, 而BN是通过增加归一化层使得每层数据分布保持在N(0, 1) He初始化 Xavier初始化适合关于0点对称的激活函数, 不适合Relu He初始化非常适合ReLu激活函数； 主要解决的问题: 由于经过ReLu后, 方差会发生变化, 因此初始化权值的方法也应该变化. 只考虑输入个数时, MSRA初始化是一个均值为0, 方差为2/n的高斯分布: w∼G[0,2n]w \\sim G\\left[0, \\sqrt{\\frac{2}{n}}\\right]w∼G[0,n2​​] He初始化的思想是: 在ReLU网络中, 假定每一层有一半的神经元被激活, 另一半为0, 要保持方差不变, 只需要在Xavier的基础上再除以2: 1w = np.random.randn(node_in, node_out) / np.sqrt(node_in/2) 12345678910# 常见的初始化权重写法def weights_init(m): classname = m.__class__.__name__ if classname.find(&#x27;Conv2d&#x27;) != -1: nn.init.xavier_normal_(m.weight.data) nn.init.constant_(m.bias.data, 0.0) elif classname.find(&#x27;Linear&#x27;) != -1: nn.init.xavier_normal_(m.weight.data) nn.init.constant_(m.bias.data, 0.0)model.apply(weights_init) # 模型权值初始化 参数 xavier_normal_初始化：针对激活函数为sigmoid的 kaiming_normal_初始化：针对激活函数为relu的 constant_：初始化为常数 学习率 学习率的作用 梯度下降通过多次迭代, 并在每一步中最小化成本函数, 在迭代中学习率会控制模型得学习进度 在迭代得前提, 学习率大便于以较快得速度进行梯度下降, 而在后期, 逐渐减小学习率有助于算法收敛, 更容易得到最优解 学习率衰减方法 分段常数衰减 指数衰减 自然指数衰减 多项式衰减 余弦衰减 数据增强方式 随机缩放 随机裁剪: 对图片随机0.6-1比率大小进行裁剪 可以保留主要特征, 而裁剪掉背景噪声, 避免噪声的过拟合 随机反转 随机旋转 色彩扰动: 亮度, 对比度, 饱和度, 色调, 高斯噪声 随机擦除(Random Erasing): 随机选择一个区域利用随机值覆盖, 模拟遮挡场景 把物体遮挡一部分后依然能够分类正确, 那么肯定会迫使网络利用局部未遮挡的数据进行识别, 加大了训练难度, 一定程度会提高泛化能力 cutout: 与Random Erasing类似 只有正方形: 大小与形状更重要 填充值只有零或其他纯色填充 mixup: 增加了样本数量, 丰富了目标背景, 提高模型的泛化能力 cutMix: CutOut和MixUp的结合 mosaic: 丰富数据集：随机使用4张图片, 随机缩放, 再随机分布进行拼接, 大大丰富了检测数据集, 特别是随机缩放增加了很多小目标, 让网络的鲁棒性更好 减少GPU小号: Mosaic增强训练时, 可以直接计算4张图片的数据, 使得Mini-batch大小并不需要很大, 一个GPU就可以达到比较好的效果 copypaste: 将实例分割的目标, 随机贴在不同的图片上, 以增加数据的多样性 Label-smooth详解 通常情况下标签都是one-hot编码(极端约束), 为了缓和label对网络的约束, 提高模型泛化能力, 减少过拟合风险 采用软标签, 可以缓和标注错误的样本带来的大损失, 抑制噪声样本, 防止产生较大的损失(不希望模型对预测结果过度自信) 公式: qi={1−N−1Nϵ=1−ϵ+ϵN ,if i=yϵN ,otherwise q_i= \\begin{cases}1-\\frac{N-1}{N} \\epsilon=1-\\epsilon+\\frac{\\epsilon}{N} &amp; \\text { ,if } i=y \\\\ \\frac{\\epsilon}{N} &amp; \\text { ,otherwise }\\end{cases}qi​={1−NN−1​ϵ=1−ϵ+Nϵ​Nϵ​​ ,if i=y ,otherwise ​, ϵ\\epsilonϵ为自定义参数 交叉熵损失发生变化 Loss⁡=−∑i=1Kpilog⁡qi→Loss⁡i={(1−ε)∗Loss⁡,if(i=y)ε∗Loss⁡,if(i≠y)\\operatorname{Loss}=-\\sum_{i=1}^K p_i \\log q_i \\rightarrow \\operatorname{Loss}_i=\\left\\{\\begin{array}{l}(1-\\varepsilon)^* \\operatorname{Loss}, i f(i=y) \\\\ \\varepsilon * \\operatorname{Loss}, i f(i \\neq y)\\end{array}\\right.Loss=−∑i=1K​pi​logqi​→Lossi​={(1−ε)∗Loss,if(i=y)ε∗Loss,if(i=y)​ 最优的预测概率分布发生变化: Zi={+∞,if(i=y)0,if(i≠y)→Zi={log⁡(k−1)(1−ε)ε+α, if (i=y)α,if(i≠y)Z_i=\\left\\{\\begin{array}{l}+\\infty, i f(i=y) \\\\ 0, i f(i \\neq y)\\end{array} \\rightarrow Z_i=\\left\\{\\begin{array}{l}\\log \\frac{(k-1)(1-\\varepsilon)}{\\varepsilon+\\alpha}, \\text { if }(i=y) \\\\ \\alpha, i f(i \\neq y)\\end{array}\\right.\\right.Zi​={+∞,if(i=y)0,if(i=y)​→Zi​={logε+α(k−1)(1−ε)​, if (i=y)α,if(i=y)​ α\\alphaα为任意实数, 最终通过抑制正负样本输出差值, 使得网络有更好的泛化能力 卷积神经网络 卷积神经网络的特点 局部连接: 使用感受野进行连接 权值共享: 计算同一深度的神经元时采用的卷积核参数是共享的 池化操作: 池化操作与多层次结构一起,实现了数据的降维,将低层次的局部特征组合成为较高层次的特征,从而对整个图片进行表示 1*1卷积作用 实现信息得跨通道交流和整合 对卷积核通道数进行降维和升维, 减小参数量 卷积层和池化层的区别 卷积层 池化层 结构 零填充时输出维度不变，而通道数改变 通常特征维度会降低，通道数不变 稳定性 输入特征发生细微改变时，输出结果会改变 感受域内的细微变化不影响输出结果 作用 感受域内提取局部关联特征 感受域内提取泛化特征，降低维度 参数量 与卷积核尺寸、卷积核个数相关 不引入额外参数 卷积层是否越大越好 3×3卷积核被广泛应用在许多卷积神经网络中. 通常认为在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核会更加有效. 在其他领域中, 有时需要直接采用较大的卷积核 怎样才能减少卷积层参数两 使用堆叠小卷积核代替大卷积核 使用分离卷积操作: K∗k∗CK*k*CK∗k∗C分离为K∗k∗1K*k*1K∗k∗1和1∗1∗C1*1*C1∗1∗C 添加1*1卷积操作 在卷积层前使用池化操作, 池化可以降低卷积层的输入特征维度 CNN分类网络的演变脉络及各自的贡献与特点 LeNet-5 贡献与关键点: 第一个将反向传播应用于实际的CNN架构 定义了基础组件: 卷积, 池化, 全连接;(称为CPF三件套) AlexNet 贡献与关键点: 多GPU训练技术 使用了ReLu激活函数, 使之有较好的梯度特性, 训练更快 使用了随机失活(Dropout技术) 大量使用数据扩充技术 VGG 贡献与关键点: 结构简单, 只有3×3卷积和2×2汇合两种配置, 并且重复堆叠相同的模块组合. 卷积层不改变空间大小, 每经过一次汇合层, 空间大小减半; 3x3卷积层的堆叠可以在获得相同感受野的前提下使用更少的参数, 多层的卷积也能增加模型的非线性效果 初始化方法: 先训练浅层网络, 并使用浅层网络对深层网络进行初始化 GoogLeNet 提出了Inception模块, 同时用1×1、3×3、5×5卷积和3×3汇合, 并保留所有结果 贡献与关键点: 多分支分别处理, 并级联结果 为了降低计算量, 使用1*1卷积降维 使用了全局平均汇合替代全连接层, 使网络参数大幅减少 ResNet 贡献与关键点: 使用短路连接, 使训练深层网络更容易, 并且重复堆叠相同的模块组 短路连接可以有效缓解反向传播时由于深度过深导致的梯度消失现象, 这使得网络加深之后性能不会变差 ResNet就引入短路连接shortcut connect机制, 直接将恒等映射做为网络的一部分, 将问题转换为学习一个残差函数. 拟合残差要比拟合恒等映射要容易的多 ResNet大量使用了批量归一层 对于很深的网络(超过50层), ResNet使用了更高效的**瓶颈(Bottleneck)**结构 ResNeXt 贡献与关键点: 在ResNet的短路连接基础上, 综合了Inception的优点, 使用多分支进行处理, 但是与Inception不同的是, 其每个分支的结构都相同 ResNeXt巧妙地利用分组卷积进行实现 DenseNet DenseNet其目的也是避免梯度消失 和residual模块不同, dense模块中任意两层之间均有短路连接 语义融合的代表, 通过跳跃连接所有的层来获得更好的聚合特征和误差 神经网络模型复杂度分析 模型计算量分析 FLOPs: 浮点运算次数(计算量), 可以用来衡量算法/模型时间的复杂度 FLOPS: 每秒执行的浮点运算次数(计算速度), 衡量硬件性能/模型速度的指标 MACCs: 乘加操作次数(一个乘法累加算作一个MAC) 卷积层计算： FLOPs =(2×Ci×K2−1)×H×W×Co (不考虑bias) FLOPs =(2×Ci×K2)×H×W×Co (考虑bias) MACCs =(Ci×K2)×H×W×Co (考虑bias) \\begin{aligned} &amp; \\text { FLOPs }=\\left(2 \\times C_i \\times K^2-1\\right) \\times H \\times W \\times C_o \\text { (不考虑bias) } \\\\ &amp; \\text { FLOPs }=\\left(2 \\times C_i \\times K^2\\right) \\times H \\times W \\times C_o \\quad \\text { (考虑bias) } \\\\ &amp; \\text { MACCs }=\\left(C_i \\times K^2\\right) \\times H \\times W \\times C_o \\text { (考虑bias) }\\end{aligned}​ FLOPs =(2×Ci​×K2−1)×H×W×Co​ (不考虑bias) FLOPs =(2×Ci​×K2)×H×W×Co​ (考虑bias) MACCs =(Ci​×K2)×H×W×Co​ (考虑bias) ​ 全连接层计算：FLOPs=(2I−1)O,IF L O P s=(2 I-1) O , IFLOPs=(2I−1)O,I 是输入层的维度, OOO 是输出层的维度 模型参数量分析: 卷积层权重参数量 =Ci×K2×Co+Co=C_i \\times K^2 \\times C_o+C_o=Ci​×K2×Co​+Co​ BN 层参数量 =2×Ci=2 \\times C_i=2×Ci​ 全连接层参数量 =Ti×To+TO=T_i \\times T_o+T_O=Ti​×To​+TO​ 手动设计高效CNN架构的结论和建议 在大多数的硬件上, channel数为16的倍数比较有利高效计算 GPU 芯片上 3×33\\times 33×3 卷积非常快, 其计算密度（理论运算量除以所用时间）可达 1×11\\times 11×1 和 5×55\\times 55×5 卷积的四倍(来源 RepVGG 论文) 从解决梯度信息冗余问题入手,提高模型推理效率.比如CSPNet 网络. 从解决DenseNet的密集连接带来的高内存访问成本和能耗问题入手,如VoVNet网络,其由OSA(One-Shot Aggregation,一次聚合)模块组成 nvidia-smi中GPU利用率的含义 该利用率表示的是在采样时间段内一个或多个内核在GPU上执行的时间百分比(内核运行时间占总时间的比例) 并不能体现算力的发挥情况 误区1: GPU利用率=GPU内计算单元干活的比例 误区2: 同等条件下利用率越高, 耗时一定越短 延迟Latency和吞吐量Throughput的介绍 延迟Latency：指提出请求与收到反应之间经过的时间 吞吐量Throughput：一个时间单元内网络能处理的最大输入样例数 2 目标检测基础知识 anchor box介绍 不同模型使用的区域采样算法可能不同 两阶段检测模型常用的一种方法是: 以每个像素为中心生成多个大小和宽高比不同的边界框, 这些边界框称为锚框(anchor box) Faster RCNN中, 每个像素都生成9个大小和宽高比不同的anchors, 长宽比为&#123;1:1, 1:2, 2:1&#125;, 由此引入检测中常用的多尺度方法 IOU的介绍及其变形介绍 IOU为交并比, 是模型产生的候选框与原标记框的交叠率, ==不仅用来确定正样本和负样本, 还可以用来评价输出框与ground-truth的距离 公式: IoU=area⁡(C)∩area⁡(G)area⁡(C)∪area⁡(G)I o U=\\frac{\\operatorname{area}(C) \\cap \\operatorname{area}(G)}{\\operatorname{area}(C) \\cup \\operatorname{area}(G)}IoU=area(C)∪area(G)area(C)∩area(G)​ 作为损失函数出现的问题(缺点) 当两个框没有相交时, IoU=0, 不能反映两者的距离大小, 没有梯度回传, 无法进行学习任务 IoU无法精确的反应两者的重合大小 GIoU: 先计算两个框最小的闭包面积(预测框和真实框的最小外接矩形), 再计算闭包区域中不属于两个框的区域在闭包中的比重, 最后用IoU减比重即得GIoU 原因：由于IoU是比值的概念, 对目标物体的scale是不敏感的. 然而检测任务中的BBox的回归损失(MSE loss, l1-smooth loss等)优化和IoU优化不是完全等价的, 而且 Ln 范数对物体的scale也比较敏感, IoU无法直接优化没有重叠的部分 公式: GIoU=IoU−∣C−(A∪B)∣∣C∣\\mathrm{GIoU}=\\mathrm{IoU}-\\frac{|\\mathrm{C}-(\\mathrm{A} \\cup \\mathrm{B})|}{|\\mathrm{C}|}GIoU=IoU−∣C∣∣C−(A∪B)∣​, CCC为最小闭包的面积 特性: 与IOU相似, 为距离度量, 作为损失函数LGIOU=1−GIOUL_{GIOU}=1-GIOULGIOU​=1−GIOU GIOU对scale不敏感 GIOU不仅关注重叠区域还关注非重合区域 DIOU(Distance-IOU): 更符合目标框回归的机制, 将目标与anchor之间的距离, 重叠率以及尺寸都考虑进去, 使得回归变得更加稳定, 不会出现发散等问题 公式: DIoU=IoU−D22DC2\\mathrm{DIoU}=\\mathrm{IoU}-\\frac{\\mathrm{D}_2^2}{\\mathrm{D}_{\\mathrm{C}}^2}DIoU=IoU−DC2​D22​​, D2D_2D2​为预测框与目标框中心点的距离, DcD_cDc​为最小外接矩形的对角线距离 特性: 作为损失函数LDIOU=1−DIOUL_{DIOU}=1-DIOULDIOU​=1−DIOU, 在与目标框不重叠时, 仍然可以为边界框提供移动方向 可以直接最小化两个目标框的距离,收敛更快 相当于在保留GIoU损失优点的基础上, 增加了中心点距离度量, 直接优化两个框中心距离, 快速收敛, 而且仅中心点完全重合的时候, 才会退化成IoU 可以替代普通的 IoU 评估, 应用于NMS中, 效果更合理 CIOU(complete-IOU): 在DIOU的基础上考虑长宽比 公式:CIoU=IoU−D22DC2−αvα=v(1−IoU)+vv=4π2(arctan⁡wgthgt−arctan⁡wh)2\\begin{gathered}\\mathrm{CIoU}=\\mathrm{IoU}-\\frac{\\mathrm{D}_2^2}{\\mathrm{D}_{\\mathrm{C}}^2}-\\alpha \\mathrm{v} \\\\ \\alpha=\\frac{\\mathrm{v}}{(1-\\mathrm{IoU})+\\mathrm{v}} \\\\ \\mathrm{v}=\\frac{4}{\\pi^2}\\left(\\arctan \\frac{\\mathrm{w}^{\\mathrm{gt}}}{\\mathrm{h}^{\\mathrm{gt}}}-\\arctan \\frac{\\mathrm{w}}{\\mathrm{h}}\\right)^2\\end{gathered}CIoU=IoU−DC2​D22​​−αvα=(1−IoU)+vv​v=π24​(arctanhgtwgt​−arctanhw​)2​, α\\alphaα为权重系数, v\\mathrm{v}v用来衡量长宽比的相似性 从α\\alphaα参数的定义可以看出, 损失函数会更加倾向于往重叠区域增多方向优化, 尤其是IoU为零的时候. 只要当IOU足够大的时候才开始着重优化宽高比, 否则优先优化IOU和距离 [ ] 三者的代码实现 Cross Entropy交叉熵损失函数介绍 常使用交叉熵来作为分类任务中训练数据分布和模型预测结果分布间的代价函数 交叉熵定义：H(P,Q)=Ex∼PlogQ(x)=−∑iP(xi)logQ(xi)H(P,Q) = \\mathbb{E}_{\\textrm{x}\\sim P} log Q(x)= -\\sum_{i}P(x_i)logQ(x_i)H(P,Q)=Ex∼P​logQ(x)=−∑i​P(xi​)logQ(xi​), P为真实分布, Q为预测分布 二分类问题中交叉熵一般形式(CE)：Loss=L(y,p)=−ylog(p)−(1−y)log(1−p)Loss = L(y, p) = -ylog(p)-(1-y)log(1-p)Loss=L(y,p)=−ylog(p)−(1−y)log(1−p), 其中 ppp 表示当预测样本等于 111 的概率, 则 1−p1-p1−p 表示样本等于 000 的预测概率 对于所有样本, 二分类交叉熵为 L=1N(∑yi=1m−log(p)−∑yi=0nlog(1−p))L = \\frac{1}{N}(\\sum_{y_i = 1}^{m}-log(p)-\\sum_{y_i = 0}^{n}log(1-p))L=N1​(∑yi​=1m​−log(p)−∑yi​=0n​log(1−p)), 其中 mmm 为正样本个数, nnn 为负样本个数, NNN 为样本总数, m+n=Nm+n=Nm+n=N 当样本类别不平衡时, 损失函数 LLL 的分布也会发生倾斜, 造成模型对少样本类别的性能较差 对于所有样本, 多分类的交叉熵损失为: L=1N∑iNLi=−1N(∑i∑c=1Myiclog(pic))L = \\frac{1}{N} \\sum_i^N L_i = -\\frac{1}{N}(\\sum_i \\sum_{c=1}^M y_{ic}log(p_{ic}))L=N1​∑iN​Li​=−N1​(∑i​∑c=1M​yic​log(pic​)), 其中 MMM 表示类别数量, yicy_{ic}yic​ 是符号函数, 如果样本 iii 的真实类别等于 ccc 取值 1, 否则取值 0; picp_{ic}pic​ 表示样本 iii 预测为类别 ccc 的概率 多分类的loss不用考虑负样本, 只考虑正样本的判断准确率提高即可 Balanced Cross Entropy损失函数介绍 对于正负样本不平衡的问题, 引入 α∈(0,1)\\alpha \\in(0,1)α∈(0,1) 参数：CE(pt)=−αlog(pt)={−αlog(p),ify=1−(1−α)log(1−p),ify=0CE(p_t) = -\\alpha log(p_t) = \\left\\{\\begin{matrix} -\\alpha log(p), &amp; if \\quad y=1\\\\ -(1-\\alpha)log(1-p), &amp; if\\quad y=0 \\end{matrix}\\right.CE(pt​)=−αlog(pt​)={−αlog(p),−(1−α)log(1−p),​ify=1ify=0​ 对于所有样本, 二分类的平衡交叉熵损失函数：L=1N(∑yi=1m−αlog(p)−∑yi=0n(1−α)log(1−p))L = \\frac{1}{N}(\\sum_{y_i = 1}^{m}-\\alpha log(p)-\\sum_{y_i = 0}^{n}(1 - \\alpha) log(1-p))L=N1​(∑yi​=1m​−αlog(p)−∑yi​=0n​(1−α)log(1−p)), 其中 α1−α=nm\\frac{\\alpha}{1-\\alpha} = \\frac{n}{m}1−αα​=mn​, 即 α\\alphaα 参数的值是根据正负样本分布比例来决定的 α\\alphaα 为什么取0.25 α\\alphaα 是为了平衡正负样本的数量, 一般样本越多的类, α\\alphaα越低 目标检测中, α\\alphaα在正样本前, 用于平衡正负样本loss比例, 单独使用时一般大于0.5, 论文中设置为0.75效果最好, 会增加正样本对损失的贡献 在Focal Loss中, α=0.25\\alpha = 0.25α=0.25, 使用focal loss之后, 很多易分负样本权重被降的很低, 继而导致难分正样本比难分负样本数量多, 所以α\\alphaα​小于0.5 Focal Loss损失函数介绍 Balanced Cross Entropy中 α\\alphaα 参数平衡了正负样本(positive/negative), 但是不能区分难易样本(easy/hard) 目标检测中大量的候选目标都是易分样本, 这些样本的损失很低,但是主导了总的损失; 易分样本(置信度高的样本)对模型的提升效果非常小, 模型应该主要关注那些难分样本 Focal Loss 在交叉熵损失函数上加上一个调整因子（modulating factor）(1−pt)γ(1-p_t)^\\gamma(1−pt​)γ, 把高置信度 ppp (易分样本)样本的损失降低 定义: FL(pt)=−(1−pt)γlog(pt)={−(1−p)γlog(p),ify=1−pγlog(1−p),ify=0FL(p_t) = -(1-p_t)^\\gamma log(p_t) = \\{\\begin{matrix} -(1-p)^\\gamma log(p), &amp; if \\quad y=1\\\\ -p^\\gamma log(1-p), &amp; if\\quad y=0 \\end{matrix}FL(pt​)=−(1−pt​)γlog(pt​)={−(1−p)γlog(p),−pγlog(1−p),​ify=1ify=0​ Focal Loss 有两个性质： 当样本被错误分类且 ptp_tpt​ 值较小时,调制因子接近于 1,loss 几乎不受影响;当 ptp_tpt​ 接近于 1, 调质因子（factor）也接近于 0, 容易分类样本的损失被减少了权重, 整体而言, 相当于增加了分类不准确样本在损失函数中的权重 γ\\gammaγ参数平滑地调整容易样本的权重下降率, 当 γ=0\\gamma = 0γ=0 时, Focal Loss 等同于 CE Loss.γ\\gammaγ 在增加, 调制因子的作用也就增加, 实验证明 γ=2\\gamma = 2γ=2 时, 模型效果最好 调制因子减少了简单样本的损失贡献, 并扩大了样本获得低损失的范围 在实践中常采用带 α\\alphaα 的 Focal Loss: FL(pt)=−α(1−pt)γlog(pt)FL(p_t) = -\\alpha (1-p_t)^\\gamma log(p_t)FL(pt​)=−α(1−pt​)γlog(pt​) 实验表明 γ\\gammaγ 取 2, α\\alphaα 取 0.25 的时候效果最佳 γ\\gammaγ的作用 用于决定对易分样本的衰减程度, 越大代表对易分样本的衰减程度越高, 即网络更加关注难分样本 当γ=0\\gamma=0γ=0​​​​时, 就变成了带有正负样本平衡的普通CE loss smooth L1 loss介绍 L2 Loss为均方误差(MSE) Smooth L1={0.5x2,∣x∣&lt;1∣x∣−0.5,otherwise\\text { Smooth } L_{1}=\\left\\{\\begin{array}{l} 0.5 x^{2}, \\quad|x|&lt;1 \\\\ |x|-0.5, \\quad \\text{otherwise} \\end{array}\\right. Smooth L1​={0.5x2,∣x∣&lt;1∣x∣−0.5,otherwise​ 优点 相比于L2损失函数, 其对离群点(指的是距离中心较远的点), 异常值(outlier)不敏感, 当异常值出现时, 不至于产生特别大的梯度, 造成梯度爆炸 相比于L1损失函数, 解是稳定的, 对于L1, 数据的一个微小移动就很可能导致参数跳过最优解, 无法收敛到最优. 梯度不至于过大, 且梯度可以足够小 NMS算法介绍 目标检测中, 常使用非极大值抑制算法对生成的大量候选框进行后处理,去除冗余的候选框, 得到最佳检测框 NMS的本质思想：搜索局部最大值, 抑制非极大值 NMS的目的就是除掉重复的边界框, 通过迭代的形式, 不断地以最大得分的框去与其他框做 IoU 操作, 并过滤那些 IoU 较大的框 实现的思想主要是将各个框的置信度进行排序, 然后选择其中置信度最高的框 A, 同时设置一个阈值, 当其他框如 B 框 与 A 框的重合程度超过阈值就将 B 舍弃掉, 然后在剩余的框中选择置信度最大的框, 重复上述操作 bounding box voting介绍 思想: 根据NMS被抑制掉重合度较高的Box修正NMS之后的边界框(参与投票的只有NMS滤除的框) 流程 NMS处理后得到NMS框 利用该框与其他预测的NMS框取交集分别计算IOU, 取大于阈值的框作为后选框 后选框中利用加权均值的方法得到最终的框, 权重为每个框的置信度 再根据评分进行过滤 Soft NMS算法介绍 NMS 算法存在一个问题是可能会把一些相邻检测框框给过滤掉(即将 IOU 大于阈值的窗口的得分全部置为 0 ), 从而导致目标的 recall 指标比较低 Soft NMS 算法会为相邻检测框设置一个衰减函数而非彻底将其分数置为零 思想: MMM为当前得分最高框, bib_{i}bi​ 为待处理框, bib_{i}bi​ 和 MMM 的 IOU 越大, bbox 的得分 sis_{i}si​ 就下降的越厉害 ( NtN_{t}Nt​ 为给定阈值) Soft NMS 在每轮迭代时, 先选择分数最高的预测框作为 MMM, 并对 BBB 中的每一个检测框 bib_ibi​ 进行 re-score, 得到新的 score, 当该框的新 score 低于某设定阈值时, 则立即将该框删除 线性加权: si={si ,if iou &lt; Nsi(1−iou) ,if iou &gt;=Ns_i=\\{\\begin{array}{cc}s_i \\text { ,if iou &lt; N}\\\\ s_i(1-iou) &amp; \\text { ,if iou &gt;=N}\\end{array}si​={si​ ,if iou &lt; Nsi​(1−iou)​ ,if iou &gt;=N​ 高斯加权: si=siexp⁡(−iou2σ)s_i=s_i \\exp (\\frac{-i o u^2}{\\sigma})si​=si​exp(σ−iou2​) TP, TN, FP, FN的含义 名称 定义 True Positive(真正例, TP) 将正类预测为正类数 True Negative(真负例, TN) 将负类预测为负类数 False Positive(假正例, FP) 将负类预测为正类数 → 误报 (Type I error) False Negative(假负例子, FN) 将正类预测为负类数 → 漏报 (Type II error) TP的定义: 预测框与真实框的IOU大于阈值(AP50AP_{50}AP50​为0.5) 置信度评分高于设定的置信度阈值(通过改变置信度阈值得到不同的PR指, 从而得到PR曲线) 当对应一个真值有多个预测结果时, 置信度最高的结果为TP, 其余为FP 精确率、召回率与F1 准确率(精度)Accuracy: Accurcay=TP+TNTP+FP+TN+FNAccurcay=\\frac{TP+TN}{TP+FP+TN+FN}Accurcay=TP+FP+TN+FNTP+TN​ 准确率可以判断总的正确率, 但是再样本不平衡的情况下不能很好的作为指标来衡量结果 精确率(查准率)P: P=TPTP+FPP=\\frac{TP}{TP+FP}P=TP+FPTP​ 精确率代表对正样本结果中的预测准确程度, 而准确率代表整体的预测准确程度 精确率描述了模型有多准 召回率(查全率)R: R=TPTP+FNR=\\frac{TP}{TP+FN}R=TP+FNTP​ 召回率描述了模型有多全 F1分数 P与R两者之间的平衡点: F1=2×P×RP+R=2×TP样例总数+TP−TNF1 = \\frac{2\\times P\\times R}{P+R} = \\frac{2\\times TP}{样例总数+TP-TN}F1=P+R2×P×R​=样例总数+TP−TN2×TP​ 在 nnn 个二分类混淆矩阵上综合考虑查准率和查全率: 一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率, 记为 (P1,R1),(P2,R2),...,(Pn,Rn)(P_1,R_1),(P_2,R_2),...,(P_n,R_n)(P1​,R1​),(P2​,R2​),...,(Pn​,Rn​) 然后取平均, 这样得到的是&quot;宏查准率(Macro-P)“, “宏查准率(Macro-R)”, 及对应的&quot;宏F1F1F1(Macro-F1)”： Macro P=1n∑i=1nPiMacro\\ P = \\frac{1}{n}\\sum_{i=1}^{n}P_iMacro P=n1​∑i=1n​Pi​ Macro R=1n∑i=1nRiMacro\\ R = \\frac{1}{n}\\sum_{i=1}^{n}R_iMacro R=n1​∑i=1n​Ri​ Macro F1=2×Macro P×Macro RMacro P+Macro RMacro\\ F1 = \\frac{2 \\times Macro\\ P\\times Macro\\ R}{Macro\\ P + Macro\\ R}Macro F1=Macro P+Macro R2×Macro P×Macro R​ PR曲线 PR曲线是以 Recall 为横轴, Precision 为纵轴, 展示的是 Precision vs Recall 曲线 P-R曲线越靠近右上角性能越好 PR曲线的两个指标都聚焦于正例 PR曲线下的面积定义为 AP PR曲线为不同阈值条件下, Recall与Precision的对应关系 AP与mAP的理解 AP 衡量的是训练好的模型在每个类别上的好坏 mAP 衡量的是模型在所有类别上的好坏 取所有 AP 的平均值即为mAP mAP 常作为目标检测算法的评价指标 对于每张图片检测模型会输出多个预测框,使用 IoU 来标记预测框是否预测准确 标记完成后, 随着预测框的增多, 查全率 R 总会上升, 在不同查全率 R 水平下对准确率 P 做平均, 即得到 AP, 最后再对所有类别按其所占比例做平均, 即得到 mAP 指标 通常情况下通过插值计算AP: 使用11点插值计算方法 coco数据集中mAP的计算 设定多个 IOU 阈值(0.5-0.95, 0.05 为步长), 在每一个 IOU 阈值下都有某一类别的 AP 值, 然后求不同 IOU 阈值下的 AP 平均, 就是所求的最终的某类别的 AP 值 [ ] 代码实现mAP计算 目标检测中的不平衡问题介绍 Class imbalance: 类别不平衡. 不同类别的输入边界框的数量不同, 包括前景/背景和前景/前景类别的不平衡 RPN 和 Focal Loss 就是解决这类问题 Scale imbalance: 尺度不平衡, 主要是目标边界框的尺度不平衡引起的, 也包括将物体分配至 feature pyramid 时的不平衡 典型如 FPN 就是解决物体多尺度问题的 Spatial imbalance: 空间不平衡. 包括不同样本对回归损失贡献的不平衡, IoU 分布的不平衡, 和目标分布位置的不平衡 Objective imbalance:不同任务（分类、回归）对总损失贡献的不平衡 ROI Pooling和ROI Align介绍 介绍: 在区域建议网络 RPN 得到候选框 ROI 之后, 需要提取该 ROI 中的固定数目的特征(Faster R-CNN中的7*7)输入到后面的分类网络以及边界回归网络的全连接层中 Faster R-CNN中使用的方法是ROI Pooling 对于像素位置精细度要求更高的Mask R-CNN使用的方法是ROI Align 区别: ROI Pooling使用了两次量化操作 ROI Align没有采用量化操作, 采用双线性插值方法 ROI Pooling Faster R-CNN中具有两次量化操作 图像坐标 -&gt; feature map坐标 feature map坐标 -&gt; ROI feature坐标 两次量化操作影响检测算法的性能 将RPN的浮点Bbox输出量化成整形; 然后从feature map中裁剪出对应的ROI, 并池化到指定大小 ROI Align 直接使用RPN的浮点Bbox, 将ROI等比例划分成多个cell, 且cell的数目与最终要求的池化输出大小一致; 从cell中随机采样一点数目的点(使用双线性差值计算浮点位置的特征), 并进行池化得到该cell的输出 Anchor-free和Anchor-based区别 Anchor-based 优点 使用Anchor机制产生密集的Anchor box, 使得网络可直接在此基础上进行目标分类及边界框坐标回归. 加入了先验框, 训练稳定 密集的Anchor box可有效提高网络目标召回能力, 对于小目标检测来说提升非常明显 缺点 Anchor机制中, 需要设定的超参：尺度和长宽比是比较难设计的, 这需要较强的先验知识. 使得这些Anchor集合存在数据相关性, 泛化性能较差 冗余框非常之多: 一张图像内的目标毕竟是有限的, 基于每个Anchor设定大量Anchor box会产生大量的easy-sample, 即完全不包含目标的背景框. 这会造成正负样本严重不平衡问题, 也是one-stage算法难以赶超two-stage算法的原因之一. 使用包括two-stage的RPN和one-stage的Focal loss 网络实质上是看不见Anchor box的, 在Anchor box的基础上进行边界回归更像是一种在范围比较小时候的强行记忆 基于Anchor box进行目标类别分类时, IOU阈值超参设置也是一个问题 Anchor-free 优点 Anchor-free要比Anchor-based少2/3的参数量, 因为Anchor-based一个位置要预测3个长宽不同的bbox, 而free只预测一个 不需要像Anchor一样, 不需要设置超参数 容易部署(这是Anchor-free得以推广的主要原因) 主要是解码方便: 直接对heatmap使用池化, 就相当于做了NMS, 然后利用偏移和宽高就可以获得对应的检测框 FCOS使用了NMS, 而centernet是直接对点进行池化做NMS Anchor-based需要解码每个位置, 再使用NMS, 还需要实现求解出每个Anchor的位置和大小, 使得解码很麻烦 缺点 正负样本极端不平衡 语义模糊性(两个目标中心点重叠), 现在这两者大多是采用Focus Loss和FPN来缓解的, 但并没有真正解决 检测结果不稳定, 需要设计更多的方法来进行re-weight [ ] 原理介绍 3 深度学习问题总结 手推公式总结 BP算法 CNN网络结构 Softmax及其求导 交叉熵及其求导 过拟合与欠拟合的变表现与解决办法 过拟合: 模型在训练集上表现好, 但在测试集(验证集)上表现差, 损失函数呈现高方差,低偏差的状态(高方差指训练集误差较低) 原因： 模型过于复杂, 导致将噪声的特征也学习到模型中, 使模型泛化性能下降 数据集规模较小, 使模型过度挖掘数据集中特征 解决办法: 获取更多的训练数据(数据扩充), 或使用迁移学习技术 降低模型复杂度(减层数减参数量) 正则化(L2正则化, 添加BN层, Dropout技术) Early Stop技术 交叉验证 集成学习 欠拟合: 模型在训练集和测试集上的表现都很差, 损失曲线呈现一种高偏差, 低方差状态;(高偏差指的是训练集和验证集的误差都较高, 但相差很少) 原因: 模型过于简单, 学习能力差 提取的特征不好, 特征不足或现有特征与标签的相关性不强 解决办法: 提高模型复杂度 增加新特征 若使用了正则项, 考虑减小正则项的系数λ\\lambdaλ 梯度消失和梯度爆炸以及解决方法 梯度消失和梯度爆炸都是出现在靠近输入层的参数中 产生原因： 梯度更新基于反向传播过程, 使用链式求导法则, 网络越深连乘的项越多就容易导致梯度值特别大或者接近零 梯度爆炸的原因：权值初始化太大 在使用sigmoid激活函数时较少出现, 不容易发生 现象: 训练不稳定, loss突然变大或变小; 极端情况下, 权重值很大甚至溢出, 造成损失为NaN 梯度消失的原因：使用了不合适的激活函数 解决办法： 梯度爆炸: pre-training + fine-tunning 梯度剪枝: 对梯度设定阈值 权值正则化: 正则化项限制权值大小(L1, L2) 改用其他激活函数(ReLu) BN: 对每一层的输出进行规范, 消除权重参数方法或缩小带来的影响, 将输出从饱和区拉到非饱和区 梯度消失: 改用其他激活函数(ReLu) BN 使用ResNet的短路连接结构 学习率和BatchSize对模型的影响 随机梯度下降算法的原理：wt+1=wt−η1n∑x∈B∇l(x,wt)w_{t+1}=w_t-\\eta \\frac{1}{n} \\sum_{x \\in \\mathcal{B}} \\nabla l\\left(x, w_t\\right)wt+1​=wt​−ηn1​∑x∈B​∇l(x,wt​) nnn时批量大小,∇\\nabla∇为学习率, 两个因子决定了权重的更新 学习率直接影响模型的收敛, BatchSize影响模型的泛化能力 学习率 初始学习率过大模型不收敛, 过小导致模型收敛太慢或无法学习(可采用搜索法进行搜索) 学习率的值经验选择为: 0.1, 0.015, 0.01, 0.005, 0.001 不同的学习策略: Mutistep: 每经过几个epoch调整一次学习率 学习率衰减: StepLR, MultiStepLR, ExponentialLR, CosineAnnealingLR, LambdaLR cyclical learning rate:周期性学习率 warmup策略: 刚开始使用较小的学习率, 然后增大到设定的学习率, 最后又随着训练的进行慢慢减小学习率 作用: 1. 有助于减缓模型在初始阶段对mini-batch的提前过拟合现象, 保持分布的稳定; 2. 有助于保持模型深度的稳定性; 由小到大: 初始时模型对数据分布理解为零, 较大的学习率导致模型不稳定, 容易过拟合; 随后适当增大学习率, 模型相对稳定, 收敛速度变快, 模型效果较好 由大到小: 学习率降低有助于较好的收敛 Adam: 自适应学习率变换方法 BatchSize 大的BatchSize减少训练时间, 提高稳定性; 微调时, BatchSize更大效果更好 大的BatchSize导致模型泛化能力下降 如果增加了学习率, 那么batch size最好也跟着增加, 这样收敛更稳定 BatchSize很大后(超过临界点)会降低模型的泛化能力, 在临界点下模型性能变化对学习率更敏感 10K样本用SGD, BatchSize在1, 100, 10000中取100收敛最快 大的BatchSize训练速度更快 BatchSize过大会导致模型泛化性能下降, 小BatchSize会更容易跳出局部最优点 特征融合concat和add的区别 add 对对应通道对应位置的值相加, 通道数不变 描述图像的特征个数不变, 但是每个特征下的信息增加 默认两个特征图对应通道所要表达的信息类似, 尺寸不一致时, 直接相加尺寸小的会被尺寸大的特征淹没, 不应该使用add 优点: 计算量少 缺点: 特征提取能力差 concat 通道合并, 通道数变多 描述图像的特征个数变多, 但是每个特征的信息不变 直接通过训练学习来整合两个通道图通道之间的信息, 可以提取出合适的信息, 效果更好 优点: 特征提取能力强 缺点: 计算量大 为什么机器学习解决回归问题通常使用均方误差 如果采用的距离是两者之差的绝对值, 那么求解的目标函数：(ω∗,b)=argmin(ω,b)∑i=1m∣f(xi)−yi∣(\\omega^*, b) = arg min_{(\\omega, b)}\\sum_{i=1}^{m}\\left|{f(x_i)-y_i}\\right|(ω∗,b)=argmin(ω,b)​∑i=1m​∣f(xi​)−yi​∣ 如果采用的距离是两者之差的平方, 那么求解的目标函数：(ω∗,b)=argmin(ω,b)∑i=1m(f(xi)−yi)2(\\omega^*, b) = arg min_{(\\omega, b)}\\sum_{i=1}^{m}({f(x_i)}-y_i)^2(ω∗,b)=argmin(ω,b)​∑i=1m​(f(xi​)−yi​)2 其中：f(xi)=ωxi+bf(x_i) = \\omega x_i + bf(xi​)=ωxi​+b 即预测值, yiy_iyi​ 为真实值, mmm 为样本总数, ω\\omegaω 和 bbb 为要求解的参数 要求得使以上损失函数最小化对应的那个 ω\\omegaω 和 bbb , 可将损失函数对 ω\\omegaω 和 bbb 求导, 并令导数为0 当采取的距离是两者之差的绝对值时, 函数在0处不可导, 且还增加的一个工作量是需要判断 f(xi)−yif(x_i)-y_if(xi​)−yi​ 正负号 而采用的距离是两者之差的平方时就没有这方面的问题 所以解决回归问题的时候一般使用平方损失 yolov5中正负样本的判断 yolov5输出有3个预测分支, 每个分支的每个网格有3个anchor与之对应 没有采用IOU最大的匹配方法, 而是通过计算该bounding box和当前层的anchor的宽高比; 如果最大比例大于4(设定阈值), 则比例过大, 则说明匹配度不高, 将该bbox过滤, 在当前层认为是背景. 计算这些box落在哪个网格内, 同时利用四舍五入规则, 找出最近的两个网格, 将这三个网格都认为是负责预测该bbox的, 所以理论上最多一个gt会分配9个正样本anchor, 最少为3个(因为引入了相邻两个网格) 能够匹配的gt, 将其所处的grid, 及其临近的两个grid也分配为正样本 SGD和Adam的区别 优化函数如果训练比较小的自定义的数据集, adam是比较合适的选择, 但是如果训练大型的数据集那么使用sgd优化函数的比较多 Adam引入了一阶动量：SGD容易陷入局部最优, 而一阶动量利用过去的信息, 可以帮助冲出局部最优点. Adam引入了二阶动量：实现了自适应学习率 对于经常更新的参数, 已经积累了大量关于它的知识, 不希望被单个样本影响太大, 希望学习速率慢一些 对于那些偶尔更新的参数, 了解的信息太少, 希望能从每个偶然出现的样本身上多学一些, 即学习速率大一些, 因此利用二阶信息就可以衡量每个参数的更新幅度 Adam缺点 可能不收敛 SGD没有用到二阶动量, 因此学习率是恒定的(实际使用过程中会采用学习率衰减策略, 因此学习率递减), 算法会使得学习率不断递减, 最终收敛到0, 模型也得以收敛 Adam则不然. 二阶动量是固定时间窗口内的累积, 随着时间窗口的变化, 遇到的数据可能发生巨变, 使得VtV_tVt​​​​可能会时大时小, 不是单调变化. 这就可能在训练后期引起学习率的震荡, 导致模型无法收敛 可能错过全局最优解 同样的一个优化问题, 不同的优化算法可能会找到不同的答案, 但自适应学习率的算法往往找到非常差的答案 自适应学习率算法可能会对前期出现的特征过拟合, 后期才出现的特征很难纠正前期的拟合效果 SGD的S(stochastic随机)体现在哪里 随机体现在, 每一步的梯度都是通过从全部数据中随机选择一个minbatch来计算loss得到的, minbatch的loss和全部数据loss不一样, 其是在不断的振动的, 但最后是达到全局最优的 模型搭建流程 模型搭建流程 加载数据. train_loader = torch.utils.data.Dataloader() 构建模型. model = torch.nn.module 构建损失. loss = torch.nn.CrossEntropyLoss() 构建优化器. optimizer = torch.optim.Adam() 设置学习率更新策略. scheduler = torch.optim.lr_scheduler.MultiStepLR() FP16, 设置FP16更新器. scaler = torch.cuda.amp.GradScaler() 更新流程 读取数据. for n_iter, (img, label) in enumerate(train_loader) 前向传播. output = model(img) loss计算. loss(output, label) 反向传播, 计算梯度. loss.backward() or scaler.scale(loss).backward() 如果有FP16, 梯度还原. scaler.unscale_(optimizer) 使用优化器由梯度更新权重. optimizer.step() or scaler.step(optimizer) 整个epoch结束后, 更新学习率. scheduler.step() function和module的区别 Function一般只定义一个操作, 因为其无法保存参数, 因此适用于激活函数, pooling等操作; Module是保存了参数, 因此适合于定义一层, 如线性层, 卷积层, 也适用于定义一个网络 Function需要定义三个方法: __init__, forward, backward(需要自己写求导公式); Module: 只需定义__init__和forward, backward的计算由自动求导机制构成 可以不严谨的认为, Module是由一系列Function组成, 因此其在forward的过程中, Function和Variable组成了计算图, 在backward时, 只需调用Function的backward就得到结果, 因此Module不需要再定义backward Module不仅包括了Function, 还包括了对应的参数, 以及其他函数与变量, 这是Function所不具备的 dataloader, dataset, sampler有什么区别 Dateloader中包含Sampler和Dataset, 使用sampler产生索引, 返回的也就是一批索引值, 然后通过索引去Dataset中找到对应的数据 Sampler产生索引, 返回的也就是一批索引值 在enumerate(Dateloader对象)过程中, Dataloader按照其参数BatchSampler规定的策略调用其Dataset的getite，m方法batchsize次, 得到一个batch, 该batch中既包含样本, 也包含相应的标签 一般只需要定义Dataset即可, shuffle=True(随机读取数据), batch_size=(一次读取的数据数), num_workers=(读取一个batch数据时所使用的进程数, 并行读取数据, 速度快) Dataset主要重写__getiterm__, 以便根据sample得到的索引来获取数据和标签 model.train和model.eval区别 主要是针对BN和Dropout这种在训练和预测期间操作不同的结构 train阶段：BN和dropout在训练中起到防止过拟合的作用 eval阶段： BN的参数直接固定, 不会再被改变, BN不会再计算输入数据的均值方差, 而是直接使用训练集统计出的均值方差, 这样就可以避免test的batchsize过小, 使得计算出的均值方差不具有统计特征, 使结果非常的差 使Dropout不起作用：训练时随机失活, 推理时全部开启, 同时最终输出要乘以失活比例, 否则会导致最后的结果翻倍 ModuleList和Sequential的区别 nn.Sequential里面的模块按照顺序进行排列的, 所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的 nn.Sequential内部实现了forward函数, 因此可以不用写forward函数. 而nn.ModuleList则没有实现内部forward函数 nn.Sequential中可以使用OrderedDict来指定每个module的名字 nn.Sequential里面的模块按照顺序进行排列的, 所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的; 而nn.ModuleList并没有定义一个网络, 它只是将不同的模块储存在一起, 这些模块之间并没有什么先后顺序可言, 执行顺序由forward函数决定 有的时候网络中有很多相似或者重复的层, 一般会考虑用 for 循环来创建它们(nn.ModuleList), 而不是一行一行地写(nn.Sequential) nn.ModuleList 不同于一般的 list, 加入到 nn.ModuleList 里面的 module 是会自动注册到整个网络上的, 同时 module 的 parameters 也会自动添加到整个网络中 若使用python的list, 则会出问题. 使用 Python 的 list 添加的卷积层和它们的 parameters 并没有自动注册到我们的网络中. 当然, 我们还是可以使用 forward 来计算输出结果. 但是如果用其实例化的网络进行训练的时候, 因为这些层的parameters不在整个网络之中, 所以其网络参数也不会被更新, 也就是无法训练 一般情况下 nn.Sequential 的用法是来组成卷积块 (block), 然后像拼积木一样把不同的 block 拼成整个网络, 让代码更简洁, 更加结构化. 而对于重复的层, 就使用nn.ModuleList及for来创建 设置随机种子, 使训练结果可复现 1234567891011def setup_seed(seed): torch.manual_seed(seed) torch.cuda.manual_seed_all(seed) np.random.seed(seed) random.seed(seed) torch.backends.cudnn.deterministic = True# 设置随机数种子setup_seed(20)# 预处理数据以及训练模型# ...# ... torch.nn.MSELoss(reduction='mean') 计算偏差的平方和均值，因此通常计算loss时，可以手动乘以1/2以确保反向传播求导容易些 如果不是'mean'，那返回的就是平方和 如果是'none'，返回的就是一个数组，包含了所有位置的偏差平方 网络设计中, 为什么卷积核设计尺寸都是奇数 保证像素点中心位置，避免位置信息偏移 填充边缘时能保证两边都能填充，原矩阵依然对称","categories":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"}],"tags":[{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"}]},{"title":"目标检测相关论文解读","slug":"深度学习相关/目标检测相关论文解读","date":"2023-03-07T09:15:33.000Z","updated":"2023-04-16T12:15:51.365Z","comments":true,"path":"2023/03/07/深度学习相关/目标检测相关论文解读/","link":"","permalink":"http://jay1060950003.github.io/2023/03/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/","excerpt":"引言 记录相关深度学习及目标检测领域的论文","text":"引言 记录相关深度学习及目标检测领域的论文 1 经典backbone总结 1.1 VGG VGG网络结构参数表如下图所示 1.2 ResNet ResNet 模型比 VGG 网络具有更少的滤波器数量和更低的复杂性 注意，论文中算的 FLOPs，把乘加当作 1 次计算。 不同层数的 Resnet 网络参数表如下图所示 ResNet 是 Backone 领域划时代的工作了，因为它让深层神经网络可以训练，基本解决了深层神经网络训练过程中的梯度消失问题，并给出了系统性的解决方案（两种残差结构），即系统性的让网络变得更“深”了 1.3 Inceptionv3 常见的一种 Inception Modules 结构如下： 1.4 Resnetv2 作者总结出恒等映射形式的快捷连接和预激活对于信号在网络中的顺畅传播至关重要的结论 1.5 ResNeXt ResNeXt 的卷积block 和 Resnet 对比图如下所示。 ResNeXt 和 Resnet 的模型结构参数对比图如下图所示。 1.6 Darknet53 Darknet53 模型结构连接图，如下图所示 1.7 DenseNet 在密集块（DenseBlock）结构中，每一层都会将前面所有层 concate 后作为输入 DenseBlock（类似于残差块的密集块结构）结构的 3 画法图如下所示： 可以看出 DenseNet 论文更侧重的是 DenseBlock 内各个卷积层之间的密集连接（dense connection）关系，另外两个则是强调每层的输入是前面所有层 feature map 的叠加，反映了 feature map 数量的变化 1.8 CSPNet CSPDenseNet 的一个阶段是由局部密集块和局部过渡层组成（a partial dense block and a partial transition layer） CSP 方法可以减少模型计算量和提高运行速度的同时，还不降低模型的精度，是一种更高效的网络设计方法，同时还能和 Resnet、Densenet、Darknet 等 backbone 结合在一起 1.9 一些结论 当卷积层的输入输出通道数相等时，内存访问代价（MAC）最小 影响 CNN 功耗的主要因素在于内存访问代价 MAC，而不是计算量 FLOPs GPU 擅长并行计算，Tensor 越大，GPU 使用效率越高，把大的卷积操作拆分成碎片的小操作不利于 GPU 计算 1x1 卷积可以减少计算量，但不利于 GPU 计算 2 经典网络精读 2.1 ResNet Deep Residual Learning for Image Recognition 2.1.1 摘要 残差网络(ResNet)的提出是为了解决深度神经网络的“退化”（优化）问题。 有论文指出，神经网络越来越深的时候，反传回来的梯度之间的相关性会越来越差，最后接近白噪声。即更深的卷积网络会产生梯度消失问题导致网络无法有效训练。 而 ResNet 通过设计残差块结构，调整模型结构，让更深的模型能够有效训练更训练。目前 ResNet 被当作目标检测、语义分割等视觉算法框架的主流 backbone。 2.1.2 残差网络介绍 作者提出认为，假设一个比较浅的卷积网络已经可以达到不错的效果，那么即使新加了很多卷积层什么也不做，模型的效果也不会变差。但，之所以之前的深度网络出现退化问题，是因为让网络层什么都不做恰好是当前神经网络最难解决的问题之一！ 因此，作者可以提出残差网络的初衷，其实是让模型的内部结构至少有恒等映射的能力（什么都不做的能力），这样可以保证叠加更深的卷积层不会因为网络更深而产生退化问题！ 2.1.2.1 残差结构原理 对于 VGG 式的卷积网络中的一个卷积 block，假设 block 的输入为 xxx ，期望输出为 H(x)H(x)H(x)，block 完成非线性映射功能。 那么，如何实现恒等映射呢？ 假设直连（plain）卷积 block 的输入为 xxx ，block 期望输出为 H(x)H(x)H(x)，我们一般第一反应是直接让学习 H(x)=xH(x) = xH(x)=x，但是这很难！ 对此，作者换了个角度想问题，既然 H(x)=xH(x) = xH(x)=x 很难学习到，那我就将 H(x)H(x)H(x) 学习成其他的，而让恒等映射能力通过其他结构来实现，比如，直接加个 shorcut 不就完事了！这样只要直连 block 网络输出学习为 0 就行了。而让直连卷积 block 输出学习为 0 比学习成恒等映射的能力是要简单很多的！毕竟前者通过 L2 正则化就能实现了！ 因此，作者将网络设计为 H(x)=F(x)+xH(x) = F(x) + xH(x)=F(x)+x，即直接把恒等映射作为网络的一部分，只要 F(x)=0F(x) = 0F(x)=0，即实现恒等映射: H(x)=xH(x) = xH(x)=x。残差块结构（resdiual block）。基本残差块结构如下图所示: 从图中可以看出，一个残差块有 222 条路径 F(x)F(x)F(x) 和 xxx，F(x)F(x)F(x) 路径拟合残差 H(x)−xH(x)-xH(x)−x，可称为残差路径，xxx 路径为恒等映射（identity mapping），称其为”shortcut”。图中的 ⊕⊕⊕ 为逐元素相加（element-wise addition），要求参与运算的 F(x)F(x)F(x) 和 xxx 的尺寸必须相同！ 这就把前面的问题转换成了学习一个残差函数 F(x)=H(x)−xF(x) = H(x) - xF(x)=H(x)−x。 综上总结：可以认为 Residual Learning 的初衷（原理），其实是让模型的内部结构至少有恒等映射的能力。以保证在堆叠网络的过程中，网络至少不会因为继续堆叠而产生退化！ 注意，很多博客片面解释 resnet 解决了梯度消失问题所以有效的的观点是片面的且方向也错了！resnet 到底解决了什么问题以及为什么有效问题的更细节回答，可以参考这个回答。 2.1.2.2 两种不同的残差路径 在 ResNet 原论文中，残差路径的设计可以分成 222 种， 一种没有 bottleneck 结构，如图3-5左所示，称之为“basic block”，由 2 个 3×33\\times 33×3 卷积层构成。2 层的残差学习单元其两个输出部分必须具有相同的通道数（因为残差等于目标输出减去输入，即 H(x)−xH(x) - xH(x)−x，所以输入、输出通道数目需相等)。 另一种有 bottleneck 结构，称之为 “bottleneck block”，对于每个残差函数 FFF，使用 333 层堆叠而不是 2 层，3 层分别是 1×11\\times 11×1，3×33\\times 33×3 和 1×11\\times 11×1 卷积。其中 1×11\\times 11×1 卷积层负责先减小然后增加（恢复）维度，使 3×33\\times 33×3 卷积层的通道数目可以降低下来，降低参数量减少算力瓶颈（这也是起名 bottleneck 的原因 ）。50 层以上的残差网络都使用了 bottleneck block 的残差块结构，因为其可以减少计算量和降低训练时间。 3 层的残差学习单元是参考了 Inception Net 结构中的 Network in Network 方法，在中间 3×33\\times 33×3 的卷积前后使用 1×11\\times 11×1 卷积，实现先降低维度再提升维度，从而起到降低模型参数和计算量的作用。 2.1.2.3 两种不同的 shortcut 路径 shortcut 路径大致也分成 222 种，一种是将输入 xxx 直接输出，另一种则需要经过 1×11\\times 11×1 卷积来升维或降采样，其是为了将 shortcut 输出与 F(x) 路径的输出保持形状一致，但是其对网络性能的提升并不明显，两种结构如图3-6所示。 Residual Block（残差块）之间的衔接，在原论文中，F(x)+xF(x)+xF(x)+x 是经过 ReLU 后直接作为下一个 block 的输入 xxx。 2.1.3 ResNet18 模型结构分析 残差网络中，将堆叠的几层卷积 layer 称为残差块（Residual Block），多个相似的残差块串联构成 ResNet。ResNet18 和 ResNet34 Backbone用的都是两层的残差学习单元（basic block），更深层的ResNet则使用的是三层的残差学习单元（bottle block）。 ResNet18 其结构如下图所示。 ResNet18 网络具体参数如下表所示。 假设图像输入尺寸为，1024×20481024\\times 20481024×2048，ResNet 共有五个阶段。 其中第一阶段的 conv1 layer 为一个 7×77\\times 77×7 的卷积核，stride 为 2，然后经过池化层处理，此时特征图的尺寸已成为输入的1/4，即输出尺寸为 512×1024512\\times 1024512×1024。 接下来是四个阶段，也就是表格中的四个 layer：conv2_x、conv3_x、conv4_x、conv5_x，后面三个都会降低特征图尺寸为原来的 1/2，特征图的下采样是通过步长为 2 的 conv3_1, conv4_1 和 conv5_1 执行。所以，最后输出的 feature_map 尺寸为输入尺寸降采样 32=4×2×2×232 = 4\\times 2\\times 2\\times 232=4×2×2×2 倍。 在工程代码中用 make_layer 函数产生四个 layer 即对应 ResNet 网络的四个阶段。根据不同层数的 ResNet(N)： 输入给每个 layer 的 blocks 是不同的，即每个阶段(layer)里面的残差模块数目不同（即 layers 列表不同) 采用的 block 类型（basic 还是 bottleneck 版）也不同。 本文介绍的 ResNet18，使用 basic block，其残差模块数量（即units数量）是 [2, 2, 2, 2]，又因为每个残差模块中只包含了 2 层卷积，故残差模块总的卷积层数为 (2+2+2+2)*2=16，再加上第一层的卷积和最后一层的分类，总共是 18 层，所以命名为 ResNet18。 ResNet50 为 [3, 4, 6, 3]。 ResNet的一个重要设计原则是：当feature map大小降低一半时，feature map的数量增加一倍，这保持了网络层的复杂度。 2.2 ResNetV2 Identity Mappings in Deep Residual Networks 前言 本文的主要贡献在于通过理论分析和大量实验证明使用恒等映射（identity mapping）作为快捷连接（skip connection）对于残差块的重要性。同时，将 BN/ReLu 这些 activation 操作挪到了 Conv（真正的weights filter操作）之前，提出“预激活“操作，并通过与”后激活“操作做对比实验，表明对于多层网络，使用了预激活残差单元（Pre-activation residual unit） 的 resnet v2 都取得了比 resnet v1（或 resnet v1.5）更好的结果。 摘要 近期已经涌现出很多以深度残差网络（deep residual network）为基础的极深层的网络架构，在准确率和收敛性等方面的表现都非常引人注目。本文主要分析残差网络基本构件（residual building block）中的信号传播，本文发现当使用恒等映射（identity mapping）作为快捷连接（skip connection）并且将激活函数移至加法操作后面时，前向-反向信号都可以在两个 block 之间直接传播而不受到任何变换操作的影响。同时大量实验结果证明了恒等映射的重要性。本文根据这个发现重新设计了一种残差网络基本单元（unit），使得网络更易于训练并且泛化性能也得到提升。 注意这里的实验是深层 ResNet（≥\\geq≥ 110 layers） 的实验，所以我觉得，应该是对于深层 ResNet，使用”预激活”残差单元（Pre-activation residual unit）的网络（ResNet v2）更易于训练并且精度也更高。 1、介绍 深度残差网络（ResNets）由残差单元（Residual Units）堆叠而成。每个残差单元（图1 (a)）可以表示为： 其中，xlx_lxl​ 和 xl+1x_{l+1}xl+1​ 是 第 lll 个残差单元的输入和输出，FFF 是残差函数。在 ResNet 中，h(xl)=xlh(x_{l})= x_{l}h(xl​)=xl​ 是恒等映射（identity），fff 是 ReLU 激活函数。在 ImageNet 数据集和 COCO 数据集上，超过 1000 层的残差网络都取得了当前最优的准确率。残差网络的核心思想是在 h(xl)h(x_{l})h(xl​) 的基础上学习附加的残差函数 FFF，其中很关键的选择就是使用恒等映射 h(xl)=xlh(x_{l})= x_{l}h(xl​)=xl​，这可以通过在网络中添加恒等快捷连接（skip connection) shortcut 来实现。 本文中主要在于分析在深度残差网络中构建一个信息“直接”传播的路径——不只是在残差单元直接，而是在整个网络中信息可以“直接”传播。如果 h(xl)h(x_{l})h(xl​) 和 f(yl)f(y_{l})f(yl​) 都是恒等映射，那么信号可以在单元间直接进行前向-反向传播。实验证明基本满足上述条件的网络架构一般更容易训练。本文实验了不同形式的 h(xl)h(x_{l})h(xl​)，发现使用恒等映射的网络性能最好，误差减小最快且训练损失最低。这些实验说明“干净”的信息通道有助于优化。各种不同形式的 h(xl)h(x_{l})h(xl​) 见论文中的图 1、图2 和 图4 中的灰色箭头所示。 为了构建 f(yl)=ylf(y_l)=y_lf(yl​)=yl​ 的恒等映射，本文将激活函数（ReLU 和 BN）移到权值层（Conv）之前，形成一种“预激活（pre-activation）”的方式，而不是常规的“后激活（post-activation）”方式，这样就设计出了一种新的残差单元（见图 1(b)）。基于这种新的单元我们在 CIFAR-10/100 数据集上使用1001 层残差网络进行训练，发现新的残差网络比之前（ResNet）的更容易训练并且泛化性能更好。同时还考察了 200 层新残差网络在 ImageNet 上的表现，原先的残差网络在这个层数之后开始出现过拟合的现象。这些结果表明网络深度这个维度还有很大探索空间，毕竟深度是现代神经网络成功的关键。 2、深度残差网络的分析 原先 ResNets 的残差单元的可以表示为： 在 ResNet 中，函数 hhh 是恒等映射，即 h(xl)=xlh(x_{l}) = x_{l}h(xl​)=xl​。公式的参数解释见下图： 如果函数 fff 也是恒等映射，即 yl≡yly_{l}\\equiv y_{l}yl​≡yl​，公式 (1)(2) 可以合并为： 那么任意深层的单元 LLL 与浅层单元 lll之间的关系为： 公式 (4) 有两个特性： 深层单元的特征可以由浅层单元的特征和残差函数相加得到； 任意深层单元的特征都可以由起始特征 x0x_0x0​ 与先前所有残差函数相加得到，这与普通（plain）网络不同，普通网络的深层特征是由一系列的矩阵向量相乘得到。残差网络是连加，普通网络是连乘。 公式 (4) 也带来了良好的反向传播特性，用 $\\varepsilon $ 表示损失函数，根据反向传播的链式传导规则，反向传播公式如下： 从公式 (5) 中可以看出，反向传播也是两条路径，其中之一直接将信息回传，另一条会经过所有的带权重层。另外可以注意到第二项的值在一个 mini-batch 中不可能一直是 -1，也就是说回传的梯度不会消失，不论网络中的权值的值再小都不会发生梯度消失现象。 3、On the Importance of Identity Skip Connection 考虑恒等映射的重要性。假设将恒等映射改为 h(xl)=λlxl)h(x_{l}) = \\lambda_{l}x_{l})h(xl​)=λl​xl​)，则： 像公式 (4) 一样递归的调用公式 (3)，得： 其中，F^\\hat{F}F^ 表示将标量合并到残差函数中，与公式 (5) 类似，反向传播公式如下： 与公式 (5) 不同，公式 (8) 的第一个加法项由因子 ∏i=lL−1λi\\prod_{i=l}^{L-1}\\lambda_{i}∏i=lL−1​λi​ 进行调节。对于一个极深的网络(LLL 极大)，考虑第一个连乘的项，如果所有的 λ\\lambdaλ 都大于 1，那么这一项会指数级增大；如果所有 λ\\lambdaλ 都小于 1，那么这一项会很小甚至消失，会阻断来自 shortcut 的反向传播信号，并迫使其流过权重层。本文通过实验证明这种方式会对模型优化造成困难。 另外其他不同形式的变换映射也都会阻碍信号的有效传播，进而影响训练进程。 4、On the Usage of Activation Functions 第 3 章考察使用不同形式映射（见图 2）来验证函数 hhh 是恒等映射的重要性，这章讨论公式(2)中的 fff，如果 fff 也是恒等映射，网络的性能会不会有所提升。通过调节激活函数 (ReLU and/or BN) 的位置，来使 fff 是恒等映射。图 4 展示了激活函数在不同位置的残差单元结构图去。 图 4(e) 的”预激活“操作是本文提出的一种对于深层残差网络能够更有效训练的网络结构（ResNet v2）。 4.1、Experiments on Activation 本章，我们使用 ResNet-110 和 164 层瓶颈结构(称为 ResNet-164)来进行实验。瓶颈残差单元包含一个 1×11\\times 11×1 的层来降维，一个 3×33\\times 33×3 的层，还有一个 1×11\\times 11×1 的层来恢复维度。如 ResNet 论文中描述的那样，它的计算复杂度和包含两个 3×33\\times 33×3 卷积层的残差单元相似。 BN after addition 效果比基准差，BN 层移到相加操作后面会阻碍信号传播，一个明显的现象就是训练初期误差下降缓慢。 ReLU before addition 这样组合的话残差函数分支的输出就一直保持非负，这会影响到模型的表示能力，而实验结果也表明这种组合比基准差。 Post-activation or pre-activation 原来的设计中相加操作后面还有一个 ReLU 激活函数，这个激活函数会影响到残差单元的两个分支，现在将它移到残差函数分支上，快捷连接分支不再受到影响。具体操作如图 5 所示。 根据激活函数与相加操作的位置关系，我们称之前的组合方式为“后激活（post-activation）”，现在新的组合方式称之为“预激活（pre-activation）”。原来的设计与预激活残差单元之间的性能对比见表 3。预激活方式又可以分为两种：只将 ReLU 放在前面，或者将 ReLU 和 BN都放到前面，根据表 2 中的结果可以看出 full pre-activation 的效果要更好。 4.2、Analysis 使用预激活有两个方面的优点：1) fff 变为恒等映射，使得网络更易于优化；2)使用 BN 作为预激活可以加强对模型的正则化。 Ease of optimization 这在训练 1001 层残差网络时尤为明显，具体见图 1。使用原来设计的网络在起始阶段误差下降很慢，因为 fff 是 ReLU 激活函数，当信号为负时会被截断，使模型无法很好地逼近期望函数；而使用预激活网络中的 fff 是恒等映射，信号可以在不同单元直接直接传播。本文使用的 1001层网络优化速度很快，并且得到了最低的误差。 fff 为 ReLU 对浅层残差网络的影响并不大，如图 6-right 所示。本文认为是当网络经过一段时间的训练之后权值经过适当的调整，使得单元输出基本都是非负，此时 fff 不再对信号进行截断。但是截断现象在超过 1000层的网络中经常发生。 Reducing overfitting 观察图 6-right，使用了预激活的网络的训练误差稍高，但却得到更低的测试误差，本文推测这是 BN 层的正则化效果所致。在原始残差单元中，尽管BN 对信号进行了标准化，但是它很快就被合并到捷径连接(shortcut)上，组合的信号并不是被标准化的。这个非标准化的信号又被用作下一个权重层的输入。与之相反，本文的预激活（pre-activation）版本的模型中，权重层的输入总是标准化的。 5、Results 表 4、表 5 分别展示了不同深层网络在不同数据集上的表现。使用的预激活单元的且更深层的残差网络（ResNet v2）都取得了最好的精度。 6、结论 恒等映射形式的快捷连接和预激活对于信号在网络中的顺畅传播至关重要。 2.3 DenseNet 摘要 ResNet 的工作表面，只要建立前面层和后面层之间的“短路连接”（shortcut），就能有助于训练过程中梯度的反向传播，从而能训练出更“深”的 CNN 网络。DenseNet 网络的基本思路和 ResNet 一致，但是它建立的是前面所有层与后面层的密集连接（dense connection）。传统的 LLL 层卷积网络有 LLL 个连接——每一层与它的前一层和后一层相连—，而 DenseNet 网络有 L(L+1)/2L(L+1)/2L(L+1)/2 个连接。 在 DenseNet 中，让网络中的每一层都直接与其前面层相连，实现特征的重复利用；同时把网络的每一层设计得特别“窄”（特征图/滤波器数量少），即只学习非常少的特征图（最极端情况就是每一层只学习一个特征图），达到降低冗余性的目的。 网络结构 DenseNet 模型主要是由 DenseBlock 组成的。 用公式表示，传统直连（plain）的网络在 lll 层的输出为： xl=Hl(xl−1)\\mathrm{x}_l = H_l(\\mathrm{\\mathrm{x}}_l-1)xl​=Hl​(xl​−1) 对于残差块（residual block）结构，增加了一个恒等映射（shortcut 连接）： xl=Hl(xl−1)+xl−1\\mathrm{x}_l = H_l(\\mathrm{\\mathrm{x}}_l-1) + \\mathrm{x}_{l-1}xl​=Hl​(xl​−1)+xl−1​ 而在密集块（DenseBlock）结构中，每一层都会将前面所有层 concate 后作为输入： xl=Hl([x0,x1,...,xl−1])\\mathrm{x}_l = H_l([\\mathrm{\\mathrm{x_0},\\mathrm{x_1},...,\\mathrm{x_{l-1}}]})xl​=Hl​([x0​,x1​,...,xl−1​]) [x0,x1,...,xl−1][\\mathrm{\\mathrm{x_0},\\mathrm{x_1},...,\\mathrm{x_{l-1}}]}[x0​,x1​,...,xl−1​] 表示网络层 0,...,l−10,...,l-10,...,l−1 输出特征图的拼接。这里暗示了，在 DenseBlock 中，每个网络层的特征图大小是一样的。Hl(⋅)H_l(\\cdot)Hl​(⋅) 是非线性转化函数（non-liear transformation），它由 BN(Batch Normalization)，ReLU 和 Conv 层组合而成。 DenseBlock 的结构图如下图所示。 在 DenseBlock 的设计中，作者重点提到了一个参数 kkk，被称为网络的增长率（growth of the network），其实是 DenseBlock 中任何一个 3×33\\times 33×3 卷积层的滤波器个数（输出通道数）。如果每个 Hl(⋅)H_l(\\cdot)Hl​(⋅) 函数都输出 kkk 个特征图，那么第 lll 层的输入特征图数量为 k0+k×(l−1)k_0 + k\\times (l-1)k0​+k×(l−1)，k0k_0k0​ 是 DenseBlock 的输入特征图数量（即第一个卷积层的输入通道数）。DenseNet 网络和其他网络最显著的区别是，kkk 值可以变得很小，比如 k=12k=12k=12，即网络变得很“窄”，但又不影响精度。如表 4 所示。 为了在 DenseNet 网络中，保持 DenseBlock 的卷积层的 feature map 大小一致，作者在两个 DenseBlock 中间插入 transition 层。其由 2×22\\times 22×2 average pool, stride=2，和 1×11\\times 11×1 conv 层组合而成，具体为 BN + ReLU + 1x1 Conv + 2x2 AvgPooling。transition 层完成降低特征图大小和降维的作用。 CNN 网络一般通过 Pooling 层或者 stride&gt;1 的卷积层来降低特征图大小（比如 stride=2 的 3x3 卷积层）， 下图给出了一个 DenseNet 的网路结构，它共包含 3 个（一半用 4 个）DenseBlock，各个 DenseBlock 之间通过 Transition 连接在一起。 和 ResNet 一样，DenseNet 也有 bottleneck 单元，来适应更深的 DenseNet。Bottleneck 单元是 BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)这样连接的结构，作者将具有 bottleneck 的密集单元组成的网络称为 DenseNet-B。 Bottleneck 译为瓶颈，一端大一端小，对应着 1x1 卷积通道数多，3x3 卷积通道数少。 对于 ImageNet 数据集，图片输入大小为 224×224224\\times 224224×224 ，网络结构采用包含 4 个 DenseBlock 的DenseNet-BC，网络第一层是 stride=2 的 7×77\\times 77×7卷积层，然后是一个 stride=2 的 3×33\\times 33×3 MaxPooling 层，而后是 DenseBlock。ImageNet 数据集所采用的网络配置参数表如表 1 所示： 网络中每个阶段卷积层的 feature map 数量都是 32。 优点 省参数 省计算 抗过拟合 注意，后续的 VoVNet 证明了，虽然 DenseNet 网络参数量少，但是其推理效率却不高。 在 ImageNet 分类数据集上达到同样的准确率，DenseNet 所需的参数量和计算量都不到 ResNet 的一半。对于工业界而言，小模型（参数量少）可以显著地节省带宽，降低存储开销。 参数量少的模型，计算量肯定也少。 作者通过实验发现，DenseNet 不容易过拟合，这在数据集不是很大的情况下表现尤为突出。在一些图像分割和物体检测的任务上，基于 DenseNet 的模型往往可以省略在 ImageNet 上的预训练，直接从随机初始化的模型开始训练，最终达到相同甚至更好的效果。 对于 DenseNet 抗过拟合的原因，作者给出的比较直观的解释是：神经网络每一层提取的特征都相当于对输入数据的一个非线性变换，而随着深度的增加，变换的复杂度也逐渐增加（更多非线性函数的复合）。相比于一般神经网络的分类器直接依赖于网络最后一层（复杂度最高）的特征，DenseNet 可以综合利用浅层复杂度低的特征，因而更容易得到一个光滑的具有更好泛化性能的决策函数。 DenseNet 的泛化性能优于其他网络是可以从理论上证明的：去年的一篇几乎与 DenseNet 同期发布在 arXiv 上的论文（AdaNet: Adaptive Structural Learning of Artificial Neural Networks）所证明的结论（见文中 Theorem 1）表明类似于 DenseNet 的网络结构具有更小的泛化误差界。 问题 1，这么多的密集连接，是不是全部都是必要的，有没有可能去掉一些也不会影响网络的性能？ 作者回答：论文里面有一个热力图（heatmap），直观上刻画了各个连接的强度。从图中可以观察到网络中比较靠后的层确实也会用到非常浅层的特征。 注意，后续的改进版本 VoVNet 设计的 OSP 模块，去掉中间层的密集连接，只有最后一层聚合前面所有层的特征，并做了同一个实验。热力图的结果表明，去掉中间层的聚集密集连接后，最后一层的连接强度变得更好。同时，在 CIFAR-10 上和同 DenseNet 做了对比实验，OSP 的精度和 DenseBlock 相近，但是 MAC 减少了很多，这说明 DenseBlock 的这种密集连接会导致中间层的很多特征冗余的。 2.4 CSPNet 摘要 CSPNet 是作者 Chien-Yao Wang 于 2019 发表的论文 CSPNET: A NEW BACKBONE THAT CAN ENHANCE LEARNING CAPABILITY OF CNN。也是对 DenseNet 网络推理效率低的改进版本。 作者认为网络推理成本过高的问题是由于网络优化中的梯度信息重复导致的。CSPNet 通过将梯度的变化从头到尾地集成到特征图中，在减少了计算量的同时可以保证准确率。CSP（Cross Stage Partial Network，简称 CSPNet） 方法可以减少模型计算量和提高运行速度的同时，还不降低模型的精度，是一种更高效的网络设计方法，同时还能和Resnet、Densenet、Darknet 等 backbone 结合在一起。 1，介绍 虽然已经出现了 MobileNetv1/v2/v3 和 ShuffleNetv1/v2 这种为移动端（CPU）设计的轻量级网络，但是它们所采用的基础技术-深度可分离卷积技术并不适用于 NPU 芯片（基于专用集成电路 (ASIC) 的边缘计算系统）。 CSPNet 和不同 backbone 结合后的效果如下图所示。 和目标检测网络结合后的效果如下图所示。 CSPNet 提出主要是为了解决三个问题： 增强 CNN 的学习能力，能够在轻量化的同时保持准确性。 降低计算瓶颈和 DenseNet 的梯度信息重复。 降低内存成本。 2，相关工作 CNN 架构的设计。 实时目标检测器。 3，改进方法 原论文命名为 Method，但我觉得叫改进方法更能体现章节内容。 3.1，Cross Stage Partial Network 1，DenseNet 其中 fff 为权值更新函数，gig_igi​ 为传播到第 iii 个密集层的梯度。从公式 (2) 可以发现，大量的度信息被重用来更新不同密集层的权值，这将导致无差异的密集层反复学习复制的梯度信息。 2，Cross Stage Partial DenseNet. 作者提出的 CSPDenseNet 的单阶段的架构如图 2(b) 所示。CSPDenseNet 的一个阶段是由局部密集块和局部过渡层组成（a partial dense block and a partial transition layer）。 总的来说，作者提出的 CSPDenseNet 保留了 DenseNet 重用特征特性的优点，但同时通过截断梯度流防止了过多的重复梯度信息。该思想通过设计一种分层的特征融合策略来实现，并应用于局部过渡层（partial transition layer）。 3，Partial Dense Block. 设计局部密集块（partial dense block）的目的是为了 增加梯度路径:通过分块归并策略，可以使梯度路径的数量增加一倍。由于采用了跨阶段策略，可以减轻使用显式特征图 copy 进行拼接所带来的弊端; 每一层的平衡计算:通常，DenseNet 基层的通道数远大于生长速率。由于在局部稠密块中，参与密集层操作的基础层通道仅占原始数据的一半，可以有效解决近一半的计算瓶颈; 减少内存流量: 假设 DenseNet 中一个密集块的基本特征图大小为 w×h×cw\\times h\\times cw×h×c，增长率为 ddd，共有 mmm 个密集块。则该密集块的 CIO为 (c×m)+((m2+m)×d)/2(c\\times m) + ((m^2+m)\\times d)/2(c×m)+((m2+m)×d)/2，而局部密集块（partial dense block）的 CIO为 ((c×m)+(m2+m)×d)/2((c\\times m) + (m^2+m)\\times d)/2((c×m)+(m2+m)×d)/2。虽然 mmm 和 ddd 通常比 ccc 小得多，但是一个局部密集的块最多可以节省网络一半的内存流量。 4，Partial Transition Layer. 设计局部过渡层的目的是使梯度组合的差异最大。局部过渡层是一种层次化的特征融合机制，它利用梯度流的聚合策略来防止不同的层学习重复的梯度信息。在这里，我们设计了两个 CSPDenseNet 变体来展示这种梯度流截断是如何影响网络的学习能力的。 Transition layer 的含义和 DenseNet 类似，是一个 1x1 的卷积层（没有再使用 average pool）。上图中 transition layer 的位置决定了梯度的结构方式，并且各有优势： © 图 Fusion First 方式，先将两个部分进行 concatenate，然后再进行输入到Transion layer 中，采用这种做法会是的大量特梯度信息被重用，有利于网络学习； (d) 图 Fusion Last 的方式，先将部分特征输入 Transition layer，然后再进行concatenate，这样梯度信息将被截断，损失了部分的梯度重用，但是由于 Transition 的输入维度比（c）图少，大大减少了计算复杂度。 (b) 图中的结构是论文 CSPNet 所采用的，其结合了 ©、(d) 的特点，提升了学习能力的同时也提高了一些计算复杂度。 作者在论文中给出其使用不同 Partial Transition Layer 的实验结果，如下图所示。具体使用哪种结构，我们可以根据条件和使用场景进行调整。 5，Apply CSPNet to Other Architectures. 将 CSP 应用到 ResNeXt 或者 ResNet 的残差单元后的结构图如下所示： 3.2，Exact Fusion Model Aggregate Feature Pyramid. 提出了 EFM 结构能够更好地聚集初始特征金字塔。 4，结论 CSPNet 是能够用于移动 gpu 或 cpu 的轻量级网络架构 作者认为论文最主要的贡献是认识到冗余梯度信息问题，及其导致的低效优化和昂贵的推理计算。同时也提出了利用跨阶段特征融合策略和截断梯度流来增强不同层间学习特征的可变性 此外，还提出了一种 EFM 结构，它结合了 Maxout 操作来压缩从特征金字塔生成的特征映射，这大大降低了所需的内存带宽，因此推理的效率足以与边缘计算设备兼容 实验结果表明，本文提出的基于 EFM 的 CSPNet 在移动GPU 和 CPU 的实时目标检测任务的准确性和推理率方面明显优于竞争对手 3 目标检测相关论文 3.1 Faster-RCNN Faster RCNN 网络概述 backbone 为 vgg16 的 faster rcnn 网络结构如下图所示，可以清晰的看到该网络对于一副任意大小 PxQ 的图像，首先缩放至固定大小 MxN，然后将 MxN 图像送入网络；而 Conv layers 中包含了 13 个 conv 层 + 13 个 relu 层 + 4 个 pooling 层；RPN 网络首先经过 3x3 卷积，再分别生成 positive anchors 和对应 bounding box regression 偏移量，然后计算出 proposals；而 Roi Pooling 层则利用 proposals 从 feature maps 中提取 proposal feature 送入后续全连接和 softmax 网络作 classification（即分类： proposal 是哪种 object）。 Conv layers 论文中 Faster RCNN 虽然支持任意图片输入，但是进入 Conv layers 网络之前会对图片进行规整化尺度操作，如可设定图像短边不超过 600，图像长边不超过 1000，我们可以假定 M×N=1000×600M\\times N=1000\\times 600M×N=1000×600（如果图片少于该尺寸，可以边缘补 0，即图像会有黑色边缘）。 13 个 conv 层：kernel_size=3, pad=1, stride=1，卷积公式：N = (W − F + 2P )/S+1，所以可知 conv 层不会改变图片大小 13 个 relu 层: 激活函数，增加非线性，不改变图片大小 4 个 pooling 层：kernel_size=2,stride=2，pooling 层会让输出图片变成输入图片的 1/2。 所以经过 Conv layers，图片大小变成 (M/16)∗(N/16)(M/16) \\ast (N/16)(M/16)∗(N/16)，即：60∗40(1000/16≈60,600/16≈40)60\\ast 40(1000/16≈60,600/16≈40)60∗40(1000/16≈60,600/16≈40)；则 Feature Map 尺寸为 60∗40∗51260\\ast 40\\ast 51260∗40∗512-d (注：VGG16 是512-d, ZF 是 256-d，d 是指特征图通道数，也叫特征图数量)，表示特征图的大小为 60∗4060\\ast 4060∗40，数量为 512。 RPN 网络 RPN 在 Extractor（特征提取 backbone ）输出的 feature maps 的基础之上，先增加了一个 3*3 卷积（用来语义空间转换？），然后利用两个 1x1 的卷积分别进行二分类（是否为正样本）和位置回归。RPN 网络在分类和回归的时候，分别将每一层的每一个 anchor 分为背景和前景两类，以及回归四个位移量，进行分类的卷积核通道数为9×2（9 个 anchor，每个 anchor 二分类，使用交叉熵损失），进行回归的卷积核通道数为 9×4（9个anchor，每个 anchor 有 4 个位置参数）。RPN是一个全卷积网络（fully convolutional network），这样对输入图片的尺寸就没有要求了。 RPN 完成 positive/negative 分类 + bounding box regression 坐标回归两个任务。 Anchors 在RPN中，作者提出了anchors，在代码中，anchors 是一组由 generate_anchors.py 生成的矩形框列表。运行官方代码的 generate_anchors.py 可以得到以下示例输出.这里生成的坐标是在原图尺寸上的坐标，在特征图上的一个像素点，可以对应到原图上一个 16×1616\\times 1616×16大小的区域。 [[ -84. -40. 99. 55.] [-176. -88. 191. 103.] [-360. -184. 375. 199.] [ -56. -56. 71. 71.] [-120. -120. 135. 135.] [-248. -248. 263. 263.] [ -36. -80. 51. 95.] [ -80. -168. 95. 183.] [-168. -344. 183. 359.]] 其中每行的 4 个值 (x1,y1,x2,y2)(x_{1}, y_{1}, x_{2}, y_{2})(x1​,y1​,x2​,y2​) 表矩形左上和右下角点坐标。9 个矩形共有 3 种形状，长宽比为大约为 width:heightϵ{1:1,1:2,2:1}width:height \\epsilon \\{1:1, 1:2, 2:1\\}width:heightϵ{1:1,1:2,2:1} 三种，如下图。实际上通过 anchors 就引入了检测中常用到的多尺度方法。 注意，generate_anchors.py 生成的只是 base anchors，其中一个 框的左上角坐标为 (0,0) 坐标（特征图左上角）的 9 个 anchor，后续还需网格化（meshgrid）生成其他 anchor。同一个 scale，但是不同的 anchor ratios 生成的 anchors 面积理论上是要一样的。 然后利用这 9 种 anchor 在特征图左右上下移动（遍历），每一个特征图上的任意一个点都有 9 个 anchor，假设原图大小为 MxN，经过 Conv layers 下采样 16 倍，则每个 feature map 生成 (M/16)*(N/16)*9个 anchor。例如，对于一个尺寸为 62×37 的 feature map，有 62×37×9 ≈ 20000 个 anchor，并输出特征图上面每个点对应的原图 anchor 坐标。这种做法很像是暴力穷举，20000 多个 anchor，哪怕是蒙也能够把绝大多数的 ground truth bounding boxes 蒙中。 因此可知，anchor 的数量和 feature map 大小相关，不同的 feature map 对应的 anchor 数量也不一样。 生成 RPN 网络训练集 在这个任务中，RPN 做的事情就是利用（AnchorTargetCreator）将 20000 多个候选的 anchor 选出 256 个 anchor 进行分类和回归位置。选择过程如下： 对于每一个 ground truth bounding box (gt_bbox)，选择和它重叠度（IoU）最高的一个 anchor 作为正样本; 对于剩下的 anchor，从中选择和任意一个 gt_bbox 重叠度超过 0.7 的 anchor ，同样作为正样本;特殊情况下，如果正样本不足 128(256 的 1/2)，则用负样本凑。 随机选择和 gt_bbox 重叠度小于 0.3 的 anchor 作为负样本。 本和正样本的总数为256 ，正负样本比例 1:1。 positive/negative 二分类 由 1×11\\times 11×1 卷积实现，卷积通道数为 9×29\\times 29×2（每个点有 9 个 anchor，每个 anchor 二分类，使用交叉熵损失），后面接 softmax 分类获得 positive anchors，也就相当于初步提取了检测目标候选区域 box（一般认为目标在 positive anchors 中）。所以可知，RPN 的一个任务就是在原图尺度上，设置了大量的候选 anchor，并通过 AnchorTargetCreator 类去挑选正负样本比为 1:1 的 256 个 anchor，然后再用 CNN (1×11\\times 11×1 卷积，卷积通道数 9×29\\times 29×2) 去判断挑选出来的 256 个 anchor 哪些有目标的 positive anchor，哪些是没目标的 negative anchor。 在挑选 1:1 正负样本比例的 anchor 用作 RPN 训练集后，还需要计算训练集数据对应的标签。对于每个 anchor, 对应的标签是 gt_label 和 gt_loc。gt_label 要么为 1（前景），要么为 0（背景），而 gt_loc 则是由 4 个位置参数 (tx,ty,tw,th)(t_x,t_y,t_w,t_h)(tx​,ty​,tw​,th​) 组成，它们是 anchor box 与 ground truth bbox 之间的偏移量，因为回归偏移量比直接回归座标更好。在 Faster RCNN原文，positive anchor 与 ground truth 之间的偏移量 (tx,ty)(t_{x}, t_{y})(tx​,ty​) 与尺度因子 (tw,th)(t_{w}, t_{h})(tw​,th​) 计算公式如下: tx=(x−xa)/wa,ty=(y−ya)/hatw=log(w/wa),th=log(h/ha)tx∗=(x∗−xa)/wa,ty∗=(y∗−ya)/hatw∗=log(w∗/wa),th∗=log(h∗/ha)\\begin{aligned} t_{x} = (x-x_{a})/w_{a}, t_{y}=(y-y_{a})/h_{a} \\\\ t_{w} = log(w/w_{a}), t_{h}=log(h/h_{a}) \\\\ t_{x}^{\\ast } = (x^{\\ast }-x_{a})/w_{a}, t_{y}^{\\ast}=(y^{\\ast}-y_{a})/h_{a} \\\\ t_{w}^{\\ast } = log(w^{\\ast }/w_{a}), t_{h}^{\\ast }=log(h^{\\ast }/h_{a}) \\end{aligned}tx​=(x−xa​)/wa​,ty​=(y−ya​)/ha​tw​=log(w/wa​),th​=log(h/ha​)tx∗​=(x∗−xa​)/wa​,ty∗​=(y∗−ya​)/ha​tw∗​=log(w∗/wa​),th∗​=log(h∗/ha​)​ 参数解释：where x,y,w,x, y, w,x,y,w, and hhh denote the box’s center coordinates and its width and height. Variables x,xax, x_{a}x,xa​，and x∗x^{*}x∗ are for the predicted box, anchor box, and groundtruth box respectively (likewise for y,w,hy, w, hy,w,h). 计算分类损失用的是交叉熵损失，计算回归损失用的是 Smooth_L1_loss。在计算回归损失的时候，只计算正样本（前景）的损失，不计算负样本的位置损失。RPN 网络的 Loss 计算公式如下： 损失函数：L1 loss, L2 loss, smooth L1 loss 公式解释：Here, iii is the index of an anchor in a mini-batch and pip_{i}pi​ is the predicted probability of anchor i being an object. The ground-truth label pi∗p_i^{\\ast}pi∗​ is 1 if the anchor is positive, and is 0 if the anchor is negative. tit_{i}ti​ is a vector representing the 4 parameterized coordinates of the predicted bounding box, and ti∗t_i^*ti∗​ is that of theground-truth box associated with a positive anchor. RPN 生成 RoIs(Proposal Layer) RPN 网络在自身训练的同时，还会由 Proposal Layer 层产生 RoIs（region of interests）给 Fast RCNN（RoIHead）作为训练样本。RPN 生成 RoIs 的过程( ProposalCreator )如下： 对于每张图片，利用它的 feature map， 计算 (H/16)× (W/16)×9（大概 20000）个 anchor 属于前景的概率，以及对应的位置参数，并选取概率较大的 12000 个 anchor； 利用回归的位置参数，修正这 12000 个 anchor 的位置，得到RoIs； 利用非极大值（(Non-maximum suppression, NMS）抑制，选出概率最大的 2000 个 RoIs。 在 RPN 中，从上万个 anchor 中，选一定数目(2000 或 300)，调整大小和位置生成 RoIs，用于 ROI Head/Fast RCNN 训练或测试，然后 ProposalTargetCreator 再从 RoIs 中会中选择 128 个 RoIs 用以 ROIHead 的训练）。 注意：RoIs 对应的尺寸是原图大小，同时在 inference 的时候，为了提高处理速度，12000 和 2000 分别变为 6000 和 300。Proposal Layer 层，这部分的操作不需要进行反向传播，因此可以利用 numpy/tensor 实现。 RPN 网络总结 RPN 网络结构：生成 anchors -&gt; softmax 分类器提取 positvie anchors -&gt; bbox reg 回归 positive anchors -&gt; Proposal Layer 生成 proposals RPN 的输出：RoIs(region of interests)（形如 2000×4 或者 300×4 的 tensor） ROIHead/Fast R-CNN RPN 只是给出了 2000 个 候选框，RoI Head 在给出的 2000 候选框之上继续进行分类和位置参数的回归。ROIHead 网络包括 RoI pooling + Classification(全连接分类)两部分，网络结构如下： 由于 RoIs 给出的 2000 个 候选框，分别对应 feature map 不同大小的区域。首先利用 ProposalTargetCreator 挑选出 128 个 sample_rois, 然后使用了 RoI Pooling 将这些不同尺寸的区域全部 pooling 到同一个尺度 7×77\\times 77×7 上，并输出 7×77\\times 77×7 大小的 feature map 送入后续的两个全连接层。两个全连接层分别完成类别分类和 bbox 回归的作用： FC 21 用来分类，预测 RoIs 属于哪个类别（20个类+背景） FC 84 用来回归位置（21个类，每个类都有4个位置参数） 论文中之所以设定为 pooling 成 7×7 的尺度，其实是为了网络输出是固定大小的vector or matrix，从而能够共享 VGG 后面两个全连接层的权重。当所有的 RoIs 都被pooling 成（512×7×7）的 feature map 后，将它 reshape 成一个一维的向量，就可以利用 VGG16 预训练的权重来初始化前两层全连接（FC 4096）。 Roi pooling RoI pooling 负责将 128 个 RoI 区域对应的 feature map 进行截取，而后利用 RoI pooling 层输出 7×77\\times 77×7 大小的 feature map，送入后续的全连接网络。从论文给出的 Faster R-CNN 网络结构图中，可以看到 Rol pooling 层有 2 个输入： 原始的 feature maps RPN 输出的 RoIs (proposal boxes, 大小各不相同） RoI Pooling 的两次量化过程： (1) 因为 proposals是对应 M×NM\\times NM×N 的原图尺寸，所以在原图上生成的 region proposal 需要映射到 feature map 上（坐标值缩小 16 倍），需要除以 16/3216/3216/32（下采样倍数），这时候边界会出现小数，自然就需要量化。 (2) 将 proposals 对应的 feature map 区域水平划分成 k×kk\\times kk×k (7×77\\times 77×7) 的 bins，并对每个 bin 中均匀选取多少个采样点，然后进行 max pooling，也会出现小数，自然就产生了第二次量化。 Mask RCNN 算法中的 RoI Align 如何改进: ROI Align 并不需要对两步量化中产生的浮点数坐标的像素值都进行计算，而是设计了一套优雅的流程。如下图，其中虚线代表的是一个 feature map，实线代表的是一个 roi (在这个例子中，一个 roi 是分成了 2×22\\times 22×2 个 bins)，实心点代表的是采样点，每个 bin 中有 4 个采样点。我们通过双线性插值的方法根据采样点周围的四个点计算每一个采样点的值，然后对着四个采样点执行最大池化操作得到当前 bin 的像素值。 RoI Align 具体做法：假定采样点数为 4，即表示，对于每个 2.97×2.972.97\\times 2.972.97×2.97 的 bin，平分四份小矩形，每一份取其中心点位置，而中心点位置的像素，采用双线性插值法进行计算，这样就会得到四个小数坐标点的像素值。 更多细节内容可以参考 RoIPooling、RoIAlign笔记。 ROI Head 训练 RPN 会产生大约 2000 个 RoIs ，ROI Head 在给出的 2000 个 RoIs 候选框基础上继续分类(目标分类)和位置参数回归。注意，这 2000 个 RoIs 不是都拿去训练，而是利用 ProposalTargetCreator（官方源码可以查看类定义） 选择 128 个 RoIs 用以训练。选择的规则如下： 在和 gt_bboxes 的 IoU 大于 0.5 的 RoIs 内，选择一些（比如 32 个）作为正样本 在和 gt_bboxes 的 IoU 小于等于 0（或者 0.1 ）RoIs 内，的选择一些（比如 128−32=96128 - 32 = 96128−32=96 个）作为负样本 选择出的 128 个 RoIs，其正负样本比例为 3:1，在源码中为了便于训练，还对他们的 gt_roi_loc 进行标准化处理（减去均值除以标准差）。 对于分类问题, 和 RPN 一样，直接利用交叉熵损失。 对于位置的回归损失，也采用 Smooth_L1 Loss, 只不过只对正样本计算损失，而且是只对正样本中的对应类别的 444 个参数计算损失。举例来说： 一个 RoI 在经过 FC84 后会输出一个 84 维的 loc 向量。 如果这个 RoI 是负样本, 则这 84 维向量不参与计算 L1_Loss。 如果这个 RoI 是正样本，且属于 类别 kkk, 那么向量的第 (k×4，k×4+1，k×4+2，k×4+3)(k×4，k×4+1 ，k×4+2， k×4+3)(k×4，k×4+1，k×4+2，k×4+3) 这 444 位置的值参与计算损失，其余的不参与计算损失。 ROI Head 测试 ROI Head 测试的时候对所有的 RoIs（大概 300 个左右) 计算概率，并利用位置参数调整预测候选框的位置，然后再用一遍极大值抑制（之前在 RPN 的ProposalCreator 也用过）。这里注意： 在 RPN 的时候，已经对 anchor 做了一遍 NMS，在 Fast RCNN 测试的时候，还要再做一遍，所以在Faster RCNN框架中，NMS操作总共有 2 次。 在 RPN 的时候，已经对 anchor 的位置做了回归调整，在 Fast RCNN 阶段还要对 RoI 再做一遍。 在 RPN 阶段分类是二分类，而 Fast RCNN/ROI Head 阶段是 21 分类。 概念理解 在阅读 Faster RCNN 论文和源码中，我们经常会涉及到一些概念的理解。 四类损失 在训练 Faster RCNN 的时候有四个损失： RPN 分类损失：anchor 是否为前景（二分类） RPN 位置回归损失：anchor 位置微调 RoI 分类损失：RoI 所属类别（21 分类，多了一个类作为背景） RoI 位置回归损失：继续对 RoI 位置微调 四个损失相加作为最后的损失，反向传播，更新参数。 三个 creator Faster RCNN 官方源码中有三个 creator 类分别实现不同的功能，不能弄混，各自功能如下： AnchorTargetCreator ： 负责在训练 RPN 的时候，从上万个 anchors 中选择一些(比如 256 )进行训练，并使得正负样本比例大概是 1:1。同时给出训练的位置参数目标，即返回 gt_rpn_loc 和 gt_rpn_label。 ProposalTargetCreator： 负责在训练 RoIHead/Fast R-CNN 的时候，从 RoIs 选择一部分(比如 128 个，正负样本比例 1:3)用以训练。同时给定训练目标, 返回（sample_RoI, gt_RoI_loc, gt_RoI_label）。 ProposalCreator： 在 RPN 中，从上万个 anchor 中，选择一定数目（ 2000 或者 300 ），调整大小和位置，生成 RoIs ，用以 Fast R-CNN 训练或者测试。 其中 AnchorTargetCreator 和 ProposalTargetCreator 类是为了生成训练的目标，只在训练阶段用到，ProposalCreator 是 RPN 为 Fast R-CNN 生成 RoIs ，在训练和测试阶段都会用到。三个 creator 的共同点在于他们都不需要考虑反向传播（因此不同框架间可以共享 numpy 实现）。 3.2 FPN 论文背景 FPN(feature pyramid networks) 是何凯明等作者提出的适用于多尺度目标检测算法。原来多数的 object detection 算法（比如 faster rcnn）都是只采用顶层特征做预测，但我们知道低层的特征语义信息比较少，但是目标位置准确；高层的特征语义信息比较丰富，但是目标位置比较粗略。另外虽然也有些算法采用多尺度特征融合的方式，但是一般是采用融合后的特征做预测，而本文不一样的地方在于预测是在不同特征层独立进行的。 引言（Introduction） 从上图可以看出，（a）使用图像金字塔构建特征金字塔。每个图像尺度上的特征都是独立计算的，速度很慢。（b）最近的检测系统选择（比如 Faster RCNN）只使用单一尺度特征进行更快的检测。（c）另一种方法是重用 ConvNet（卷积层）计算的金字塔特征层次结构（比如 SSD），就好像它是一个特征化的图像金字塔。（d）我们提出的特征金字塔网络（FPN）与（b）和（c）类似，但更准确。在该图中，特征映射用蓝色轮廓表示，较粗的轮廓表示语义上较强的特征。 特征金字塔网络 FPN 作者提出的 FPN 结构如下图：这个金字塔结构包括一个自底向上的线路，一个自顶向下的线路和横向连接（lateral connections）。 自底向上其实就是卷积网络的前向过程。在前向过程中，feature map 的大小在经过某些层后会改变，而在经过其他一些层的时候不会改变，作者将不改变 feature map 大小的层归为一个 stage，因此这里金字塔结构中每次抽取的特征都是每个 stage 的最后一个层的输出。在代码中我们可以看到共有C1、C2、C3、C4、C5五个特征图，C1 和 C2 的特征图大小是一样的，所以，FPN 的建立也是基于从 C2 到 C5 这四个特征层上。 自顶向下的过程采用上采样（upsampling）进行，而横向连接则是将上采样的结果和自底向上生成的相同大小的 feature map 进行融合（merge）。在融合之后还会再采用 3*3 的卷积核对每个融合结果进行卷积，目的是消除上采样的混叠效应（aliasing effect）。并假设生成的 feature map 结果是 P2，P3，P4，P5，和原来自底向上的卷积结果 C2，C3，C4，C5一一对应。 这里贴一个 ResNet 的结构图：论文中作者采用 conv2_x，conv3_x，conv4_x 和 conv5_x 的输出，对应 C1，C2，C3，C4，C5，因此类似 Conv2就可以看做一个stage。 FPN网络建立 这里自己没有总结，因为已经有篇博文总结得很不错了，在这。 通过 ResNet50 网络，得到图片不同阶段的特征图，最后利用 C2，C3，C4，C5 建立特征图金字塔结构： 将 C5 经过 256 个 1*1 的卷积核操作得到：32*32*256，记为 P5； 将 P5 进行步长为 2 的上采样得到 64*64*256，再与 C4 经过的 256 个 1*1 卷积核操作得到的结果相加，得到 64*64*256，记为 P4； 将 P4 进行步长为 2 的上采样得到 128*128*256，再与 C3 经过的 256 个 1*1 卷积核操作得到的结果相加，得到 128*128*256，记为 P3； 将 P3 进行步长为 2 的上采样得到 256*256*256，再与 C2 经过的 256 个 1*1 卷积核操作得到的结果相加，得到 256*256*256，记为 P2； 将 P5 进行步长为 2 的最大池化操作得到：16*16*256，记为 P6； 结合从 P2 到 P6 特征图的大小，如果原图大小 1024*1024, 那各个特征图对应到原图的步长依次为 [P2,P3,P4,P5,P6]=&gt;[4,8,16,32,64]。 Anchor锚框生成规则 当 Faster RCNN 采用 FPN 的网络作 backbone 后，锚框的生成规则也会有所改变。基于上一步得到的特征图 [P2,P3,P4,P5,P6],再介绍下采用 FPN 的 Faster RCNN（或者 Mask RCNN）网络中 Anchor 锚框的生成，根据源码中介绍的规则，与之前 Faster-RCNN 中的生成规则有一点差别。 遍历 P2 到 P6 这五个特征层，以每个特征图上的每个像素点都生成 Anchor 锚框； 以 P2 层为例，P2 层的特征图大小为 256*256，相对于原图的步长为4，这样 P2上的每个像素点都可以生成一个基于坐标数组 [0,0,3,3] 即 4*4 面积为 16 大小的Anchor锚框，当然，可以设置一个比例 SCALE，将这个基础的锚框放大或者缩小，比如，这里设置 P2 层对应的缩放比例为 16，那边生成的锚框大小就是长和宽都扩大16倍，从 4*4 变成 64*64，面积从 16 变成 4096，当然在保证面积不变的前提下，长宽比可以变换为 32*128、64*64 或 128*32，这样以长、宽比率 RATIO = [0.5,1,2] 完成了三种变换，这样一个像素点都可以生成3个Anchor锚框。在 Faster-RCNN 中可以将 Anchor scale 也可以设置为多个值，而在MasK RCNN 中则是每一特征层只对应着一个 Anchor scale即对应着上述所设置的 16； 以 P2 层每个像素点位中心，对应到原图上，则可生成 256*256*3(长宽三种变换) = 196608 个锚框； 以 P3 层每个像素点为中心，对应到原图上，则可生成 128*128*3 = 49152 个锚框； 以 P4 层每个像素点为中心，对应到原图上，则可生成 64*64*3 = 12288 个锚框； 以 P5 层每个像素点为中心，对应到原图上，则生成 32*32*3 = 3072 个锚框； 以 P6 层每个像素点为中心，对应到原图上，则生成 16*16*3 = 768 个锚框。 从 P2 到 P6 层一共可以在原图上生成 196608+49152+12288+3072+768=261888196608 + 49152 + 12288 + 3072 + 768 = 261888196608+49152+12288+3072+768=261888 个 Anchor 锚框。 实验 看看加入FPN 的 RPN 网络的有效性，如下表 Table1。网络这些结果都是基于 ResNet-50。评价标准采用 AR，AR 表示 Average Recall，AR 右上角的 100 表示每张图像有 100 个 anchor，AR 的右下角 s，m，l 表示 COCO 数据集中 object 的大小分别是小，中，大。feature 列的大括号 {} 表示每层独立预测。 从（a）（b）（c）的对比可以看出 FPN 的作用确实很明显。另外（a）和（b）的对比可以看出高层特征并非比低一层的特征有效。 （d）表示只有横向连接，而没有自顶向下的过程，也就是仅仅对自底向上（bottom-up）的每一层结果做一个 1*1 的横向连接和 3*3 的卷积得到最终的结果，有点像 Fig1 的（b）。从 feature 列可以看出预测还是分层独立的。作者推测（d）的结果并不好的原因在于在自底向上的不同层之间的 semantic gaps 比较大。 （e）表示有自顶向下的过程，但是没有横向连接，即向下过程没有融合原来的特征。这样效果也不好的原因在于目标的 location 特征在经过多次降采样和上采样过程后变得更加不准确。 （f）采用 finest level 层做预测（参考 Fig2 的上面那个结构），即经过多次特征上采样和融合到最后一步生成的特征用于预测，主要是证明金字塔分层独立预测的表达能力。显然 finest level 的效果不如 FPN 好，原因在于 PRN 网络是一个窗口大小固定的滑动窗口检测器，因此在金字塔的不同层滑动可以增加其对尺度变化的鲁棒性。另外（f）有更多的 anchor，说明增加 anchor 的数量并不能有效提高准确率。 3.3 Mask-RCNN ROI Pooling 和 ROI Align 的区别 Understanding Region of Interest — (RoI Align and RoI Warp) Mask R-CNN 网络结构 Mask RCNN 继承自 Faster RCNN 主要有三个改进： feature map 的提取采用了 FPN 的多尺度特征网络 ROI Pooling 改进为 ROI Align 在 RPN 后面，增加了采用 FCN 结构的 mask 分割分支 网络结构如下图所示： 可以看出，Mask RCNN 是一种先检测物体，再分割的思路，简单直接，在建模上也更有利于网络的学习。 骨干网络 FPN 卷积网络的一个重要特征：深层网络容易响应语义特征，浅层网络容易响应图像特征。Mask RCNN 的使用了 ResNet 和 FPN 结合的网络作为特征提取器。 anchor 锚框生成规则 在 Faster-RCNN 中可以将 SCALE 也可以设置为多个值，而在 Mask RCNN 中则是每一特征层只对应着一个SCALE 即对应着上述所设置的 16。 实验 何凯明在论文中做了很多对比单个模块试验，并放出了对比结果表格。 从上图表格可以看出： sigmoid 和 softmax 对比，sigmoid 有不小提升； 特征网络选择：可以看出更深的网络和采用 FPN 的实验效果更好，可能因为 FPN 综合考虑了不同尺寸的 feature map 的信息，因此能够把握一些更精细的细节。 RoI Align 和 RoI Pooling 对比：在 instance segmentation 和 object detection 上都有不小的提升。这样看来，RoIAlign 其实就是一个更加精准的 RoIPooling，把前者放到 Faster RCNN 中，对结果的提升应该也会有帮助 3.4 Retinanet 摘要 Retinanet 是作者 Tsung-Yi Lin 和 Kaiming He（四作） 于 2018 年发表的论文 Focal Loss for Dense Object Detection. 作者深入分析了极度不平衡的正负（前景背景）样本比例导致 one-stage 检测器精度低于 two-stage 检测器，基于上述分析，提出了一种简单但是非常实用的 Focal Loss 焦点损失函数，并且 Loss 设计思想可以推广到其他领域，同时针对目标检测领域特定问题，设计了 RetinaNet 网络，结合 Focal Loss 使得 one-stage 检测器在精度上能够达到乃至超过 two-stage 检测器。 1，引言 作者认为一阶段检测器的精度不能和两阶段检测相比的原因主要在于，训练过程中的类别不平衡，由此提出了一种新的损失函数-Focal Loss。 R-CNN(Fast RCNN) 类似的检测器之所以能解决类别不平衡问题，是因为两阶段级联结构和启发式采样。提取 proposal 阶段（例如，选择性搜索、EdgeBoxes、DeepMask、RPN）很快的将候选对象位置的数量缩小到一个小数目（例如，1-2k），过滤掉大多数背景样本（其实就是筛选 anchor 数量）。在第二个分类阶段，执行启发式采样（sampling heuristics），例如固定的前景背景比（1:3），或在线难样本挖掘（OHEM），以保持前景和背景之间的平衡。 相比之下，单级检测器必须处理在图像中定期采样的一组更大的候选对象位置。实际上，这通常相当于枚举 ∼100k 个位置，这些位置密集地覆盖空间位置、尺度和纵横。虽然也可以应用类似的启发式采样方法，但效率低下，因为训练过程仍然由易于分类的背景样本主导。 2，相关工作 Two-stage Detectors: 与之前使用两阶段的分类器生成 proposal 不同，Faster RCNN 模型的 RPN 使用单个卷积就可以生成 proposal。 One-stage Detectors：最近的一些研究表明，只需要降低输入图像分辨率和 proposal 数量，两阶段检测器速度就可以变得更快。但是，对于一阶段检测器，即使提高模型计算量，其最后的精度也落后于两阶段方法[17]。同时，作者强调，Reinanet 达到很好的结果的原因不在于网络结构的创新，而在于损失函数的创新。 论文 [17] Speed/accuracy trade-offs for modern convolutional object detectors（注重实验）. 但是，从这几年看，一阶段检测器也可以达到很高的精度，甚至超过两阶段检测器，这几年的一阶段检测和两阶段检测器有相互融合的趋势了。 Class Imbalance: 早期的目标检测器 SSD 等在训练过程中会面临严重的类别不平衡（class imbalance）的问题，即正样本太少，负样本太多，这会导致两个问题： 训练效率低下：大多数候选区域都是容易分类的负样本，并没有提供多少有用的学习信号。 模型退化：易分类的负样本太多会压倒训练，导致模型退化。 通常的解决方案是执行某种形式的难负样本挖掘，如在训练时进行难负样本采样或更复杂的采样/重新称重方案。相比之下，Focla Loss 自然地处理了单级检测器所面临的类别不平衡，并且允许在所有示例上有效地训练，而不需要采样，也不需要容易的负样本来压倒损失和计算的梯度。 Robust Estimation: 人们对设计稳健的损失函数（例如 Huber loss）很感兴趣，该函数通过降低具有大错误的示例（硬示例）的损失来减少对总损失的贡献。相反， Focal Loss 对容易样本(inliers)减少权重来解决（address）类别不平衡问题（class imbalance），这意味着即使容易样本数量大，但是其对总的损失函数贡献也很小。换句话说，Focal Loss 与鲁棒损失相反，它侧重于训练稀疏的难样本。 3，网络架构 retinanet 的网络架构图如下所示。 3.1，Backbone Retinanet 的 Backbone 为 ResNet 网络，ResNet 一般从 18 层到 152 层（甚至更多）不等，主要区别在于采用的残差单元/模块不同或者堆叠残差单元/模块的数量和比例不同，论文主要使用 ResNet50。 两种残差块结构如下图所示，ResNet50 及更深的 ResNet 网络使用的是 bottleneck 残差块。 3.2，Neck Neck 模块即为 FPN 网络结构。FPN 模块接收 c3, c4, c5 三个特征图，输出 P2-P7 五个特征图，通道数都是 256, stride 为 (8,16,32,64,128)，其中大 stride (特征图小)用于检测大物体，小 stride (特征图大)用于检测小物体。P6 和 P7 目的是提供一个大感受野强语义的特征图，有利于大物体和超大物体检测。注意：在 RetinaNet 的 FPN 模块中只包括卷积，不包括 BN 和 ReLU。 3.3，Head Head 即预测头网络。 YOLOv3 的 neck 输出 3 个分支，即输出 3 个特征图， head 模块只有一个分支，由卷积层组成，该卷积层完成目标分类和位置回归的功能。总的来说，YOLOv3 网络的 3 个特征图有 3 个预测分支，分别预测 3 个框，也就是分别预测大、中、小目标。 Retinanet 的 neck 输出 5 个分支，即输出 5 个特征图。head 模块包括分类和位置检测两个分支，每个分支都包括 4 个卷积层，但是 head 模块的这两个分支之间参数不共享，分类 Head 输出通道是 A*K，A 是类别数；检测 head 输出通道是 4*K, K 是 anchor 个数, 虽然每个 Head 的分类和回归分支权重不共享，但是 5 个输出特征图的 Head 模块权重是共享的。 4，Focal Loss Focal Loss 是在二分类问题的交叉熵（CE）损失函数的基础上引入的，所以需要先学习下交叉熵损失的定义。 4.1，Cross Entropy 可额外阅读文章 理解交叉熵损失函数。 在深度学习中我们常使用交叉熵来作为分类任务中训练数据分布和模型预测结果分布间的代价函数。对于同一个离散型随机变量 x\\textrm{x}x 有两个单独的概率分布 P(x)P(x)P(x) 和 Q(x)Q(x)Q(x)，其交叉熵定义为： P 表示真实分布， Q 表示预测分布。 $H(P,Q) = \\mathbb{E}{\\textrm{x}\\sim P} log Q(x)= -\\sum{i}P(x_i)logQ(x_i) \\tag{1} $ 但在实际计算中，我们通常不这样写，因为不直观。在深度学习中，以二分类问题为例，其交叉熵损失（CE）函数如下： Loss = L(y, p) = -ylog(p)-(1-y)log(1-p) \\tag{2} 其中 ppp 表示当预测样本等于 111 的概率，则 1−p1-p1−p 表示样本等于 000 的预测概率。因为是二分类，所以样本标签 yyy 取值为 {1,0}\\{1,0\\}{1,0}，上式可缩写至如下： CE = \\left\\{\\begin{matrix} -log(p), &amp; if \\quad y=1 \\\\ -log(1-p), &amp; if\\quad y=0 \\tag{3} \\end{matrix}\\right. 为了方便，用 ptp_tpt​ 代表 ppp，ptp_tpt​ 定义如下： pt={p,ify=11−p,ify=0p_t = \\left\\{\\begin{matrix} p, &amp; if \\quad y=1 \\\\ 1-p, &amp; if\\quad y=0 \\end{matrix}\\right.pt​={p,1−p,​ify=1ify=0​ 则(3)(3)(3)式可写成： CE(p, y) = CE(p_t) = -log(p_t) \\tag{4} 前面的交叉熵损失计算都是针对单个样本的，对于所有样本，二分类的交叉熵损失计算如下： L=1N(∑yi=1m−log(p)−∑yi=0nlog(1−p))L = \\frac{1}{N}(\\sum_{y_i = 1}^{m}-log(p)-\\sum_{y_i = 0}^{n}log(1-p))L=N1​(∑yi​=1m​−log(p)−∑yi​=0n​log(1−p)) 其中 mmm 为正样本个数，nnn 为负样本个数，NNN 为样本总数，m+n=Nm+n=Nm+n=N。当样本类别不平衡时，损失函数 LLL 的分布也会发生倾斜，如 m≪nm \\ll nm≪n 时，负样本的损失会在总损失占主导地位。又因为损失函数的倾斜，模型训练过程中也会倾向于样本多的类别，造成模型对少样本类别的性能较差。 再衍生以下，对于所有样本，多分类的交叉熵损失计算如下： L=1N∑iNLi=−1N(∑i∑c=1Myiclog(pic)L = \\frac{1}{N} \\sum_i^N L_i = -\\frac{1}{N}(\\sum_i \\sum_{c=1}^M y_{ic}log(p_{ic})L=N1​∑iN​Li​=−N1​(∑i​∑c=1M​yic​log(pic​) 其中，MMM 表示类别数量，yicy_{ic}yic​ 是符号函数，如果样本 iii 的真实类别等于 ccc 取值 1，否则取值 0; picp_{ic}pic​ 表示样本 iii 预测为类别 ccc 的概率。 对于多分类问题，交叉熵损失一般会结合 softmax 激活一起实现，PyTorch 代码如下，代码出自这里。 4.2，Balanced Cross Entropy 对于正负样本不平衡的问题，较为普遍的做法是引入 α∈(0,1)\\alpha \\in(0,1)α∈(0,1) 参数来解决，上面公式重写如下： CE(pt)=−αlog(pt)={−αlog(p),ify=1−(1−α)log(1−p),ify=0CE(p_t) = -\\alpha log(p_t) = \\left\\{\\begin{matrix} -\\alpha log(p), &amp; if \\quad y=1\\\\ -(1-\\alpha)log(1-p), &amp; if\\quad y=0 \\end{matrix}\\right.CE(pt​)=−αlog(pt​)={−αlog(p),−(1−α)log(1−p),​ify=1ify=0​ 对于所有样本，二分类的平衡交叉熵损失函数如下： L=1N(∑yi=1m−αlog(p)−∑yi=0n(1−α)log(1−p))L = \\frac{1}{N}(\\sum_{y_i = 1}^{m}-\\alpha log(p)-\\sum_{y_i = 0}^{n}(1 - \\alpha) log(1-p))L=N1​(∑yi​=1m​−αlog(p)−∑yi​=0n​(1−α)log(1−p)) 其中 α1−α=nm\\frac{\\alpha}{1-\\alpha} = \\frac{n}{m}1−αα​=mn​，即 α\\alphaα 参数的值是根据正负样本分布比例来决定的， 4.3，Focal Loss Definition 虽然 α\\alphaα 参数平衡了正负样本（positive/negative examples），但是它并不能区分难易样本（easy/hard examples），而实际上，目标检测中大量的候选目标都是易分样本。这些样本的损失很低，但是由于难易样本数量极不平衡，易分样本的数量相对来讲太多，最终主导了总的损失。而本文的作者认为，易分样本（即，置信度高的样本）对模型的提升效果非常小，模型应该主要关注与那些难分样本（这个假设是有问题的，是 GHM 的主要改进对象） Focal Loss 作者建议在交叉熵损失函数上加上一个调整因子（modulating factor）(1−pt)γ(1-p_t)^\\gamma(1−pt​)γ，把高置信度 ppp（易分样本）样本的损失降低一些。Focal Loss 定义如下： FL(pt)=−(1−pt)γlog(pt)={−(1−p)γlog(p),ify=1−pγlog(1−p),ify=0FL(p_t) = -(1-p_t)^\\gamma log(p_t) = \\left\\{\\begin{matrix} -(1-p)^\\gamma log(p), &amp; if \\quad y=1 \\\\ -p^\\gamma log(1-p), &amp; if\\quad y=0 \\end{matrix}\\right.FL(pt​)=−(1−pt​)γlog(pt​)={−(1−p)γlog(p),−pγlog(1−p),​ify=1ify=0​ Focal Loss 有两个性质： 当样本被错误分类且 ptp_tpt​ 值较小时，调制因子接近于 1，loss 几乎不受影响；当 ptp_tpt​ 接近于 1，调质因子（factor）也接近于 0，容易分类样本的损失被减少了权重，整体而言，相当于增加了分类不准确样本在损失函数中的权重。 γ\\gammaγ 参数平滑地调整容易样本的权重下降率，当 γ=0\\gamma = 0γ=0 时，Focal Loss 等同于 CE Loss。 γ\\gammaγ 在增加，调制因子的作用也就增加，实验证明 γ=2\\gamma = 2γ=2 时，模型效果最好。 直观地说，调制因子减少了简单样本的损失贡献，并扩大了样本获得低损失的范围。例如，当γ=2\\gamma = 2γ=2 时，与 CECECE 相比，分类为 pt=0.9p_t = 0.9pt​=0.9 的样本的损耗将降低 100 倍，而当 pt=0.968p_t = 0.968pt​=0.968 时，其损耗将降低 1000 倍。这反过来又增加了错误分类样本的重要性（对于 pt≤0.5pt≤0.5pt≤0.5 和 γ=2\\gamma = 2γ=2，其损失最多减少 4 倍）。在训练过程关注对象的排序为正难 &gt; 负难 &gt; 正易 &gt; 负易。 在实践中，我们常采用带 α\\alphaα 的 Focal Loss： FL(pt)=−α(1−pt)γlog(pt)FL(p_t) = -\\alpha (1-p_t)^\\gamma log(p_t)FL(pt​)=−α(1−pt​)γlog(pt​) 作者在实验中采用这种形式，发现它比非 α\\alphaα 平衡形式（non-α\\alphaα-balanced）的精确度稍有提高。实验表明 γ\\gammaγ 取 2，α\\alphaα 取 0.25 的时候效果最佳。 网上有各种版本的 Focal Loss 实现代码，大多都是基于某个深度学习框架实现的，如 Pytorch和 TensorFlow，我选取了一个较为清晰的通用版本代码作为参考，代码来自 这里。 后续有必要自己实现以下，有时间还要去看看 Caffe 的实现。这里的 Focal Loss 代码与后文不同，这里只是纯粹的用于分类的 Focal_loss 代码，不包含 BBox 的编码过程 3.5 YOLOv1 YOLOv1 出自 2016 CVPR 论文 You Only Look Once:Unified, Real-Time Object Detection. YOLO 系列算法的核心思想是将输入的图像经过 backbone 提取特征后，将得到特征图划分为 S x S 的网格，物体的中心落在哪一个网格内，这个网格就负责预测该物体的置信度、类别以及坐标位置。 1. Introduction 之前的目标检测器是重用分类器来执行检测，为了检测目标，这些系统在图像上不断遍历一个框，并利用分类器去判断这个框是不是目标。像可变形部件模型（DPM）使用互动窗口方法，其分类器在整个图像的均匀间隔的位置上运行。 作者将目标检测看作是单一的回归问题，直接从图像像素得到边界框坐标和类别概率。 首先，YOLO 速度非常快，我们将检测视为回归问题，所以检测流程也简单。其次，YOLO 在进行预测时，会对图像进行全面地推理。第三，YOLO 模型具有泛化能力，其比 DPM 和R-CNN 更好。最后，虽然 YOLO 模型在精度上依然落后于最先进（state-of-the-art）的检测系统，但是其速度更快。 2. Unified Detectron YOLO 系统将输入图像划分成 S×SS\\times SS×S 的网格（grid），然后让每个gird 负责检测那些中心点落在 grid 内的目标。 检测任务：每个网络都会预测 BBB 个边界框及边界框的置信度分数，所谓置信度分数其实包含两个方面：一个是边界框含有目标的可能性，二是边界框的准确度。前者记为 Pr(Object)Pr(Object)Pr(Object)，当边界框包含目标时，Pr(Object)Pr(Object)Pr(Object) 值为 1，否则为 0；后者记为 IOUpredtruthIOU_{pred}^{truth}IOUpredtruth​，即预测框与真实框的 IOU。因此形式上，我们将置信度定义为 Pr(Object)∗IOUpredtruthPr(Object)*IOU_{pred}^{truth}Pr(Object)∗IOUpredtruth​。如果 grid 不存在目标，则置信度分数置为 0，否则，置信度分数等于预测框和真实框之间的交集（IoU）。 每个边界框（bounding box）包含 5 个预测变量：xxx，yyy，www，hhh 和 confidence。(x,y)(x,y)(x,y) 坐标不是边界框中心的实际坐标，而是相对于网格单元左上角坐标的偏移（需要看代码才能懂，论文只描述了出“相对”的概念）。而边界框的宽度和高度是相对于整个图片的宽与高的比例，因此理论上以上 4 预测量都应该在 [0,1][0,1][0,1] 范围之内。最后，置信度预测表示预测框与实际边界框之间的 IOU。 值得注意的是，中心坐标的预测值 (x,y)(x,y)(x,y) 是相对于每个单元格左上角坐标点的偏移值，偏移量 = 目标位置 - grid的位置。 分类任务：每个网格单元（grid）还会预测 CCC 个类别的概率 Pr(Classi)∣Object)Pr(Class_i)|Object)Pr(Classi​)∣Object)。grid 包含目标时才会预测 PrPrPr，且只预测一组类别概率，而不管边界框 BBB 的数量是多少。 在推理时，我们乘以条件概率和单个 box 的置信度。 Pr(Classi)∣Object)∗Pr(Object)∗IOUpredtruth=Pr(Classi)∗IOUpredtruthPr(Class_i)|Object)*Pr(Object)*IOU_{pred}^{truth} = Pr(Class_i)*IOU_{pred}^{truth}Pr(Classi​)∣Object)∗Pr(Object)∗IOUpredtruth​=Pr(Classi​)∗IOUpredtruth​ 它为我们提供了每个框特定类别的置信度分数。这些分数编码了该类出现在框中的概率以及预测框拟合目标的程度。 在 Pscal VOC 数据集上评测 YOLO 模型时，我们设置 S=7S=7S=7, B=2B=2B=2（即每个 grid 会生成 2 个边界框）。Pscal VOC 数据集有 20 个类别，所以 C=20C=20C=20。所以，模型最后预测的张量维度是 7×7×(20+5∗2)=14707 \\times 7\\times (20+5*2) = 14707×7×(20+5∗2)=1470。 总结：YOLO 系统将检测建模为回归问题。它将图像分成 S×SS \\times SS×S 的 gird，每个 grid 都会预测 BBB 个边界框，同时也包含 CCC 个类别的概率，这些预测对应的就是 S×S×(C+5∗B)S \\times S \\times (C + 5*B)S×S×(C+5∗B)。 这里其实就是在描述 YOLOv1 检测头如何设计：回归网络的设计 + 训练集标签如何构建（即 yoloDataset 类的构建）。 一张图片对应的标签张量 target 的维度是 7×7×307 \\times 7 \\times 307×7×30。然后分别对各个目标框的 boxes: (x1,y1,x2,y2)(x1,y1,x2,y2)(x1,y1,x2,y2) 和 labels：(0,0,...,1,0)(one-hot 编码的目标类别信息）进行处理，符合检测系统要求的输入形式。算法步骤如下： 计算目标框中心点坐标和宽高，并遍历各个目标框； 计算目标中心点落在哪个 grid 上，target 相应位置的两个框的置信度值设为 1，同时对应类别值也置为 1； 计算目标中心所在 grid（网格）的左上角相对坐标：ij*cell_size，然后目标中心坐标相对于子网格左上角的偏移比例 delta_xy； 最后将 target 对应网格位置的 (x,y,w,h)(x, y, w, h)(x,y,w,h) 分别赋相应 wh、delta_xy 值。 2.1. Network Design YOLO 模型使用卷积神经网络来实现，卷积层负责从图像中提取特征，全连接层预测输出类别概率和坐标。 YOLO 的网络架构受 GooLeNet 图像分类模型的启发。网络有 24 个卷积层，最后面是 2 个全连接层。整个网络的卷积只有 1×11 \\times 11×1 和 3×33 \\times 33×3 卷积层，其中 1×11 \\times 11×1 卷积负责降维 ，而不是 GoogLeNet 的 Inception 模块。 图3：网络架构。作者在 ImageNet 分类任务上以一半的分辨率（输入图像大小 224×224224\\times 224224×224）训练卷积层，但预测时分辨率加倍。 Fast YOLO 版本使用了更少的卷积，其他所有训练参数及测试参数都和 base YOLO 版本是一样的。 网络的最终输出是 7×7×307\\times 7\\times 307×7×30 的张量。这个张量所代表的具体含义如下图所示。对于每一个单元格，前 20 个元素是类别概率值，然后 2 个元素是边界框置信度，两者相乘可以得到类别置信度，最后 8 个元素是边界框的 (x,y,w,h)(x,y,w,h)(x,y,w,h) 。之所以把置信度 ccc 和 (x,y,w,h)(x,y,w,h)(x,y,w,h) 都分开排列，而不是按照(x,y,w,h,c)(x,y,w,h,c)(x,y,w,h,c) 这样排列，存粹是为了后续计算时方便。 划分 7×77 \\times 77×7 网格，共 98 个边界框，2 个框对应一个类别，所以 YOLOv1 只能在一个网格中检测出一个目标、单张图片最多预测 49 个目标。 2.2 Training 模型训练最重要的无非就是超参数的调整和损失函数的设计。 因为 YOLO 算法将检测问题看作是回归问题，所以自然地采用了比较容易优化的均方误差作为损失函数，但是面临定位误差和分类误差权重一样的问题；同时，在每张图像中，许多网格单元并不包含对象，即负样本（不包含物体的网格）远多于正样本（包含物体的网格），这通常会压倒了正样本的梯度，导致训练早期模型发散。 为了改善这点，引入了两个参数：λcoord=5\\lambda_{coord}=5λcoord​=5 和 λnoobj=0.5\\lambda_{noobj} =0.5λnoobj​=0.5。对于边界框坐标预测损失（定位误差），采用较大的权重 λcoord=5\\lambda_{coord} =5λcoord​=5，然后区分不包含目标的边界框和含有目标的边界框，前者采用较小权重 λnoobj=0.5\\lambda_{noobj} =0.5λnoobj​=0.5。其他权重则均设为 0。 对于大小不同的边界框，因为较小边界框的坐标误差比较大边界框要更敏感，所以为了部分解决这个问题，将网络的边界框的宽高预测改为对其平方根的预测，即预测值变为 (x,y,w,h)(x, y, \\sqrt w, \\sqrt h)(x,y,w​,h​)。 YOLOv1 每个网格单元预测多个边界框。在训练时，每个目标我们只需要一个边界框预测器来负责。我们指定一个预测器“负责”根据哪个预测与真实值之间具有当前最高的 IOU 来预测目标。这导致边界框预测器之间的专业化。每个预测器可以更好地预测特定大小，方向角，或目标的类别，从而改善整体召回率。 YOLO 由于每个网格仅能预测 2 个边界框且仅可以包含一个类别，因此是对于一个单元格存在多个目标的问题，YOLO 只能选择一个来预测。这使得它在预测临近物体的数量上存在不足，如钢筋、人脸和鸟群检测等。 最终网络总的损失函数计算公式如下： IijobjI_{ij}^{obj}Iijobj​ 指的是第 iii 个单元格存在目标，且该单元格中的第 jjj 个边界框负责预测该目标。 IiobjI_{i}^{obj}Iiobj​ 指的是第 iii 个单元格存在目标。 前 2 行计算前景的 geo_loss（定位 loss）。 第 3 行计算前景的 confidence_loss（包含目标的边界框的置信度误差项）。 第 4 行计算背景的 confidence_loss。 第 5 行计算分类损失 class_loss。 值得注意的是，对于不存在对应目标的边界框，其误差项就是只有置信度，坐标项误差是没法计算的。而只有当一个单元格内确实存在目标时，才计算分类误差项，否则该项也是无法计算的。 2.4. Inferences 同样采用了 NMS 算法来抑制多重检测，对应的模型推理结果解码代码如下，这里要和前面的 encoder 函数结合起来看。 3.6 YOLOv2 摘要 YOLOv2 其实就是 YOLO9000，作者在 YOLOv1 基础上改进的一种新的 state-of-the-art 目标检测模型，它能检测多达 9000 个目标！利用了多尺度（multi-scale）训练方法，YOLOv2 可以在不同尺寸的图片上运行，并取得速度和精度的平衡。 在速度达到在 40 FPS 同时，YOLOv2 获得 78.6 mAP 的精度，性能优于backbone 为 ResNet 的 Faster RCNN 和 SSD 等当前最优（state-of-the-art） 模型。最后作者提出一种联合训练目标检测和分类的方法，基于这种方法，YOLO9000 能实时检测多达 9000 种目标。 YOLOv1 虽然速度很快，但是还有很多缺点： 虽然每个 grid 预测两个框，但是只能对应一个目标，对于同一个 grid 有着两个目标的情况下，YOLOv1 是检测不全的，且模型最多检测 7×7=497 \\times 7 = 497×7=49 个目标，即表现为模型查全率低。 预测框不够准确，之前回归 (x,y,w,h)(x,y,w,h)(x,y,w,h) 的方法不够精确，即表现为模型精确率低。 回归参数网络使用全连接层参数量太大，即模型检测头还不够块。 YOLOv2 的改进 1，中心坐标位置预测的改进 YOLOv1 模型预测的边界框中心坐标 (x,y)(x,y)(x,y) 是基于 grid 的偏移，这里 grid 的位置是固定划分出来的，偏移量 = 目标位置 - grid 的位置。 边界框的编码过程：YOLOv2 参考了两阶段网络的 anchor boxes 来预测边界框相对先验框的偏移，同时沿用 YOLOv1 的方法预测边界框中心点相对于 grid 左上角位置的相对偏移值。(x,y,w,h)(x,y,w,h)(x,y,w,h) 的偏移值和实际坐标值的关系如下图所示。 各个字母的含义如下： bx,by,bw,bhb_x,b_y,b_w,b_hbx​,by​,bw​,bh​ ：模型预测结果转化为 box 中心坐标和宽高后的值 tx,ty,tw,tht_x,t_y,t_w,t_htx​,ty​,tw​,th​ ：模型要预测的偏移量。 cx,cyc_x,c_ycx​,cy​ ：grid 的左上角坐标，如上图所示。 pw,php_w,p_hpw​,ph​ ：anchor 的宽和高，这里的 anchor 是人为定好的一个框，宽和高是固定的。 通过以上定义我们从直接预测位置改为预测一个偏移量，即基于 anchor 框的宽高和 grid 的先验位置的偏移量，位置上使用 grid，宽高上使用 anchor 框，得到最终目标的位置，这种方法叫作 location prediction。 预测偏移不直接预测位置，是因为作者发现直接预测位置会导致神经网络在一开始训练时不稳定，使用偏移量会使得训练过程更加稳定，性能指标提升了 5% 左右。 边界框的解码过程：虽然模型预测的是边界框的偏移量 (tx,ty,tw,th)(t_x,t_y,t_w,t_h)(tx​,ty​,tw​,th​)，但是可通过以下公式计算出边界框的实际位置。 $ b_x = \\sigma(t_x) + c_x \\\\ b_y = \\sigma(t_y) + c_y \\\\ b_w = p_{w}e^{t_w} \\\\ b_h = p_{h}e^{t_h} $ 其中，(cx,cy)(c_x, c_y)(cx​,cy​) 为 grid 的左上角坐标，因为 σ\\sigmaσ 表示的是 sigmoid 函数，所以边界框的中心坐标会被约束在 grid 内部，防止偏移过多。pwp_wpw​、php_hph​ 是先验框（anchors）的宽度与高度，其值相对于特征图大小 W×HW\\times HW×H = 13×1313\\times 1313×13 而言的，因为划分为 13×1313 \\times 1313×13 个 grid，所以最后输出的特征图中每个 grid 的长和宽均是 1。知道了特征图的大小，就可以将边界框相对于整个特征图的位置和大小计算出来（均取值 0,1{0,1}0,1）。 bx=(σ(tx)+cx)/Wby=(σ(ty)+cy)/Hbw=pwetw/Wbh=pheth/H b_x = (\\sigma(t_x) + c_x)/W \\\\\\\\ b_y = (\\sigma(t_y) + c_y)/H \\\\\\\\ b_w = p_{w}e^{t_w}/W \\\\\\\\ b_h = p_{h}e^{t_h}/H bx​=(σ(tx​)+cx​)/Wby​=(σ(ty​)+cy​)/Hbw​=pw​etw​/Wbh​=ph​eth​/H 在模型推理的时候，将以上 4 个值分别乘以图片的宽度和长度（像素点值）就可以得到边界框的实际中心坐标和大小。 在模型推理过程中，模型输出张量的解析，即边界框的解码函数如下： 2，1 个 gird 只能对应一个目标的改进 或者说很多目标预测不到，查全率低的改进 YOLOv2 首先把 7×77 \\times 77×7 个区域改为 13×1313 \\times 1313×13 个 grid（区域），每个区域有 5 个anchor，且每个 anchor 对应着 1 个类别，那么，输出的尺寸就应该为：[N,13,13,125] 125=5×(5+20)125 = 5 \\times (5 + 20)125=5×(5+20) 值得注意的是之前 YOLOv1 的每个 grid 只能预测一个目标的分类概率值，两个 boxes 共享这个置信度概率。现在 YOLOv2 使用了 anchor 先验框后，每个 grid 的每个 anchor 都单独预测一个目标的分类概率值。 之所以每个 grid 取 5 个 anchor，是因为作者对 VOC/COCO 数据集进行 K-means 聚类实验，发现当 k=5 时，模型 recall vs. complexity 取得了较好的平衡。当然，kkk 越好，mAP 肯定越高，但是为了平衡模型复杂度，作者选择了 5 个聚类簇，即划分成 5 类先验框。设置先验框的主要目的是为了使得预测框与 ground truth 的 IOU 更好，所以聚类分析时选用 box 与聚类中心 box 之间的 IOU 值作为距离指标： d(box,centroid)=1−IOU(box,centroid)d(box, centroid) = 1-IOU(box, centroid)d(box,centroid)=1−IOU(box,centroid) 与 Faster RCNN 手动设置 anchor 的大小和宽高比不同，YOLOv2 的 anchor 是从数据集中统计得到的。 3，backbone 的改进 作者提出了一个全新的 backbone 网络：Darknet-19，它是基于前人经典工作和该领域常识的基础上进行设计的。Darknet-19 网络和 VGG 网络类似，主要使用 3×33 \\times 33×3 卷积，并且每个 2×22 \\times 22×2 pooling 操作之后将特征图通道数加倍。借鉴 NIN 网络的工作，作者使用 global average pooling 进行预测，并在 3×33 \\times 33×3 卷积之间使用 1×11 \\times 11×1 卷积来降低特征图通道数从而降低模型计算量和参数量。Darknet-19 网络的每个卷积层后面都是用了 BN 层来加快模型收敛，防止模型过拟合。 Darknet-19 网络总共有 19 个卷积层（convolution）、5 最大池化层（maxpooling）。Darknet-19 以 5.58 T的计算量在 ImageNet 数据集上取得了 72.9% 的 top-1 精度和 91.2% 的 top-5 精度。Darket19 网络参数表如下图所示。 检测训练。在 Darknet19 网络基础上进行修改后用于目标检测。首先，移除网络的最后一个卷积层，然后添加滤波器个数为 1024 的 3×33 \\times 33×3 卷积层，最后添加一个 1×11 \\times 11×1 卷积层，其滤波器个数为模型检测需要输出的变量个数。对于 VOC 数据集，每个 grid 预测 5 个边界框，每个边界框有 5 个坐标（tx,ty,tw,th 和 tot_x, t_y, t_w, t_h \\ 和\\ t_otx​,ty​,tw​,th​ 和 to​）和 20 个类别，所以共有 125 个滤波器。我们还添加了从最后的 3×3×512 层到倒数第二层卷积层的直通层，以便模型可以使用细粒度特征。 Pr(object)∗IOU(b;object)=σ(to)P_r(object)*IOU(b; object) = \\sigma (t_o)Pr​(object)∗IOU(b;object)=σ(to​) Yolov2 整个模型结构代码如下： 代码来源 这里。 4，多尺度训练 YOLOv1 输入图像分辨率为 448×448448 \\times 448448×448，因为使用了 anchor boxes，所以 YOLOv2 将输入分辨率改为 416×416416 \\times 416416×416。又因为 YOLOv2 模型中只有卷积层和池化层，所以YOLOv2的输入可以不限于 416×416416 \\times 416416×416 大小的图片。为了增强模型的鲁棒性，YOLOv2 采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔一定的 iterations 之后改变模型的输入图片大小。由于 YOLOv2 的下采样总步长为 32，所以输入图片大小选择一系列为 32 倍数的值： {320,352,...,608}\\lbrace 320, 352,...,608 \\rbrace{320,352,...,608} ，因此输入图片分辨率最小为 320×320320\\times 320320×320，此时对应的特征图大小为 10×1010\\times 1010×10（不是奇数），而输入图片最大为 608×608608\\times 608608×608 ，对应的特征图大小为 19×1919\\times 1919×19 。在训练过程，每隔 10 个 iterations 随机选择一种输入图片大小，然后需要修最后的检测头以适应维度变化后，就可以重新训练。 采用 Multi-Scale Training 策略，YOLOv2 可以适应不同输入大小的图片，并且预测出很好的结果。 损失函数 YOLOv2 的损失函数的计算公式归纳如下 第 2,3 行：ttt 是迭代次数，即前 12800 步我们计算这个损失，后面不计算了。即前 12800 步我们会优化预测的 (x,y,w,h)(x,y,w,h)(x,y,w,h) 与 anchor 的 (x,y,w,h)(x,y,w,h)(x,y,w,h) 的距离 + 预测的 (x,y,w,h)(x,y,w,h)(x,y,w,h) 与 GT 的 (x,y,w,h)(x,y,w,h)(x,y,w,h) 的距离，12800 步之后就只优化预测的 (x,y,w,h)(x,y,w,h)(x,y,w,h)与 GT 的 (x,y,w,h)(x,y,w,h)(x,y,w,h) 的距离，原因是这时的预测结果已经较为准确了，anchor已经满足检测系统的需要，而在一开始预测不准的时候，用上 anchor 可以加速训练。 3.7 YOLOv3 摘要 我们对 YOLO 再次进行了更新，包括一些小的设计和更好的网络结构。在输入图像分辨率为 320×320320 \\times 320320×320 上运行 YOLOv3 模型，时间是 22 ms 的同时获得了 28.2 的 mAP，精度和 SSD 类似，但是速度更快。和其他阈值相比，YOLOv3 尤其在 0.5 IOU（也就是 AP50AP_{50}AP50​）这个指标上表现非常良好。 2，改进 YOLOv3 大部分有意的改进点都来源于前人的工作，当然也训练了一个比其他人更好的分类器网络。 2.1，边界框预测 这部分内容和 YOLOv2 几乎一致，但是内容更细致，且阈值的取值有些不一样。 和 YOLOv2 一样，我们依然使用维度聚类的方法来挑选 anchor boxes 作为边界框预测的先验框。每个边界框都会预测 444 个偏移坐标 (tx,ty,tw,th)(t_x,t_y,t_w,t_h)(tx​,ty​,tw​,th​)。假设 (cx,cy)(c_x, c_y)(cx​,cy​) 为 grid 的左上角坐标，pwp_wpw​、php_hph​ 是先验框（anchors）的宽度与高度，那么网络预测值和边界框真实位置的关系如下所示： 假设某一层的 feature map 的大小为 13×1313 \\times 1313×13， 那么 grid cell 就有 13×1313 \\times 1313×13 个，则第 nnn 行第 nnn 列的 grid cell 的坐标 (xx,cy)(x_x, c_y)(xx​,cy​) 就是 (n−1,n)(n-1,n)(n−1,n)。 $ b_x = \\sigma(t_x) + c_x \\\\ b_y = \\sigma(t_y) + c_y \\\\ b_w = p_{w}e^{t_w} \\\\ b_h = p_{h}e^{t_h} $ bx,by,bw,bhb_x,b_y,b_w,b_hbx​,by​,bw​,bh​ 是边界框的实际中心坐标和宽高值。在训练过程中，我们使用平方误差损失函数。利用上面的公式，可以轻松推出这样的结论：如果预测坐标的真实值（ground truth）是 t^∗\\hat{t}_{\\ast}t^∗​，那么梯度就是真实值减去预测值 t^∗−t∗\\hat{t}_{\\ast} - t_{\\ast }t^∗​−t∗​。 梯度变成 t^∗−t∗\\hat{t}_{\\ast} - t_{\\ast }t^∗​−t∗​ 有什么好处呢？ 注意，计算损失的时候，模型预测输出的 tx,tyt_x,t_ytx​,ty​ 外面要套一个 sigmoid 函数 ，否则坐标就不是 (0,1)(0,1)(0,1) 范围内的，一旦套了 sigmoid，就只能用 BCE 损失函数去反向传播，这样第一步算出来的才是 tx−t^xt_x-\\hat{t}_xtx​−t^x​；(tw,th)(t_w,t_h)(tw​,th​) 的预测没有使用 sigmoid 函数，所以损失使用 MSEMSEMSE。 t^x\\hat{t}_xt^x​ 是预测坐标偏移的真实值（ground truth）。 YOLOv3 使用逻辑回归来预测每个边界框的 objectness score（置信度分数）。如果当前先验框和 ground truth 的 IOU 超过了前面的先验框，那么它的分数就是 1。和 Faster RCNN 论文一样，如果先验框和 ground truth 的 IOU不是最好的，那么即使它超过了阈值，我们还是会忽略掉这个 box，正负样本判断的阈值取 0.5。YOLOv3 检测系统只为每个 ground truth 对象分配一个边界框。如果先验框（bonding box prior，其实就是聚类得到的 anchors）未分配给 ground truth 对象，则不会造成位置和分类预测损失，只有置信度损失（only objectness）。 2.2，分类预测 每个框使用多标签分类来预测边界框可能包含的类。我们不使用 softmax 激活函数，因为我们发现它对模型的性能影响不好。相反，我们只是使用独立的逻辑分类器。在训练过程中，我们使用二元交叉熵损失来进行类别预测。 在这个数据集 Open Images Dataset 中有着大量的重叠标签。如果使用 softmax ，意味着强加了一个假设，即每个框只包含一个类别，但通常情况并非如此。多标签方法能更好地模拟数据。 2.3，跨尺度预测 YOLOv3 可以预测 3 种不同尺度（scale）的框。 总的来说是，引入了类似 FPN 的多尺度特征图融合，从而加强小目标检测。与原始的 FPN 不同，YOLOv3 的 Neck 网络只输出 3 个分支，分别对应 3 种尺度，高层网络输出的特征图经过上采样后和低层网络输出的特征图融合是使用 concat 方式拼接，而不是使用 element-wise add 的方法。 首先检测系统利用和特征金字塔网络（FPN 网络）类似的概念，来提取不同尺度的特征。我们在基础的特征提取器基础上添加了一些卷积层。这些卷积层的最后会预测一个 3 维张量，其是用来编码边界框，框中目标和分类预测。在 COCO 数据集的实验中，我们每个输出尺度都预测 3 个 boxes，所以模型最后输出的张量大小是 N×N×[3∗(4+1+80)]N \\times N \\times [3*(4+1+80)]N×N×[3∗(4+1+80)]，其中包含 4 个边界框offset、1 个 objectness 预测（前景背景预测）以及 80 种分类预测。 objectness 预测其实就是前景背景预测，有些类似 YOLOv2 的置信度 c 的概念。 然后我们将前面两层输出的特征图上采样 2 倍，并和浅层中的特征图，用 concatenation 方式把高低两种分辨率的特征图连接到一起，这样做能使我们同时获得上采样特征的有意义的语义信息和来自早期特征的细粒度信息。之后，再添加几个卷积层来处理这个融合后的特征，并输出大小是原来高层特征图两倍的张量。 按照这种设计方式，来预测最后一个尺度的 boxes。可以知道，对第三种尺度的预测也会从所有先前的计算中（多尺度特征融合的计算中）获益，同时能从低层的网络中获得细粒度（ finegrained ）的特征。 显而易见，低层网络输出的特征图语义信息比较少，但是目标位置准确；高层网络输出的特征图语义信息比较丰富，但是目标位置比较粗略。 依然使用 k-means 聚类来确定我们的先验边界框（box priors，即选择的 anchors），但是选择了 9 个聚类（clusters）和 3 种尺度（scales，大、中、小三种 anchor 尺度），然后在整个尺度上均匀分割聚类。 从上面的描述可知，YOLOv3 的检测头变成了 3 个分支，对于输入图像 shape 为 (3, 416, 416)的 YOLOv3 来说，Head 各分支的输出张量的尺寸如下： [13, 13, 3*(4+1+80)] [26, 2, 3*(4+1+80)] [52, 52, 3*(4+1+80)] 3 个分支分别对应 32 倍、16 倍、8倍下采样，也就是分别预测大、中、小目标。32 倍下采样的特征图的每个点感受野更大，所以用来预测大目标。 每个 sacle 分支的每个 grid 都会预测 3 个框，每个框预测 5 元组+ 80 个 one-hot vector类别，所以一共 size 是：3*(4+1+80)。 根据前面的内容，可以知道，YOLOv3 总共预测 (13×13+26×26+52×52)×3=10467(YOLOv3)≫845=13×13×5(YOLOv2)(13 \\times 13 + 26 \\times 26 + 52 \\times 52) \\times 3 = 10467(YOLOv3) \\gg 845 = 13 \\times 13 \\times 5(YOLOv2)(13×13+26×26+52×52)×3=10467(YOLOv3)≫845=13×13×5(YOLOv2) 个边界框。 2.4，新的特征提取网络 我们使用一个新的网络来执行特征提取。它是 Darknet-19和新型残差网络方法的融合，由连续的 3×33\\times 33×3 和 1×11\\times 11×1 卷积层组合而成，并添加了一些 shortcut connection，整体体量更大。因为一共有 $53 = (1+2+8+8+4)\\times 2+4+2+1 $ 个卷积层，所以我们称为 Darknet-53。 总的来说，DarkNet-53 不仅使用了全卷积网络，将 YOLOv2 中降采样作用 pooling 层都换成了 convolution(3x3，stride=2) 层；而且引入了残差（residual）结构，不再使用类似 VGG 那样的直连型网络结构，因此可以训练更深的网络，即卷积层数达到了 53 层。（更深的网络，特征提取效果会更好） 3 个预测分支，对应预测 3 种尺度（大、种、小），也都采用了全卷积的结构。 Darknet-53 和 state-of-the-art 分类器相比，有着更少的 FLOPs 和更快的速度。Darknet-53 可以实现每秒最高的测量浮点运算。这意味着其网络结构可以更好地利用 GPU，从而使其评估效率更高，速度更快。这主要是因为 ResNets 的层数太多，效率不高。 2.5，训练 和 YOLOv2 一样，我们依然训练所有图片，没有 hard negative mining or any of that stuff。我们依然使用多尺度训练，大量的数据增强操作和 BN 层以及其他标准操作。 损失函数的计算公式如下。 YOLO v3 使用多标签分类，用多个独立的 logistic 分类器代替 softmax 函数，以计算输入属于特定标签的可能性。在计算分类损失进行训练时，YOLOv3 对每个标签使用二元交叉熵损失。 正负样本的确定： 正样本：与 GT 的 IOU 最大的框。 负样本：与 GT 的 IOU&lt;0.5 的框。 忽略的样本：与 GT 的 IOU&gt;0.5 但不是最大的框。 使用 txt_xtx​ 和 tyt_yty​ （而不是 bxb_xbx​ 和 byb_yby​ ）来计算损失。 注意：每个 GT 目标仅与一个先验边界框相关联。如果没有分配先验边界框，则不会导致分类和定位损失，只会有目标的置信度损失。 YOLOv3 网络结构图如下所示（这里输入图像大小为 608*608）。 2.5，推理 总的来说还是将输出的特侦图划分成 S*S（这里的S和特征图大小一样） 的网格，通过设置置信度阈值对网格进行筛选，只有大于指定阈值的网格才认为存在目标，即该网格会输出目标的置信度、bbox 坐标和类别信息，并通过 NMS 操作筛选掉重复的框。 4，失败的尝试 一些没有作用的尝试工作如下。 Anchor box x,y 偏移预测。我们尝试了常规的 Anchor box 预测方法，比如利用线性激活将坐标 x、yx、yx、y 的偏移程度，预测为边界框宽度或高度的倍数。但我们发现这种做法降低了模型的稳定性，且效果不佳。 用线性方法预测 x,y，而不是使用 logistic。我们尝试使用线性激活函数来直接预测 x，yx，yx，y 的偏移，而不是 ligistic 激活函数，但这降低了 mAP。 focal loss。我们尝试使用focal loss，但它使我们的 mAP降低了 2 点。 对于 focal loss 函数试图解决的问题，YOLOv3 已经具有鲁棒性，因为它具有单独的对象性预测（objectness predictions）和条件类别预测。因此，对于大多数示例来说，类别预测没有损失？或者其他的东西？我们并不完全确定。 双 IOU 阈值和真值分配。在训练过程中，Faster RCNN 用了两个IOU 阈值，如果预测的边框与的 ground truth 的 IOU 是 0.7，那它是正样本 ；如果 IOU 在 [0.3—0.7]之间，则忽略这个 box；如果小于 0.3，那它是个负样本。我们尝试了类似的策略，但效果并不好。 5，改进的意义 YOLOv3 是一个很好的检测器，速度很快，很准确。虽然它在 COCO 数据集上的 mAP 指标，即 AP50AP_{50}AP50​ 到 AP90AP_{90}AP90​ 之间的平均值上表现不好，但是在旧指标 AP50AP_{50}AP50​ 上，它表现非常好。 总结 YOLOv3 的改进点如下： 使用金字塔网络来实现多尺度预测，从而解决小目标检测的问题。 借鉴残差网络来实现更深的 Darknet-53，从而提升模型检测准确率。 使用 sigmoid 函数替代 softmax 激活来实现多标签分类器。 位置预测修改，一个 gird 预测 3 个 box。 3.8 YOLOv4 3，方法 3.2，Selection of BoF and BoS 为了更好的训练目标检测模型，CNN 通常使用如下方法： 激活函数：ReLU，leaky-ReLU，parameter-ReLU，ReLU6，SELU，Swish 或 Mish； 边界框回归损失：MSE，IoU，GIoU，CIoU，DIoU 损失； 数据扩充：CutOut，MixUp，CutMix 正则化方法：DropOut，DropPath，空间 DropOut 或 DropBlock 通过均值和方差对网络激活进行归一化：批归一化（BN），交叉-GPU 批处理规范化（CGBN 或 SyncBN），过滤器响应规范化（FRN）或交叉迭代批处理规范化（CBN）； 跳跃连接：残差连接，加残差连接，多输入加权残差连接或跨阶段局部连接（CSP） 3.3，额外的改进 这些方法是作者对现有方法做的一些改进。 为了让 YOLOv4 能更好的在单个 GPU 上训练，我们做了以下额外改进： 引入了新的数据增强方法：Mosaic 和自我对抗训练 self-adversarial training（SAT）。 通过遗传算法选择最优超参数。 修改了 SAM、PAN 和 CmBN。 Mosaic 是一种新的数据增强方法，不像 cutmix 仅混合了两张图片，它混合了 444 张训练图像，从而可以检测到超出其正常上下文的对象。 此外，BN 在每层上计算的激活统计都是来自 4 张不同图像，这大大减少了对大 batch size 的需求。 CmBN 仅收集单个批次中的 mini-batch 之间的统计信息。 3.4 YOLOv4 YOLOv4 网络由以下部分组成： Backbone: CSPDarknet53 Neck: SPP, PAN Head: YOLOv3 同时，YOLO v4 使用了： 用于 backbone 的 BoF：CutMix 和 Mosaic数据增强，DropBlock正则化，类标签平滑。 用于 backbone 的 BoS：Mish激活，跨阶段部分连接（CSP），多输入加权残余连接（MiWRC）。 用于检测器的 BoF：CIoU 损失，CmBN，DropBlock 正则化，mosaic 数据增强，自我对抗训练，消除网格敏感性，在单个 ground-truth 上使用多个 anchor，余弦退火调度器，最佳超参数，随机训练形状。 用于检测器 BoS：Mish 激活，SPP 模块，SAM 模块，PAN 路径聚集块，DIoU-NMS。 6，YOLOv4 主要改进点 6.1，Backbone 改进 Yolov4 的整体结构可以拆分成四大板块，结构图如下图所示。 YOLOv4 的五个基本组件如下： CBM：Yolov4 网络结构中的最小组件，由 Conv+Bn+Mish 激活函数三者组成。 CBL：由 Conv+Bn+Leaky_relu 激活函数三者组成。 Res unit：借鉴 Resnet 网络中的残差结构思想，让网络可以构建的更深，和 ResNet 的 basic block 由两个 CBL（ReLU）组成不同，这里的 Resunit 由 2 个 CBM 组成。 CSPX：借鉴 CSPNet 网络结构，由三个卷积层和 X 个 Res unint 模块 Concate 组成。 SPP：采用 1×1，5×5，9×9，13×13 的最大池化的方式，进行多尺度融合。 其他基础操作： Concat：张量拼接，会扩充维度。 add：逐元素相加操作，不改变维度（element-wise add）。 因为每个 CSPX 模块有 5+2∗X5+2\\ast X5+2∗X 个卷积层，因此整个 backbone 中共有 1+(5+2×1)+(5+2×2)+(5+2×8)+(5+2×8)+(5+2×4)=721 + (5+2\\times 1) + (5+2\\times 2) + (5+2\\times 8) + (5+2\\times 8) + (5+2\\times 4) = 721+(5+2×1)+(5+2×2)+(5+2×8)+(5+2×8)+(5+2×4)=72 个卷积层 这里卷积层的数目 72 虽然不等同于 YOLOv3 中 53，但是 backbone 依然是由 [1、2、8、8、4] 个卷积模块组成的，只是这里的 YOLOv4 中的卷积模块替换为了 CSPX 卷积模块，猜想是这个原因所以 YOLOv4 的作者这里依然用来 Darknet53 命名后缀。 6.1.1，CSPDarknet53 YOLOv4 使用 CSPDarknet53 作为 backbone，它是在 YOLOv3 的骨干网络 Darknet53 基础上，同时借鉴 2019 年的 CSPNet 网络，所产生的新 backbone。 CSPNet 作者认为，MobiletNet、ShuffleNet 系列模型是专门为移动端（CPU）平台上设计的，它们所采用的深度可分离卷积技术（DW+PW Convolution）并不兼容用于边缘计算的 ASIC 芯片。 CSP 结构是一种思想，它和ResNet、DenseNet 类似，可以看作是 DenseNet 的升级版，它将 feature map 拆成两个部分，一部分进行卷积操作，另一部分和上一部分卷积操作的结果进行concate。 CSP 结构主要解决了四个问题： 增强 CNN 的学习能力，能够在轻量化的同时保持着准确性； 降低计算成本； 降低内存开销。CSPNet 改进了密集块和过渡层的信息流，优化了梯度反向传播的路径，提升了网络的学习能力，同时在处理速度和内存方面提升了不少。 能很好的和 ResNet、DarkNet 等网络嵌入在一起，增加精度的同时减少计算量和降低内存成本。 6.1.2，Mish 激活 在 YOLOv4 中使用 Mish 函数的原因是它的低成本和它的平滑、非单调、无上界、有下界等特点，在表 2 的对比实验结果中，和其他常用激活函数如 ReLU、Swish 相比，分类器的精度更好。 Mish 激活函数是光滑的非单调激活函数，定义如下： Mish(x)=x⋅tanh(In(1+ex))Swish(x)=x⋅sigmoid(x) Mish(x) = x\\cdot tanh(In(1 + e^x)) \\\\\\\\ Swish(x) = x\\cdot sigmoid(x) \\\\\\\\ Mish(x)=x⋅tanh(In(1+ex))Swish(x)=x⋅sigmoid(x) Mish 函数曲线图和 Swish 类似，如下图所示。 值得注意的是 Yolov4 的 Backbone 中的激活函数都使用了Mish 激活，但后面的 neck + head 网络则还是使用leaky_relu 函数。 Leaky ReLU(x)={x,x&gt;0λx,x≤0 Leaky \\ ReLU(x) = \\begin{cases} x, &amp; x &gt; 0 \\\\\\\\ \\lambda x, &amp; x \\leq 0 \\end{cases} Leaky ReLU(x)=⎩⎪⎪⎨⎪⎪⎧​x,λx,​x&gt;0x≤0​ 6.1.3，Dropblock Yolov4 中使用的 Dropblock ，其实和常见网络中的 Dropout 功能类似，也是缓解过拟合的一种正则化方式。 传统 dropout 功能是随机删除减少神经元的数量，使网络变得更简单（缓解过拟合）。 6.2，Neck 网络改进 在目标检测领域中，为了更好的融合 low-level 和 high-level 特征，通常会在 backbone 和 head 网络之间插入一些网络层，这个中间部分称为 neck 网络，典型的有 FPN 结构。 YOLOv4 的 neck 结构采用了 SPP 模块 和 FPN+PAN 结构。 FPN 是自顶向下的，将高层的特征信息经过上采样后和低层的特征信息进行传递融合，从而得到进行预测的特征图 ①②③。 再看下图 YOLOv4 的 Neck 网络的立体图像，可以更清楚的理解 neck 是如何通过 FPN+PAN 结构进行融合的。 FPN 层自顶向下传达强语义特征，而特征金字塔则自底向上传达强定位特征，两两联手，从不同的主干层对不同的检测层进行参数聚合，这种正向反向同时结合的操作确实 6 啊。 值得注意的是，Yolov3 的 FPN 层输出的三个大小不一的特征图①②③直接进行预测。但Yolov4 输出特征图的预测是使用 FPN 层从最后的一个 76*76 特征图 ① 和而经过两次PAN 结构的特征图 ② 和 ③ 。 另外一点是，原本的 PANet 网络的 PAN 结构中，两个特征图结合是采用 shortcut + element-wise 操作，而 Yolov4 中则采用 concat（route）操作，特征图融合后的尺寸会变化。原本 PAN 和修改后的 PAN 结构对比图如下图所示。 6.3，预测的改进 6.3.1，使用CIoU Loss Bounding Box Regeression 的 Loss 近些年的发展过程是：Smooth L1 Loss-&gt; IoU Loss（2016）-&gt; GIoU Loss（2019）-&gt; DIoU Loss（2020）-&gt;CIoU Loss（2020） 6.3.2，使用DIoU_NMS 6.4，输入端改进 6.4.1，Mosaic 数据增强 YOLOv4 原创的 Mosaic 数据增强方法是基于 2019 年提出的 CutMix 数据增强方法做的优化。CutMix 只对两张图片进行拼接，而 Mosaic 更激进，采用 4 张图片，在各自随机缩放、裁剪和排布后进行拼接。 针对这种状况，Yolov4 的作者采用了 Mosaic 数据增强的方式。主要有几个优点： 丰富数据集：随机使用 4 张图片，随机缩放，再随机分布进行拼接，大大丰富了检测数据集，特别是随机缩放增加了很多小目标，让网络的鲁棒性更好。 减少训练所需 GPU 数量： Mosaic 增强训练时，可以直接计算 4 张图片的数据，使得 Mini-batch 大小并不需要很大，一个 GPU 就可以训练出较好的模型。 3.9 YOLOv5 5.1，网络架构 通过解析代码仓库中的 .yaml 文件中的结构代码，YOLOv5 模型可以概括为以下几个部分： Backbone: Focus structure, CSP network Neck: SPP block, PANet Head: YOLOv3 head using GIoU-loss 5.2，创新点 5.2.1，自适应anchor 在训练模型时，YOLOv5 会自己学习数据集中的最佳 anchor boxes，而不再需要先离线运行 K-means 算法聚类得到 k 个 anchor box 并修改 head 网络参数。总的来说，YOLOv5 流程简单且自动化了。 5.2.2， 自适应图片缩放 在常用的目标检测算法中，不同的图片长宽都不相同，因此常用的方式是将原始图片统一缩放到一个标准尺寸，再送入检测网络中。","categories":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/categories/deeplearning/"}],"tags":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/tags/deeplearning/"}]},{"title":"Windows深度学习环境配置","slug":"深度学习相关/Windows深度学习环境配置","date":"2022-11-03T11:28:11.000Z","updated":"2023-04-09T13:31:59.197Z","comments":true,"path":"2022/11/03/深度学习相关/Windows深度学习环境配置/","link":"","permalink":"http://jay1060950003.github.io/2022/11/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/Windows%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"引言 Windows环境下深度学习环境配置","text":"引言 Windows环境下深度学习环境配置 配置深度学习 在Windows环境下配置深度学习环境 首推conda + pytorch + Nvidia cudatoolkit的方案，在深度学习的项目运行时pytorch占用的显存小 在安装时选择cuda下的所有内容安装 重启根据pytorch官网的内容进行安装 其次conda + pytorch + conda cudatoolkit的方案，在深度学习的项目运行时pytorch占用的显存较大 1234567891011121314151617181920212223242526272829303132# (0)安装前检查# 1. 检查nvidia支持的cuda版本, 在bash中输入以下命令检查cuda版本，若cuda版本过低，则升级显卡驱动nvidia-smi# 2. 随后在pytorch官网查看支持的cuda版本,https://pytorch.org/get-started/locally/# (1)安装cuda# 1. 下载安装合适的nvidia的cuda版本,https://developer.nvidia.com/cuda-toolkit-archive寻找合适的版本,参考官网的安装命令# -----安装时全选cuda下的内容(重要)# 2. 添加环境变量(系统path)C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\libC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\lib\\x64C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\libnvvpC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\includeC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\binC:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v11.6\\bin\\win64C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v11.6\\common\\lib\\x64C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2022.1.1\\# (2)安装合适的cudnn# 1 在官网下载合适的cudnn版本,需要nvidia账户,https://developer.nvidia.com/rdp/cudnn-archive# 2 解压缩文件# 3 复制文件到cuda目录(C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6)# -----直接将cudnn下的文件夹复制到该路径下(windows会自动合并)# (3) 在conda对应的环境中安装pytorchconda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia# 在cmd下检查安装cuda是否成功nvcc -V# 在C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\extras\\demo_suite路径下使用powershell检查安装cudnn是否成功bandwidthTestdeviceQuery","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"CMake学习笔记","slug":"小工具记录/CMake学习笔记","date":"2022-11-02T13:22:17.000Z","updated":"2023-04-09T13:36:36.627Z","comments":true,"path":"2022/11/02/小工具记录/CMake学习笔记/","link":"","permalink":"http://jay1060950003.github.io/2022/11/02/%E5%B0%8F%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/CMake%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"引言 CMake学习笔记","text":"引言 CMake学习笔记 0 CMake cmake：高级编译配置工具:当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库，所有的操作通过编译CMakeLists.txt完成 1 CMake一个HelloWord 编写cpp程序 写CMakeLists.txt 使用cmake，生成makefile文件 使用make编译 最终生成了Hello的可执行程序 123456789101112131415161718192021// 1. main.cpp#include &lt;iostream&gt;int main()&#123;std::cout &lt;&lt; &quot;hello word&quot; &lt;&lt; std::endl;&#125;// 2.CMakeLists.txtPROJECT (HELLO)SET(SRC_LIST main.cpp)MESSAGE(STATUS &quot;This is BINARY dir &quot; $&#123;HELLO_BINARY_DIR&#125;)MESSAGE(STATUS &quot;This is SOURCE dir &quot;$&#123;HELLO_SOURCE_DIR&#125;)ADD_EXECUTABLE(hello $&#123;SRC_LIST&#125;)// 3.cmakecmake .// 目录下就生成了文件: CMakeFiles, CMakeCache.txt, cmake_install.cmake等文件// 并且生成了Makefile(重要)// 4. makemake 2 CMake语法介绍 2.1 PROJECT关键字 指定工程的名字和支持的语言，默认支持所有语言 PROJECT (HELLO) 指定了工程的名字，并且支持所有语言(建议) PROJECT (HELLO CXX) 指定了工程的名字，并且支持语言是C++ PROJECT (HELLO C CXX) 指定了工程的名字，并且支持语言是C和C++ 该指令隐式定义了两个CMAKE的变量 &lt;projectname&gt;_BINARY_DIR,本例中是 HELLO_BINARY_DIR &lt;projectname&gt;_SOURCE_DIR,本例中是 HELLO_SOURCE_DIR MESSAGE关键字可以直接使用者两个变量 问题：如果改了工程名，这两个变量名也会改变 解决：定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的 2.2 SET关键字 显示的指定变量的 SET(SRC_LIST main.cpp) SRC_LIST变量就包含了main.cpp SET(SRC_LIST main.cpp t1.cpp t2.cpp) 2.3 MESSAGE关键字 向终端输出用户自定义的信息 主要包含三种信息： SEND_ERROR, 产生错误，生成过程被跳过 SATUS, 输出前缀为—的信息 FATAL_ERROR, 立即终止所有 cmake 过程 2.4 ADD_EXECUTABLE关键字 生成可执行文件 ADD_EXECUTABLE(hello ${SRC_LIST})， 生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容 也可以直接写 ADD_EXECUTABLE(hello main.cpp) 123// 上面的CMakeLists.txt可简化写为PROJECT(HELLO)ADD_EXECUTABLE(hello main.cpp) 注意：工程名的 HELLO 和生成的可执行文件 hello 没有任何关系 2.5 语法的基本原则 变量使用${}方式取值 但在 IF 控制语句中是直接使用变量名 指令(参数 1 参数 2…) 参数使用括弧括起，参数之间使用空格或分号分开 例子 ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp) 指令是大小写无关的，参数和变量是大小写相关的 推荐全部使用大写 注意事项 SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”) 如果源文件名中含有空格，就必须要加双引号 ADD_EXECUTABLE(hello main) 不写后缀会自动去找.c和.cpp(不推荐) 3 内部构建和外部构建 上述例子就是内部构建，生产的临时文件特别多，不方便清理 外部构建会把生成的临时文件放在build目录下，不会对源文件有任何影响 强烈使用外部构建方式 3.1 外部构建方式举例 建立一个build目录，可以在任何地方(建议在当前目录下) 进入build目录, 运行cmake .. ..表示上一级目录，也可以写 CMakeLists.txt所在的绝对路径，生产的文件都在build目录下 在build目录下，运行make来构建工程 注意外部构建的两个变量 HELLO_SOURCE_DIR 工程路径 HELLO_BINARY_DIR 编译路径(build目录) 3.2 将目标文件放入构建目录的 bin 子目录 123456789101112// 项目的结构.├── build├── CMakeLists.txt├── doc // 用来放置这个工程的文档 hello.txt ├── hello.txt├── COPYRIGHT├── README├── runhello.sh // 用来调用 hello 二进制└── src ├── CMakeLists.txt └── main.cpp 每个目录下都要有一个CMakeLists.txt说明 1234567// 外层CMakeLists.txtPROJECT(HELLO)ADD_SUBDIRECTORY(src bin)// src下的CMakeLists.txtADD_EXECUTABLE(hello main.cpp) 3.2.1 ADD_SUBDIRECTORY 指令 ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置 EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example ADD_SUBDIRECTORY(src bin) 将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录 如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录 3.2.2 更改二进制的保存路径 指定最终的目标二进制的位置： SET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 SET(EXECUTABLE_OUTPUT_PATH $&#123;PROJECT_BINARY_DIR&#125;/bin) SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_BINARY_DIR&#125;/lib) 哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写 4 安装 一种是从代码编译后直接 make install 安装 一种是从打包时的指定目录进行安装 简单的可以这样指定目录：make install DESTDIR=/tmp/test 稍微复杂一点可以这样指定目录：./configure –prefix=/usr CMake语法新内容： INSTALL可以安装：二进制、动态库、静态库以及文件、目录、脚本等 CMAKE一个新的变量：CMAKE_INSTALL_PREFIX 4.1安装文件COPYRIGHT和README INSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/) FILES：文件 DESTINATION： 可以写绝对路径 可以写相对路径，相对路径实际路径是：$&#123;CMAKE_INSTALL_PREFIX&#125;/&lt;DESTINATION 定义的路径&gt; CMAKE_INSTALL_PREFIX 默认是在 /usr/local/ cmake -DCMAKE_INSTALL_PREFIX=/usr 在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径 4.2 安装脚本runhello.sh PROGRAMS：非目标文件的可执行程序安装(比如脚本之类) INSTALL(PROGRAMS runhello.sh DESTINATION bin) 实际安装到的是 /usr/bin 4.3 安装 doc 中的 hello.txt 在 doc 目录建立CMakeLists.txt ，通过install下的file 直接在工程目录通过 INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake) DIRECTORY 后面连接的是所在 Source 目录的相对路径 abc 和 abc/有很大的区别 目录名不以/结尾：这个目录将被安装为目标路径下的 目录名以/结尾：将这个目录中的内容安装到目标路径 4.4 安装过程 123cmake ..makemake install 5 静态库和动态库的构建 任务 建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串 安装头文件与共享库 静态库和动态库的区别 静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。 静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行 动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。 1234567891011121314151617181920212223242526272829303132333435// -------// 构建实例// -------// 项目目录.├── build├── CMakeLists.txt└── lib ├── CMakeLists.txt ├── hello.cpp └── hello.h// hello.h#ifndef HELLO_H#define Hello_Hvoid HelloFunc();#endif// hello.cpp#include &quot;hello.h&quot;#include &lt;iostream&gt;void HelloFunc()&#123; std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl;&#125;// CMakeLists.txtPROJECT(HELLO)ADD_SUBDIRECTORY(lib bin)// lib/CMakeLists.txtSET(LIBHELLO_SRC hello.cpp)ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;) 5.1 同时构建静态和动态库 123456789// 静态库的后缀是.a// 如果用这种方式，只会构建一个动态库，不会构建出静态库ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;)ADD_LIBRARY(hello STATIC $&#123;LIBHELLO_SRC&#125;)// 修改静态库的名字，这样是可以的// 但是往往希望名字是相同的，只是后缀不同ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;)ADD_LIBRARY(hello_static STATIC $&#123;LIBHELLO_SRC&#125;) 5.1.1 ADD_LIBRARY ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;) hello：正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so SHARED, 动态库 STATIC, 静态库 ${LIBHELLO_SRC} ：源文件 5.1.2 SET_TARGET_PROPERTIES 可以用来设置输出的名称 对于动态库，还可以用来指定动态库版本和 API 版本 1234567891011121314151617// ------------------// 同时构建静态和动态库// ------------------SET(LIBHELLO_SRC hello.cpp)ADD_LIBRARY(hello_static STATIC $&#123;LIBHELLO_SRC&#125;)// 对hello_static的重名为helloSET_TARGET_PROPERTIES(hello_static PROPERTIES OUTPUT_NAME &quot;hello&quot;)// cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.aSET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT 1)ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;)SET_TARGET_PROPERTIES(hello PROPERTIES OUTPUT_NAME &quot;hello&quot;)SET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUTPUT 1) 5.1.3 动态库的版本号 一般动态库都有一个版本号的关联 libhello.so.1.2 libhello.so -&gt;libhello.so.1 libhello.so.1-&gt;libhello.so.1.2 CMakeLists.txt 插入的内容 SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1) VERSION 指代动态库版本，SOVERSION 指代 API 版本 5.2 安装共享库和头文件 将 hello 的共享库安装到&lt;prefix&gt;/lib目录 将 hello.h 安装到&lt;prefix&gt;/include/hello 目录 123456//文件放到该目录下INSTALL(FILES hello.h DESTINATION include/hello)//二进制，静态库，动态库安装都用TARGETS//ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。INSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib) 注意：安装的时候，指定一下路径，放到系统下: cmake -DCMAKE_INSTALL_PREFIX=/usr .. 5.3 使用外部共享库和头文件 新建一个目录来使用外部共享库和头文件 1234567891011121314// 项目结构.├── build├── CMakeLists.txt└── src ├── CMakeLists.txt └── main.cpp// main.cpp#include &lt;hello.h&gt;int main()&#123; HelloFunc();&#125; 5.3.1 解决：make后头文件找不到的问题 PS：include &lt;hello/hello.h&gt; 这样include是可以，这么做的话，就没啥好讲的了 关键字：INCLUDE_DIRECTORIES 这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割 在CMakeLists.txt中加入头文件搜索路径 INCLUDE_DIRECTORIES(/usr/include/hello) 5.3.2 解决：找到引用的函数问题 报错信息：undefined reference to `HelloFunc()’ 关键字：LINK_DIRECTORIES 添加非标准的共享库搜索路径 指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs) 关键字：TARGET_LINK_LIBRARIES 添加需要链接的共享库 使用TARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字就行了 在CMakeLists.txt中插入链接共享库，主要要插在executable的后面 链接静态库：TARGET_LINK_LIBRARIES(main libhello.a) 5.3.3 特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH 环境变量而不是 cmake 变量 指明include路径的方法(两种方法) 使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置 使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello 6 其他内容 生产debug版本的方法：cmake .. -DCMAKE_BUILD_TYPE=debug 12345678&lt;!-- 遍历src下的所有cpp文件的main函数进行构建 --&gt;&lt;!-- src/CMakeLists.txt中添加的内容 --&gt;file (GLOB_RECURSE files *.cpp)foreach (file $&#123;files&#125;)string(REGEX REPLACE &quot;.+/(.+)\\\\..*&quot; &quot;\\\\1&quot; exe $&#123;file&#125;)add_executable ($&#123;exe&#125; $&#123;file&#125;)message (\\ \\ \\ \\ --\\ src/$&#123;exe&#125;.cpp\\ will\\ be\\ compiled\\ to\\ bin/$&#123;exe&#125;)endforeach ()","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"ISP算法精讲","slug":"专业知识相关/ISP算法精讲","date":"2022-09-29T13:52:19.000Z","updated":"2023-04-16T12:15:50.274Z","comments":true,"path":"2022/09/29/专业知识相关/ISP算法精讲/","link":"","permalink":"http://jay1060950003.github.io/2022/09/29/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%9B%B8%E5%85%B3/ISP%E7%AE%97%E6%B3%95%E7%B2%BE%E8%AE%B2/","excerpt":"引言 哔哩哔哩学习食鱼者的ISP视频笔记","text":"引言 哔哩哔哩学习食鱼者的ISP视频笔记 1 ISP Pipeline BAYER格式简介 色光三原色RGB展示真实世界中的物体 CMOS SENSOR: 为三维矩阵数据,分别表示R,G,B三个通道的数据 BAYER数据: 为二维数据, 其中每个元素表示R,G,B中的一个值 BAYER数据二维矩阵(单通道),每个像素点为一个通道的数据,其中整个矩阵为R,G,B的组合排列 根据中间的像素的排布可以分为GRBG, RGGB等 Pipeline lens-&gt;sensor-&gt;ISP/DSP(主控芯片) sensor: bayer filter(bayer滤光片)和sensor(coms,ccd) Basic处理流程: bayer raw data -&gt; DPC -&gt; BLC -&gt; Denoise -&gt; LSC -&gt; AWB -&gt; Demosiac -&gt; CCM -&gt; Gamma -&gt; EE -&gt; CSM -&gt; YUV DPC: defect pixel correction(坏点检测) 由sensor工艺造成,在工作时像素点不工作或工作性能较差(表现为图像中的亮点或暗点) BLC: Black Level correction 由于芯片的暗电流,造成黑色不黑 Denoise/NR (降噪) LSC: Lens Shading Correction 在拍摄时,借助灰阶卡片进行矫正 AWB: Auto White Balance 色温 A光: 2850K Demosiac(去马赛克) CCM(Color Correction Matrix)颜色矫正 Gamma 主要对亮度有影响,进而对颜色有影响 EE(Edge Enhance): 边缘增强 2 BLC 2.1 BL产生的原因 暗电流 指在没有光照射的状态下,在光敏二极管,光导电元件,光电管等的受光元件中流动的电流,一般由于载流子的扩散或者器件内部缺陷噪声 常用的COMS为光电元件,在光照为0时也会有电压输出 COMS内部为PN结,其符合二极管的伏安特性曲线,工作在反向电压下,在无光照时的微小电流为暗电流 AD前添加一个固定值 sensor到ISP会存在一个AD转换过程,而AD芯片具有一个灵敏度,当电压低于该阈值时无法进行AD转转,故人为添加一个常量将低于阈值的部分能被AD转换 人眼对暗部细节更加敏感,故增加一个常量牺牲人眼不敏感的亮区保留更大暗部细节 2.2 BL校正 BL校正分为sensor端和isp端两部分,重点介绍isp端的算法 sensor端算法(下图所示) 有效像素区：3280*2464(最大出图分辨率) Effective OPB: 有效OB区 有效像素区可以正常曝光,OB区在工艺上不能接受光子(在感光表面涂黑色不感光物质),利用OB区无光照的值完成校正有效像素的值 最简单的校正做法: 利用OB区像素值取均匀,利用每个像素的值减均值完成校正 比亚迪专利(CMOS传感器及图像中黑电平的调整方法)：分别计算每个颜色通道黑电平的平均值,计算CMOS传感器图像中黑电平的目标值,分为计算每个颜色通道内黑电平平均值和目标值差值的绝对值,当某个颜色通道内黑电平平均值和目标值差值绝对值大于阈值时,对对应颜色通道内的黑电平平均值进行模拟调整,小于阈值时进行数字调整 思特威专利(图像传感器的黑电平校正方法及系统)：将OB区分为左,中,右三个区域,对区域内曲线进行拟合,根据曲线进行校正 isp端: 对黑帧RAW图进行处理(以8位为例) 扣除固定值法(简单粗暴): 每个通道扣除一个固定值 采集黑帧RAW图,将其分为Gr,Gb,R,BG_r, G_b,R,BGr​,Gb​,R,B四个通道 计算校正值:对四个通道求平均值(或中位值,或其他) 后续图像的每个通道都利用上一步的校正值进行校正 对Gr,GbG_r, G_bGr​,Gb​通道进行归一化,将平移后的最大值恢复到255, Gin⁡×255255−BL\\operatorname{Gin} \\times \\frac{255}{255-B L}Gin×255−BL255​ R和B通道不进行归一化, 后续AWB通过gain将其范围提升至0-255 ISO联动法: 暗电流和gain值和温度等相关,通过联动的方式确定每个条件下的校正值,后续依据参数查表得到校正值进行校正 初始化一个ISO值(AG和DG的组合), 然后重复固定值中的做法,采集黑帧,标定各个通道的校正值 在初始化ISO的基础上通过等差或等比数列的方式增长iso,重复步骤1求取各个通道的校正值 将二维数据做成LUT,后续图像通过ISO值查找或插值的方式获取相应的校正值进行校正 曲线拟合法: 实际在像素不同位置黑帧的数据不一样,更准确的方式为每个点求出一个校正值进行校正 在黑帧中选择一部分像素点求出校正值,将坐标和校正值存在LUT中,后续其他像素点的校正值可以通过坐标和LUT进行线性插值求校正值以进行精准校正 sensor端可以进行模拟处理和数字处理 isp端只能进行数字处理,其接受的信号是通过AD转换得到的数字信号,可以通过数字处理的方式进行校正,节省硬件资源 3 LSC 上图为拍摄灰度色卡时的shading的具体现象,左侧为Luma shading,右侧为color shading 3.1 LS现象及原因 Luma shading的产生原因: 光学渐晕现象 镜头中心到边缘的能量衰减导致,通常表现为亮度向边缘衰减变暗,通常衰减符合 f(θ)=cos4(θ)f(θ)=cos^4 (θ)f(θ)=cos4(θ) Color shading的产生原因: 色像差(位置色差和倍率色差) 3.2 校正方法 在标定时使用D65,D50拍摄15%灰度图像,目标灰度以最大值(或中位值,或均值) LSC的本质为能量衰减,为了校正,就使用该点的像素值乘以一个gain值,让其恢复到衰减前的状态 LSC校正的本质就是找到gain值 目前的校正算法可以分为:1. 储存增益法, 2. 多项式拟合法, 3. 自动校正法(不常见) 储存增益法 mesh shading correct(网格法)：将图像分为n*n个网格,然后针对网格顶点求出校正的增益,然后把这些顶点的增益储存到内存中,其他点的增益通过插值算法求出 radial shading correct(半径法)：用半径为变量来求出不同半径像素所需要的增益, 然后将半径对应的增益储存在内存中,使用时查表取出增益进行校正 通过采样的方式提取半径的增益储存到内存,然后其他半径对应的增益在校正时通过插值算法求出 该方法受限较多,使用较少,如镜头中心会发生偏移,导致使用该方法进行校正时不匹配 多项式拟合方法:分段式线性补偿或高次函数拟合方法 对图像的target亮度,取图像的中心,以不同的半径为采样点,计算该半径下所有像素的均值与target的比例,该比例为gain值,对不同半径的gain值进行处理即可获取不同位置处的gain值 分段式线性补偿:使用分段函数进行解决 高此函数拟合： 以半径为采样点,然后把这些采样点通过高次拟合的方法拟合为高次曲线,然后把高次曲线的参数储存起来,使用时将半径带入公式求出对应的gain值用于校正 可采用拉格朗日插值法进行插值：rgain=32+(r−x(2))⋅(−x(3))⋅(r−x(4))⋅(r−x(5))/(x(1)−x(2))⋅(x(1)−x(3))⋅(x(1)−x(4))⋅(x(1)−x(5))⋅rGain(1)+(r−x(1))⋅(r−x(3))⋅(r−x(4))⋅(r−x(5))/(x(2)−x(1))⋅(x(2)−x(3))⋅(x(2)−x(4))⋅(x(2)−x(5))⋅rGain(2)+(r−x(1))⋅(r−x(2))⋅(r−x(4))⋅(r−x(5))/(x(3)−x(1))⋅(x(3)−x(2))⋅(x(3)−x(4))⋅(x(3)−x(5))⋅rGain(3)+(r−x(1))⋅(r−x(2))⋅(r−x(3))⋅(r−x(5))/(x(4)−x(1))⋅(x(4)−x(2))⋅(x(4)−x(3))⋅(x(4)−x(5))⋅rGain(4)+(r−x(1))⋅(r−x(2))⋅(r−x(3))⋅(r−x(4))/(x(5)−x(1))⋅(x(5)−x(2))⋅(x(5)−x(3))⋅(x(5)−x(4))⋅rGain(5)r_gain =32+(r-x(2)) \\cdot(-x(3)) \\cdot(r-x(4)) \\cdot(r-x(5))/(x(1)-x(2)) \\cdot(x(1)-x(3)) \\cdot(x(1)-x(4)) \\cdot(x(1)-x(5)) \\cdot rGain(1)+(r-x(1)) \\cdot(r-x(3)) \\cdot(r-x(4)) \\cdot(r-x(5))/(x(2)-x(1)) \\cdot(x(2)-x(3)) \\cdot(x(2)-x(4)) \\cdot(x(2)-x(5)) \\cdot rGain(2) +(r-x(1)) \\cdot(r-x(2)) \\cdot(r-x(4)) \\cdot(r-x(5))/(x(3)-x(1)) \\cdot(x(3)-x(2)) \\cdot(x(3)-x(4)) \\cdot(x(3)-x(5)) \\cdot rGain(3)+(r-x(1)) \\cdot(r-x(2)) \\cdot(r-x(3)) \\cdot(r-x(5))/(x(4)-x(1)) \\cdot(x(4)-x(2)) \\cdot(x(4)-x(3)) \\cdot(x(4)-x(5)) \\cdot rGain(4)+(r-x(1)) \\cdot(r-x(2)) \\cdot(r-x(3)) \\cdot(r-x(4))/(x(5)-x(1)) \\cdot(x(5)-x(2)) \\cdot(x(5)-x(3)) \\cdot(x(5)-x(4)) \\cdot rGain(5)rg​ain=32+(r−x(2))⋅(−x(3))⋅(r−x(4))⋅(r−x(5))/(x(1)−x(2))⋅(x(1)−x(3))⋅(x(1)−x(4))⋅(x(1)−x(5))⋅rGain(1)+(r−x(1))⋅(r−x(3))⋅(r−x(4))⋅(r−x(5))/(x(2)−x(1))⋅(x(2)−x(3))⋅(x(2)−x(4))⋅(x(2)−x(5))⋅rGain(2)+(r−x(1))⋅(r−x(2))⋅(r−x(4))⋅(r−x(5))/(x(3)−x(1))⋅(x(3)−x(2))⋅(x(3)−x(4))⋅(x(3)−x(5))⋅rGain(3)+(r−x(1))⋅(r−x(2))⋅(r−x(3))⋅(r−x(5))/(x(4)−x(1))⋅(x(4)−x(2))⋅(x(4)−x(3))⋅(x(4)−x(5))⋅rGain(4)+(r−x(1))⋅(r−x(2))⋅(r−x(3))⋅(r−x(4))/(x(5)−x(1))⋅(x(5)−x(2))⋅(x(5)−x(3))⋅(x(5)−x(4))⋅rGain(5) 针对光学中心不是图像中心的问题,可在图像中找出光学中心,然后以光学中心为真实中心完成标定,随后代入公式求出gain值 3.3 插值算法 邻域插值：Pr=Amin(r1,r2,...)P_r=A_{min(r_1,r_2,...)}Pr​=Amin(r1​,r2​,...)​ 在代码中为了减小运算量,判断该点位于4个象限的哪一个象限,随后使用该象限对应的值 线性插值：两个点进行插值 双线性插值：利用4个点进行3次线性插值可以计算出对应点的值 利用同一行的A1,A2A_1,A_2A1​,A2​和A3,A4A_3,A_4A3​,A4​线性插值出B1,B2B_1,B_2B1​,B2​,随后利用B1,B2B_1,B_2B1​,B2​插值得到该目标点的值 双三次插值算法 双三次插值 对于一个点(x,y)(x,y)(x,y),该点的值的确定需要16个点的值进行确定,其插值的曲面表示为 p(x,y)=∑i=03∑j=03aijxiyjp(x, y)=\\sum_{i=0}^3 \\sum_{j=0}^3 a_{i j} x^i y^jp(x,y)=∑i=03​∑j=03​aij​xiyj,其插值问题即确定16个系数aija_{ij}aij​的值,其中利用四个角点(0,0),(1,0),(0,1),(1,1)(0,0),(1,0),(0,1),(1,1)(0,0),(1,0),(0,1),(1,1)的值和两个方向(x,y)(x,y)(x,y)方向的8个偏导数以及4个混合偏导数可以确定上述系数 aija_{ij}aij​ 其公式为p(x,y)=[1xx2x3][a00a01a02a03a10a11a12a13a20a21a22a23a30a31a32a33][1yy2y3]p(x, y)=\\left[\\begin{array}{llll}1 &amp; x &amp; x^2 &amp; x^3\\end{array}\\right]\\left[\\begin{array}{llll}a_{00} &amp; a_{01} &amp; a_{02} &amp; a_{03} \\\\ a_{10} &amp; a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{20} &amp; a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{30} &amp; a_{31} &amp; a_{32} &amp; a_{33}\\end{array}\\right]\\left[\\begin{array}{c}1 \\\\ y \\\\ y^2 \\\\ y^3\\end{array}\\right]p(x,y)=[1​x​x2​x3​]⎣⎢⎢⎢⎡​a00​a10​a20​a30​​a01​a11​a21​a31​​a02​a12​a22​a32​​a03​a13​a23​a33​​⎦⎥⎥⎥⎤​⎣⎢⎢⎢⎡​1yy2y3​⎦⎥⎥⎥⎤​ 双三次卷积算法 双三次样条插值需要对每个网格像元进行上述操作,在两个维度应用卷积核W(x)={(a+2)∣x∣3−(a+3)∣x∣2+1 for ∣x∣≤1a∣x∣3−5a∣x∣2+8a∣x∣−4a for 1&lt;∣x∣&lt;20 otherwise W(x)= \\begin{cases}(a+2)|x|^3-(a+3)|x|^2+1 &amp; \\text { for }|x| \\leq 1 \\\\ a|x|^3-5 a|x|^2+8 a|x|-4 a &amp; \\text { for } 1&lt;|x|&lt;2 \\\\ 0 &amp; \\text { otherwise }\\end{cases}W(x)=⎩⎪⎪⎨⎪⎪⎧​(a+2)∣x∣3−(a+3)∣x∣2+1a∣x∣3−5a∣x∣2+8a∣x∣−4a0​ for ∣x∣≤1 for 1&lt;∣x∣&lt;2 otherwise ​ 其中a值通常为-0.5或-0.75,当a=−0.5a=-0.5a=−0.5时,一维方向上的方程为p(t)=12[1tt2t3][0200−10102−54−1−13−31][f−1f0f1f2]p(t)=\\frac{1}{2}\\left[\\begin{array}{llll}1 &amp; t &amp; t^2 &amp; t^3\\end{array}\\right]\\left[\\begin{array}{cccc}0 &amp; 2 &amp; 0 &amp; 0 \\\\ -1 &amp; 0 &amp; 1 &amp; 0 \\\\ 2 &amp; -5 &amp; 4 &amp; -1 \\\\ -1 &amp; 3 &amp; -3 &amp; 1\\end{array}\\right]\\left[\\begin{array}{c}f_{-1} \\\\ f_0 \\\\ f_1 \\\\ f_2\\end{array}\\right]p(t)=21​[1​t​t2​t3​]⎣⎢⎢⎢⎡​0−12−1​20−53​014−3​00−11​⎦⎥⎥⎥⎤​⎣⎢⎢⎢⎡​f−1​f0​f1​f2​​⎦⎥⎥⎥⎤​ ISP中双三次插值 利用S(x)=[1−2∣x∣2+∣x∣3∣x∣&lt;14−8∣x∣+5∣x∣2−∣x∣31≤∣x∣≤20∣x∣&gt;2S(x)=\\left[\\begin{array}{cc}1-2|x|^2+|x|^3 &amp; |x|&lt;1 \\\\ 4-8|x|+5|x|^2-|x|^3 &amp; 1 \\leq|x| \\leq 2 \\\\ 0 &amp; |x|&gt;2\\end{array}\\right.S(x)=⎣⎢⎡​1−2∣x∣2+∣x∣34−8∣x∣+5∣x∣2−∣x∣30​∣x∣&lt;11≤∣x∣≤2∣x∣&gt;2​分段拟合曲线,从而求待求点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180%% --------------------------------%% fuction: 邻域插值%% --------------------------------​clc,clear,close all;% 读取图片orgImage = imread(&#x27;lena.bmp&#x27;);figure;imshow(orgImage);title(&#x27;org image&#x27;);​% 获取长宽[width, height] = size(orgImage);m = width / 2;n = height / 2;smallImage = zeros(m,n);% 降采样,将原图缩减为原来的1/2for i=1:m for j=1:n smallImage(i,j) = orgImage(2*i,2*j); endendfigure;imshow(uint8(smallImage));title(&#x27;small image&#x27;);​% 插值时需要特殊处理四周最外圈的行和列,本算法中将其向外扩展一圈,用最外圈的值填充headRowMat = smallImage(1,:);%取f的第1行tailRowMat = smallImage(m,:);%取f的第m行% 行扩展后,列扩展时需要注意四个角需要单独扩展进去,不然就成了十字架形的headColumnMat = [smallImage(1,1), smallImage(:,1)&#x27;, smallImage(m,1)];tailColumnMat = [smallImage(1,n), smallImage(:,n)&#x27;, smallImage(m,n)];expandImage = [headRowMat; smallImage; tailRowMat];expandImage = [headColumnMat; expandImage&#x27;; tailColumnMat];expandImage = uint8(expandImage&#x27;);figure;imshow(expandImage);title(&#x27;expand image&#x27;);​% 按比例放大[smallWidth, smallHeight] = size(smallImage);% 设置放大系数magnification = 2;newWidth = magnification * smallWidth;newHeight = magnification * smallHeight;% 创建一个新的矩阵,用于承接变换后的图像newImage = zeros(newWidth, newHeight);​% 循环计算出新图像的像素值for i = 1 : newWidth for j = 1: newHeight detaX = rem(i, magnification) / magnification; floorX = floor(i / magnification) + 1; detaY = rem(j, magnification) / magnification; floorY = floor(j / magnification) + 1; if detaX &lt; 0.5 &amp;&amp; detaY &lt; 0.5 newImage(i, j) = expandImage(floorX, floorY); elseif detaX &lt; 0.5 &amp;&amp; detaY &gt;= 0.5 newImage(i, j) = expandImage(floorX, floorY + 1); elseif detaX &gt;= 0.5 &amp;&amp; detaY &lt; 0.5 newImage(i, j) = expandImage(floorX + 1, floorY); else newImage(i, j) = expandImage(floorX + 1, floorY + 1); end endendfigure;imshow(uint8(newImage));title(&#x27;NeighborhoodInterpolation&#x27;);%% --------------------------------%% fuction: 双线性插值%% f(x,y) = [f(1,0)-f(0,0)]*x+[f(0,1)-f(0,0)]*y+[f(1,1)+f(0,0)-f(1,0)-f(0,1)]*xy+f(0,0)%% x,y都是归一化的值%% --------------------------------​clc,clear,close all;% 读取图片orgImage = imread(&#x27;lena.bmp&#x27;);figure;imshow(orgImage);title(&#x27;org image&#x27;);​% 获取长宽[width, height] = size(orgImage);m = width / 2;n = height / 2;smallImage = zeros(m,n);% 降采样,将原图缩减为原来的1/2for i=1:m for j=1:n smallImage(i,j) = orgImage(2*i,2*j); endendfigure;imshow(uint8(smallImage));title(&#x27;small image&#x27;);​% 插值时需要特殊处理四周最外圈的行和列,本算法中将其向外扩展一圈,用最外圈的值填充headRowMat = smallImage(1,:);%取f的第1行tailRowMat = smallImage(m,:);%取f的第m行% 行扩展后,列扩展时需要注意四个角需要单独扩展进去,不然就成了十字架形的headColumnMat = [smallImage(1,1), smallImage(:,1)&#x27;, smallImage(m,1)];tailColumnMat = [smallImage(1,n), smallImage(:,n)&#x27;, smallImage(m,n)];expandImage = [headRowMat; smallImage; tailRowMat];expandImage = [headColumnMat; expandImage&#x27;; tailColumnMat];expandImage = uint8(expandImage&#x27;);figure;imshow(expandImage);title(&#x27;expand image&#x27;);​% 按比例放大[smallWidth, smallHeight] = size(smallImage);% 设置放大系数magnification = 2;newWidth = magnification * smallWidth;newHeight = magnification * smallHeight;% 创建一个新的矩阵,用于承接变换后的图像newImage = zeros(newWidth, newHeight);​% f(x,y) = [f(1,0)-f(0,0)]*x+[f(0,1)-f(0,0)]*y+[f(1,1)+f(0,0)-f(1,0)-f(0,1)]*xy+f(0,0)for i = 1 : newWidth for j = 1: newHeight detaX = rem(i, magnification) / magnification; floorX = floor(i / magnification) + 1; detaY = rem(j, magnification) / magnification; floorY = floor(j / magnification) + 1; newImage(i, j) = (expandImage(floorX + 1,floorY) - expandImage(floorX,floorY)) * detaX + ... (expandImage(floorX, floorY + 1) - expandImage(floorX, floorY)) * detaY + ... (expandImage(floorX+1, floorY+1) + expandImage(floorX, floorY) - ... expandImage(floorX+1, floorY) - expandImage(floorX, floorY+1)) * detaX * detaY + ... expandImage(floorX, floorY); endendfigure;imshow(uint8(newImage));title(&#x27;BilinearInterpolation&#x27;);​%% --------------------------------%% fuction: 双三次内插法%% --------------------------------clc,clear,close all;orgImage = imread(&#x27;lena.bmp&#x27;);[width, height] = size(orgImage);%将图像隔行隔列抽取元素,得到缩小的图像ffigure; imshow(orgImage); title(&#x27;org image&#x27;);%显示原图像​m = width/2;n = height/2;smallImage = zeros(m, n);for i = 1: m for j = 1: n smallImage(i, j) = orgImage(2*i, 2*j); endendfigure;imshow(uint8(smallImage));title(&#x27;small image&#x27;);%显示缩小的图像​​magnification = 2;%设置放大倍数a = smallImage(1,:);%取f的第1行c = smallImage(m,:);%取f的第m行%将待插值图像矩阵前后各扩展两行两列,共扩展四行四列到f1b = [smallImage(1,1), smallImage(1,1), smallImage(:,1)&#x27;, smallImage(m,1), smallImage(m,1)];d = [smallImage(1,n), smallImage(1,n), smallImage(:,n)&#x27;, smallImage(m,n), smallImage(m,n)];a1 = [a; a; smallImage; c; c];b1 = [b; b; a1&#x27;; d; d];expandImage = double(b1&#x27;);​newImage = zeros(magnification*m,magnification*n);for i = 1:magnification * m%利用双三次插值公式对新图象所有像素赋值 u = rem(i, magnification)/magnification; i1 = floor(i/magnification) + 2;%floor()向左取整,floor(1.3)=floor(1.7)=1 A = [sw(1+u) sw(u) sw(1-u) sw(2-u)]; for j = 1:magnification*n v = rem(j, magnification)/magnification; j1=floor(j/magnification)+2; C = [sw(1+v); sw(v); sw(1-v); sw(2-v)]; B = [expandImage(i1-1,j1-1) expandImage(i1-1,j1) expandImage(i1-1,j1+1) expandImage(i1-1,j1+2); expandImage(i1,j1-1) expandImage(i1,j1) expandImage(i1,j1+1) expandImage(i1,j1+2); expandImage(i1+1,j1-1) expandImage(i1+1,j1) expandImage(i1+1,j1+1) expandImage(i1+1,j1+2); expandImage(i1+2,j1-1) expandImage(i1+2,j1) expandImage(i1+2,j1+1) expandImage(i1+2,j1+2)]; newImage(i,j) = (A*B*C); endend%显示插值后的图像figure,imshow(uint8(newImage));title(&#x27;BicubicInterpolation&#x27;);%% --------------------------------%% fuction: 双三次插值算法sin函数的拟合函数%% --------------------------------function A = sw(w1)w = abs(w1);if w &lt; 1 &amp;&amp; w &gt;= 0 A = 1 - 2 * w^2 + w^3; elseif w &gt;= 1 &amp;&amp; w &lt; 2 A = 4 - 8 * w + 5 * w^2 - w^3;else A = 0;end 4 DPC(Defective Pixel Correction) 造成坏点的原因 感光元件芯片自身工艺技术瑕疵造成 光线采集存在缺陷 制造商产品差异 坏点分类 hot pixel: 固定保持较高的像素值,呈现为亮点 dead pixel: 固定保持较低的像素值,呈现为暗点 noise pixel：信号强度随光照呈现的变化规律不符合正常的变化规律 校正方法 静态校正: 由sensor厂商在生产后进行标定,会使用OTP将所有像素位置记录下来,随后在校正时利用LUT颜色查找表通过查表得方式找到坏点进行校正 动态校正：在ISP算法中通过特殊算法判断一个点是否为坏点进行校正 4.1 动态算法讲解 静态坏点检测的局限性 标定方式需要消耗人力物力,且储存标定数据对硬件有要求 产品使用时间增加,坏点数目会增加,新增坏点没有进行标定 有些坏点表现为正常情况下的光电特性正常,长时间使用或高ISO时才会形成坏点 在实际应用时静态坏点检测disable pinto算法主要思想: 坏点往往是在一个领域中的极亮或极暗点故以5*5的邻域为检测区域 如图的5*5邻域内同一颜色通道相对于中心像素都有8个临近像素,校正步骤 计算中心像素与周围八个像素值的差 判断八个差值是否都为正值或负值 如果有的为正有的为负,那么就为正常值,否则进行下一步 设置一个阈值,如果8个差值的绝对值都超过阈值,就判断为坏点 判断为坏点后就用8个临近像素值得中位数来替换当前的像素值 该算法在实际使用中阈值的选择十分重要,当阈值较小时会将本该判断成边缘的信息去除,导致图像变模糊 梯度法：该算法针对三个通道都使用这一种窗口进行检测 计算四个方向的梯度 水平方向三个二阶梯度：Dh1=∣P1+P3−2∗P2∣,Dh2=∣P4+P5−2∗Pc∣,Dh3=∣P6+P8−2∗P7∣Dh_1 = |P1+P3-2*P2|, Dh_2 = |P4+P5-2*Pc|,Dh_3 = |P6+P8-2*P7|Dh1​=∣P1+P3−2∗P2∣,Dh2​=∣P4+P5−2∗Pc∣,Dh3​=∣P6+P8−2∗P7∣ 数值方向三个二阶梯度：Dv1=∣P1+P6−2∗P4∣,Dv2=∣P2+P7−2∗Pc∣,Dv3=∣P3+P8−2∗P5∣Dv_1 = |P1+P6-2*P4|, Dv_2 = |P2+P7-2*Pc|,Dv_3 = |P3+P8-2*P5|Dv1​=∣P1+P6−2∗P4∣,Dv2​=∣P2+P7−2∗Pc∣,Dv3​=∣P3+P8−2∗P5∣ 45°三个二阶梯度：D451=2∗∣P4−P2∣,D452=∣P3+P6−2∗Pc∣,D453=2∗∣P7−P5∣D45_1 = 2*|P4-P2|, D45_2 =|P3+P6-2*Pc|, D45_3 = 2*|P7-P5|D451​=2∗∣P4−P2∣,D452​=∣P3+P6−2∗Pc∣,D453​=2∗∣P7−P5∣ 135°三个二阶梯度: D1351=2∗∣P2−P5∣,D1352=∣P1+P8−2∗Pc∣,D1353=2∗∣P7−P4∣D135_1 = 2*|P2-P5|, D135_2 =|P1+P8-2*Pc|, D135_3 = 2*|P7-P4|D1351​=2∗∣P2−P5∣,D1352​=∣P1+P8−2∗Pc∣,D1353​=2∗∣P7−P4∣ 取出各个方向梯度绝对值的中值median_Dh=median(Dh1,Dh2,Dh3)median\\_Dh = median(Dh1,Dh2,Dh3)median_Dh=median(Dh1,Dh2,Dh3),同理求出其他三个方向的中值 求出四个中值的最小值作为边缘方向：min_grad=min(median_Dh,median_Dv,median_D45,median_D135)min\\_grad = min(median\\_Dh,median\\_Dv,median\\_D45,median\\_D135)min_grad=min(median_Dh,median_Dv,median_D45,median_D135) 如果最小梯度方向为水平或者竖直,若过Pc那个梯度的绝对值大于同方向的另外两个梯度绝对值和的4倍,则Pc为坏点 如果是45°方向,则计算135°三个梯度绝对值两两之差的绝对值的和D135_sum=∣D1351−D1352∣+∣D1351−D1353∣+∣D1352−D1353∣D135\\_sum= |D135_1-D135_2|+|D135_1-D135_3|+|D135_2-D135_3|D135_sum=∣D1351​−D1352​∣+∣D1351​−D1353​∣+∣D1352​−D1353​∣, 如果D135_sum&lt;100D135\\_sum&lt;100D135_sum&lt;100,若此时D452&gt;3(D451+D453)且D1352&gt;3(D1351+D1353)D45_2&gt;3(D45_1+D45_3)且D135_2&gt;3(D135_1+D135_3)D452​&gt;3(D451​+D453​)且D1352​&gt;3(D1351​+D1353​),则Pc为坏点。否则D452&gt;3x(D451+D453)D45_2&gt;3x(D45_1+D45_3)D452​&gt;3x(D451​+D453​)就为坏点 135°方向和45°相反的方向计算和判断即可 为减少漏判,当Pc小于15且周围点都大于40以上,则Pc为坏点。如果Pc大于230,且周围的点都下于Pc30以下,则该点为坏点 边缘为水平方向,且判断为坏点,如果∣P4−Pc∣&lt;∣Pc−P5∣|P4-Pc|&lt;|Pc-P5|∣P4−Pc∣&lt;∣Pc−P5∣则Pc更靠近P4,根据同一颜色通道亮度的渐变性可以推导出ouput=P4+(P2+P7−P1−P6)/2ouput=P4+(P2+P7-P1-P6)/2ouput=P4+(P2+P7−P1−P6)/2;否则ouput=P6+(P2+P7−P3−P9)/2ouput=P6+(P2+P7-P3-P9)/2ouput=P6+(P2+P7−P3−P9)/2； 如果为竖直方向可以参考水平方向求出 边缘为45°,如果∣P3−Pc∣&lt;∣P6−Pc∣|P3-Pc|&lt;|P6-Pc|∣P3−Pc∣&lt;∣P6−Pc∣则根据同一原则output=P3+(P4+P7−P2−P5)/2output=P3+(P4+P7-P2-P5)/2output=P3+(P4+P7−P2−P5)/2;否则为output=P7+(P2+P5−P7−p3)/2output=P7+(P2+P5-P7-p3)/2output=P7+(P2+P5−P7−p3)/2 边缘为135°则按照45°的方式反过来计算即可 DPC和demosaic结合法 思路:先对bayer图像插值成全彩图像,然后对每个点进行坏点检测,检测时只用同一通道的像素检测,而且每个像素点用的颜色通道即为该点raw图对应的颜色通道 RGGB图像对于这四个点,第一个点只通过周围4个临近点的像素值中位数插值出的R值来检测R是否为坏点,其余两个同样这么处理,这样就保证和RAW处理时一样,只需要处理M*N个像素点即可。利用pinto算法进行检测,若该点为坏点就对其进行校正并重新对齐进行颜色插值,流程处理完坏点就被校正而直接输出全彩图像 在插值时部分算法使用周围8个临近点,但若该8个点中存在噪点,则对插值的影响较大,故一般使用周围4个像素点进行插值 行检测法：该算法检测和校正时不使用整帧图像,而是通过几行数据来处理,对硬件buffer要求低,CMOS也是行扫描,一次正好收集一行数据 缓存一行数据,在同一行中通过比较同一通道相邻的数据的插值,如果待检测的点同时大于相邻点一个阈值,或者同时小于相邻点一个阈值,那么这个点就是候选坏点 有的算法还会利用buffer缓存上一行的数据,然后判断这个坏点在当前行周围有没有候选坏点,并判断上一行对应位置的点是否为候选坏点,如果都不是,那么当前点就是真实坏点,就通过周围点矫正,如果周围有候选坏点,那么就判断为非真是坏点,不用矫正 在上一条提到的缓存的上一行数据,有的算法中不是缓存上一行每个像素的信息,而是上一行经过判断后的属性值,比如上一行存储的是每个点是否为候选坏点或者坏点,那么每个点就可以用0或者1来表示,那么上一行每个像素只需要1bit的数据量来存储,这样就能进一步降低对硬件的要求了 5 AWB 5.1 产生原因 色温的定义：色温描述的是具有一定表面温度的“黑体”的幅射光的光谱特性 颜色恒常性：指照度发生变化的条件下人们对物体表面颜色的知觉趋于稳定的心里倾向 白平衡原理：传感器不具有人眼的不同光照色温下的色彩恒常性,白平衡模块就需要将人眼看来白色的物体进行色彩的还原,使其在照片上也呈现为白色 5.2 校正方法 YCbCrYC_bC_rYCb​Cr​颜色空间 Gray World Assumption(灰度世界方法) 理论：任一幅图像,当他有足够的色彩变化,则它的RGB分量的均值会趋于相等 流程: 计算各个颜色通道的平均值Rmean,Bmean,GmeanR_{mean}, B_{mean}, G_{mean}Rmean​,Bmean​,Gmean​ 寻找一个参考值K,一般选取GmeanG_{mean}Gmean​(人眼对绿色较为敏感,不对G通道进行调整) 计算Rgain=GmeanRmean,Bgain=GmeanBmeanR_{gain} = \\frac{G_{mean}}{R_{mean}}, B_{gain} = \\frac{G_{mean}}{B_{mean}}Rgain​=Rmean​Gmean​​,Bgain​=Bmean​Gmean​​ 进行校正(R,G,B)→(R∗Rgain,G,B∗Bgain)(R,G,B) \\rightarrow (R*R_{gain}, G, B*B_{gain})(R,G,B)→(R∗Rgain​,G,B∗Bgain​) 完美反射法 假设：图像中最亮的像素相当于物体有光泽或镜面上的点,传达了很多关于场景照明条件的信息。如果景物中有纯白的部分,那么就可以直接从这些像素中提取出光源信息。因为镜面或有光泽的平面本身不吸收光线,所以其反射的颜色即为光源的真实颜色,这是因为镜面或有光泽的平面的反射比函数在很长的一段波长范围内是保持不变的 算法执行时,检测图像中亮度最高的像素并且将它作为参考白点。基于这种思想的方法都被称为是完美反射法,也称镜面法,算法执行时检测图像中亮度最高的像素并且将它作为参考百点 通俗的意思就是整个图像中最亮的点就是白色或者镜面反射出来的,那么最亮的点就是光源的属性,但是该点本身应该是白点,以此为基础就可计算出gain值从而进行校正 流程 图像相关信息统计:{Rmax⁡=max⁡(Rij)(i=1⋯N,j=1⋯M)Gmax⁡=max⁡(Gij)(i=1⋯N,j=1⋯M)Bmax⁡=max⁡(Bij)(i=1⋯N,j=1⋯M)\\left\\{\\begin{array}{l}R_{\\max }=\\max \\left(R_{i j}\\right)(i=1 \\cdots N, j=1 \\cdots M) \\\\ G_{\\max }=\\max \\left(G_{i j}\\right)(i=1 \\cdots N, j=1 \\cdots M) \\\\ B_{\\max }=\\max \\left(B_{i j}\\right)(i=1 \\cdots N, j=1 \\cdots M)\\end{array}\\right.⎩⎪⎨⎪⎧​Rmax​=max(Rij​)(i=1⋯N,j=1⋯M)Gmax​=max(Gij​)(i=1⋯N,j=1⋯M)Bmax​=max(Bij​)(i=1⋯N,j=1⋯M)​ RGB通道增益计算：{ Gain Rmax⁡=max⁡(Rmax⁡,Gmax⁡,Bmax⁡)/Rmax⁡ Gain Gmax⁡=max⁡(Rmax⁡,Gmax⁡,Bmax⁡)/Gmax⁡ Gain Bmax⁡=max⁡(Rmax⁡,Gmax⁡,Bmax⁡)/Bmax⁡\\left\\{\\begin{array}{l}\\text { Gain }_{R \\max }=\\max \\left(R_{\\max }, G_{\\max }, B_{\\max }\\right) / R_{\\max } \\\\ \\text { Gain }_{G \\max }=\\max \\left(R_{\\max }, G_{\\max }, B_{\\max }\\right) / G_{\\max } \\\\ \\text { Gain }_{B \\max }=\\max \\left(R_{\\max }, G_{\\max }, B_{\\max }\\right) / B_{\\max }\\end{array}\\right.⎩⎪⎨⎪⎧​ Gain Rmax​=max(Rmax​,Gmax​,Bmax​)/Rmax​ Gain Gmax​=max(Rmax​,Gmax​,Bmax​)/Gmax​ Gain Bmax​=max(Rmax​,Gmax​,Bmax​)/Bmax​​ Rmax⁡′={R∗ Gain Rmax⁡⟶R∗GainRmax⁡&lt;255255⟶R∗GainRmax⁡&gt;255R_{\\max }^{\\prime}=\\left\\{\\begin{array}{l}R^* \\text { Gain }_{R \\max } \\longrightarrow R^*Gain_{R \\max }&lt;255 \\\\ 255 \\longrightarrow R^*Gain_{R \\max }&gt;255\\end{array}\\right.Rmax′​={R∗ Gain Rmax​⟶R∗GainRmax​&lt;255255⟶R∗GainRmax​&gt;255​ QCGP(将灰度世界和完全反射以正交方式结合),以R通道为例 urRave 2+vrRave=Kave,urRmax⁡2+vrRmax⁡=Kmax⁡,Kave=Rave+Gave+Bave3,Kmax⁡=Rmax⁡+Gmax⁡+Bmax⁡3u^r R_{\\text {ave }}^2+v^r R_{\\mathrm{ave}}=K_{\\mathrm{ave}}, u^r R_{\\max }^2+v^r R_{\\max }=K_{\\max }, K_{\\mathrm{ave}}=\\frac{R_{\\mathrm{ave}}+G_{\\mathrm{ave}}+B_{\\mathrm{ave}}}{3}, K_{\\max }=\\frac{R_{\\max }+G_{\\max }+B_{\\max }}{3}urRave 2​+vrRave​=Kave​,urRmax2​+vrRmax​=Kmax​,Kave​=3Rave​+Gave​+Bave​​,Kmax​=3Rmax​+Gmax​+Bmax​​ 通过上面的方程组就可以解出uru^{r}ur和vrv^{r}vr 然后对原像素进行校正：Rnew=urRorg2+vrRorgR_{new}=u^{r} R_{org}^{2}+v^{r} R_{org}Rnew​=urRorg2​+vrRorg​ 模糊逻辑算法 下图圆圈表示颜色本身应该在坐标系中所处的位置,箭头分别表示随色温的变化发生的偏移(先验知识获得,后面再通过这个进行校正) 将图像按下图两种方式分割成8块,然后通过模糊逻辑的方式计算出每个块的权重(和亮度,色温相关,通过模糊逻辑方式进行确定), 随后可计算出整个图像的加权均值 如下图10a,黑点表示八个块的分布,XXX表示整幅图像均值的位置 通过调整增益的方式调试 XXX 往白点上靠,调整完增益后,每个块儿的均值又会发生变化,然后又重新计算出每个块的权重,再通过权重计算出整个图像的均值 XXX,如图10b,XXX 已经靠近原点了(设定的范围内)则认为完成白平衡,否则继续调整增益重复上述步骤进行校正 基于白点的算法 流程 将RGB颜色空间转换到YUV空间 通过限制YUV的区域判断是否为白点,满足条件的点为白点参与后续计算 找到白点集合后,可以对白点集合运用GW算法或其他算法计算GAIN值从而进行校正 基于色温的方法 通过在不同色温的环境下拍摄灰卡可以得到两个曲线,一个是gain值的关系曲线,另一个是R/G与色温T的关系,如果获取了一张图像知道了拍摄的色温,就可以通过第二张图获取R/G的值,然后根据图1就可计算出B/G从而获得R和B的gain值 通过一定的技术手段获取色温即可 一种方法就是通过加一个色温传感器获取环境色温 另一种就是通过计算求出T(下图论文) 定义Tmin=2000K,Tmax=15000K; -Tmin是否大于10,如果小如或等于10,那么久可以直接返回T,此时T可以去min,man或者二者的均值,如果满足大于10的条件,则T=(Tmin+Tmax)/2; 通过图中公式(实验拟合总结),通过T就可以计算出一个R’G’B’ 对于原始图像可以求出各个通道的均值RGB,如果B’/R’&gt;B/R那么Tmax=T,否则Tmin=T;重复上述步骤即可迭代求出色温T 基于边缘的方法 流程 先通过一定的手段,比如梯度的方式求出图像中的边缘,然后在边缘各侧各取两个点参与计算 通过上述得到的参考点集合,就可以运行灰度世界或者其他的算法求出gain值 优点： 减少的大色块的干扰,因为一般认为边缘就是色块变化的的分界线,那么提取边缘两侧的样本点就可以满足颜色充分的条件,那么就可以运用灰度世界法求出gain 且有大色块的时候计算的也是也只是选取边缘的几个点,就可以避免大色块分量太大造成白平衡异常的问题。 多种方法融合(色温和白点融合) 蓝色的框就代表一种色温(实验经验所得),比如9代表2000K,8代表2500K 绿色的点就是通过白点算法筛选出来的白点候选点 然后调试的时候就是在不同色温下拍摄灰卡,挪动蓝色选框,使其包围绿点,然后右上角就是估计色温,调试时使估计色温和真实色温相差最小。随后标定若干组色温确定该方案的一个色温曲线 后续在pipeline中通过白点检测算法筛选出白点,然后根据白点的分布,可以找到大多数白点分布的色温,该色温就是当前的色温,通过色温再按照前面提到的算法就可以计算出一个gain值,再和灰度世界算法进行一个混合就可以得到最终ISP中使用的gain值 6 Gamma Gamma主要影响对比度和动态范围,合适的对比度和动态范围不造成画面朦胧的感觉 6.1 产生原因 CRT显示器属性导致 屏幕亮度和电子枪的电压为非线性关系,其符合对数关系, 为反gamma曲线:Iscreen=f(V)I_{screen} = f(V)Iscreen​=f(V) 因为显示时会把亮度压低,所以为了还原成原本的线性特征,需要在显示之前进行矫正,使其恢复为线性,此为gamma校正。现在液晶显示不满足该特性,但为了兼容以前的视频格式,也会认为在显示的时候添加反伽马矫正 人眼视觉属性 人眼的亮度响应曲线不是线性的,而是非线性属性 为了更好符合人眼的特性,就需要对暗区进行加强以提高画面的动态范围和暗区细节,更好的响应人眼对暗部更敏感的特性 6.2 校正方法 LUT法(查表法)：目前的常用方法 方法：提前把每个像素值经gamma矫正后对应的值求出来,然后把这些数据直接存储到一个数中,到矫正的时候根据输入的值就能直接通过数组下标就能找到对应的矫正后的值 优点：快,几乎不消耗硬件资源,几乎不用做任何计算的处理 缺点：需要大量的内存来存储这么这个表 线性插值法 在gamma曲线上提取一些采样点,然后把采样点的输入输出存储起来,校正时依据真实值和插值得到校正值(具有一定的误差,线性方程不能完全拟合gamma曲线) 小结 更加认同gamma原因是受人眼特性而来的,因为如果是为了矫正CRT的反伽马特性,那么gamma矫正曲线应该是比较规范的一条曲线,这样才能保证正法结合后恢复成线性。而在实际中对颜色要求不高的情况下,不同的gamma曲线能将画面效果调到最好,调gamma主要还是为了人眼看着舒服合适,说到底还是为了人眼看东西的特性 从曲线中也可以看出输出的大小比输入大。一般都是这样,输出会提高位数来保留更多信息量,减少非线性变换带来的信息损失。因为线性的时候肯定是每个输入对应一个输出,但是经过gamma变换后,就会出现对多个输入对应的一个输出的现象,这种输入的这些信息量就会损失,而如果提高输出的位数,用更多的数来表示,就能保证对每个输入都有一个输出与之对应从而保证信息不损失 模拟gamma法 这种方法的大概思路就是AD转换的时候经过一定的处理使其呈现非线性的特性 如上图定义Vramp和Vsig,当电压达到Vramp时产生一个斜坡信号,同时始终信号开始工作并计数,然后当电压到达Vsig时latch信号发生一个跳变使得始终信号停止基数,然后这个电压值就会和这种始终信号有一个非线性特性,人后根据这个特性进行gamma矫正 该方法不涉及ISP算法 7 HVS(Human Visual System) 人眼的分辨率很高,在CV中高分辨率高像素就意味着更高的硬件要求,但目前深度学习网络本身就对硬件要求较高,在此基础上分辨率无疑是负担,因此CV数据集分辨率一般不大 ISP算法是为了camera更好吻合HVS特性,若为了给CV系统作为输入,就需要适应CVS的特性 频率角度看,人眼具有低通特性 由于瞳孔具有一定的几何尺寸和一定的光学像差,视觉细胞有一定的大小,故人眼的分辨率不可能是无穷大,HVS对高频不敏感 测试镜头解析度ISO12233测试卡：当MTF很高时镜头解析不过来,TV线会模糊,人眼一样当频率很高时人眼无法分辨。基于这一点,在图像压缩技术中有应用,jpg压缩技术会牺牲部分高频信息 人眼有边缘增强特性 人眼的边缘增强特性：常用灰阶测试卡的一部分,这些块的边缘为突变的,但在这些块放在一起,人眼看起来边缘会有一个加强,呈现一条条的竖线 相应曲线表示,真实的亮度变化如黑色实线,但人眼看到的变化如虚线所示,会有增强的效果 ISP会有一个overshoot和undershoot的调节,为了增强黑色边缘从提高清晰度,但过大会超过人眼特性范围带来负面效果 下图左侧为专业文字拍照设备拍摄的文字,拍文字时提高边缘和对比会使文字效果更清晰,故会在字体周围加一圈白边,提高黑色反差提高清晰度；使用手机拍摄文字,手机多是拍人像就不需要重的白边,故图像为平滑过渡 人眼对空间分辨率大于色度分辨率 人眼对亮度的变化比颜色的变化更敏感,与人眼锥状细胞和杆状细胞的工作方式有关 例：在黑暗环境下（不是全黑环境）人眼看周围物体几乎是灰色,但是明亮环境却能看到鲜艳的颜色,但是在按环境下并不影响人眼对事物的判断 基于这样一特性有的ISP主控就设置了动态饱和度,就是随着环境亮度的变化,整个画面的饱和度(saturation)也是动态变化从而更好适应人眼特性 人眼能够同时分辨的亮度范围,远远小于人眼对亮度的适应范围 人眼能分辨的最黑和最亮的数量级很大,但是当一个环境亮度确定的时候,人眼能分辨的最黑最亮的数量级没有前面说的那个数量级大 为方便理解真实的分辨率不是这个范围：简单理解就是假如人眼能分辨的亮度范围是0-255,那么当环境亮度为128的时候,人眼能分辨的亮度范围就是50-200,低于50的就都是最黑的了,大于200的就都是最亮的,环境亮度确定了之后范围会变窄 人眼对亮度的响应呈现对数特性(gamma特性)：对暗区感应能力较强 人眼辨别亮度差别的能力,与环境亮度和本身亮度有关 左图为人眼对亮度的灵敏度特性(韦伯比)：有个实验就是在一个均匀亮度的屏幕上有个圆圈,然后逐渐增加圆圈的亮度值,当圆圈亮度变化很小的时候人眼感受不到变化,当变化达到一定量时人眼就能明显感受到中见的圆圈出现。最后通过实验人们发现这个变化量和背景亮度I有一定关系 人眼对这个变化符合右图曲线：当背景亮度小的时候,就需要更大的变化才能使得人眼感受到圆圈的变化,当背景亮度大的时候只需要很小的变化人眼就能感受到,这个就是人眼亮度的灵敏度 亮度响应特性和亮度灵敏度的区别 gamma曲线的特性和亮度灵敏度(韦伯比)的特性为两个不同的概念 下图上面灰阶卡是gamma特性的变化,下面在每个灰阶中加了一个变化的灰块,人眼看起来最右侧中间块好像变化更大,但实际上中间灰色块和所处的大的灰阶的亮度差值一样,但由于上面灵敏度的原因故会导致人眼看上去右侧差别更大 8 NR 8.1 产生原因 噪声原因 图像获取过程中：由于受传感器材料属性、工作环境、电子元器件和电路结构的影响,会引入各种噪声,如电阻引起的热噪声,场效应管的沟道热噪声,光子噪声,暗电流噪声和光响应非均匀性噪声 信号传输过程中：由于传输介质和记录设备等的不完善,数字图像在其传输记录过程中往往会受到多种噪声的污染,另外在图像处理的某些环节当输入的噪声并不如预想时也会在结果图像中引入噪声 8.2 校正方法 12345678910111213141516graph LR图像去噪--&gt; 硬件滤波图像去噪--&gt; 空域滤波图像去噪--&gt; 变换域滤波图像去噪--&gt; 时域滤波空域滤波--&gt; 均值滤波空域滤波--&gt; 中值滤波均值滤波--&gt; 基础均值滤波均值滤波--&gt; 加权均值滤波加权均值滤波--&gt; 高斯滤波加权均值滤波--&gt; 双边滤波加权均值滤波--&gt; NLM加权均值滤波--&gt; ...中值滤波--&gt; 基础中值滤波中值滤波--&gt; 中值混合滤波中值滤波--&gt; 中值有理滤波 8.2.1 均值滤波方法 均值滤波 为线性滤波,主要采用邻域平均法 假设图像在一个很小的邻域范围内像素的变化不会太大,那可以在一个很小的邻域范围内求一个平均值来取代当前的像素值从而达到降噪的效果 典型的应用就是在图像中取一个3X3的邻域,然后每个像素给权重1,最后求和取平均。然后让这个邻域遍历整个图像 高斯滤波 加权平均方法, 某个点的值和本身的像素值关系最大,故对应本身点的权重更大 高斯滤波的具体思路 使用与中心像素的距离,通过高斯函数来计算该点的权重 将所有点的权重求出来后对权重进行归一化处理 利用加权平均的方式计算滤波后的像素值 邻域窗口遍历图像,重复上述操作 卷积核如下图所示 双边滤波 高斯滤波相对于均值滤波性能有所提升,但依然边缘损失严重,为保留边缘信息,故对边缘做进一步处理,在高斯分布上增加一个权重与像素值的差别相联系,此方法为双边滤波算法 公式中可以看出双边滤波有两个高斯权重叠加而来：∣∣p−q∣∣||p-q||∣∣p−q∣∣为高斯滤波中使用的距离权重,∣∣Ip−Iq∣∣||I_p-I_q||∣∣Ip​−Iq​∣∣为像素值的高斯分布权重 去噪时需要相似的区域有更大的贡献,不相同的给小的权重,对于边缘而言,两侧像素值差距较大,也会导致离边缘另一侧不同的会分配一个小权重,同侧差异小的会有一个很大的权重,这样不会由于取平均时将边缘两侧的大差异变小导致边缘变弱,达到保留边缘的目的 如下图：对白点位置进行滤波时,同侧像素差别较小会有一个大权重,而另一侧差别很大权重也就很小,两者结合后相当于高斯滤波取一侧,然后利用这个核进行滤波操作 相当于只对同侧的像素进行高斯滤波,而另一侧保留原来的值,有较好的保边效果 NLM(non-local mean) 双边滤波只在图像的局部进行滤波,而有时候需要考虑图像整体的信息进行滤波 如文中实例：对于p点而言,q1和q2点所在的邻域和p所在的邻域更相似,那么就给q1和q2较大的权重,而q3邻域和p邻域差别较大,就赋予一个较小的权重。具体权重的赋予方式其实也是高斯的一种方式,只不过e的对数是通过邻域的欧拉距离来计算(相当于求了几邻域中对应位置像素差的平方和作为分配权重的依据) 当邻域相似时方差小,权重大,而差异大时方差大,权重小。理论上每一个点进行去噪时会利用整个图像的信息来计算,但是为了降低运算量,一般不会用整个图像的信息来计算,而是在整个图像中先选择一个大的范围,然后用这个范围内的点的信息进行降噪处理 算法流程： 遍历整幅图像 针对每一个点定义一个滑动窗口,降噪的时候利用该窗口中的所有点的信息计算 定义一个邻域范围,用来计算像素块的差异 遍历滑动窗口中的点,求每个点的邻域范围和当前点的邻域范围的像素差值的平方和,并利用该值计算一个权重 遍历完滑动窗口中的所有点后,滑动窗口中的每个点都有一个权重,对权重进行归一化处理 得到归一化处理后的权重通过加权平均的方式计算出当前点的新的像素值； 简化为图形就是如图的方式 最中间的黑色框的范围就是实际图像大小,外面蓝色范围是扩充的图像（为了处理边缘领域不够的问题） 计算黑色点的时候,就是定义一个红色框,然后黄色点在黄色框中遍历,每次都计算出两个小黑色框对应位置像素的差值的平方从而求出一个权重,当红色框遍历完了之后对权重进行归一化,然后加权平均就能求出黑色点的值 接着黑色点在图像中遍历,同时红色框随着黑点移动,然后黄色点又在红色框中移动,以此循环即可完成整幅图像的去噪操作 8.2.2 中值滤波方法 均值滤波对高斯噪声的效果很好,但对椒盐噪声的效果一般 均值滤波为线性方法,平均整个窗口内的像素值,不能很好的保护图像细节,去噪的同时破坏了图像的细节部分 中值滤波作为一种顺序滤波器,对椒盐噪声的效果很好,且保边能力很强 中值滤波为非线性滤波 中值滤波：通过求小窗口中的中位值来取代当前位置的方式来滤波 如图：绿色窗口就是当前的滤波窗口,在3X3的邻域窗口中进行滤波,中值滤波： 对这个邻域中的像素值进行排序：[45, 50, 52, 60, 75, 80, 90, 200, 255] 从排序后的数据中找出中位值：75 用中位值取代当前位置的像素值得到右侧的滤波后的数据 多级中值滤波：将多个中值滤波进行多级级联实现更好的滤波效果 下图是一种多级级联的方式,先在窗口中定义一个’+'和’X’形的窗口,然后分别求出这两个窗口的中位值,然后结合当前窗口的中心点就有3个候选值,再从这三个值中求出一个中位值作为滤波后的结果 可直接应用到RAW图中做BNR,需要修改的就是窗口设置为5X5,在做滤波时需要区分G和RB通道(RAW图中的RGB分布是不均匀的,G占50%,R和B各占25%) 左侧就是针对G通道的滤波器,右侧是R和B通道的滤波器,都是定义了一个’+'和’X’形的窗口,不同的只是取的点的位置不同 多级中值混合滤波:将中值滤波和多级滤波结合起来,相互弥补实现更好的滤波效果 算法流程 求出竖直方向相邻三个点的均值和水平方向相邻三个点的均值,再结合当前点,用这三个点再求一个中位值； 求出45°和135°方向上的均值,然后结合当前点求出一个中位值； 两个中位值结合当前点组成新的数组,最后求一个中位值作为当前点的值完成滤波。 应用在RAW图上,只需要对滤波器稍作改善即可 多级中值有理混合滤波 WMF加权中值滤波：在原始数据的基础上给每个点分别赋予一个权重,在加权后的数据中取出中位值作为滤波后的值 算法流程 求出’+'形和’X’形的窗口的中位值 对’+'形窗口再利用CWMF求出一个值,CWMF是WMF的一种特殊情况,就是只对中心点进行加权 对以上求出的三个参数用一下公式计算出一个新的值作为滤波后的值y(m,n)=ϕ2(m,n)+ϕ1(m,n)−2∗ϕ2(m,n)+ϕ3(m,n)h+k(ϕ1(m,n)−ϕ3(m,n))y(m, n)=\\phi 2(m, n)+\\frac{\\phi 1(m, n)-2 * \\phi 2(m, n)+\\phi 3(m, n)}{h+k(\\phi 1(m, n)-\\phi 3(m, n))}y(m,n)=ϕ2(m,n)+h+k(ϕ1(m,n)−ϕ3(m,n))ϕ1(m,n)−2∗ϕ2(m,n)+ϕ3(m,n)​ 该算法稍加改动就可用于raw格式图像 9 BNR(Bayer Noise Reduce) 9.1 BNR的意义 RAW图上的噪声模型通常用高斯-泊松模型进行描述,但是在PIPELINE中每经过一个处理模块,噪声都会发相应的变化,在经过一系列的线性和非线性变化后噪声模型会变得更加复杂,很难通过模型去降低噪声 下图是前面介绍LSC时标定得到的补偿Gain值,可以发现四周的gain值会比中间的大很多,这样就会导致原本均匀分布的噪声在不同的gain值作用下变得不均匀,这种不均匀和镜头相关,噪声模型就会变得复杂 去马赛克算法对噪声模型的影响：不同的去去马赛克算法对噪声模型的改变程度和方式都会有所差异,经过去马赛克后噪声模型无法确定 除此之外pipeline中还会经过Gamma,CCM,AWB等一系列线性和非线性的变换,会使得噪声模型更加复杂,后面再去除噪声会变得更加困难 所以一种很理想的方式就是直接在RAW上就对噪声进行抑制,让噪声在一个合理的范围内 9.2 方法 9.2.1 PCA简介 PCA简介 对数据找到主要的分布方向,对分散的数据经过旋转变换或其他变换找到其主要分布形式,对其进行投影以最大程度的表示数据的方法 对于矩阵M∗N=M∗M×M∗N×N∗N对于矩阵M*N = M*M \\times M*N \\times N*N对于矩阵M∗N=M∗M×M∗N×N∗N M∗N×N∗K→M∗KM*N \\times N*K \\rightarrow M*KM∗N×N∗K→M∗K 若k远远小于Nk远远小于Nk远远小于N,则实现了降维的操作 可以使用SVD奇异值分解A=UEVTA = U \\Epsilon V^TA=UEVT 参考矩阵理论知识 算法原理 PCA降噪 主要依据：噪声是均匀分布的,而图像的有用信息主要分布在主成的特征上,故经过PCA降维后图像的主要信息得到了保留,而噪声随着减少的维度损失,再经过反PCA变换后SNR就可以得到提升 该算法的主要思路 首先在整副图中选择一个区域,即图中最大的黑框（training block） PCA需要有特征需要选择特征框（variable block）,即图中小框,如图将特征框的尺寸定义为6*6 假设小框的排列为Gr,R,B,Gb,那么就可以得到一个[Gr1,R1,Gr2,R2...B1,Gb1,B2,Gb2...]’[Gr1,R1,Gr2,R2...B1,Gb1,B2,Gb2...]’[Gr1,R1,Gr2,R2...B1,Gb1,B2,Gb2...]’的一个列向量,那么在training block中有多少个小框,那么就有多少个这样的列向量 假设有255个小框,那么就可以组成一个36*255的矩阵,其中36代表有36个特征,255代表有255个数据 为了进一步提高算法的效果,在这255个数据中找出相似区域做PCA,因为不相似区域的贡献度太高在后续的去马赛克算法中会使得图像容易出现伪彩 找相似的方式,作者使用的方式是通过求每个列向量与中心向量（图中绿色框）的曼哈顿距离来排序,然后选择距离相近的N个数据作为最终的PCA数据 经过处理后数据就变为36*N维 再对这个二维数据进行主成分分析,找出前m维个特征进行降维（m是对36个特征进行处理） 再对降维后的数据进行反PCA变换就可以起到降噪的功效 论文中还有一些提升效果的操作 在做PCA之前会进行去中心化,保证数据的中心与原点重合 如主成分的变换矩阵是通过模型求的没有噪声特性的图像的变换矩阵,在对图像进行PCA变换的时候就可以降低噪声对图像主成分的干扰 PCA之前会通过小波得到噪声模型的方差,用来分析噪声 小波降噪 小波变换：F(w)=∫−∞∞f(t)∗e−iwtdtWT(a,τ)=1a∫−∞∞f(t)∗ψ(t−τa)dtF(w)=\\int_{-\\infty}^{\\infty} f(t) * e^{-i w t} d t \\quad W T(a, \\tau)=\\frac{1}{\\sqrt{a}} \\int_{-\\infty}^{\\infty} f(t) * \\psi\\left(\\frac{t-\\tau}{a}\\right) d tF(w)=∫−∞∞​f(t)∗e−iwtdtWT(a,τ)=a​1​∫−∞∞​f(t)∗ψ(at−τ​)dt 小波降噪,对图像的按频率进行分层 降噪的理论依据 图像的能量主要集中在低频子带上,而噪声信号的能量主要分布在各个高频子带上 原始图像信息的小波系数绝对值较大,噪声信息小波系数的绝对值较小 9.2.2 PSEUDO FOUR-CHANNEL IMAGE DENOISING FOR NOISY CFA RAWDATA PSEUDO FOUR-CHANNEL IMAGE DENOISING FOR NOISY CFA RAWDATA 需要的内存较大,还没验证在实际PIPELINE上的效果 主要思路：将一个选择不同的起始点得四种不同的数据,然后对这四种数据进行PCA降噪,然后再次展开成四张RAW图,然后对四张RAW进行平均得到最终的raw图 9.2.3 Noise Reduction for CFA Image Sensors Exploiting HVS Behaviour 噪声模型：在sensor端较多的引入噪声 光子噪声(光子散粒噪声),暗噪声: 符合泊松分布 读噪声,ADC噪声：符合高斯分布 之前使用AWGN,加性高斯白噪声作为噪声模型,此时具有泊松分布的噪声,其模型不适用; 另外还有1/f噪声和复位噪声,在硬件上可使用CDS技术进行消除 算法原理：结合HVS进行bayer域的降噪 主要是通过几个模块进行降噪,通过像素值的差来作为判断依据,包括Signal Analyzer Block,Texture Degree Analyzer, Noise Level Estimator, Similarity Thresholds and Weighting Coefficients computation Signal Analyzer Block --&gt; HVS wieght 噪声在RAW上的分布符合高斯泊松分布,故噪声随着亮度增加会变大(一般说的是越暗噪声越大,但因为人眼看到的噪声大小是通过SNR指标来体现的) 结论通常可以通过拍摄以上的连续灰阶卡来证明,拍摄N张以上的灰阶卡,然后从水平方向采样,将所有的采样信息通过绘制可以得到下面的分布 中间的黑色线就是均值,红色点就是实际像素值的分布,可以看出随着亮度变大,像素分布的方差越大说明噪声变大 根据变化趋势可以拟合曲线可以看出：随着均值变大方差变大,故亮度越大降噪力度需要加大 根据人眼亮度灵敏度：越暗的区域人眼对于亮度变化的灵敏度越不敏感,故对于暗部区域可以提高降噪力度 由于以上两个特性的,最终将降噪力度和亮度变化的关系定义为Fig3中的曲线：中间亮度值对应的降噪力度为最小,然后两侧呈显现增长 Texture Degree Analyzer 该模块的主要功能：通过上一个模块计算的HVS权重和下一个模块计算的noise level来判断平坦去和纹理区从而实现不同力度的降噪 首先通过 TextureThreshold c(k)=HVSweight(k)+NLc(k−1)\\text { TextureThreshold }_{c}(k)=HVS_{\\text {weight}}(k)+NL_{c}(k-1) TextureThreshold c​(k)=HVSweight​(k)+NLc​(k−1) 公式计算出一个TextureThreshold,用于判断给定的降噪力度 因为NL(noise level)是下一个模块计算出来的,所以这里利用上一个像素点计算出来的noise level来预估当前的noise level,然后本次计算的noise level来预估下次,故是一个循环迭代过程 最开始的像素没有前一个像素的noise level的时候会设置一个初始值,初始值的是调试时需要根据效果选择的了 随后根据邻域内像素点和中心像素值的差异（TdT_dTd​）来判断是否为平坦区,Td(T_d(Td​( green )={1Dmax⁡=0−Dmax⁡ TextureThreshold +10&lt;Dmax⁡≤ TextureThreshold 0Dmax⁡&gt; TextureThreshold ,Td()= \\begin{cases}1 &amp; D_{\\max }=0 \\\\ -\\frac{D_{\\max }}{\\text { TextureThreshold }}+1 &amp; 0&lt;D_{\\max } \\leq \\text { TextureThreshold } \\\\ 0 &amp; D_{\\max }&gt;\\text { TextureThreshold }\\end{cases},T_d()=⎩⎪⎪⎨⎪⎪⎧​1− TextureThreshold Dmax​​+10​Dmax​=00&lt;Dmax​≤ TextureThreshold Dmax​&gt; TextureThreshold ​,Td​( red /// blue )={1Dmax⁡≤ThR/B−(Dmax⁡−ThR/B)( TextureThreshold −ThR/B)+1ThR/B&lt;Dmax⁡≤ TextureThreshold 0Dmax⁡&gt; TextureThreshold )= \\begin{cases}1 &amp; D_{\\max } \\leq T h_{R / B} \\\\ -\\frac{\\left(D_{\\max }-T h_{R / B}\\right)}{\\left(\\text { TextureThreshold }-T h_{R / B}\\right)}+1 &amp; T h_{R / B}&lt;D_{\\max } \\leq \\text { TextureThreshold } \\\\ 0 &amp; D_{\\max }&gt;\\text { TextureThreshold }\\end{cases})=⎩⎪⎪⎪⎨⎪⎪⎪⎧​1−( TextureThreshold −ThR/B​)(Dmax​−ThR/B​)​+10​Dmax​≤ThR/B​ThR/B​&lt;Dmax​≤ TextureThreshold Dmax​&gt; TextureThreshold ​ G通道和RB通道分开处理 因为人眼对G分量更为敏感,RB通道可以更多的维持在平坦区（即图中Td=1）,后面会加大平坦区的降噪力度 因为人眼不敏感,故RB通道牺牲更多的细节是在允许范围内的 Noise Level Estimator：用来评估噪声水平 如果被判断为平坦区（Td=1）将noise level设置为Dmax 如果被判断为纹理去（Td=0）将noise level保持为上一个像素的noise level； 若果介于平坦区和纹理去之间通过插值的方式计算出noise level, NLR(k)=Td(k)∗Dmax⁡(k)+[1−Td(k)]∗NLR(k−1)NLG(k)=Td(k)∗Dmax⁡(k)+[1−Td(k)]∗NLG(k−1)NLB(k)=Td(k)∗Dmax⁡(k)+[1−Td(k)]∗NLB(k−1)\\begin{aligned}N L_{R}(k) &amp;=T_{d}(k) *D_{\\max }(k)+\\left[1-T_{d}(k)\\right]* N L_{R}(k-1) \\\\N L_{G}(k) &amp;=T_{d}(k) * D_{\\max }(k)+\\left[1-T_{d}(k)\\right] *N L_{G}(k-1) \\\\N L_{B}(k) &amp;=T_{d}(k)* D_{\\max }(k)+\\left[1-T_{d}(k)\\right] * N L_{B}(k-1)\\end{aligned}NLR​(k)NLG​(k)NLB​(k)​=Td​(k)∗Dmax​(k)+[1−Td​(k)]∗NLR​(k−1)=Td​(k)∗Dmax​(k)+[1−Td​(k)]∗NLG​(k−1)=Td​(k)∗Dmax​(k)+[1−Td​(k)]∗NLB​(k−1)​ 式中的NLR(k)N L_{R}(k)NLR​(k)代表当前像素点的nosie level,NLR(k−1)N L_{R}(k-1)NLR​(k−1)代表上一个像素的noise level,所以对于开始的像素没有上一个同通道的像素可以设置一个初始值 Similarity Thresholds and Weighting Coefficients computation:主要计算各个点的权重值 如图为红色通道的权求解方式:利用周围像素与中心像素的差值来作为权重的最终判定依据 首先通过计算的像素值差异求出一个Thlow和THhigh,{Thlow =Thhigh =Dmax⁡ if Td=1Thlow =Dmin⁡ if Td=0Thhigh =Dmin⁡+Dmax⁡2 if Td=0Dmin⁡&lt;Thlow &lt;Thhigh if 0&lt;Td&lt;1Dmin⁡+Dmax⁡2&lt;Thhigh &lt;Dmax⁡ if 0&lt;Td&lt;1\\left\\{\\begin{array}{l}T h_{\\text {low }}=T h_{\\text {high }}=D_{\\max } \\text { if } \\quad T_{d}=1 \\\\T h_{\\text {low }}=D_{\\min } \\quad \\text { if } \\quad T_{d}=0 \\\\T h_{\\text {high }}=\\frac{D_{\\min }+D_{\\max }}{2} \\quad \\text { if } \\quad T_{d}=0 \\\\D_{\\min }&lt;T h_{\\text {low }}&lt;T h_{\\text {high }} \\quad \\text { if } \\quad 0&lt;T_{d}&lt;1 \\\\\\frac{D_{\\min }+D_{\\max }}{2}&lt;T h_{\\text {high }}&lt;D_{\\max } \\quad \\text { if } \\quad 0&lt;T_{d}&lt;1\\end{array}\\right.⎩⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎧​Thlow ​=Thhigh ​=Dmax​ if Td​=1Thlow ​=Dmin​ if Td​=0Thhigh ​=2Dmin​+Dmax​​ if Td​=0Dmin​&lt;Thlow ​&lt;Thhigh ​ if 0&lt;Td​&lt;12Dmin​+Dmax​​&lt;Thhigh ​&lt;Dmax​ if 0&lt;Td​&lt;1​ 随后通过比较每个点的像素差异和这两个阈值的差异来给定权重 低于最低阈值,说明像素差异很小,在滤波时的贡献应该大,需要给一个大的权重 相反差异太大就不应该对滤波提供大的贡献,所以需要将权重设置小 所以通过如上的一个分段线性的方式来给每个像素点分配权重。 Final Weighted Average Pf=1N∑i=1N[WiPi+(1−Wi)Pc]P_{f}=\\frac{1}{N} \\sum_{i=1}^{N}\\left[W_{i} P_{i}+\\left(1-W_{i}\\right) P_{c}\\right]Pf​=N1​∑i=1N​[Wi​Pi​+(1−Wi​)Pc​] 最后通过上述公式完成滤波和归一化即可得到最终降噪后的像素值 10 Demosaicking 10.1 CMOS成像基础 CMOS结构分为前照式CMOS和背照式CMOS:工艺不同,金属排线的位置不同 前照式CMOS,会挡住一部分光线,导致感光能力下降 背照式CMOS,工艺更加复杂 相机系统用的感光器件只是一个光电转换器件,感光器件只对亮度分量敏感,无法感知颜色,故需要通过滤光片将光线分解成RGB三个分量用感光器件接受 3CCD：最直接的方式就是用三个滤光片分别过滤出RGB三个通道的分量,然后用三个感光器件去分别接受三个通道的强度,然后再将这三个通道的值叠加到一起就能复现出正常的颜色(工艺复杂且成本较高) 柯达公司发明廉价且高效的方案只需要在一个CCD阵列上制造三种不同的滤光膜,构成一个滤光膜阵列(CFA) ==在感光器件上面通过交替的滤光透镜过滤出三中颜色分量形成RGB三色交替的图像,后期通过算法通过周边的颜色恢复出确实的颜色,最终形成RGB的颜色 这种后期的处理方式就是本文讨论的重点,一般称作去马赛克算法（demosaicking） 去马赛克也称为CFA重构,无限还原回RGB真彩空间 10.2 算法精讲 10.2.1 简单的线性插值 如图是Bayer格式的raw图,RGB三种颜色交替覆盖,且绿色分量是RB分量的两倍 由于这种特殊的分布方式,所以可以通过简单的线性插值插值出同一通道缺失的分量,current:B,RGB:(mean(σR),B,mean(σG)current: B, RGB:(mean(\\sigma R), B, mean(\\sigma G)current:B,RGB:(mean(σR),B,mean(σG) 简单的线性插值的效果一般,存在画面整体清晰度变差,高频存在伪彩,边缘存在伪像 10.2.2 色差法和色比法 色比法和色差法基于两个假设实现插值 色比法假设：在一个邻域范围内不同颜色通道的值的比值是固定的,简单来说就说相邻像素的R/G的值和B/G的值是一样的(设计算法时就可利用这一点) 一般情况下都会先插值出G的缺失值,然后通过与G的比值恒定插值出其他的缺失值 如上展示的RAW图,可以通过G9,G13, G15,G19做简单的线性插值恢复G14,然后通过R14/G14 = R13/G13的假设恢复出R13;同理可以恢复出其他缺失的颜色 色差法和色比法类似,色差法假设在一个邻域内不同通道的色差值是恒定的 只是将色比法的比值转换为差值即可 效果一般,存在画面整体清晰度变差,高频存在伪彩,边缘存在伪像 10.2.3 基于方向加权的方法 由于上述简单的插值算法存在诸多缺陷,其主要原因就是没有针对边缘做处理 更好的算法就对边缘做了识别,针对边缘做特殊的处理,然后同时利用色差或色比的方法融合到一起得到更好的效果 由于绿色在RAW图中占50%,对图像更重要,故一般先将G通道先差值出来 RB缺失的G通道的插值(以B上G的插值为例) 对于点(i,j)(i,j)(i,j),使用表中的n方向对应的vn和hnv_n和h_nvn​和hn​代入In(i,j)=Kn(abs(P(i+vn,j+hn)−P(i−vn,j−hn))+abs(P(i+2vn,j+2hn)−P(i,j)))I_n(i,j)=K_n(abs(P(i+v_n,j+h_n)-P(i-v_n,j-h_n)) + abs(P(i+2v_n,j+2h_n)-P(i,j)))In​(i,j)=Kn​(abs(P(i+vn​,j+hn​)−P(i−vn​,j−hn​))+abs(P(i+2vn​,j+2hn​)−P(i,j)))计算 依次计算12个方向的类梯度值,得到计算结果In(i,j)I_n(i,j)In​(i,j) KnK_nKn​为权重,可在1,2,3,4方向上取Kn=1K_n=1Kn​=1,5,6,7,8,9,10,11,12方向上Kn=0.5K_n=0.5Kn​=0.5 计算权重Wn(i,j)=11+In(i,j)∑11+In(i,j)W_n(i,j)=\\frac{\\frac{1}{1+I_n(i,j)}}{\\sum \\frac{1}{1+I_n(i,j)}}Wn​(i,j)=∑1+In​(i,j)1​1+In​(i,j)1​​ G(i,j)=B(i,j)+∑Wn(i,j)∗Kb,n(i+vn,j+hn)G(i,j) = B(i,j) + \\sum W_n(i,j)*K_{b,n}(i+v_n,j+h_n)G(i,j)=B(i,j)+∑Wn​(i,j)∗Kb,n​(i+vn​,j+hn​) Kb,n(i+vn,j+hn)=G(i+vn,j+hn)−B(i+vn,j+hn)K_{b,n}(i+v_n,j+h_n)=G(i+v_n,j+h_n)-B(i+v_n,j+h_n)Kb,n​(i+vn​,j+hn​)=G(i+vn​,j+hn​)−B(i+vn​,j+hn​)为色差,使用左右的B或上下的B的均值计算 RB缺失的BG插值 对于点(i,j)(i,j)(i,j),使用表中的n方向对应的vn和hnv_n和h_nvn​和hn​代入In(i,j)=Kn(abs(P(i+vn′,j+hn′)−P(i−vn′,j−hn′))+abs(P(i+2vn′,j+2hn′)−P(i,j)))I_n(i,j)=K_n(abs(P(i+v_n^{&#x27;},j+h_n^{&#x27;})-P(i-v_n^{&#x27;},j-h_n^{&#x27;})) + abs(P(i+2v_n^{&#x27;},j+2h_n^{&#x27;})-P(i,j)))In​(i,j)=Kn​(abs(P(i+vn′​,j+hn′​)−P(i−vn′​,j−hn′​))+abs(P(i+2vn′​,j+2hn′​)−P(i,j)))计算 计算权重Wn(i,j)=11+In(i,j)∑11+In(i,j)W_n(i,j)=\\frac{\\frac{1}{1+I_n(i,j)}}{\\sum \\frac{1}{1+I_n(i,j)}}Wn​(i,j)=∑1+In​(i,j)1​1+In​(i,j)1​​ R(i,j)=G(i,j)+∑Wn(i,j)∗Kb,n(i+vn′,j+hn′)R(i,j) = G(i,j) + \\sum W_n(i,j)*K_{b,n}(i+v_n^{&#x27;},j+h_n^{&#x27;})R(i,j)=G(i,j)+∑Wn​(i,j)∗Kb,n​(i+vn′​,j+hn′​) Kb,n(i+vn,j+hn)=G(i+vn′,j+hn′)−R(i+vn′,j+hn′)K_{b,n}(i+v_n,j+h_n)=G(i+v_n^{&#x27;},j+h_n^{&#x27;})-R(i+v_n^{&#x27;},j+h_n^{&#x27;})Kb,n​(i+vn​,j+hn​)=G(i+vn′​,j+hn′​)−R(i+vn′​,j+hn′​) G缺失的BR插值 In(i,j)=κn(abs(P(i+vn,j+hn)−P(i−vn,j−hn))+abs⁡(P(i+2vn,j+2hn)−P(i,j)))I_n(i, j)=\\kappa_n(a b s(P(i+v_n, j+h_n)-P(i-v_n, j-h_n))+ \\operatorname{abs}(P(i+2 v_n, j+2 h_n)-P(i, j)))In​(i,j)=κn​(abs(P(i+vn​,j+hn​)−P(i−vn​,j−hn​))+abs(P(i+2vn​,j+2hn​)−P(i,j))) wn(i,j)=(11+In(i,j))/∑n=11211+In(i,j)w_n(i, j)=\\left(\\frac{1}{1+I_n(i, j)}\\right) / \\sum_{n=1}^{12} \\frac{1}{1+I_n(i, j)}wn​(i,j)=(1+In​(i,j)1​)/∑n=112​1+In​(i,j)1​, R(i,j)=G(i,j)−∑n=112wn(i,j)∗Kr,n(i+vn,j+hn)R(i, j)=G(i, j)-\\sum_{n=1}^{12} w_n(i, j)^* K_{r, n}\\left(i+v_n, j+h_n\\right)R(i,j)=G(i,j)−∑n=112​wn​(i,j)∗Kr,n​(i+vn​,j+hn​) 10.2.4 基于边缘检测的方法 计算水平和竖直梯度: 水平梯度eh=14(∣C(i−1,j−1)−C(i−1,j+1)∣+2∣C(i,j−1)−C(i,j+1)∣+∣C(i+1,j−1)−C(i+1,j+1)∣)e_h = \\frac{1}{4}(|C(i-1,j-1)-C(i-1,j+1)|+2|C(i,j-1)-C(i,j+1)|+|C(i+1,j-1)-C(i+1,j+1)|)eh​=41​(∣C(i−1,j−1)−C(i−1,j+1)∣+2∣C(i,j−1)−C(i,j+1)∣+∣C(i+1,j−1)−C(i+1,j+1)∣),同理计算竖直梯度eve_vev​ 计算缺失的G 计算权重:Wh=1eh1eh+1evW_h = \\frac{\\frac{1}{e_h}}{\\frac{1}{e_h}+\\frac{1}{e_v}}Wh​=eh​1​+ev​1​eh​1​​, Wv=1ev1eh+1evW_v = \\frac{\\frac{1}{e_v}}{\\frac{1}{e_h}+\\frac{1}{e_v}}Wv​=eh​1​+ev​1​ev​1​​ G^h(i,j)=E(Gh)+δCh(i,j),G^v(i,j)=E(Gv)+δCv(i,j),E(Gh),E(Gh)分别为水平和竖直方向的均值\\hat{G}_h(i,j)=E(G_h)+\\delta C_h(i,j), \\hat{G}_v(i,j)=E(G_v)+\\delta C_v(i,j),E(G_h),E(G_h)分别为水平和竖直方向的均值G^h​(i,j)=E(Gh​)+δCh​(i,j),G^v​(i,j)=E(Gv​)+δCv​(i,j),E(Gh​),E(Gh​)分别为水平和竖直方向的均值 δCh(i,j)=12(12(C(i,j)−C(i,j−2))+12(C(i,j)−C(i,j+2)))\\delta C_h(i,j)=\\frac{1}{2} (\\frac{1}{2}(C(i,j)-C(i,j-2))+\\frac{1}{2}(C(i,j)-C(i,j+2)))δCh​(i,j)=21​(21​(C(i,j)−C(i,j−2))+21​(C(i,j)−C(i,j+2))) G′(i,j)=Wh(i,j)∗G^h(i,j)+Wv(i,j)∗G^v(i,j)G^{&#x27;}(i,j)=W_h(i,j)*\\hat{G}_h(i,j)+W_v(i,j)*\\hat{G}_v(i,j)G′(i,j)=Wh​(i,j)∗G^h​(i,j)+Wv​(i,j)∗G^v​(i,j) 计算缺失的RB δGc=1n∑G′(i+k,j+l)−C(i+k,j+l)\\delta G_c = \\frac{1}{n} \\sum G^{&#x27;}(i+k,j+l)-C(i+k,j+l)δGc​=n1​∑G′(i+k,j+l)−C(i+k,j+l) R′(i,j)=G′(i,j)+δGcR^{&#x27;}(i,j) = G^{&#x27;}(i,j)+\\delta G_cR′(i,j)=G′(i,j)+δGc​ G缺失的RB 10.2.5 基于学习的方法 马赛克与降噪结合的方法 该算法默认的raw输入为3通道,这个图可以通过1通道的raw生成,就是只保留该点原本的颜色值,其他两个通道为0即可 大体模型就是输入的RAW先通过降采样生成4通道的长宽均缩小一半的数据 降采样有两种方式,一种是直接将图像拆分为R,B,Gr,和Gb四个通道,然后再进网络 另一种方式就是如图中的方式,通过一个2X2,步长为2的卷积核进行一个卷积运算输出一个4通道 在经过降采样后再经过14次3X3的卷积并用ReLu作为激活函数,同时整个过程维持64通道 在15层通过3X3卷积输出一个12通道的数据,接着通过一个上采样卷积生成一个3通道的数据 然后将这个3通道的数据和原始的raw数据做一个叠加生成一个6通道的数据 紧接着再经过一个3X3卷积生成64通道数据,最后再通过一个3X3的卷积生成最终的图像 基于这个模型通过大量的数据来学习最终生成模型 其他方法：Bayesian估计方法, 残差网络模型 11 CCM(color correction matrix) 颜色学基础：人眼的视锥细胞和视杆细胞、颜色匹配实验、CIE_RGB出现负数的原因、CIE_XYZ sensor和人眼对颜色的感知存在差别,且不同sensor之间的颜色感知也存在差别,因此需要将设备的颜色感知统一标准 理解为人眼对物体感受的颜色是目标,需要将sensor感光数据经过某种变换达到目标 假设人眼能感受到的颜色种类有m种,那自然界的颜色就可以表示为一个3Xm的矩阵,同理sensor对自然界的感光也可以得到一个3Xm的矩阵 需要做的就是将右侧sensor感光的数据转换到左侧人眼感光的数据上来 3D-LUT法 3D查表法,若值在表中,则直接给出,否则插值得到 多项式拟合 [R1R2R3RmG1G2G3…GmB1B2B3Bm]←[M11M12M13M21M22M23M31M32M33][R1′R2′R3′Rm′G1′G2′G3′…Gm′B1′B2′B3′Bm′]\\left[\\begin{array}{ccccc}R_1 &amp; R_2 &amp; R_3 &amp; &amp; R_{\\mathrm{m}} \\\\ G_1 &amp; G_2 &amp; G_3 &amp; \\ldots &amp; G_{\\mathrm{m}} \\\\ B_1 &amp; B_2 &amp; B_3 &amp; &amp; B_{\\mathrm{m}}\\end{array}\\right] \\leftarrow\\left[\\begin{array}{lll}M_{11} &amp; M_{12} &amp; M_{13} \\\\ M_{21} &amp; M_{22} &amp; M_{23} \\\\ M_{31} &amp; M_{32} &amp; M_{33}\\end{array}\\right]\\left[\\begin{array}{ccccc}R_1^{\\prime} &amp; R_2^{\\prime} &amp; R_3^{\\prime} &amp; &amp; R_m^{\\prime} \\\\ G_1^{\\prime} &amp; G_2^{\\prime} &amp; G_3^{\\prime} &amp; \\ldots &amp; G_m^{\\prime} \\\\ B_1^{\\prime} &amp; B_2^{\\prime} &amp; B_3^{\\prime} &amp; &amp; B_m^{\\prime}\\end{array}\\right]⎣⎢⎡​R1​G1​B1​​R2​G2​B2​​R3​G3​B3​​…​Rm​Gm​Bm​​⎦⎥⎤​←⎣⎢⎡​M11​M21​M31​​M12​M22​M32​​M13​M23​M33​​⎦⎥⎤​⎣⎢⎡​R1′​G1′​B1′​​R2′​G2′​B2′​​R3′​G3′​B3′​​…​Rm′​Gm′​Bm′​​⎦⎥⎤​ 此处的3X3的矩阵是需要的颜色校正矩阵,即CCM 在进行CCM之前已经进行AWB,使得r=g=br=g=br=g=b,故需要M11+M12+M13=M21+M22+M33=M31+M32+M33M_{11}+M_{12}+M_{13}=M_{21}+M_{22}+M_{33}=M_{31}+M_{32}+M_{33}M11​+M12​+M13​=M21​+M22​+M33​=M31​+M32​+M33​限制条件,实际过程中使用最优化的方法,拉格朗日乘数法进行求解,通常不会通过简单的矩阵求解,而是通过带限制条件的优化方程的方式来求解,目的是保证白平衡不被破坏 CCM同时也有3X4,4X3矩阵,为加上一个offset参数 实际使用中不多： 根多项式方法: e=a11r+a12g+a13b+a14rg+a15rb+a16gbe=a_{11}r+a_{12}g+a_{13}b+a_14\\sqrt{rg}+a_15\\sqrt{rb}+a_16\\sqrt{gb}e=a11​r+a12​g+a13​b+a1​4rg​+a1​5rb​+a1​6gb​ 多项式: e=a11r+a12g+a13b+a14rg+a15rb+a16gbe=a_{11}r+a_{12}g+a_{13}b+a_14rg+a_15rb+a_16gbe=a11​r+a12​g+a13​b+a1​4rg+a1​5rb+a1​6gb 常规做法： 使用color char(为24色标准色卡) 通常在LAB颜色空间,在LAB颜色空间具有δE\\delta EδE参数,可以更精确的表示人眼的距离关系 CIE_RGB到CIE_XYZ解决了负数的问题,而CIE_XYZ中距离不能表示颜色的差异,因此引入了CIE_LAB颜色空间,L表示亮度,AB表示色相,根据A或B的值可以表示颜色的差异,δE=δl2+δA2+δE2\\delta E =\\sqrt{\\delta l^2 + \\delta A^2 + \\delta E^2}δE=δl2+δA2+δE2​ 在2000年提出δE2000\\delta E_2000δE2​000标准,该标准更符合人眼的特性 神经网络 神经网络的方式,因为其实输入就是一个矩阵,输出也是一个矩阵,那么中间通过网络连接,然后通过数据训练也能得到一个转换的网络参数 总结概念 sensor RGB: sensor的感光相关 CIE_RGB RAW图 --&gt; 去马赛克 --&gt; rgb图(为sensor RGB, 为线性RGB) --CCM_1–&gt; XYZ --CCM_2–&gt; LAB --CCM_3–&gt; target LAB --CCM_4&gt; target XYZ --CCM_5–&gt; sRGB(线性sRGB) 其中CCM_4和CCM_5的转换矩阵已知 线性sRGB --gamma校正–&gt; sRGB非线性 调试时,与gamma相关,gamma常规值为2.2或0.45,在调试时会预先设置一条Gamma曲线,经反变换之后得到sRGB,随后根据sensor RGB就可以得到CCM矩阵 CCM调试之前先调Gamma,在pipline中Gamma位于CCM之后 12 CSC 12.1 CSC简介 CSC-coloer space convert,也称CSM（color space matrix） 通过一些线性变化,将原本图像的颜色空间转换到其他的颜色空间(常见的有RGB2YUV,RGB2SV等),下图是MATLAB文档中对CSC的定义 但是通常在ISP的Pipeline中用到的CSC转换只有RGB2YUV,部分主控在CCM之后会有RGB2HSV的转换,以便进一步通过色度和饱和度两个层面对颜色做进一步的处理 ISP要实现RGB2YUV转换需要转换公式,各个转换公式的的标准不同,通常采用BT的标准,也就是国际电信联盟指定的标准 如下图分别罗列了BT601,BT709和BT2020三个标准,具体在选用的时候根据需要选择一个就行了 12.2 YUV的作用 1234graph LRYUV格式的作用--&gt; 最早为了适配彩色电视和黑白电视的兼容YUV格式的作用--&gt; 将Y和UV分开,根据人眼对亮度和色彩灵敏度的差异做差异化处理YUV格式的作用--&gt; 为后续的数据压缩做准备 为什么pipeline中需要这么一个转换将RGB转为YUV： YUV是早期欧洲定义的一种信号格式,主要是为了解决黑白电视和彩色电视过渡时期的信号兼容问题,黑白电视只需要亮度值,不需要彩色信号,而彩色电视既需要亮度信号也需要色彩信号,所以如果直接使用RGB就会带来兼容问题,而采用YUV信号,黑白电视不处理彩色信号即可； 可以将Y和UV分开处理,即将亮度信号和色度信号分开处理,更符合HVS,HVS中人眼对亮度信号更明高,对色度信号相对不明感,在去噪等一些处理时就可以针对不同层面的信号做不同强度的处理,从而最大程度的保护图像效果 为后续的数据压缩做准备,因为通常现在用的多的MJPG和网络传输用的H264和H265等信号都是基于YUV信号的基础上做进一步的数据压缩得来的 12.3 YUV简介 YUV中Y表示亮度信号,UV表示色度信号也就是色差信息 通常查资料会出现YCrCb信号：YCrCb是数字信号时代定义的一种色差信号,是通过YUV加上一定程度的offset得到的,使得色差数据都大于0 ==大多数情况下已不对二者进行区分,现在提到的YUV其实都是指的YCrCb格式,只是习惯原因通常还是会直接说是YUV= YUV格式有很多种类,如下图是微软WindowsAPI文档中对YUV的一些宏定义 图中的数据格式是YUV格式,而它们各自的区别主要就是采样比和信号的排列循序 如图是三种最常见的采样比例,黑色实心点为Y分量,空心的圆圈为UV分量 YUV444：完全采样,即每一个Y信号对应的UV信号都采样,没有损失任何信号 YUV422：两个Y信号公用一个UV分量,及4个有分量对应2个U和2个V分量,色度信号损失一部分从而减小数据量 YUV420：四个Y分量公用一个UV分量,在422的基础上进一步降低数据量 其实从定义看YUV420可能叫411更好理解,但是为啥又叫420呢？ 因为还有一种基本没见过（也可能是作者见识短）的格式叫YUV411,他和420一样也是4个Y对应一个UV,不同的是411只在水平方向对UV降采样 12.3.1 信号排列分类 从微软文档中可以看到有一个YUY2的格式,其实这种格式又叫YUYV格式是一种422的采样格式,然后还有一种YVYU的格式也是422采样,两者又有什么不同呢 其实就是信号排列不同,比如在内存中YUYV格式存储为Y1U1Y2V1Y3U2Y4V2而YVYU则存储为Y1V1Y2U1Y3V2Y3U2这种方式都是Y和UV交替存储,还有一种常见的存储方式就是先将所有的Y分量存储好,然后再去存储UV分量,当时后续的UV分量的排列又会有不同的变化 13 3A算法——AE(auto exposure) 13.1 预实验公式+LUT法 算法说明 根据以下公式Σ=k1×L×G×S\\Sigma=k 1 \\times L \\times G \\times SΣ=k1×L×G×S,∑为ISP芯片内的统计值,可以通过读取寄存器地址直接获取,L为当前物体的亮度,G为gain值,S为曝光时间 变换以下公式：L=Σ/(k1×G×S)L=\\Sigma /(k 1 \\times G \\times S)L=Σ/(k1×G×S),L是当前物体的亮度,当环境不发生变化时L是一个定值 初始化时先给定一组GS,K为常数,然后通过寄存器读出∑的值就可以计算出L,然后通过前期试验找出不同L对应的最佳GS参数组合,然后通过LUT找到这种参数组合,重新赋值给GS即可完成曝光 同时该论文中设定L的取值范围是100Lx—100000Lx之间,这么大的范围如果一个一个测试费时且内存过大,故将这个范围分成一个等比数列 $L n=(100000 / 100)^{I /(N-1)} \\times L_{(n-1)} $,N为设计的地址的个数,根据这个数目将这个范围分成一个等比数列 然后为了进一步简化运算,将公式(1)取对数log⁡L=log⁡Σ−log⁡S−log⁡G−log⁡k1\\log L=\\log \\Sigma-\\log S-\\log G-\\log k 1logL=logΣ−logS−logG−logk1,因为Ln是等比数列,那么 log⁡L\\log LlogL 就是等差数列,那么L(n)−L(n−1)/q{L_{(n)} - L_{(n-1)}} / qL(n)​−L(n−1)​/q 就是一个等差为1的等差数列,就正好设计为LUT的地址,这样用一个数组就可以解决（q为等比数列的公比） 13.2 公式+LUT+微调法 流程：通过初始化参数获取图像,用测光得到图像的平均亮度,根据LUT找到对应调整步伐,判断该步伐是否超过最大步伐,如果超过则使用最大步伐调整,调整后平均亮度理论上应该接近目标亮度,所以调整后就可以通过微调进一步优化 该算法的重点：如何建立内建表,AEstep=(1/EStep)∗log⁡2( TY/Yave)\\mathrm{AE}_{\\mathrm{step}}=\\left(1 / \\mathrm{E}_{\\mathrm{Step}}\\right) * \\log _{2}\\left(\\mathrm{~T}_{Y} / \\mathrm{Y}_{\\mathrm{ave}}\\right)AEstep​=(1/EStep​)∗log2​( TY​/Yave​) 公式按照理解也是通过大量实验得到的,下面对公式做解释： AEstep\\mathrm{AE}_{\\mathrm{step}}AEstep​ : 所需要调整的步阶数 EStep\\mathrm{E}_{\\mathrm{Step}}EStep​ : 调整曝光时间的最小单位,这个值对于同一设备是常亮 TY\\mathrm{~T}_{Y} TY​ : 所需要的的目标亮度 Yave\\mathrm{Y}_{\\mathrm{ave}}Yave​ : 画面的平均亮度 具体做法：八位数据两说亮度值就是0-255,0不能最分母,且一般也不会拍摄亮度为0的画面,所以内建表就设计为1-255,然后根据设置的target的值计算出每一个平均亮度对应的AEstep\\mathrm{AE}_{\\mathrm{step}}AEstep​,当相机计算出平均亮度就立马能找到对应的步伐进行调整,从而完成曝光任务 但是该方法的弊端就在于目标亮度不同就会得建立不同的内建表,如果需要更新目标亮度就得更新整张表,如果建立多张表的话对于内存大小又有要求 13.3 公式快速带入法 该方法最重要的就是求出公式,一般求公式的方式也是通过实验获取一些输入,然后通过机器学或者其他方式拟合出一条曲线,最后根据曲线方程计算出相应的参数 该论文中主要通过 Y=M(1−e−KGXM)Y=M\\left(1-e^{-\\frac{KGX}{M}}\\right)Y=M(1−e−MKGX​) 建立 Y: 表示成像器获取的图像亮度 M：表示成像器所能获取的最高图像亮度值 K: 表示曝光时间为1个单位时间,即最小步长是成像器获取的图像亮度 G: 表示电子增益 x: 表示曝光时间 算法的具体操作步骤如下 通过初始化参数G1, T1即可获取该参数下的图像亮度Y1；就有Y1=M(1−e−KG1T1M)Y_{1}=M\\left(1-e^{-\\frac{KG_{1}T_{1}}{M}}\\right)Y1​=M(1−e−MKG1​T1​​) 那么对于目标亮度YtargetY_{target}Ytarget​就有对应的参数G2和T2,同理瞒住公式：Ytarget=M(1−e−KG2T2M)Y_{target}=M\\left(1-e^{-\\frac{KG_{2}T_{2}}{M}}\\right)Ytarget​=M(1−e−MKG2​T2​​) 对上面两公式化简可得：ln⁡(M−Y1)−ln⁡(M)ln⁡(M−Ytarget)−ln⁡(M)=G1T1G2T2\\frac{\\ln \\left(M-Y_{1}\\right)-\\ln (M)}{\\ln \\left(M-Y_{target}\\right)-\\ln (M)}=\\frac{G_{1} T_{1}}{G_{2} T_{2}}ln(M−Ytarget​)−ln(M)ln(M−Y1​)−ln(M)​=G2​T2​G1​T1​​ 进一步归纳公式： (ln⁡(M−Ytarget)−ln⁡(M))G1T1ln⁡(M−Y1)−ln⁡(M)=G2T2\\frac{(\\ln \\left(M-Y_{target}\\right)-\\ln (M))G_{1} T_{1}}{\\ln \\left(M-Y_{1}\\right)-\\ln (M)}={G_{2} T_{2}}ln(M−Y1​)−ln(M)(ln(M−Ytarget​)−ln(M))G1​T1​​=G2​T2​ 公式左侧MMM, YtargetY_{target}Ytarget​, Y1Y_{1}Y1​, G1G_{1}G1​, T1T_{1}T1​ 均为已知,那么新的曝光参数的乘积就是一个已知量 论文中给出的方式就是先确定一个G2G_{2}G2​ 值,然后根据公式求出T2T_{2}T2​ 的值,然后对求出来的值取整,得到最终的T2T_{2}T2​ 根据最终的T2T_{2}T2​ 的值再反过来求出G2G_{2}G2​ 的值；,而且 理论上只需一帧就可以调整到合适曝光参数 对于第6步中先确定的G2G_{2}G2​ 的值来说,因为增加gain对增加信息量没有作用,而且通过gain值增加亮度还会导致噪声变大,所以这篇论文中给出gain的取值范围为1-2,所以对于第六步其实可以默认G2G_{2}G2​ 为1,然后求出一个T,然后判断T是否超过最大曝光时间,如果没有就继续上面的步骤,如果超过了既可以用最大曝光时间算出一个gain,然后判断这个gain时候超过2,如果没有就确定了一组参数,如果超过就取gain为2接着计算T也能得到一组新的参数。","categories":[{"name":"ISP","slug":"ISP","permalink":"http://jay1060950003.github.io/categories/ISP/"}],"tags":[{"name":"ISP","slug":"ISP","permalink":"http://jay1060950003.github.io/tags/ISP/"}]},{"title":"李沐动手学深度学习","slug":"深度学习相关/李沐动手学深度学习","date":"2022-09-14T07:44:36.000Z","updated":"2023-04-16T12:15:50.280Z","comments":true,"path":"2022/09/14/深度学习相关/李沐动手学深度学习/","link":"","permalink":"http://jay1060950003.github.io/2022/09/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/%E6%9D%8E%E6%B2%90%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","excerpt":"0 引言 李沐老师的《动手学深度学习》课程笔记 跳转至课程网站","text":"0 引言 李沐老师的《动手学深度学习》课程笔记 跳转至课程网站 1 课程安排 内容 深度学习基础：线性神经网络，多路感知机 卷积神经网络：LeNet,AlexNet,VGG,Inception,ResNet 循环神经网络: RNN, GRU, LSTM, seq2seq 注意力机制: Attention, Transformer 优化算法: SGD, Momentum, Adam 高性能计算: 并行, 多GPU, 分布式 计算机视觉: 目标检测, 语义分割 自然语言处理: 词嵌入, BERT 3 安装 1234567891011sudo apt install build-essential # 安装编译环境sudo apt install zip# conda环境下安装pip install jupyter d2l# 下载代码wget https://courses.d2l.ai/zh-v2/# 将服务器端的端口8888映射到本地ssh -L8888:localhost:8888 ubuntu@远端服务器ip 4 数据操作+数据预处理 4.1 数据操作 N维数组是机器学习和神经网络的主要数据结构 0-d标量：一个类别 1-d向量：一个特征向量 2-d矩阵：一个样本-特征矩阵 3-d： RGB图片(*宽*高*通道) 4-d：一个RGB图像批量(批量大小*宽*高*通道) 5-d: 一个视频批量(批量大小*时间*宽*高*通道) python中 : 代表的区间为前开后闭的区间 id()类似C++中指针 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[1:3, 1:] # 访问子区域，表示访问1-2行，1到最后一列[::3, ::2] # 跳跃访问：表示每三行一跳，每2列一跳# 导入模块import torch# 张量表示一个数值组成的数组，这个数组可能有多个维度x = torch.arrange(12) # 创建序列0-11# 可通过张量的shape属性访问张量的形状和张量中元素的总数x.shape() # torch.Size([12])x.numel() # 元素总数# 可以使用reshape()改变张量的形状而不改变元素数量和元素值x = x.reshape(3, 4)# 使用全0, 全1, 其他常量或从特定分布中随机采样的数字torch.zeros((2,3,4))torch.ones((2,3,4))# 通过提供包含数值的Python列表来为所需张量中的每个元素赋予确定值torch.tensor(array)# 常见的标准算数运算符(+,-*,/,**)都可以被升级为按元素运算torch.exp(x)# 将多个张量连结在一起X = torch.arrange(12, dtype=torch.float32).reshape((3,4))Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])torch.cat((X,Y),dim=0), torch.cat((X,Y), dim=1) # dim=0为按行拼接,dim=1按列拼接# 通过逻辑运算符构建二元张量X == Y# 对张量中的所有元素进行求和会产生一个只有一个元素的张量x.sum()# 即使形状不同，仍然可以通过调用广播机制来执行按元素操作a = torch.arrange(3).reshape((3,1))b = torch.arrange(2).reshape((1,2))a + b# 可以使用[-1]访问最后一个元素,[1:3]访问第1,2个元素x[-1],x[1:3]# 运行一些操作可能会导致为新结果分配内存(内存析构)before = id(Y)Y = Y+Xid(Y) = before# 执行原地操作z = torch.zeros_like(Y)print(id(z))z[:] = X+Yprint(id(z))# 后续计算没有重复使用X，减少内存开销before = id(X)X+=Yid(X) == before# 转换为numpy张量A = x.numpy()B = torch.tensor(A)# 将大小为1的张量转换为python标量a = torch.tensor([3.5])a, a.item, float(a), int(a) 4.2 数据预处理 12345678910111213141516171819202122232425262728293031# 创建一个人工数据集,并存储在csv文件import osos.makedirs(os.path.join(&#x27;..&#x27;,&#x27;data&#x27;), exist_ok=True)data_file = os.makedirs(os.path.join(&#x27;..&#x27;,&#x27;data&#x27;), &#x27;house_tiny.csv&#x27;)with open(data_file, &#x27;w&#x27;) as f: f.write(&#x27;NumRomms,Alley,Price\\n&#x27;) f.write(&#x27;NA,Pave,127500\\n&#x27;) f.write(&#x27;2,NA,106000\\n&#x27;) f.write(&#x27;4,NA,178100\\n&#x27;) f.write(&#x27;NA,NA,140000\\n&#x27;)# 从创建的csv文件中加载原始数据集import pandas as pddata = pd.read_csv(data_file)# 为了处理缺失的数据，典型的方法包括插值和删除# 使用插值inputs, outputs = data.iloc[:,0:2], data.iloc[:,2]inputs = inputs.fillna(inputs.mean()) # 使用均值进行填充print(inputs)# 对于inputs中的类别值或离散值，将Nan视为一个类别inputs = pd.get_dummies(inputs, dummy_na=True) # 将类别值或离散值映射为值# input和outputs中的所有条目都是数值类型，可以转换为张量格式immport torchX, y = torch.tensor(inputs.values), torch.tensor(outputs.values)# 使用float32浮点数进行计算速度较快 4.3 数据操作 123456# reshape 和 view的 区别a = torch.arange(12)b = a.reshape((3, 4))b[:] = 2a# reshape为浅拷贝方式 tensor为张量，为数学上的定义,array为数学上的数组的定义 5 线性代数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394# 标量import torchx = torch.tensor(3.0)y = torch.tensor(2.0)x + y, x * y, x / y, x**y# 向量x = torch.arange(4)# 长度,维度和形状# 访问张量的长度len(x)# 张量的形状x.shape# 矩阵A = torch.arange(20).reshape(5, 4)A.T # 矩阵的转置B == B.T # 对称矩阵,B等于其转置# 张量X = torch.arange(24).reshape(2, 3, 4)# 张量算法的基本性质A = torch.arange(20, dtype=torch.float32).reshape(5, 4)B = A.clone() # 通过分配新内存，将A的一个副本分配给BA, A + B# 两个矩阵按元素乘法为哈达玛积A * B# 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘a = 2X = torch.arange(24).reshape(2, 3, 4)a + X, (a * X).shape# 计算其元素的和x = torch.arange(4, dtype=torch.float32)x, x.sum()# 表示任意形状张量的元素和A = torch.arange(20*2).reshape(2,5,4)A.shape, A.sum()# 指定求和汇总张量的轴# 对哪个维度求和，得到的维度为丢掉该维度，若keepdims则将丢掉的维度设置为 1A_sum_axis0 = A.sum(axis=0)A_sum_axis0, A_sum_axis0.shape()A_sum_axis1 = A.sum(axis=1)A_sum_axis1, A_sum_axis1.shape()# 一个就和相关的量是平均值A.mean(), A.sum() / A.numel()A.mean(axis=0), A.sum(axis=0)/A.shape[0]# 计算总和或均值的保持轴数不变sum_A = A.sum(axis=1,keepdims=True)sum_A# 通过广播将A除以sum_AA/sum_A# 某个轴计算A元素的累积总和A.cumsum(axis=0)# 点积是相同位置的按元素乘积的和y = torch.ones(4, dtype=torch.float32)x, y, torch.dot(x, y)# 可通过执行元素乘法,然后进行求和来表示两向量的点击torch(x*y)# 矩阵向量积AxA.shape, x.shape, torch.mv(A, x)# 矩阵矩阵乘法B = torch.ones(4,3)torch.mm(A, B)# L2范数(对向量)u = torch.tensor([3.0, -4.0])torch.norm(u)# L1范数torch.abs(u).sum()# F范数(矩阵元素的平方和的平方根)torch.norm(torch.ones((4,9))) 对指定维度求和 sum:对哪个维度求和，得到的维度为丢掉该维度，若keepdims则将丢掉的维度设置为 1 6 矩阵计算 7 自动求导 7.1 自动求导 自动求导计算一个函数在指定值上的导数 计算图 将代码分解成操作子 将计算表示成一个无环图 反向累计总结 构造计算图 前向: 执行图,存储中间结果 反向: 从相反方向执行图,去除不需要的枝 复杂度 计算复杂度: 反向:O(n)O(n)O(n),n是操作子个数，正向和反向的代价类似 正向:O(n)O(n)O(n),计算复杂度用来计算一个变量的梯度 内存复杂度: 反向:O(n)O(n)O(n),需要存储正向的所有中间结果,消耗GPU资源 正向:O(1)O(1)O(1) 7.2 自动求导实现 实现对函数y=2xTxy=2x^Txy=2xTx求导 12345678910111213141516171819202122import torch# 关于列向量x求导x = torch.arange(4.0)# 需要一个地方存储梯度x.requires_grad_(True) # 等价于x = torch.arange(4.0, requires_grad=True)x.grad # 默认值None# 计算 yy = 2*torch.dot(x,x)# tensor(28., grad_fn=&lt;MulBackward0&gt;),grad_fn求梯度函数的属性# 通过反向传播函数来自动计算y关于x每个分量的梯度y.backward()x.grad()# 默认情况下,pytorch回累计梯度，需要清除之前的值x.grad.zero_() # 清除之前的值y = x.sum()y.backward()x.grad() 非标量变量的反向传播 当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵 对于高阶和高维的y和x，求导的结果可以是一个高阶张量 然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中），但当调用向量的反向计算时，通常会试图计算一批训练样本中每个组成部分的损失函数的导数(我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。) 1234567# 深度学习中，目的不是计算微分矩阵，而是批量中每个样本单独计算的偏微分之和# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。x.grad.zero_()y = x * x# 等价于y.backward(torch.ones(len(x)))y.sum().backward()x.grad 分离计算:将某些计算移动到记录的计算图之外] 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。需要计算z关于x的梯度，但由于某种原因希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用 可以分离y来返回一个新变量u，该变量与y具有相同的值，但丢弃计算图中如何计算y的任何信息 换句话说，梯度不会向后流经u到x，后面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理，而不是z=x*x*x关于x的偏导数 1234567891011121314151617181920212223242526272829# 将某些计算移动到记录的计算图之外x.grad.zero_()y = x*xu = y.detach() # 将y当作常数,而不是关于x的函数z = u*xz.sum().backward()x.grad == ux.grad.zero_()y.sum().backward()x.grad == 2*x# 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），仍然可以计算得到的变量的梯度def f(a): b = a * 2 while b.norm() &lt; 1000: b = b * 2 if b.sum() &gt; 0: c = b else: c = 100 * b return ca = torch.randn(size=(), requires_grad=True)d = f(a)d.backward()a.grad == d/a pytorch为隐式构造，对控制流的计算较好，但计算速度较显示构造慢 多个损失函数分别反向时需要累计梯度，因此pytorch默认为累计梯度的 8 线性回归+基础优化算法 线性总结 线性回归是对n维输入的加权，外加偏差 使用平方损失来衡量预测值和真实值的差异 线性回归有显示解 线性回归可以看作单层神经网络 梯度下降 挑选一个初始值w0w_0w0​ 重复迭代参数t=1,2,3,wt=wt−1−η∂ℓ∂wt−1t=1,2,3, \\mathbf{w}_t=\\mathbf{w}_{t-1}-\\eta \\frac{\\partial \\ell}{\\partial \\mathbf{w}_{t-1}}t=1,2,3,wt​=wt−1​−η∂wt−1​∂ℓ​ 沿梯度方向将增加损失函数值 学习率:步长的超参数 小批量随机梯度下降 在整个训练集上算梯度太贵，一个深度神经网络模型可能需要数分钟至数小时 可以随机采样b个样本i1,u2,...,ibi_1,u_2,...,i_bi1​,u2​,...,ib​来近似损失,1b∑i∈Ibℓ(xi,yi,w)\\frac{1}{b} \\sum_{i \\in I_b} \\ell\\left(\\mathbf{x}_i, y_i, \\mathbf{w}\\right)b1​∑i∈Ib​​ℓ(xi​,yi​,w) b是批量大小，另一个重要的超参数 批量太小，计算量太小不适合并行来最大利用计算资源 批量太大内存消耗增加，浪费计算 总结 梯度下降通过不断沿着繁体都方向更新参数求解 小批量随机梯度下降是深度学习默认的求解算法 两个重要的超参数是批量大小和学习率 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# ----------------------# 1 线性回归的从零开始实现# ----------------------# 从零开始实现整个方法,包括数据流水线,模型,损失函数和小批量随机梯度下降优化器%matplotlib inlineimport randomimport torchfrom d2l import torch as d2l# 根据带有噪声的线性模型构造一个人造数据集# 使用线性模型参数2=[2,-3,4]T,b=4.2和噪声生成数据集及其标签# 函数def synthetic_data(w, b, num_examples): #@save &quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot; X = torch.normal(0, 1, (num_examples, len(w))) #均值为0,方差为1,大小为(num_examples, len(w))的随机数 y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1))# 生成训练样本true_w = torch.tensor([2, -3.4])true_b = 4.2features, labels = synthetic_data(true_w, true_b, 1000)print(&#x27;features:&#x27;, features[0],&#x27;\\nlabel:&#x27;, labels[0])# 图像观察数据d2l.set_figsize()d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)# 读取数据集# 定义一个data_iter函数,接受批量大小,特征矩阵和标签向量操作为输入,生成大小为batch_size的小批量def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 这些样本是随机读取的，没有特定的顺序 random.shuffle(indices) for i in range(0, num_examples, batch_size): batch_indices = torch.tensor( indices[i: min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] # yield为生成器，每次产生并返回一个随机顺序的特征x和值ybatch_size = 10for X, y in date_iter(batch_size, features, labels): print(X, &#x27;\\n&#x27;, y) break# 定义初始化模型参数w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)b = torch.zeros(1, requires_grad=True)# 定义模型def linreg(X, w, b): #@save &quot;&quot;&quot;线性回归模型&quot;&quot;&quot; return torch.matmul(X, w) + b# 定义损失函数def squared_loss(y_hat, y): #@save &quot;&quot;&quot;均方损失&quot;&quot;&quot; return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2# 定义优化函数def sgd(params, lr, batch_size): #@save # params为输入的数据,lr为学习率,batch_size为批量大小 &quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot; with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_()# 训练过程lr = 0.03num_epochs = 3net = linregloss = squared_lossfor epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X和y的小批量损失 # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起， # 并以此计算关于[w,b]的梯度 l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数 with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f&#x27;epoch &#123;epoch + 1&#125;, loss &#123;float(train_l.mean()):f&#125;&#x27;)# 比较真实参数和通过训练学到的参数来评估训练的成功程度print(f&#x27;w的估计误差: &#123;true_w - w.reshape(true_w.shape)&#125;&#x27;)print(f&#x27;b的估计误差: &#123;true_b - b&#125;&#x27;) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# ----------------# 线性回归的简洁实现# ----------------# 通过使用深度学习框架来简洁实现线性回归模型生成数据集import numpy as npimport torchfrom torch.utils import datafrom d2l import torch as d2ltrue_w = torch.tensor([2, -3.4])true_b = 4.2features, labels = d2l.synthetic_data(true_w, true_b, 1000)# 调用框架中现成的API来读取数据def load_array(data_arrays, batch_size, is_train=True): #@save &quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot; dataset = data.TensorDataset(*data_arrays) return data.DataLoader(dataset, batch_size, shuffle=is_train) # 随机读取batch_size个大小的数据batch_size = 10data_iter = load_array((features, labels), batch_size)# 使用 iter 构造Python迭代器，并使用 next 从迭代器中获取第一项next(iter(data_iter))# 使用框架的预定义好的层# nn是神经网络的缩写from torch import nnnet = nn.Sequential(nn.Linear(2, 1)) # 将该层放在Sequential的容器中，在容器中各层以流水线连接# 初始化模型参数net[0].weight.data.normal_(0, 0.01)net[0].bias.data.fill_(0)# 计算均方误差使用的是MSELoss类,也称为平方范数loss = nn.MSELoss()# 实例化SGD实例trainer = torch.optim.SGD(net.parameters(),lr=0.03)# 训练代码与从零开始实现时所做的非常相似num_epochs = 3for epoch in range(num_epochs): for X, y in data_iter: # 提取数据集X,y l = loss(net(X) ,y) # 计算损失函数, 将数据集X输入给网络 trainer.zero_grad() # 梯度清零，防止累加 l.backward() # 计算梯度，反向传播过程 trainer.step() # 进行模型更新 l = loss(net(features), labels) print(f&#x27;epoch &#123;epoch + 1&#125;, loss &#123;l:f&#125;&#x27;)w = net[0].weight.dataprint(&#x27;w的估计误差：&#x27;, true_w - w.reshape(true_w.shape))b = net[0].bias.dataprint(&#x27;b的估计误差：&#x27;, true_b - b) 为什么使用平方损失而不是绝对差值 平方损失和绝对差值的差别不大，绝对差值是一个不可导的函数，在0点时绝对差值的导数不好求解 损失为什么取平均 本质上没有太大差别，取平均之后梯度数值较小，便于计算。不使用损失取平均，使用学习率除以n也可以 GD和SGD的差别 GD在每次迭代都需要用到全部训练数据 SGD每次迭代可以只用一个训练数据来更新参数 使用生成器生成数据的优势 相比return，需要一个batch运行一遍，并不需要完全设置好 9 Softmax 回归 + 损失函数 + 图片分类数据集 9.1 Softmax 回归 回归 VS 分类 回归估计一个连续值 单连续数值输出,输出为自然区间R\\RR, 跟真实值的区别作为损失 分类预测一个离散类别 通常多个输出,输出i是预测为第i类的置信度 从回归到多类分类——均方损失 对类别进行1为有效编码 y=[y1,y2,...,yn]T,yi={1 if i=y0 otherwise y = [y_1, y_2, ..., y_n]^T, y_i=\\left\\{\\begin{array}{l}1 \\text { if } i=y \\\\ 0 \\text { otherwise }\\end{array}\\right.y=[y1​,y2​,...,yn​]T,yi​={1 if i=y0 otherwise ​ 使用均方损失训练,y^=argmaxi oi\\hat{y} ={argmax}_i \\space o_iy^​=argmaxi​ oi​ 无校验比例: 需要更置信的识别正确类(大余类)，oy−oi≥Δ(y,i)o_y-o_i \\geq \\Delta(y, i)oy​−oi​≥Δ(y,i) 校验比例 输出匹配概率(非负,和为1): y^=softmax⁡(o)\\hat{\\mathbf{y}}=\\operatorname{softmax}(\\mathbf{o})y^​=softmax(o) y^i=exp⁡(oi)∑kexp⁡(ok)\\hat{y}_i=\\frac{\\exp \\left(o_i\\right)}{\\sum_k \\exp \\left(o_k\\right)}y^​i​=∑k​exp(ok​)exp(oi​)​ 概率 yyy 和 y^\\hat{y}y^​ 的区别作为损失 softmax和交叉熵损失 交叉熵常用来衡量两个概率的区别H(p,q)=∑−pilog⁡(qi)H(p,q) = \\sum -p_i \\log(q_i)H(p,q)=∑−pi​log(qi​) 损失函数l(y,y^)=−∑iyilog⁡y^i=−log⁡y^yl(\\mathbf{y}, \\hat{\\mathbf{y}})=-\\sum_i y_i \\log \\hat{y}_i=-\\log \\hat{y}_yl(y,y^​)=−∑i​yi​logy^​i​=−logy^​y​ 梯度是真实概率和预测概率的区别 ∂oil(y,y^)=softmax⁡(0)i−yi\\partial_{o_i} l(\\mathbf{y}, \\hat{\\mathbf{y}})=\\operatorname{softmax}(\\mathbf{0})_i-y_i∂oi​​l(y,y^​)=softmax(0)i​−yi​ 总结 softmax是一个多分类模型 使用softmax操作子得到每个类的预测置信度 使用交叉熵来衡量预测和标号的区别 9.2 损失函数 均方损失L2 Loss: l(y,y′)=12(y−y′)2l\\left(y, y^{\\prime}\\right)=\\frac{1}{2}\\left(y-y^{\\prime}\\right)^2l(y,y′)=21​(y−y′)2 绝对值损失函数L1 Loss : l(y,y′)=∣y−y′∣l(y,y^{&#x27;})=|y-y^{&#x27;}|l(y,y′)=∣y−y′∣ 当预测值和真值相距较远时，梯度仍然较大，参数更新速度不变，但 0 点处不可导，不平滑，优化末期时会不稳定 Huber损失函数：l(y,y′)={∣y−y′∣−12 if ∣y−y′∣&gt;112(y−y′)2 otherwise l\\left(y, y^{\\prime}\\right)= \\begin{cases}\\left|y-y^{\\prime}\\right|-\\frac{1}{2} &amp; \\text { if }\\left|y-y^{\\prime}\\right|&gt;1 \\\\ \\frac{1}{2}\\left(y-y^{\\prime}\\right)^2 &amp; \\text { otherwise }\\end{cases}l(y,y′)={∣y−y′∣−21​21​(y−y′)2​ if ∣y−y′∣&gt;1 otherwise ​ 综合上述两个损失函数的特点,当预测值和真值相差较大时参数更新速度不变，在优化末期，梯度更新速度会越来越小，优化较为平滑 9.3 图片分类数据集 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# MNIST数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单# 将使用类似但更复杂的Fashion-MNIST数据集%matplotlib inlineimport torchimport torchvisionfrom torch.utils import datafrom torchvision import transformsfrom d2l import torch as d2ld2l.use_svg_display()# 通过框架中的内置函数将Fashion-MNIST数据集下载并读取到内存中# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，# 并除以255使得所有像素的数值均在0到1之间trans = transforms.ToTensor()mnist_train = torchvision.datasets.FashionMNIST( root=&quot;../data&quot;, train=True, transform=trans, download=True)mnist_test = torchvision.datasets.FashionMNIST( root=&quot;../data&quot;, train=False, transform=trans, download=True)# Fashion-MNIST由10个类别的图像组成，每个类别由训练数据集train dataset中的6000张图像和测试数据集test dataset中的1000张图像组成len(mnist_train), len(mnist_test)# 每个输入图像的高度和宽度均为28像素,数据集由灰度图像组成，其通道数为1mnist_train[0][0].shape# 可视化数据集的函数def get_fashion_mnist_labels(labels): #@save &quot;&quot;&quot;返回Fashion-MNIST数据集的文本标签&quot;&quot;&quot; text_labels = [&#x27;t-shirt&#x27;, &#x27;trouser&#x27;, &#x27;pullover&#x27;, &#x27;dress&#x27;, &#x27;coat&#x27;, &#x27;sandal&#x27;, &#x27;shirt&#x27;, &#x27;sneaker&#x27;, &#x27;bag&#x27;, &#x27;ankle boot&#x27;] return [text_labels[int(i)] for i in labels]def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save &quot;&quot;&quot;绘制图像列表&quot;&quot;&quot; figsize = (num_cols * scale, num_rows * scale) _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize) axes = axes.flatten() for i, (ax, img) in enumerate(zip(axes, imgs)): if torch.is_tensor(img): # 图片张量 ax.imshow(img.numpy()) else: # PIL图片 ax.imshow(img) ax.axes.get_xaxis().set_visible(False) ax.axes.get_yaxis().set_visible(False) if titles: ax.set_title(titles[i]) return axes# 几个样本的图像及其标签X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));# 读取一小批量数据,大小为batch_sizebatch_size = 256def get_dataloader_workers(): #@save &quot;&quot;&quot;使用4个进程来读取数据&quot;&quot;&quot; return 4train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers())timer = d2l.Timer()for X, y in train_iter: continuef&#x27;&#123;timer.stop():.2f&#125; sec&#x27;# 整合成 load_data_fashion_minist函数def load_data_fashion_mnist(batch_size, resize=None): #@save &quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot; trans = [transforms.ToTensor()] if resize: trans.insert(0, transforms.Resize(resize)) trans = transforms.Compose(trans) mnist_train = torchvision.datasets.FashionMNIST( root=&quot;../data&quot;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=&quot;../data&quot;, train=False, transform=trans, download=True) return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) 9.4 softmax回归从零开始实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171# softmax回归的从零开始实现import torchfrom IPython import displayfrom d2l import torch as d2lbatch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)# 将展平每个图像，将它们视为长度为784的向量# 因为数据集有10个类别，所以网络输出维度为10num_inputs = 784num_outputs = 10W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)b = torch.zeros(num_outputs, requires_grad=True)# 定义softmax操作def softmax(X): X_exp = torch.exp(X) partition = X_exp.sum(1, keepdim=True) # 按行求和[784,1] return X_exp / partition # 这里应用了广播机制# 验证softmax操作:根据概率原理，每行总和为1X = torch.normal(0, 1, (2, 5))X_prob = softmax(X)X_prob, X_prob.sum(1)# 实现softmax回归模型def net(X): return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)# 定义交叉熵损失函数def cross_entropy(y_hat, y): return - torch.log(y_hat[range(len(y_hat)), y])# 将预测类别与真实y元素进行比较def accuracy(y_hat, y): #@save &quot;&quot;&quot;计算预测正确的数量&quot;&quot;&quot; if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1: y_hat = y_hat.argmax(axis=1) cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum())# 评估在任意模型net的准确度def evaluate_accuracy(net, data_iter): #@save &quot;&quot;&quot;计算在指定数据集上模型的精度&quot;&quot;&quot; if isinstance(net, torch.nn.Module): net.eval() # 将模型设置为评估模式 metric = Accumulator(2) # 正确预测数、预测总数 with torch.no_grad(): for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1]# Accumulator实例中创建了2个变量,用于分别存储正确预测的数量和预测的总数量class Accumulator: #@save &quot;&quot;&quot;在n个变量上累加&quot;&quot;&quot; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx]# softmax回归的训练def train_epoch_ch3(net, train_iter, loss, updater): #@save &quot;&quot;&quot;训练模型一个迭代周期（定义见第3章）&quot;&quot;&quot; # 将模型设置为训练模式 if isinstance(net, torch.nn.Module): net.train() # 训练损失总和、训练准确度总和、样本数 metric = Accumulator(3) for X, y in train_iter: # 计算梯度并更新参数 y_hat = net(X) l = loss(y_hat, y) if isinstance(updater, torch.optim.Optimizer): # 使用PyTorch内置的优化器和损失函数 updater.zero_grad() l.mean().backward() updater.step() else: # 使用定制的优化器和损失函数 l.sum().backward() updater(X.shape[0]) metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # 返回训练损失和训练精度 return metric[0] / metric[2], metric[1] / metric[2]# 定义一个在动画中绘制数据的实用程序类class Animator: #@save &quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot; def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale=&#x27;linear&#x27;, yscale=&#x27;linear&#x27;, fmts=(&#x27;-&#x27;, &#x27;m--&#x27;, &#x27;g-.&#x27;, &#x27;r:&#x27;), nrows=1, ncols=1, figsize=(3.5, 2.5)): # 增量地绘制多条线 if legend is None: legend = [] d2l.use_svg_display() self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize) if nrows * ncols == 1: self.axes = [self.axes, ] # 使用lambda函数捕获参数 self.config_axes = lambda: d2l.set_axes( self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts = None, None, fmts def add(self, x, y): # 向图表中添加多个数据点 if not hasattr(y, &quot;__len__&quot;): y = [y] n = len(y) if not hasattr(x, &quot;__len__&quot;): x = [x] * n if not self.X: self.X = [[] for _ in range(n)] if not self.Y: self.Y = [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) self.Y[i].append(b) self.axes[0].cla() for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait=True)# 训练函数def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save &quot;&quot;&quot;训练模型&quot;&quot;&quot; animator = Animator(xlabel=&#x27;epoch&#x27;, xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[&#x27;train loss&#x27;, &#x27;train acc&#x27;, &#x27;test acc&#x27;]) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) animator.add(epoch + 1, train_metrics + (test_acc,)) train_loss, train_acc = train_metrics assert train_loss &lt; 0.5, train_loss assert train_acc &lt;= 1 and train_acc &gt; 0.7, train_acc assert test_acc &lt;= 1 and test_acc &gt; 0.7, test_acc# 小批量随机梯度下降来优化模型的损失函数lr = 0.1def updater(batch_size): return d2l.sgd([W, b], lr, batch_size)# 训练模型10个迭代周期num_epochs = 10train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)# 预测def predict_ch3(net, test_iter, n=6): #@save &quot;&quot;&quot;预测标签&quot;&quot;&quot; for X, y in test_iter: break trues = d2l.get_fashion_mnist_labels(y) preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) titles = [true +&#x27;\\n&#x27; + pred for true, pred in zip(trues, preds)] d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])predict_ch3(net, test_iter) 9.5 softmax的简洁实现 12345678910111213141516171819202122232425262728# 通过深度学习框架的高级API能够很容易的实现softmax回归import torchfrom torch import nnfrom d2l import torch as d2lbatch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)# softmax回归的输出层是一个全连接层# PyTorch不会隐式地调整输入的形状。因此，在线性层前定义了展平层（flatten），来调整网络输入的形状# 展平层（flatten）将任何维度的tensor转换为2维tensor, 将第0维保留，其他维度转换为向量net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))def init_weights(m): if type(m) == nn.Linear: # 如果为线性层 nn.init.normal_(m.weight, std=0.01) # 将weight设置为均值为0，方差为0.01的随机值net.apply(init_weights); # 在net的每一层使用init_weights函数# 在交叉熵损失函数中传递未归一化的预测，同时计算softmax及其对数loss = nn.CorssEntropyLoss()# 使用学习率为0.1的小批量随机梯度下降作为优化算法trainer = torch.optim.SGD(net.parameters(), lr=0.1)# 调用之前定义的训练函数来训练模型num_epochs = 10d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 9.6 QA hard label 更容易标注,但会丢失类内,类间的关联并且引入噪声 softlabel 给模型带来更返回能力,携带更多信息，对噪声鲁棒 softlabel训练策略 在hard label监督下，由于softmax的作用,one-hot的最大值位置无限往1优化，但永远不可能等于1，达到一定优化程度后达到饱和区,可以保证优化过程处于优化效率最高的中间区域，避免进入饱和区 使用one-hot编码会使不正确的类变为0, 因此损失函数不计不正确的类,实际上是关心不正确的类 最小化损失等价于最大化似然函数，统计学中的概念 在计算精度时使用eval()将模型设置为评估模式可以避免在评估模式时计算梯度 10 多层感知机+代码实现 10.1 感知机 给定输入xxx, 权重www, 和偏移b， 感知机输出o=σ(⟨w,x⟩+b)σ(x)={1 if x&gt;0−1 otherwise o=\\sigma(\\langle\\mathbf{w}, \\mathbf{x}\\rangle+b) \\quad \\sigma(x)= \\begin{cases}1 &amp; \\text { if } x&gt;0 \\\\ -1 &amp; \\text { otherwise }\\end{cases}o=σ(⟨w,x⟩+b)σ(x)={1−1​ if x&gt;0 otherwise ​ 二分类:-1或1 回归输出实数,Softmax输出概率 训练感知机 等价于使用批量大小为1的梯度下降,并使用损失函数l(y,x,w)=max(0,−y&lt;w,x&gt;)l(y,x,w)=max(0, -y&lt;w,x&gt;)l(y,x,w)=max(0,−y&lt;w,x&gt;) 当分类正确时，相当于−y&lt;w,x&gt;-y&lt;w,x&gt;−y&lt;w,x&gt;小于0，则损失函数为0，不进行更新 收敛定理 数据在半径rrr内 余量 ρ分类两类：y(xTw+b)&gt;=ρ,对于∣∣w∣∣2+b2&lt;=1\\rho 分类两类： y(x^Tw+b) &gt;= \\rho, 对于||w||^2+b^2 &lt;= 1ρ分类两类：y(xTw+b)&gt;=ρ,对于∣∣w∣∣2+b2&lt;=1 感知机保证在r2+1ρ2\\frac{r^2+1}{\\rho^2}ρ2r2+1​步后收敛 10.2 多层感知机 上述问题需要实现异或操作,一个分类器无法实现，则使用多个分类器组合 隐藏层大小是超参数 单隐藏层——单分类 输入: x∈Rnx \\in \\R^{n}x∈Rn 隐藏层: W1∈Rm∗n,b1∈RmW_1 \\in \\R^{m*n}, b_1 \\in \\R^mW1​∈Rm∗n,b1​∈Rm 输出层: w2∈Rm,b2∈Rw_2 \\in \\R^m, b_2 \\in \\Rw2​∈Rm,b2​∈R -h=σ(W1x+b1),σh = \\sigma(W_1x+b_1),\\sigmah=σ(W1​x+b1​),σ是按元素的激活函数，激活函数为非线性函数 -o=w2Th+b2o=w_2^Th+b_2o=w2T​h+b2​ 激活函数 sigmoid函数：将输入投影到(0, 1) tanh激活函数: 将输入投影到(-1, 1) ReLu函数: ReLu = max(x, 0) 多类分类: y1,...yk=softmax(o1,...ok)y_1,...y_k=softmax(o_1,...o_k)y1​,...yk​=softmax(o1​,...ok​) 与softmax回归的唯一区别，添加了隐藏层 输入: x∈Rnx \\in \\R^{n}x∈Rn 隐藏层: W1∈Rm∗n,b1∈RmW_1 \\in \\R^{m*n}, b_1 \\in \\R^mW1​∈Rm∗n,b1​∈Rm 输出层: w2∈Rm∗k,b2∈Rkw_2 \\in \\R^{m*k}, b_2 \\in \\R^kw2​∈Rm∗k,b2​∈Rk -h=σ(W1x+b1)h = \\sigma(W_1x+b_1)h=σ(W1​x+b1​) -o=w2Th+b2o=w_2^Th+b_2o=w2T​h+b2​ -y=softmax(o)y=softmax(o)y=softmax(o) 可以使用多隐藏层: -h1=σ(W1x+b1)h_1 = \\sigma(W_1x+b_1)h1​=σ(W1​x+b1​) -h2=σ(W2h1+b2)h_2 = \\sigma(W_2h_1+b_2)h2​=σ(W2​h1​+b2​) -h2=σ(W3h2+b3)h_2 = \\sigma(W_3h_2+b_3)h2​=σ(W3​h2​+b3​) -o=w4Th3+b4o=w_4^Th_3+b_4o=w4T​h3​+b4​ 超参数 隐藏层数 每层隐藏层的大小 多隐藏层时，隐藏层的大小越往后越压缩，最好是慢慢做压缩，不断对信息做提炼，在一开始可以比输入层稍大一点，扩充数据，（但在CNN中会有先压缩再扩张的模型） 10.3 多层感知机的实现 12345678910111213141516171819202122232425262728293031323334353637383940# 1 多层感知机的从零开始实现import torchfrom torch import nnfrom d2l import torch as d2lbatch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)# 实现一个具有单隐藏层的多层感知机,包含256个隐藏单元num_inputs, num_outputs, num_hiddens = 784, 10, 256W1 = nn.Parameter(torch.randn( num_inputs, num_hiddens, requires_grad=True) * 0.01)b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))W2 = nn.Parameter(torch.randn( num_hiddens, num_outputs, requires_grad=True) * 0.01)b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))params = [W1, b1, W2, b2]# 实现ReLu激活函数def relu(X): a = torch.zeros_like(X) return torch.max(X, a)# 实现模型def net(X): X = X.reshape((-1, num_inputs)) H = relu(X @ W1 + b1) # @表示矩阵乘法 return (H @ W2 + b2)loss = nn.CrossEntropyLoss(reduction=&#x27;none&#x27;)# 训练num_epochs, lr = 10, 0.1updater = torch.optim.SGD(params, lr=lr)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)# 预测d2l.predict_ch3(net, test_iter) 多层感知机的精度和softmax回归的精度差别不大，损失减小 使用MLP(多层感知机)而不是SVM的原因:MLP方便之后效果不好时调整模型，代码方便实现 123456789101112131415161718192021222324# 2 多层感知机的简洁实现import torchfrom torch import nnfrom d2l import torch as d2l# 隐藏层包含256个隐藏单元,并使用了ReLu激活函数net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10))def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01)net.apply(init_weights);# 训练过程, 与之前相同batch_size, lr, num_epochs = 256, 0.1, 10loss = nn.CrossEntropyLoss(reduction=&#x27;none&#x27;)trainer = torch.optim.SGD(net.parameters(), lr=lr)train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 10.4 QA 神经网络中一般使用增加隐藏层的层数，而不是神经元个数 因为一层中神经元个数太多，网络较难训练 不同任务下的激活函数本质上区别不大，该超参数的调节意义较小 一般使用ReLu即可 11 模型选择 + 过拟合和欠拟合 11.1 模型选择 训练误差和泛化误差 训练误差:模型在训练数据上的误差 泛化误差：模型在新数据上的误差 验证数据集和测试数据集 验证数据集：一个用来评估模型好坏的数据集 经常称为test_data，但是是错误的 测试数据集：只用一次的数据集 解决数据集数量不足的问题:K-折交叉验证 在没有足够多数据时使用 算法 将驯良数据分割成K块 For i=1,…,K 使用第i块作为验证数据集，其余的作为训练数据集 报告K个验证集误差的平均 常用K=5,或K=10 11.2 过拟合和欠拟合 模型容量 拟合各种函数的能力 低容量的模型难以拟合训练数据 高容量的模型可以记住所有的训练数据 在模型足够大的前提下，控制模型容量是泛化误差向下降，泛化误差和训练误差的gap变小，可以容忍一定程度的过拟合 模型容量的两个主要因素：参数的个数和参数值的选择范围 VC维 对于一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号，都存在一个模型来对它进行完美分类 二维输入的感知机，VC维=3 能够分类任何3个点，而不是4个(xor) 支持N维输入的感知机的VC维是N+1 一些多层感知机的VC维是O(Nlog2N)O(Nlog_2N)O(Nlog2​N) 深度学习中很少使用，衡量不是很准确，且计算较难 数据复杂度 多个重要因素:样本个数,每个样本的元素个数,时间和空间结构,多样性 11.3 代码 使用多项式来生成训练和测试数据的标签：y=5+1.2x−3.4x22!+5.6x33!+ϵ where ϵ∼N(0,0.12).y = 5 + 1.2x - 3.4\\frac{x^2}{2!} + 5.6 \\frac{x^3}{3!} + \\epsilon \\text{ where }\\epsilon \\sim \\mathcal{N}(0, 0.1^2).y=5+1.2x−3.42!x2​+5.63!x3​+ϵ where ϵ∼N(0,0.12). 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 1 模型选择,欠拟合和过拟合# 通过多项式拟合来交互探索这些概念import mathimport numpy as npimport torchfrom torch import nnfrom d2l import torch as d2l# 生成训练和测试数据标签max_degree = 20 # 多项式的最大阶数n_train, n_test = 100, 100 # 训练和测试数据集大小true_w = np.zeros(max_degree) # 分配大量的空间true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])features = np.random.normal(size=(n_train + n_test, 1))np.random.shuffle(features)poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))for i in range(max_degree): poly_features[:, i] /= math.gamma(i + 1) # gamma(n)=(n-1)!# labels的维度:(n_train+n_test,)labels = np.dot(poly_features, true_w)labels += np.random.normal(scale=0.1, size=labels.shape)# 看一下前2个样本# NumPy ndarray转换为tensortrue_w, features, poly_features, labels = [torch.tensor(x, dtype= torch.float32) for x in [true_w, features, poly_features, labels]]features[:2], poly_features[:2, :], labels[:2]# 实现一个函数来评估模型在给定数据集上的损失def evaluate_loss(net, data_iter, loss): #@save &quot;&quot;&quot;评估给定数据集上模型的损失&quot;&quot;&quot; metric = d2l.Accumulator(2) # 损失的总和,样本数量 for X, y in data_iter: out = net(X) y = y.reshape(out.shape) l = loss(out, y) metric.add(l.sum(), l.numel()) return metric[0] / metric[1]# 定义训练函数def train(train_features, test_features, train_labels, test_labels, num_epochs=400): loss = nn.MSELoss(reduction=&#x27;none&#x27;) input_shape = train_features.shape[-1] # 不设置偏置，因为我们已经在多项式中实现了它 net = nn.Sequential(nn.Linear(input_shape, 1, bias=False)) batch_size = min(10, train_labels.shape[0]) train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)), batch_size) test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)), batch_size, is_train=False) trainer = torch.optim.SGD(net.parameters(), lr=0.01) animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss&#x27;, yscale=&#x27;log&#x27;, xlim=[1, num_epochs], ylim=[1e-3, 1e2], legend=[&#x27;train&#x27;, &#x27;test&#x27;]) for epoch in range(num_epochs): d2l.train_epoch_ch3(net, train_iter, loss, trainer) if epoch == 0 or (epoch + 1) % 20 == 0: animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss), evaluate_loss(net, test_iter, loss))) print(&#x27;weight:&#x27;, net[0].weight.data.numpy())# 三阶多项式函数拟合(正确)# 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3!train(poly_features[:n_train, :4], poly_features[n_train:, :4], labels[:n_train], labels[n_train:])# 线性函数拟合(欠拟合)# 从多项式特征中选择前2个维度，即1和xtrain(poly_features[:n_train, :2], poly_features[n_train:, :2], labels[:n_train], labels[n_train:])# 高阶多项式函数拟合(过拟合)# 从多项式特征中选取所有维度train(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:], num_epochs=1500) 12 权重衰退 12.1 权重衰退 使用均方范数作为硬性限制 权重衰退，通过限制参数值的选择范围来控制模型容量: min l(w,b) subjectto∣∣w∣∣2&lt;=θmin \\space l(w,b) \\space subject to ||w||^2 &lt;= \\thetamin l(w,b) subjectto∣∣w∣∣2&lt;=θ 通常不限制偏移 b (限制不限制都差不多) 小的 θ\\thetaθ 意味着更强的正则项 使用均方单数作为柔性限制 对于每个 θ\\thetaθ，都可以找到 λ\\lambdaλ 使之前的目标函数等价于 min l(w,b)+λ2∣∣w∣∣2min \\space l(w,b)+\\frac{\\lambda}{2}||w||^2min l(w,b)+2λ​∣∣w∣∣2,(可通过拉格朗日乘子来证明) 超参数 λ\\lambdaλ 控制了正则项的重要程度 -λ=0\\lambda=0λ=0:无作用 -λ→inf⁡,w∗→0\\lambda \\rightarrow \\inf, w^* \\rightarrow 0λ→inf,w∗→0 参数更新法则 计算梯度:∂∂w(ℓ(w,b)+λ2∥w∥2)=∂ℓ(w,b)∂w+λw\\frac{\\partial}{\\partial \\mathbf{w}}\\left(\\ell(\\mathbf{w}, b)+\\frac{\\lambda}{2}\\|\\mathbf{w}\\|^2\\right)=\\frac{\\partial \\ell(\\mathbf{w}, b)}{\\partial \\mathbf{w}}+\\lambda \\mathbf{w}∂w∂​(ℓ(w,b)+2λ​∥w∥2)=∂w∂ℓ(w,b)​+λw 时间t更新参数:wt+1=(1−ηλ)wt−η∂ℓ(wt,bt)∂wt\\mathbf{w}_{t+1}=(1-\\eta \\lambda) \\mathbf{w}_t-\\eta \\frac{\\partial \\ell\\left(\\mathbf{w}_t, b_t\\right)}{\\partial \\mathbf{w}_t}wt+1​=(1−ηλ)wt​−η∂wt​∂ℓ(wt​,bt​)​ 通常ηλ&lt;1\\eta \\lambda &lt; 1ηλ&lt;1,在深度学习中通常叫做权重衰退 权重衰退用来可解决欠拟合问题 12.2 代码实现 生成数据的公式: y=0.05+∑i=1d0.01xi+ϵ where ϵ∼N(0,0.012).y = 0.05 + \\sum_{i = 1}^d 0.01 x_i + \\epsilon \\text{ where }\\epsilon \\sim \\mathcal{N}(0, 0.01^2).y=0.05+∑i=1d​0.01xi​+ϵ where ϵ∼N(0,0.012). 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 1 权重衰退的从零开始实现# 权重衰退是最广泛使用的正则化技术之一%matplotlib inlineimport torchfrom torch import nnfrom d2l import torch as d2l# 生成数据集n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5 # 训练数据容易发生过拟合true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05train_data = d2l.synthetic_data(true_w, true_b, n_train)train_iter = d2l.load_array(train_data, batch_size)test_data = d2l.synthetic_data(true_w, true_b, n_test)test_iter = d2l.load_array(test_data, batch_size, is_train=False)# 初始化模型参数def init_params(): w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) return [w, b]# 定义L2范数惩罚def l2_penalty(w): return torch.sum(w.pow(2)) / 2# 定义训练代码实现def train(lambd): w, b = init_params() net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss num_epochs, lr = 100, 0.003 animator = d2l.Animator(xlabel=&#x27;epochs&#x27;, ylabel=&#x27;loss&#x27;, yscale=&#x27;log&#x27;, xlim=[5, num_epochs], legend=[&#x27;train&#x27;, &#x27;test&#x27;]) for epoch in range(num_epochs): for X, y in train_iter: # 增加了L2范数惩罚项， # 广播机制使l2_penalty(w)成为一个长度为batch_size的向量 l = loss(net(X), y) + lambd * l2_penalty(w) l.sum().backward() d2l.sgd([w, b], lr, batch_size) if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print(&#x27;w的L2范数是：&#x27;, torch.norm(w).item())# 忽略正则化训练train(lambd=0)# 使用权重衰减train(lambd=3)# 2 权重衰减的简洁实现# 其中使用weight-decay实现权重衰退,即W每次减小def train_concise(wd): net = nn.Sequential(nn.Linear(num_inputs, 1)) for param in net.parameters(): param.data.normal_() loss = nn.MSELoss(reduction=&#x27;none&#x27;) num_epochs, lr = 100, 0.003 # 偏置参数没有衰减 trainer = torch.optim.SGD([ &#123;&quot;params&quot;:net[0].weight, &#x27;weight_decay&#x27;: wd&#125;, &#123;&quot;params&quot;:net[0].bias&#125;], lr=lr) animator = d2l.Animator(xlabel=&#x27;epochs&#x27;, ylabel=&#x27;loss&#x27;, yscale=&#x27;log&#x27;, xlim=[5, num_epochs], legend=[&#x27;train&#x27;, &#x27;test&#x27;]) for epoch in range(num_epochs): for X, y in train_iter: trainer.zero_grad() l = loss(net(X), y) l.mean().backward() trainer.step() if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print(&#x27;w的L2范数：&#x27;, net[0].weight.norm().item())# 忽略正则化训练train_concise(0)# 使用权重衰退train_concise(3) 12.3 QA 一般权重衰减的值取10e0,10e-1,10e-2,10e-3,10e-4 权重衰退的效果有限，使用时初始设置10e-3即可 13 丢弃法 13.1 丢弃法(dropout) 动机 一个好的模型需要对输入数据的扰动鲁棒 使用有噪声的数据等价于Tikhonov正则 丢弃法:在层之间加入噪音 无偏差的加入噪音 对 xxx 加入噪音得到 x′x^{&#x27;}x′，但希望 E(x′)=xE(x^{&#x27;}) = xE(x′)=x 丢弃法对每个元素进行扰动：xi′={0 with probablity pxi1−p otherise x_i^{\\prime}= \\begin{cases}0 &amp; \\text { with probablity } p \\\\ \\frac{x_i}{1-p} &amp; \\text { otherise }\\end{cases}xi′​={01−pxi​​​ with probablity p otherise ​，不改变数据的期望 dropout参数p为丢弃的节点的概率 使用丢弃法：通常将丢弃法作用在隐藏全连接层的输出上 -h=σ(W1x+b1)h=\\sigma(W_1x+b_1)h=σ(W1​x+b1​) -h′=dropout(h)h^{&#x27;} = dropout(h)h′=dropout(h) -o=W2h′+b2o = W_2h^{&#x27;}+b_2o=W2​h′+b2​ y = softmax(o) 推理中的丢弃法 正则项只在训练中使用：影响模型参数的更新 在推理过程中，丢弃法直接返回输入: h=dropout(h)h = dropout(h)h=dropout(h) 保证确定性的输出 总结 丢弃法将一些输出项随机置0来控制模型复杂度 常作用在多层感知机的隐藏层输出上 丢弃概率是控制模型复杂度的超参数 13.2 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# 1 Dropout的从零开始实现# 实现dropout_layer函数,该函数以dropout的概率丢弃张量输入x中的元素import torchfrom torch import nnfrom d2l import torch as d2ldef dropout_layer(X, dropout): assert 0 &lt;= dropout &lt;= 1 # 在本情况中，所有元素都被丢弃 if dropout == 1: return torch.zeros_like(X) # 在本情况中，所有元素都被保留 if dropout == 0: return X mask = (torch.rand(X.shape) &gt; dropout).float() # 在GPU或CPU中做乘法比选元素的效率快 return mask * X / (1.0 - dropout)# 测试dropout_layer函数X= torch.arange(16, dtype = torch.float32).reshape((2, 8))print(X)print(dropout_layer(X, 0.))print(dropout_layer(X, 0.5))print(dropout_layer(X, 1.))# 定义具有两个隐藏层的多层感知机,每个隐藏层包含256个单元num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256dropout1, dropout2 = 0.2, 0.5class Net(nn.Module): def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training = True): super(Net, self).__init__() self.num_inputs = num_inputs self.training = is_training self.lin1 = nn.Linear(num_inputs, num_hiddens1) self.lin2 = nn.Linear(num_hiddens1, num_hiddens2) self.lin3 = nn.Linear(num_hiddens2, num_outputs) self.relu = nn.ReLU() def forward(self, X): H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs)))) # 只有在训练模型时才使用dropout if self.training == True: # 在第一个全连接层之后添加一个dropout层 H1 = dropout_layer(H1, dropout1) H2 = self.relu(self.lin2(H1)) if self.training == True: # 在第二个全连接层之后添加一个dropout层 H2 = dropout_layer(H2, dropout2) out = self.lin3(H2) return outnet = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)# 训练和测试num_epochs, lr, batch_size = 10, 0.5, 256loss = nn.CrossEntropyLoss(reduction=&#x27;none&#x27;)train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)trainer = torch.optim.SGD(net.parameters(), lr=lr)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)# 2 Dropout的简洁实现net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), # 在第一个全连接层之后添加一个dropout层 nn.Dropout(dropout1), nn.Linear(256, 256), nn.ReLU(), # 在第二个全连接层之后添加一个dropout层 nn.Dropout(dropout2), nn.Linear(256, 10))def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01)net.apply(init_weights)# 训练trainer = torch.optim.SGD(net.parameters(), lr=lr)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 13.3 QA dropout随机置0的地方梯度也为0，dropout随机置0的地方的权重在该轮不被更新 BN为卷积层使用的，dropout为全连接层使用的 BN层，可以加快网络的训练和收敛的速度，控制梯度爆炸防止梯度消失，防止过拟合 dropout改变的为隐藏层的输出 也可以改变标签实现正则化(CV中会使用) dropout和权重衰减为两种解决过拟合的方法 权重衰减weight_weak更为常用可以在CNN等中使用 dropout更容易调参 训练一个单隐藏层的全连接MLP，隐藏层不使用dropout为64，而使用dropout=0.5隐藏层为128，效果可能较好，需要让模型更强而使用正则使模型学偏 14 数值稳定性 + 模型初始化和激活函数 14.1 数值稳定性 神经网络的梯度 考虑有d层的神经网络: h^t=f_t(h^{t-1}) \\space and \\space y=l_d_d_...*f_1(x) 计算损失关于参数的梯度: ∂ℓ∂Wt=∂ℓ∂hd∂hd∂hd−1…∂ht+1∂ht∂ht∂Wt\\frac{\\partial \\ell}{\\partial \\mathbf{W}^t}=\\frac{\\partial \\ell}{\\partial \\mathbf{h}^d} \\frac{\\partial \\mathbf{h}^d}{\\partial \\mathbf{h}^{d-1}} \\ldots \\frac{\\partial \\mathbf{h}^{t+1}}{\\partial \\mathbf{h}^t} \\frac{\\partial \\mathbf{h}^t}{\\partial \\mathbf{W}^t}∂Wt∂ℓ​=∂hd∂ℓ​∂hd−1∂hd​…∂ht∂ht+1​∂Wt∂ht​ 上述表达式中间计算了d−td-td−t次矩阵乘法 太多矩阵乘法会带来梯度爆炸和梯度消失的问题 梯度爆炸的问题 值超出值域(对float16尤为严重,GPU对float16运算速度较快) 对学习率敏感 学习率太大-&gt;大参数值-&gt;更大的梯度 学习率太小-&gt;训练无进展 可能需要在训练过程不断调整学习率 梯度消失的问题 梯度值变成0(对float16尤为严重) 训练没有进展,不管如何选择学习率 对于底部层尤为严重，仅仅顶部层训练的较好,无法让神经网络更深 14.2 模型初始化和激活函数 让训练更加稳定 目标：让梯度值在合理的范围内 让乘法变成加法: ResNet,LSTM 归一化: 梯度归一化,梯度裁剪 合理的权重初始和激活函数 将神经网络设计的每层设计为如下形式可以使训练更加稳定 让每层的方差都是一个常数 让每层的输出和梯度都看作随机变量 让均值和方差都保持一致 - 正向 反向 E[hit]=0E[∂ℓ∂hit]=0Var⁡[∂ℓ∂hit]=b∀i,tVar⁡[hit]=a\\begin{array}{cc}\\text { 正向 } &amp; \\text { 反向 } \\\\ \\mathbb{E}\\left[h_i^t\\right]=0 &amp; \\mathbb{E}\\left[\\frac{\\partial \\ell}{\\partial h_i^t}\\right]=0 \\quad \\operatorname{Var}\\left[\\frac{\\partial \\ell}{\\partial h_i^t}\\right]=b \\quad \\forall i, t \\\\ \\operatorname{Var}\\left[h_i^t\\right] =a \\end{array} 正向 E[hit​]=0Var[hit​]=a​ 反向 E[∂hit​∂ℓ​]=0Var[∂hit​∂ℓ​]=b∀i,t​,a和b都是常数 具体做法 权重初始化：在合理区间里随机初始参数 训练开始的时候更容易有数值不稳定 远离最优解的地方损失函数表面可能很复杂 最优解附近表面比较平 使用N(0,0.01)N(0,0.01)N(0,0.01)来初始可能对小网络没问题，但不能保证深度神经网络 例子MLP 假设 -wi,jtw_{i, j}^twi,jt​ 是 i.i.d, 那么E [wi,jt]=0,Var⁡[wi,jt]=γt\\left[w_{i, j}^t\\right]=0, \\operatorname{Var}\\left[w_{i, j}^t\\right]=\\gamma_t[wi,jt​]=0,Var[wi,jt​]=γt​ -hit−1h_i^{t-1}hit−1​ 独立于 wi,jtw_{i, j}^twi,jt​ 假设没有激活函数 ht=Wtht−1\\mathbf{h}^t=\\mathbf{W}^t \\mathbf{h}^{t-1}ht=Wtht−1, 这里 Wt∈Rnl×nt−1\\mathbf{W}^t \\in \\mathbb{R}^{n_l \\times n_{t-1}}Wt∈Rnl​×nt−1​ -E[hit]=E[∑jwi,jthjt−1]=∑jE[wi,jt]E[hjt−1]=0\\mathbb{E}\\left[h_i^t\\right]=\\mathbb{E}\\left[\\sum_j w_{i, j}^t h_j^{t-1}\\right]=\\sum_j \\mathbb{E}\\left[w_{i, j}^t\\right] \\mathbb{E}\\left[h_j^{t-1}\\right]=0E[hit​]=E[∑j​wi,jt​hjt−1​]=∑j​E[wi,jt​]E[hjt−1​]=0 正向方差:Var⁡[(hit)2]=nt−1γtVar⁡[hjt−1]\\operatorname{Var}\\left[(h_{i}^t)^2\\right]=n_{t-1} \\gamma_t \\operatorname{Var}\\left[h_j^{t-1}\\right]Var[(hit​)2]=nt−1​γt​Var[hjt−1​] 假设输入方差和输出方差一致,则nt−1γt=1n_{t-1} \\gamma_t = 1nt−1​γt​=1 反向均值和方差 -∂ℓ∂ht−1=∂ℓ∂htWt→(∂ℓ∂ht−1)T=(Wt)T(∂ℓ∂ht)T\\frac{\\partial \\ell}{\\partial \\mathbf{h}^{t-1}}=\\frac{\\partial \\ell}{\\partial \\mathbf{h}^t} \\mathbf{W}^t \\rightarrow \\left(\\frac{\\partial \\ell}{\\partial \\mathbf{h}^{t-1}}\\right)^T=\\left(W^t\\right)^T\\left(\\frac{\\partial \\ell}{\\partial \\mathbf{h}^t}\\right)^T∂ht−1∂ℓ​=∂ht∂ℓ​Wt→(∂ht−1∂ℓ​)T=(Wt)T(∂ht∂ℓ​)T -E[∂ℓ∂hit−1]=0\\mathbb{E}\\left[\\frac{\\partial \\ell}{\\partial h_i^{t-1}}\\right]=0E[∂hit−1​∂ℓ​]=0 -Var⁡[∂ℓ∂hit−1]=ntγtVar⁡[∂ℓ∂hjt]→ntγt=1\\operatorname{Var}\\left[\\frac{\\partial \\ell}{\\partial h_i^{t-1}}\\right]=n_t \\gamma_t \\operatorname{Var}\\left[\\frac{\\partial \\ell}{\\partial h_j^t}\\right] \\rightarrow n_t \\gamma_t=1Var[∂hit−1​∂ℓ​]=nt​γt​Var[∂hjt​∂ℓ​]→nt​γt​=1 Xavier初始化(权重初始化的方法,设置权重的方差) 难以满足ntγt=1和nt−1γt=1n_t \\gamma_t=1 和 n_{t-1} \\gamma_t=1nt​γt​=1和nt−1​γt​=1 Xavier 使得 γt(nt−1+nt)/2=1→γt=2/(nt−1+nt)\\gamma_t\\left(n_{t-1}+n_t\\right) / 2=1 \\quad \\rightarrow \\gamma_t=2 /\\left(n_{t-1}+n_t\\right)γt​(nt−1​+nt​)/2=1→γt​=2/(nt−1​+nt​) 正态分布 N(0,2/(nt−1+nt))\\mathcal{N}\\left(0, \\sqrt{2 /\\left(n_{t-1}+n_t\\right)}\\right)N(0,2/(nt−1​+nt​)​) 均匀分布 U(−6/(nt−1+nt),6/(nt−1+nt))U\\left(-\\sqrt{6 /\\left(n_{t-1}+n_t\\right)}, \\sqrt{6 /\\left(n_{t-1}+n_t\\right)}\\right)U(−6/(nt−1​+nt​)​,6/(nt−1​+nt​)​) 分布 U[−a,a]U[-a, a]U[−a,a] 和方差是 a2/3a^2 / 3a2/3 适配权重形状更新,特别是ntn_tnt​ 激活函数的选取 假设线性的激活函数σ(x)=αx+β,h′=Wtht−1\\sigma(x)=\\alpha x+\\beta, \\mathbf{h}^{\\prime}=\\mathbf{W}^t \\mathbf{h}^{t-1} \\quadσ(x)=αx+β,h′=Wtht−1 and ht=σ(h′)\\quad \\mathbf{h}^t=\\sigma\\left(\\mathbf{h}^{\\prime}\\right)ht=σ(h′) 正向 -E[hit]=E[αhi′+β]=β→β=0\\mathbb{E}\\left[h_i^t\\right]=\\mathbb{E}\\left[\\alpha h_i^{\\prime}+\\beta\\right]=\\beta \\rightarrow \\beta=0E[hit​]=E[αhi′​+β]=β→β=0 -Var[hit]=a2Var[hit]→α=1\\mathbb{Var}\\left[h_i^t\\right]=a^2 \\mathbb{Var}\\left[h_i^t\\right] \\rightarrow \\alpha=1Var[hit​]=a2Var[hit​]→α=1 反向∂ℓ∂h′=∂ℓ∂ht(Wt)T\\frac{\\partial \\ell}{\\partial \\mathbf{h}^{\\prime}}=\\frac{\\partial \\ell}{\\partial \\mathbf{h}^t}\\left(W^t\\right)^T∂h′∂ℓ​=∂ht∂ℓ​(Wt)T and ∂ℓ∂ht−1=α∂ℓ∂h′\\frac{\\partial \\ell}{\\partial \\mathbf{h}^{t-1}}=\\alpha \\frac{\\partial \\ell}{\\partial \\mathbf{h}^{\\prime}}∂ht−1∂ℓ​=α∂h′∂ℓ​ -E[∂ℓ∂hit−1]=0→β=0\\mathbb{E}\\left[\\frac{\\partial \\ell}{\\partial h_i^{t-1}}\\right]=0 \\rightarrow \\beta=0E[∂hit−1​∂ℓ​]=0→β=0 -Var⁡[∂ℓ∂hit−1]=α2Var⁡[∂ℓ∂hj′]→α=1\\operatorname{Var}\\left[\\frac{\\partial \\ell}{\\partial h_i^{t-1}}\\right]=\\alpha^2 \\operatorname{Var}\\left[\\frac{\\partial \\ell}{\\partial h_j^{\\prime}}\\right] \\rightarrow \\alpha=1Var[∂hit−1​∂ℓ​]=α2Var[∂hj′​∂ℓ​]→α=1 常用的激活函数,使用泰勒展开 -sigmoid⁡(x)=12+x4−x348+O(x5)tanh⁡(x)=0+x−x33+O(x5)relu⁡(x)=0+x for x≥0\\begin{aligned} \\operatorname{sigmoid}(x) &amp;=\\frac{1}{2}+\\frac{x}{4}-\\frac{x^3}{48}+O\\left(x^5\\right) \\\\ \\tanh (x) &amp;=0+x-\\frac{x^3}{3}+O\\left(x^5\\right) \\\\ \\operatorname{relu}(x) &amp;=0+x \\quad \\text { for } x \\geq 0 \\end{aligned}sigmoid(x)tanh(x)relu(x)​=21​+4x​−48x3​+O(x5)=0+x−3x3​+O(x5)=0+x for x≥0​ sigmoid的一次项不满足要求，则需要调整sigmoid为4∗sigmoid(x)−24*sigmoid(x)-24∗sigmoid(x)−2即可满足要求 14.3 QA nan和inf的产生原因和解决办法 nan的产生原因：除以0出现，一般梯度过小会出现 inf的产生原因：learning rate过大，或权重初始时值太大出现 解决办法：学习率选择不太大(优先调整学习率使不产生nan和inf)，合理初始化权重，激活函数的选择 在训练过程中，如果网络层的输出中间层特征元素的值突然变成nan，一般是发生了梯度爆炸问题 梯度消失的原因可能由sigmoid激活函数引起，但不仅仅是由该原因引起 15 实战：Kaggle房价预测 + 课程竞赛：加州2020年房价预测 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197# 实现几个函数来方便下载数据import hashlibimport osimport tarfileimport zipfileimport requests#@saveDATA_HUB = dict()DATA_URL = &#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;def download(name, cache_dir=os.path.join(&#x27;..&#x27;, &#x27;data&#x27;)): #@save &quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot; assert name in DATA_HUB, f&quot;&#123;name&#125; 不存在于 &#123;DATA_HUB&#125;&quot; url, sha1_hash = DATA_HUB[name] os.makedirs(cache_dir, exist_ok=True) fname = os.path.join(cache_dir, url.split(&#x27;/&#x27;)[-1]) if os.path.exists(fname): sha1 = hashlib.sha1() with open(fname, &#x27;rb&#x27;) as f: while True: data = f.read(1048576) if not data: break sha1.update(data) if sha1.hexdigest() == sha1_hash: return fname # 命中缓存 print(f&#x27;正在从&#123;url&#125;下载&#123;fname&#125;...&#x27;) r = requests.get(url, stream=True, verify=True) with open(fname, &#x27;wb&#x27;) as f: f.write(r.content) return fnamedef download_extract(name, folder=None): #@save &quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot; fname = download(name) base_dir = os.path.dirname(fname) data_dir, ext = os.path.splitext(fname) if ext == &#x27;.zip&#x27;: fp = zipfile.ZipFile(fname, &#x27;r&#x27;) elif ext in (&#x27;.tar&#x27;, &#x27;.gz&#x27;): fp = tarfile.open(fname, &#x27;r&#x27;) else: assert False, &#x27;只有zip/tar文件可以被解压缩&#x27; fp.extractall(base_dir) return os.path.join(base_dir, folder) if folder else data_dirdef download_all(): #@save &quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot; for name in DATA_HUB: download(name)# 使用pandas读入并处理数据%matplotlib inlineimport numpy as npimport pandas as pdimport torchfrom torch import nnfrom d2l import torch as d2lDATA_HUB[&#x27;kaggle_house_train&#x27;] = ( #@save DATA_URL + &#x27;kaggle_house_pred_train.csv&#x27;, &#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;)DATA_HUB[&#x27;kaggle_house_test&#x27;] = ( #@save DATA_URL + &#x27;kaggle_house_pred_test.csv&#x27;, &#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;)train_data = pd.read_csv(download(&#x27;kaggle_house_train&#x27;))test_data = pd.read_csv(download(&#x27;kaggle_house_test&#x27;))print(train_data.shape)print(test_data.shape)# 前四个和最后两个特征,以及相应标签print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])# 在每个样本中，第一个特征是ID，将其从数据集中删除all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))# 将所有缺失的值替换成相应特征的平均值,通过将特征重新缩放到零均值和单位方差来标准化数据# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dtypes[all_features.dtypes != &#x27;object&#x27;].indexall_features[numeric_features] = all_features[numeric_features].apply( lambda x: (x - x.mean()) / (x.std()))# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0all_features[numeric_features] = all_features[numeric_features].fillna(0)# 处理离散值,使用一次独热编码替换它们# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征all_features = pd.get_dummies(all_features, dummy_na=True)all_features.shape# 从pandas格式中提取Numpy格式,并将其转换为张量n_train = train_data.shape[0]train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)train_labels = torch.tensor( train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)# 训练loss = nn.MSELoss()in_features = train_features.shape[1]def get_net(): net = nn.Sequential(nn.Linear(in_features,1)) return net# 更关心相对误差，解决问题的一种方法就是用价格预测的对数来衡量差异def log_rmse(net, features, labels): # 为了在取对数时进一步稳定该值，将小于1的值设置为1 clipped_preds = torch.clamp(net(features), 1, float(&#x27;inf&#x27;)) rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels))) return rmse.item()# 训练函数借助Adam优化器def train(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size): train_ls, test_ls = [], [] train_iter = d2l.load_array((train_features, train_labels), batch_size) # 这里使用的是Adam优化算法 optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, weight_decay = weight_decay) for epoch in range(num_epochs): for X, y in train_iter: optimizer.zero_grad() l = loss(net(X), y) l.backward() optimizer.step() train_ls.append(log_rmse(net, train_features, train_labels)) if test_labels is not None: test_ls.append(log_rmse(net, test_features, test_labels)) return train_ls, test_ls# K折交叉验证def get_k_fold_data(k, i, X, y): assert k &gt; 1 fold_size = X.shape[0] // k X_train, y_train = None, None for j in range(k): idx = slice(j * fold_size, (j + 1) * fold_size) X_part, y_part = X[idx, :], y[idx] if j == i: X_valid, y_valid = X_part, y_part elif X_train is None: X_train, y_train = X_part, y_part else: X_train = torch.cat([X_train, X_part], 0) y_train = torch.cat([y_train, y_part], 0) return X_train, y_train, X_valid, y_valid# 返回训练和验证误差的平均值def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size): train_l_sum, valid_l_sum = 0, 0 for i in range(k): data = get_k_fold_data(k, i, X_train, y_train) net = get_net() train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size) train_l_sum += train_ls[-1] valid_l_sum += valid_ls[-1] if i == 0: d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls], xlabel=&#x27;epoch&#x27;, ylabel=&#x27;rmse&#x27;, xlim=[1, num_epochs], legend=[&#x27;train&#x27;, &#x27;valid&#x27;], yscale=&#x27;log&#x27;) print(f&#x27;折&#123;i + 1&#125;，训练log rmse&#123;float(train_ls[-1]):f&#125;, &#x27; f&#x27;验证log rmse&#123;float(valid_ls[-1]):f&#125;&#x27;) return train_l_sum / k, valid_l_sum / k# 模型验证k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)print(f&#x27;&#123;k&#125;-折验证: 平均训练log rmse: &#123;float(train_l):f&#125;, &#x27; f&#x27;平均验证log rmse: &#123;float(valid_l):f&#125;&#x27;)# 提交kaggle预测def train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size): net = get_net() train_ls, _ = train(net, train_features, train_labels, None, None, num_epochs, lr, weight_decay, batch_size) d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel=&#x27;epoch&#x27;, ylabel=&#x27;log rmse&#x27;, xlim=[1, num_epochs], yscale=&#x27;log&#x27;) print(f&#x27;训练log rmse：&#123;float(train_ls[-1]):f&#125;&#x27;) # 将网络应用于测试集。 preds = net(test_features).detach().numpy() # 将其重新格式化以导出到Kaggle test_data[&#x27;SalePrice&#x27;] = pd.Series(preds.reshape(1, -1)[0]) submission = pd.concat([test_data[&#x27;Id&#x27;], test_data[&#x27;SalePrice&#x27;]], axis=1) submission.to_csv(&#x27;submission.csv&#x27;, index=False)train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size) 16 PyTorch 神经网络基础 16.1 模型构造 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 层和块# 回顾多层感知机import torchfrom torch import nnfrom torch.nn import functional as F # 定义了一些函数net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))X = torch.rand(2, 20)net(X)# nn.Sequential定义了一种特殊的Module# 自定义定义块class MLP(nn.Module): # 用模型参数声明层。这里，我们声明两个全连接的层 def __init__(self): # 调用MLP的父类Module的构造函数来执行必要的初始化。 # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍） super().__init__() self.hidden = nn.Linear(20, 256) # 隐藏层 self.out = nn.Linear(256, 10) # 输出层 # 定义模型的前向传播，即如何根据输入X返回所需的模型输出 def forward(self, X): # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。 return self.out(F.relu(self.hidden(X)))net = MLP()net(X)# 顺序块class MySequential(nn.Module): def __init__(self, *args): super().__init__() for idx, module in enumerate(args): # 这里，module是Module子类的一个实例。我们把它保存在&#x27;Module&#x27;类的成员 # 变量_modules中。_module的类型是OrderedDict self._modules[str(idx)] = module def forward(self, X): # OrderedDict保证了按照成员添加的顺序遍历它们 for block in self._modules.values(): X = block(X) return Xnet = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))net(X)# 在正向传播函数中执行代码class FixedHiddenMLP(nn.Module): def __init__(self): super().__init__() # 不计算梯度的随机权重参数。因此其在训练期间保持不变 self.rand_weight = torch.rand((20, 20), requires_grad=False) self.linear = nn.Linear(20, 20) def forward(self, X): X = self.linear(X) # 使用创建的常量参数以及relu和mm函数 X = F.relu(torch.mm(X, self.rand_weight) + 1) # 复用全连接层。这相当于两个全连接层共享参数 X = self.linear(X) # 控制流 while X.abs().sum() &gt; 1: X /= 2 return X.sum()net = FixedHiddenMLP()net(X)# 混合搭配各种组合块的方法class NestMLP(nn.Module): def __init__(self): super().__init__() self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU()) self.linear = nn.Linear(32, 16) def forward(self, X): return self.linear(self.net(X))chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())chimera(X) 16.2 参数管理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# 参数管理# 首先关注具有单隐藏层的多层感知机import torchfrom torch import nnnet = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))X = torch.rand(size=(2, 4))net(X)# 参数访问，拿出层的参数print(net[2].state_dict())# 目标参数print(type(net[2].bias))print(net[2].bias)print(net[2].bias.data)# class &#x27;torch.nn.parameter.Parameter&#x27;说明类型为可更新的参数net[2].weight.grad == None # 访问梯度# 一次性访问所有参数print(*[(name, param.shape) for name, param in net[0].named_parameters()])print(*[(name, param.shape) for name, param in net.named_parameters()])net.state_dict()[&#x27;2.bias&#x27;].data # 直接使用名字访问参数# 从嵌套块收集参数def block1(): return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())def block2(): net = nn.Sequential() for i in range(4): # 在这里嵌套 net.add_module(f&#x27;block &#123;i&#125;&#x27;, block1()) return netrgnet = nn.Sequential(block2(), nn.Linear(4, 1))rgnet(X)# 查看如何组织网络的print(rgnet)rgnet[0][1][0].bias.data# 内置初始化def init_normal(m): if type(m) == nn.Linear: # _下滑线为一种内置写法，表示的是替换操作，而不是返回一个值 nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.zeros_(m.bias)net.apply(init_normal) # 遍历net里面的层使用init_normalnet[0].weight.data[0], net[0].bias.data[0]def init_constant(m): if type(m) == nn.Linear: nn.init.constant_(m.weight, 1) # 将weight全部初始化为 1, 但实际中不可以 nn.init.zeros_(m.bias)net.apply(init_constant)net[0].weight.data[0], net[0].bias.data[0]# 对某些快应用不同的初始化方法def init_xavier(m): if type(m) == nn.Linear: nn.init.xavier_uniform_(m.weight)def init_42(m): if type(m) == nn.Linear: nn.init.constant_(m.weight, 42)net[0].apply(init_xavier)net[2].apply(init_42)print(net[0].weight.data[0])print(net[2].weight.data)# 自定义初始化def my_init(m): if type(m) == nn.Linear: print(&quot;Init&quot;, *[(name, param.shape) for name, param in m.named_parameters()][0]) nn.init.uniform_(m.weight, -10, 10) m.weight.data *= m.weight.data.abs() &gt;= 5net.apply(my_init)net[0].weight[:2]# 始终可以手动设置参数net[0].weight.data[:] += 1net[0].weight.data[0, 0] = 42net[0].weight.data[0]# 参数绑定# 在多个层间共享参数：可以定义一个稠密层，然后使用它的参数来设置另一个层的参数# 我们需要给共享层一个名称，以便可以引用它的参数shared = nn.Linear(8, 8)net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1))net(X)# 检查参数是否相同print(net[2].weight.data[0] == net[4].weight.data[0])net[2].weight.data[0, 0] = 100# 确保它们实际上是同一个对象，而不只是有相同的值print(net[2].weight.data[0] == net[4].weight.data[0]) 16.3 自定义层 1234567891011121314151617181920212223242526272829303132333435363738394041# 构造一个没有任何参数的自定义层import torchimport torch.nn.functional as Ffrom torch import nnclass CenteredLayer(nn.Module): def __init__(self): super().__init__() def forward(self, X): return X - X.mean()layer = CenteredLayer()layer(torch.FloatTensor([1, 2, 3, 4, 5]))# 将层作为组件合并到构建更加复杂的模型中net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())Y = net(torch.rand(4, 8))Y.mean()# 带参数的图层class MyLinear(nn.Module): def __init__(self, in_units, units): super().__init__() self.weight = nn.Parameter(torch.randn(in_units, units)) self.bias = nn.Parameter(torch.randn(units,)) def forward(self, X): linear = torch.matmul(X, self.weight.data) + self.bias.data return F.relu(linear)linear = MyLinear(5, 3)linear.weight# 使用自定义层执行前向计算linear(torch.rand(2, 5))# 使用自定义层构建模型net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))net(torch.rand(2, 64)) 16.4 读写文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 加载和保存张量import torchfrom torch import nnfrom torch.nn import functional as Fx = torch.arange(4)torch.save(x, &#x27;x-file&#x27;)x2 = torch.load(&#x27;x-file&#x27;)x2# 存储一个张量列表，然后把它们读回内存y = torch.zeros(4)torch.save([x, y],&#x27;x-files&#x27;)x2, y2 = torch.load(&#x27;x-files&#x27;)(x2, y2)# 导入或读取从字符串映射到张量的字典mydict = &#123;&#x27;x&#x27;: x, &#x27;y&#x27;: y&#125;torch.save(mydict, &#x27;mydict&#x27;)mydict2 = torch.load(&#x27;mydict&#x27;)mydict2# 加载和保存模型参数class MLP(nn.Module): def __init__(self): super().__init__() self.hidden = nn.Linear(20, 256) self.output = nn.Linear(256, 10) def forward(self, x): return self.output(F.relu(self.hidden(x)))net = MLP()X = torch.randn(size=(2, 20))Y = net(X)# 将模型参数存储在mlp.params文件中torch.save(net.state_dict(), &#x27;mlp.params&#x27;)# 实例化了原始多层感知机模型的一个备份# 直接读取文件中存储的参数clone = MLP()clone.load_state_dict(torch.load(&#x27;mlp.params&#x27;))clone.eval()Y_clone = clone(X)Y_clone == Y 16.5 QA 将特征字符串变成tensor，使用one-hot方法进行转换，内存不足时的解决办法 方法一：使用稀疏矩阵进行解决 方法二：使用其他方法进行解决，使用summary net(x)实现的原理 其继承的nn.module实现了__call__方法,类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用 17 使用和购买 GPU 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 计算设备import torchfrom torch import nntorch.device(&#x27;cpu&#x27;), torch.device(&#x27;cuda&#x27;), torch.device(&#x27;cuda:1&#x27;)# 查询可用gpu的数量torch.cuda.device_count()# 允许在请求的GPU不存在的情况下运行代码def try_gpu(i=0): #@save &quot;&quot;&quot;如果存在，则返回gpu(i)，否则返回cpu()&quot;&quot;&quot; if torch.cuda.device_count() &gt;= i + 1: return torch.device(f&#x27;cuda:&#123;i&#125;&#x27;) return torch.device(&#x27;cpu&#x27;)def try_all_gpus(): #@save &quot;&quot;&quot;返回所有可用的GPU，如果没有GPU，则返回[cpu(),]&quot;&quot;&quot; devices = [torch.device(f&#x27;cuda:&#123;i&#125;&#x27;) for i in range(torch.cuda.device_count())] return devices if devices else [torch.device(&#x27;cpu&#x27;)]try_gpu(), try_gpu(10), try_all_gpus()# 查询张量所在的设备x = torch.tensor([1, 2, 3])x.device# 存储在GPU上X = torch.ones(2, 3, device=try_gpu())X# 第二个GPU上创建一个随机张量Y = torch.rand(2, 3, device=try_gpu(1))Y# 要计算X+Y,需要决定在哪里执行这个操作# 必须保证运算的对象在同一个GPU上Z = X.cuda(1)print(X)print(Z)Y + ZZ.cuda(1) is Z# 数据在CPU和GPU之间传递，尤其消耗资源# 神经网络与GPUnet = nn.Sequential(nn.Linear(3, 1))net = net.to(device=try_gpu()) # 将网络迁移到GPU上net(X)# 确认模型参数存储在同一个GPU上net[0].weight.data.device 18 预测房价竞赛总结 使用的方法： 跳转至 autogluon 跳转至 h2o 跳转至 随机森林the-th-place-approach-random-forest 在该竞赛中，排名靠前的都是用了集成学习 集成学习为刷榜的常用方法 特征预处理和超参数是取得好成绩的基础 房价数据集的难点 数值较大 有文本特征（地址，介绍） 训练数据是前6个月，公榜是后3个月，私榜是再后3个月 关于automl 数据科学家80%时间在处理数据，20%调模型 automl目前节省10%时间 19 卷积层 19.1 从全连接到卷积 重新考察全连接层 将输入和输出变形为矩阵(宽度,高度) 将权重变形为4-D张量(h,w)(h,w)(h,w)到(h′,w′)(h^{&#x27;},w^{&#x27;})(h′,w′):hi,j=∑wi,j,k,lxk,l=∑vi,j,a,bxi+a,j+bh_{i,j} = \\sum w_{i,j,k,l}x_{k,l} = \\sum v_{i,j,a,b}x_{i+a,j+b}hi,j​=∑wi,j,k,l​xk,l​=∑vi,j,a,b​xi+a,j+b​ V是W的重新索引vi,j,a,b=wi,j,i+a,j+bv_{i,j,a,b}=w_{i,j,i+a,j+b}vi,j,a,b​=wi,j,i+a,j+b​ 原则#1-平移不变性 x的平移导致h的平移hi,j=∑vi,j,a,bxi+a,j+bh_{i,j} = \\sum v_{i,j,a,b}x_{i+a,j+b}hi,j​=∑vi,j,a,b​xi+a,j+b​ v不应该依赖于(i,j)(i,j)(i,j) 解决方案：vi,j,a,b=va,bv_{i,j,a,b}=v_{a,b}vi,j,a,b​=va,b​,hi,j=∑va,bxi+a,j+bh_{i,j} = \\sum v_{a,b}x_{i+a,j+b}hi,j​=∑va,b​xi+a,j+b​ 这就是二维卷积(实际为二维交叉相关) 原则#2-局部性 -hi,j=∑va,bxi+a,j+bh_{i,j} = \\sum v_{a,b}x_{i+a,j+b}hi,j​=∑va,b​xi+a,j+b​ 当评估hi,jh_{i,j}hi,j​时，不应该用远离xi,jx_{i,j}xi,j​的参数 解决方案:当∣a∣,∣b∣&gt;Δ|a|,|b|&gt;\\Delta∣a∣,∣b∣&gt;Δ时，使得va,b=0v_{a,b}=0va,b​=0 -hi,j=∑a=−ΔΔ∑b=−ΔΔva,bxi+a,j+bh_{i,j}=\\sum_{a=-\\Delta}^\\Delta\\sum_{b=-\\Delta}^\\Delta v_{a,b}x_{i+a,j+b}hi,j​=∑a=−ΔΔ​∑b=−ΔΔ​va,b​xi+a,j+b​ 卷积层是特殊的全连接层,其使用了平移不变性和局部性原理 19.2 卷积层 二维卷积层 输入X:nh∗nwn_h*n_wnh​∗nw​ 核W:kh∗kwk_h*k_wkh​∗kw​ 偏差b∈Rb\\in\\Rb∈R 输出Y：(nh−kh+1)∗(nw−kw+1)(n_h-k_h+1)*(n_w-k_w+1)(nh​−kh​+1)∗(nw​−kw​+1) -Y=X⋆W+b\\mathbf{Y}=\\mathbf{X} \\star \\mathbf{W}+bY=X⋆W+b 核矩阵 W 和 偏移 b是可学习的参数， 核矩阵的大小是超参数 卷积层实际上计算的是交叉相关 交叉相关和卷积由于对称性，实际在使用中没有区别 二维交叉相关：yi,j=∑a=1h∑b=1wwa,bxi+a,j+by_{i, j}=\\sum_{a=1}^h \\sum_{b=1}^w w_{a, b} x_{i+a, j+b}yi,j​=∑a=1h​∑b=1w​wa,b​xi+a,j+b​ 卷积：yi,j=∑a=1h∑b=1ww−a,−bxi+a,j+by_{i, j}=\\sum_{a=1}^h \\sum_{b=1}^w w_{-a,-b} x_{i+a, j+b}yi,j​=∑a=1h​∑b=1w​w−a,−b​xi+a,j+b​ 一维交叉相关：文本，语言，时序序列 三维：视频，医学图像，气象图片 19.3 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 互相关运算import torchfrom torch import nnfrom d2l import torch as d2ldef corr2d(X, K): #@save &quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot; h, w = K.shape Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i:i + h, j:j + w] * K).sum() return Y# 验证上述互相关运算的输出X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])corr2d(X, K)# 实现二维卷积层class Conv2D(nn.Module): def __init__(self, kernel_size): super().__init__() self.weight = nn.Parameter(torch.rand(kernel_size)) self.bias = nn.Parameter(torch.zeros(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias# 卷积层的一个简单应用：检测图像中不同颜色的边缘X = torch.ones((6, 8))X[:, 2:6] = 0X# 构建卷积核K = torch.tensor([[1.0, -1.0]])# 输出Y中的1代表从白到黑的边缘，-1表示从黑到白Y = corr2d(X, K)Y# 卷积核K只能检测垂直边缘corr2d(X.t(), K)# 学习由X生成Y的卷积核# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），# 其中批量大小和通道数都为1X = X.reshape((1, 1, 6, 8))Y = Y.reshape((1, 1, 6, 7))lr = 3e-2 # 学习率for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 conv2d.zero_grad() l.sum().backward() # 迭代卷积核 conv2d.weight.data[:] -= lr * conv2d.weight.grad if (i + 1) % 2 == 0: print(f&#x27;epoch &#123;i+1&#125;, loss &#123;l.sum():.3f&#125;&#x27;)conv2d.weight.data.reshape((1, 2)) 19.4 QA 感受野不是越大越好，最好将网络设计的深一点，而不是大卷积核，类似全连接层为什么不做的很大的问题 20 卷积层里的填充和步幅 20.1 填充和步幅 填充 给定32*32输入图像 应用5*5大小的卷积核 第1层得到输出大小28*28 第7层得到输出大小4*4 更大的卷积核可以更快地减小输出大小 形状从 n_k_n_w 减小到 (nj−kh+1)(nw−kw+1)(n_j-k_h+1)_(n_w-k_w+1)(nj​−kh​+1)(​nw​−kw​+1) 填充：在输入周围添加额外的行/列 填充php_hph​行和pwp_wpw​列,输出形状为(nh−kh+ph+1)∗(nw−kw+pw+1)(n_h-k_h+p_h+1)*(n_w-k_w+p_w+1)(nh​−kh​+ph​+1)∗(nw​−kw​+pw​+1) 通常取ph=kh−1,pw=kw−1p_h=k_h-1,p_w=k_w-1ph​=kh​−1,pw​=kw​−1 当khk_hkh​为奇数：在上下两侧填充ph2\\frac{p_h}{2}2ph​​ 当khk_hkh​为偶数：在上侧填充[ph2][\\frac{p_h}{2}][2ph​​], 在下侧填充[ph2][\\frac{p_h}{2}][2ph​​] 步幅 填充减小的输出大小与层数线性相关 给定输入大小224*224，在使用5*5卷积核的情况下，需要44层将输出降低到4*4 需要大量计算才能得到较小输出 步幅是指行/列的滑动步长 给定高度 shs_hsh​ 和宽度 sws_wsw​ 的步幅,输出形状是 [(nh−kh+ph+sh)/sh]∗[(nw−kw+pw+sw)/sw][(n_h-k_h+p_h+s_h)/s_h]*[(n_w-k_w+p_w+s_w)/s_w][(nh​−kh​+ph​+sh​)/sh​]∗[(nw​−kw​+pw​+sw​)/sw​] 如果ph=kh−1,pw=kw−1p_h=k_h-1,p_w=k_w-1ph​=kh​−1,pw​=kw​−1，[(nh+sh−1)/sh]∗[(nw+sw−1)/sw][(n_h+s_h-1)/s_h]*[(n_w+s_w-1)/s_w][(nh​+sh​−1)/sh​]∗[(nw​+sw​−1)/sw​] 如果输入高度和宽度都可被步幅整除:(nhsh)∗(nwsw)(\\frac{n_h}{s_h}) * (\\frac{n_w}{s_w})(sh​nh​​)∗(sw​nw​​) 总结 填充和步幅是卷积层的超参数 填充在输入周围添加额外的行/列,来控制输出形状的减小量 步幅是每次滑动核窗口时的行/列的步长,可以成倍的减少输出形状 20.2 代码实现 12345678910111213141516171819202122232425262728293031# 填充和步幅# 在所有侧边填充1个像素import torchfrom torch import nn# 为了方便起见，我们定义了一个计算卷积层的函数。# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数def comp_conv2d(conv2d, X): # 这里的（1，1）表示批量大小和通道数都是1 X = X.reshape((1, 1) + X.shape) Y = conv2d(X) # 省略前两个维度：批量大小和通道 return Y.reshape(Y.shape[2:])# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)X = torch.rand(size=(8, 8))comp_conv2d(conv2d, X).shape# 上下各填充2行，左右各填充1列conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))comp_conv2d(conv2d, X).shape# 将高度和宽度的步幅设置为 2conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)comp_conv2d(conv2d, X).shape# 稍微复杂的例子conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))comp_conv2d(conv2d, X).shape 20.3 QA 超参数：核大小，填充，步幅 一般而言，填充保证输入和输出的大小相同，填充为核大小减一，为默认值 一般而言，步幅，步幅为 1 最好，当计算量太大时，步幅较大，取 2 一般而言，核大小为最关键的 填充，步幅和通道数一般是网络架构的一部分，一般不改变 卷积核的边长一般取奇数，一般选择 3*3 使用自动机学习,NAS方法可以让超参数一起训练 21 卷积层里的多输入多输出通道 多个输入通道 彩色图片可能有RGB三个通道，转换为灰度会丢失信息 每个通道都有一个卷积核，结果是所有通道卷积结果的和 输入X:c_i_n_h_n_w 核W:c_i_k_h_k_w 输出Y:mh∗mwm_h*m_wmh​∗mw​,表达式为Y=∑i=0ciXi,:,:⋆Wi,:,:\\mathbf{Y}=\\sum_{i=0}^{c_i} \\mathbf{X}_{i,:,:} \\star \\mathbf{W}_{i,:,:}Y=∑i=0ci​​Xi,:,:​⋆Wi,:,:​ 多个输出通道 无论多少个输入通道目前只用到单输出通道 可以有多个三维卷积核，每个核生成一个输出通道 输入X:c_i_n_h_n_w 核W:c_o_c_i_k_h*k_w 输出Y:c_o_m_h_m_w,表达式为Yi,:,:=X⋆Wi,:,:,:\\mathbf{Y}_{i,:,:}=\\mathbf{X} \\star \\mathbf{W}_{i,:,:,:}Yi,:,:​=X⋆Wi,:,:,:​ 多个输入和输出通道 每个输出通道可以识别特定模式 输入通道核识别并组合输入中的模式 1*1卷积核 -kh=kw=1k_h=k_w=1kh​=kw​=1是一个受欢迎的选择，不识别空间模式，只是融合通道 相当于输入形状为n_hn_w_c_i,权重为c_o_c_i的全连接层 二维卷积层 输入X:c_i_n_h_n_w 核W:c_o_c_i_k_h*k_w 偏差B:co∗cic_o*c_ico​∗ci​ 输出Y:c_o_m_h_m_w,表达式为Yi,:,:=X⋆W+B\\mathbf{Y}_{i,:,:}=\\mathbf{X} \\star \\mathbf{W} + \\mathbf{B}Yi,:,:​=X⋆W+B 计算复杂度(浮点计算书FLOP) O(cicokhkwmhmw)O(c_ic_ok_hk_wm_hm_w)O(ci​co​kh​kw​mh​mw​) 每个输入通道有独立的二维卷积核,所有通道结果相加得到一个输出通道结果；每个输出通道有独立的三维卷积核 12345678910111213141516171819202122232425262728293031323334353637383940414243# 实现以下多输入通道互相关运算import torchfrom d2l import torch as d2ldef corr2d_multi_in(X, K): # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起 return sum(d2l.corr2d(x, k) for x, k in zip(X, K))# 验证互相关运算的输出X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]], [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])corr2d_multi_in(X, K)# 计算多个通道的输出的互相关函数def corr2d_multi_in_out(X, K): # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。 # 最后将所有结果都叠加在一起 return torch.stack([corr2d_multi_in(X, k) for k in K], 0)K = torch.stack((K, K + 1, K + 2), 0)K.shapecorr2d_multi_in_out(X, K)# 1*1卷积核def corr2d_multi_in_out_1x1(X, K): c_i, h, w = X.shape c_o = K.shape[0] X = X.reshape((c_i, h * w)) K = K.reshape((c_o, c_i)) # 全连接层中的矩阵乘法 Y = torch.matmul(K, X) return Y.reshape((c_o, h, w))X = torch.normal(0, 1, (3, 3, 3))K = torch.normal(0, 1, (2, 3, 1, 1))Y1 = corr2d_multi_in_out_1x1(X, K)Y2 = corr2d_multi_in_out(X, K)assert float(torch.abs(Y1 - Y2).sum()) &lt; 1e-6 QA 通常情况下，输入和输出大小减半时，输出的通道数会加一倍（空间信息压缩使用更多通道存储信息） Padding 0很多不会影响卷积神经网络 每个通道的卷积核不一样，同一层不同通道的卷积核大小一样，为了计算方便，若不一样需要进行两个卷积分开操作，计算效率更高 在计算卷积时，偏差的作用性越来越低，尤其是在batch normalization时 MobileNet：使用3*3*3和1*1*n的卷积层叠加，来分别进行空间信息的检测和信息融合以及输出通道的调整 22 池化层 池化层 积对位置敏感 需要一定程度的平移不变性，物体稍微改动，输出不变，因此需要一个池化层 池化层的目的为：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性 二维最大池化层 返回滑动窗口中的最大值 填充,步幅,和多个通道 池化层与卷积层类似，都具有填充、步幅和窗口大小作为超参数 没有可学习的参数 在每个输入通道应用池化层以获得相应的输出通道，不会像卷积层将多个通道融合 输出通道数=输入通道数 平均池化层 最大池化层：每个窗口中最强的模式信号 平均池化层：将最大池化层中最大操作替换成平均 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 实现池化层的正向传播import torchfrom torch import nnfrom d2l import torch as d2ldef pool2d(X, pool_size, mode=&#x27;max&#x27;): p_h, p_w = pool_size Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): if mode == &#x27;max&#x27;: Y[i, j] = X[i: i + p_h, j: j + p_w].max() elif mode == &#x27;avg&#x27;: Y[i, j] = X[i: i + p_h, j: j + p_w].mean() return Y# 验证二维最大池化层的输出X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])pool2d(X, (2, 2))# 验证平均池化层pool2d(X, (2, 2), &#x27;avg&#x27;)# 填充和步幅X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))X# 深度学习框架中的步幅与池化窗口的大小相同 (3*3的窗口)pool2d = nn.MaxPool2d(3)pool2d(X)# 填充和步幅可以手动设定pool2d = nn.MaxPool2d(3, padding=1, stride=2)pool2d(X)# 设定一个任意大小的矩形池化窗口，并设置填充和步幅，2行*3列的padding窗口pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))pool2d(X)# 池化层在每个输入通道上单独运算X = torch.cat((X, X + 1), 1)pool2d = nn.MaxPool2d(3, padding=1, stride=2)pool2d(X) QA 池化层一般放在卷积层之后，降低卷积对位置的敏感性 池化时，窗口重叠与没有重叠几乎没有影响 目前池化层的使用越来越少，通过其他操作实现 23 经典卷积神经网络 LeNet LeNet其中使用5*5的卷积核和2*2的平均池化层 先用卷积层来学习图片空间信息然后使用全连接层来转换到类别空间 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# LeNet由两个部分组成：卷积编码器和全连接层密集块import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential( nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(), #为了获得更多信息,padding了 2 nn.AvgPool2d(kernel_size=2, stride=2), nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(), nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10))# 检查模型X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)for layer in net: X = layer(X) print(layer.__class__.__name__,&#x27;output shape: \\t&#x27;,X.shape)# LeNet在Fashion-MNIST数据集上的表现batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)# 使用GPU对evaluate_accuracy函数进行轻微的修改def evaluate_accuracy_gpu(net, data_iter, device=None): #@save &quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot; if isinstance(net, nn.Module): net.eval() # 设置为评估模式 if not device: device = next(iter(net.parameters())).device # 正确预测的数量，总预测的数量 metric = d2l.Accumulator(2) with torch.no_grad(): for X, y in data_iter: if isinstance(X, list): # BERT微调所需的（之后将介绍） X = [x.to(device) for x in X] else: X = X.to(device) y = y.to(device) metric.add(d2l.accuracy(net(X), y), y.numel()) return metric[0] / metric[1]# 为了使用GPU，需要修改train函数#@savedef train_ch6(net, train_iter, test_iter, num_epochs, lr, device): &quot;&quot;&quot;用GPU训练模型&quot;&quot;&quot; def init_weights(m): if type(m) == nn.Linear or type(m) == nn.Conv2d: nn.init.xavier_uniform_(m.weight) net.apply(init_weights) print(&#x27;training on&#x27;, device) net.to(device) optimizer = torch.optim.SGD(net.parameters(), lr=lr) loss = nn.CrossEntropyLoss() # 交叉熵 animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, xlim=[1, num_epochs], legend=[&#x27;train loss&#x27;, &#x27;train acc&#x27;, &#x27;test acc&#x27;]) timer, num_batches = d2l.Timer(), len(train_iter) for epoch in range(num_epochs): # 训练损失之和，训练准确率之和，样本数 metric = d2l.Accumulator(3) net.train() for i, (X, y) in enumerate(train_iter): timer.start() optimizer.zero_grad() X, y = X.to(device), y.to(device) y_hat = net(X) l = loss(y_hat, y) l.backward() optimizer.step() # 进行模型更新 with torch.no_grad(): metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0]) timer.stop() train_l = metric[0] / metric[2] train_acc = metric[1] / metric[2] if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.add(epoch + (i + 1) / num_batches, (train_l, train_acc, None)) test_acc = evaluate_accuracy_gpu(net, test_iter) animator.add(epoch + 1, (None, None, test_acc)) print(f&#x27;loss &#123;train_l:.3f&#125;, train acc &#123;train_acc:.3f&#125;, &#x27; f&#x27;test acc &#123;test_acc:.3f&#125;&#x27;) print(f&#x27;&#123;metric[2] * num_epochs / timer.sum():.1f&#125; examples/sec &#x27; f&#x27;on &#123;str(device)&#125;&#x27;)# 训练和评估LeNet模型lr, num_epochs = 0.9, 10train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) 卷积神经网络设计思想： 使用不同的卷积层获取空间信息并不断进行压缩，将压缩后的信息增加到不同通道中，不断减小高和宽，最后通过感知机实现 QA 常见做法：高宽减半,通道数翻倍(使通道能匹配的模式更多) 24 深度卷积神经网络 AlexNet AlexNet AlexNet赢了2012年ImageNet竞赛 更深更大的LeNet 主要改进 丢弃法：方便做更大的模型 ReLu：让Sigmoid激活函数梯度可以更大，支持更深的模型 MaxPooling：使得输出值比较大，梯度值相应更大，使得训练更加容易 计算机视觉方法论的改变 对比 传统机器学习方法:输入图片-&gt;人工特征提取-&gt;SVM 深度学习方法：输入图片-&gt;通过CNN学习特征-&gt;Softmax回归 构造CNN相对简单, Softmax更加高效 转换为端到端的学习 AlexNet相较于LeNet的架构变化 更大的核窗口和步长，因为图片更大了 使用3*3的池化窗口，2*2运行一个像素往一边移动一下不影响输出，而3*3允许往左右各移一点不影响输出 输出通道变为256，用更大的输出通道，识别更多的模式 新加了3层卷积层和一个池化层 从120增加到了4096，输出1000类 窗口更大，增加了三个卷积层，最后的全连接层更大 激活函数从sigmoid变到了ReLu（减缓梯度消失） 隐藏全连接层后加入了丢弃层（两个4096全连接层增加dropout丢弃） 数据增强 123456789101112131415161718192021222324252627282930313233343536373839404142# AlexNet深度神经网络import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential( # 这里，我们使用一个11*11的更大窗口来捕捉对象。 # 同时，步幅为4，以减少输出的高度和宽度。 # 另外，输出通道的数目远大于LeNet nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数 nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), # 使用三个连续的卷积层和较小的卷积窗口。 # 除了最后的卷积层，输出通道的数量进一步增加。 # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度 nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(), # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合 nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5), # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000 nn.Linear(4096, 10))# 构造一个单通道数据，观察每一层的输出X = torch.randn(1, 1, 224, 224)for layer in net: X=layer(X) print(layer.__class__.__name__,&#x27;output shape:\\t&#x27;,X.shape)# Fashion-MNIST图像的分辨率低于ImageNet图像，将它们增加到224*224# (图片拉大并不会增加信息量)batch_size = 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)# 训练lr, num_epochs = 0.01, 10d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) QA 卷积神经网络卷积层提取的信息不够充足，需要两个全连接Dense(4096)层，若只是用一个，效果会变差 网络要求输入size固定，对于不同的图片需要保持长宽比，将短边resize到指定的尺寸再进行裁剪 25 使用块的网络 VGG AlexNet最大问题是结构不够规则，结构不够清晰，设计更深的网络需要更好的设计思想，将框架设计的更加规则 使用更多的全连接层(太贵) 更多的卷积层 将卷积层组合成块(VGG的重要思想) VGG块 同样的计算开销的情况下，深但窄效果更好 3*3卷积(填充1)，n层，m通道 2*2最大池化层（步幅2） VGG结构 多个VGG块后接全连接层 不同次数的重复块得到不同的架构,VGG-16,VGG-19,… VGG对AlexNet最大的贡献：将AlexNet中的卷积和池化层抽离成VGG块 总结 VGG 使用可重复使用的卷积块来构建深度卷积神经网络 不同的卷积块个数和超参数可以得到不同复杂度的变种 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# VGG块import torchfrom torch import nnfrom d2l import torch as d2ldef vgg_block(num_convs, in_channels, out_channels): layers = [] for _ in range(num_convs): layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)) layers.append(nn.ReLU()) in_channels = out_channels # 每层的输入为上一层的输出大小 layers.append(nn.MaxPool2d(kernel_size=2,stride=2)) return nn.Sequential(*layers)# 原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层# 第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512# 由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))def vgg(conv_arch): conv_blks = [] in_channels = 1 # 卷积层部分 for (num_convs, out_channels) in conv_arch: conv_blks.append(vgg_block(num_convs, in_channels, out_channels)) in_channels = out_channels return nn.Sequential( *conv_blks, nn.Flatten(), # 全连接层部分 nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 10))net = vgg(conv_arch)# 观察每个层输出的形状X = torch.randn(size=(1, 1, 224, 224))for blk in net: X = blk(X) print(blk.__class__.__name__,&#x27;output shape:\\t&#x27;,X.shape)# 由于VGG-11比AlexNet计算量更大，因此构建了一个通道数较少的网络ratio = 4small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]net = vgg(small_conv_arch)# 模型训练lr, num_epochs, batch_size = 0.05, 10, 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) 26 网络中的网络 NiN 网络中的网络NiN目前使用较少，但提出很多思想 全连接层的问题 卷积层需要较少的参数 c_i_c_o_k^2 但卷积层后的第一个全连接层的参数 LeNet 16_5_5*120=48k AlexNet 255_5_5*4096=26M VGG 512_7_7*4096=102M,占用空间较大,空间的大部分占用都在卷积层后的第一个全连接层 为了解决VGG中参数较多，占用较大的问题，提出NiN NiN的思想：完全不要全连接层 NiN块 一个卷积层后跟两个全连接层 步幅1，无填充，输出形状跟卷积层输出一样 1*1卷积层起到了全连接层的作用 NiN块类似最简单的卷积神经网络 NiN架构 无全连接层 交替使用NiN块和步幅为2的最大池化层 逐步减小高宽和增大通道数，步幅为2的最大池化层为高宽减半 最后使用全局平均池化层（高宽等于输入的高宽）得到输出 其输入通道数是类别数 总结 NiN块使用卷积层加两个1*1卷积层 后者对每个像素增加了非线性性（两个卷积层相当于做了两个隐含层的MLP，MLP的ReLu函数增加了线性性） NiN使用全局平均池化层来替代VGG和AlexNet中的全连接层 不容易过拟合，更少的参数个数 12345678910111213141516171819202122232425262728293031323334353637# NiN块import torchfrom torch import nnfrom d2l import torch as d2ldef nin_block(in_channels, out_channels, kernel_size, strides, padding): return nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())# NiN模型（模型的许多参数都是从AlexNet而来）net = nn.Sequential( nin_block(1, 96, kernel_size=11, strides=4, padding=0), nn.MaxPool2d(3, stride=2), nin_block(96, 256, kernel_size=5, strides=1, padding=2), nn.MaxPool2d(3, stride=2), nin_block(256, 384, kernel_size=3, strides=1, padding=1), nn.MaxPool2d(3, stride=2), nn.Dropout(0.5), # 标签类别数是10 nin_block(384, 10, kernel_size=3, strides=1, padding=1), nn.AdaptiveAvgPool2d((1, 1)), # 将四维的输出转成二维的输出，其形状为(批量大小,10) nn.Flatten())# 查看每个块的输出形状X = torch.rand(size=(1, 1, 224, 224))for layer in net: X = layer(X) print(layer.__class__.__name__,&#x27;output shape:\\t&#x27;, X.shape)# 训练模型lr, num_epochs, batch_size = 0.1, 10, 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) QA 使用pytorch的部署到C++生产环境中，可以使用torchScript或者onnx部署 分类使用softmax，softmax函数写在training函数的loss函数中，没有写在神经网络中 加入全局池化层，将输入降低，且没有可学习的参数，使学习变得简单，最大的好处是使模型复杂度降低，提升泛化性，缺点是使收敛变慢 27 含并行连结的网络 GoogLeNet / Inception googleNet 最好的卷积层超参数 Inception块：4个路径从不同层面抽取信息，然后再输出通道维合并 结构 第一条路径使用1*1的卷积层 第二条路先使用1*1的卷积层对通道做变换，然后使用3*3的卷积层 第三条路先使用1*1的卷积层对通道做变换，然后使用5*5的卷积层 第四条路先使用3*3的池化层，然后使用1*1的卷积层 最后使用concatenation做合并，跟输入等同高宽 跟单3*3或5*5卷积层比,Inception块由更少的参数个数和计算复杂度 上图中白色的框用来变换通道数，其他蓝色框用来抽取空间信息 GoogLeNet 5段,9个Inception块 stage：高宽减半为一个stage GoogLeNet stage1 为 7*7卷积核3*3MaxPool GoogLeNet stage2 为 1*1卷积 3*3卷积核 3*3MaxPool GoogLeNet stage3 为 2 个Inception block(不改变高宽只改变通道数) 3*3MaxPool GoogLeNet stage4 为 5 个Inception block(不改变高宽只改变通道数) 3*3MaxPool GoogLeNet stage5 为 2 个Inception block(不改变高宽只改变通道数) 3*3MaxPool 最后使用全局池化层和全连接层 GoogLeNet大量使用1*1卷积层增加通道数,并且使用全局池化层 段1 &amp; 段2：更小的窗口，更多的通道 快速减小图像尺寸并迅速增大通道数，使用更小的卷积层高宽保留更流 段3： 2个Inception block的通道数的分配不同 段4 &amp; 段5： 5个Inception block Inception由各种后续变种 Inception-BN(V2)：使用batch normalization Inception-V3：修改了Inception块 替换5*5为多个3*3卷积层 替换5*5为1*7和7*1卷积层 替换3*3为1*3和3*1卷积层 更深 Inception-V4：使用残差连接 上图右侧为InceptionV1的版本,左图为InceptionV3的版本 总结 Inception块由4条由不同超参数的卷积层和池化层的路来抽取不同的信息 一个主要优点就是模型参数小，计算复杂度低 GoogLeNet使用了9个Inception块，是第一个达到上百层的网络 后续有一系列改进 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# Inception块import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lclass Inception(nn.Module): # c1--c4是每条路径的输出通道数 def __init__(self, in_channels, c1, c2, c3, c4, **kwargs): super(Inception, self).__init__(**kwargs) # 线路1，单1x1卷积层 self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1) # 线路2，1x1卷积层后接3x3卷积层 self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1) self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1) # 线路3，1x1卷积层后接5x5卷积层 self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1) self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2) # 线路4，3x3最大汇聚层后接1x1卷积层 self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1) def forward(self, x): p1 = F.relu(self.p1_1(x)) p2 = F.relu(self.p2_2(F.relu(self.p2_1(x)))) p3 = F.relu(self.p3_2(F.relu(self.p3_1(x)))) p4 = F.relu(self.p4_2(self.p4_1(x))) # 在通道维度上连结输出 return torch.cat((p1, p2, p3, p4), dim=1)# 实现每一个stageb1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1), nn.ReLU(), nn.Conv2d(64, 192, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32), Inception(256, 128, (128, 192), (32, 96), 64), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64), Inception(512, 160, (112, 224), (24, 64), 64), Inception(512, 128, (128, 256), (24, 64), 64), Inception(512, 112, (144, 288), (32, 64), 64), Inception(528, 256, (160, 320), (32, 128), 128), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128), Inception(832, 384, (192, 384), (48, 128), 128), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))# 为了使Fashion-MNIST上的训练短小精悍，将输入的高和宽从224降到96X = torch.rand(size=(1, 1, 96, 96))for layer in net: X = layer(X) print(layer.__class__.__name__,&#x27;output shape:\\t&#x27;, X.shape)# 训练lr, num_epochs, batch_size = 0.1, 10, 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) QA 1*1的卷积层用来降低通道数，减小计算量 在神经网络搭建中，最好不要修改经典的模型，或者将通道数整体减少 通道数通常设置为2n2^n2n，主要是为了方便GPU计算 目前主要使用GoogleNetV3 28 批量归一化(Batch norm) 批量归一化 问题 损失出现在最后，后面的层训练较快 数据在最底部 底部的层训练较慢 底部层一变化，所有都得跟着变 最后的那些层需要重新学习多次 导致收敛变慢 批量归一化可以在学习底部层的时候避免变化顶部层 原理 固定小批量里面的均值和方差：μB=1∣B∣∑i∈Bxi\\mu_B=\\frac{1}{|B|} \\sum_{i \\in B} x_iμB​=∣B∣1​∑i∈B​xi​ and σB2=1∣B∣∑i∈B(xi−μB)2+ϵ\\sigma_B^2=\\frac{1}{|B|} \\sum_{i \\in B}\\left(x_i-\\mu_B\\right)^2+\\epsilonσB2​=∣B∣1​∑i∈B​(xi​−μB​)2+ϵ 然后再做额外的调整（可学习的参数）：xi+1=γxi−μBσB+β,β为均值,γ为方差x_{i+1}=\\gamma \\frac{x_i-\\mu_B}{\\sigma_B}+\\beta, \\beta为均值,\\gamma为方差xi+1​=γσB​xi​−μB​​+β,β为均值,γ为方差 批量归一化层 可学习的参数γβ\\gamma \\betaγβ 作用在 全连接层和卷积层输出上，激励函数前 全连接层和卷积层输入上 对全连接层，作用在特征维 二维输入，每一行为样本，每一列为特征 对卷积层，作用在通道维 在每个批量里，一个像素是一个样本，与像素(样本)对应的通道维为就是特征维 批量归一化在做什么 最初论文是向用它来减少内部协变量转移 后续有论文指出它可能就是通过在每个小批量里加入噪声来控制模型变量:xi+1=γxi−μBσB+β,μb和σbx_{i+1}=\\gamma \\frac{x_i-\\mu_B}{\\sigma_B}+\\beta,\\mu_b和\\sigma_bxi+1​=γσB​xi​−μB​​+β,μb​和σb​为随机偏移和随机缩放，为噪声，然后通过一个学习到的方差和均值进行归一化 没必要和dropout丢弃法混合使用 批量归一化固定小批量中的均值和方差，然后学习出适合的偏移和缩放 可以加速收敛速度，但一般不改变模型精度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# batch norm的从零开始实现import torchfrom torch import nnfrom d2l import torch as d2ldef batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum): # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式 if not torch.is_grad_enabled(): # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差 X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps) else: assert len(X.shape) in (2, 4) if len(X.shape) == 2: # 使用全连接层的情况，计算特征维上的均值和方差 mean = X.mean(dim=0) var = ((X - mean) ** 2).mean(dim=0) else: # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。 # 这里我们需要保持X的形状以便后面可以做广播运算 mean = X.mean(dim=(0, 2, 3), keepdim=True) var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True) # 训练模式下，用当前的均值和方差做标准化 X_hat = (X - mean) / torch.sqrt(var + eps) # 更新移动平均的均值和方差 moving_mean = momentum * moving_mean + (1.0 - momentum) * mean moving_var = momentum * moving_var + (1.0 - momentum) * var Y = gamma * X_hat + beta # 缩放和移位 return Y, moving_mean.data, moving_var.dataclass BatchNorm(nn.Module): # num_features：完全连接层的输出数量或卷积层的输出通道数。 # num_dims：2表示完全连接层，4表示卷积层 def __init__(self, num_features, num_dims): super().__init__() if num_dims == 2: shape = (1, num_features) else: shape = (1, num_features, 1, 1) # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0 self.gamma = nn.Parameter(torch.ones(shape)) self.beta = nn.Parameter(torch.zeros(shape)) # 非模型参数的变量初始化为0和1 self.moving_mean = torch.zeros(shape) self.moving_var = torch.ones(shape) def forward(self, X): # 如果X不在内存上，将moving_mean和moving_var复制到X所在显存上 if self.moving_mean.device != X.device: self.moving_mean = self.moving_mean.to(X.device) self.moving_var = self.moving_var.to(X.device) # 保存更新过的moving_mean和moving_var Y, self.moving_mean, self.moving_var = batch_norm( X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps=1e-5, momentum=0.9) return Y# 应用BatchNorm于LeNet模型上net = nn.Sequential( nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.Linear(16*4*4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(), nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(), nn.Linear(84, 10))# 训练lr, num_epochs, batch_size = 1.0, 10, 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())# 查看gamma和betanet[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,))# -------# 简洁实现net = nn.Sequential( nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(), nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(), nn.Linear(84, 10))d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) 代码实现中:momentum=0.9, eps=1e-5, 1e-6, 1e-7 都可以，不同的 eps 对输出有一定影响 pytorch中默认momentum=0.1 QA xavier保证在参数初始化时初始化正常避免梯度爆炸和消失；BN保证在训练过程中均值和方差，可以保证较大的梯度，保证可使用较大的学习率，保证训练速度 29 残差网络 ResNet ResNet是实际使用中较好用的一个神经网络 对于非嵌套函数类，较复杂（由较大区域表示）的函数类不能保证更接近“真”函数（ f∗f^*f∗ ），在嵌套函数类中不会发生，只有当较复杂的函数类包含较小的函数类时才能确保提高它们的性能 对于深度神经网络，如果我们能将新添加的层训练成_恒等映射_f(x)=xf(\\mathbf{x}) = \\mathbf{x}f(x)=x，新模型和原模型将同样有效；同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差 对于非嵌套函数类（图左边），较复杂的函数类并不总是向“真”函数f∗f^*f∗靠拢（复杂度由F1\\mathcal{F}_1F1​向F6\\mathcal{F}_6F6​递增），虽然F3\\mathcal{F}_3F3​比F1\\mathcal{F}_1F1​更接近f∗f^*f∗，但F6\\mathcal{F}_6F6​却离的更远了 相反对于图右侧的嵌套函数类F1⊆…⊆F6\\mathcal{F}_1 \\subseteq \\ldots \\subseteq \\mathcal{F}_6F1​⊆…⊆F6​，可以避免上述问题 残差网络的核心思想是：每个附加层都应该更容易地包含原始函数作为其元素之一 残差块 串联一个层改变函数类，希望能扩大函数类 残差块加入快速通道（右边）来得到 f(x)=x+g(x)f(x) = x+g(x)f(x)=x+g(x) 的结构 左边的ResNet的高宽不变，右边的ResNet块高宽减半，靠近输入的3*3卷积核和1*1卷积核的步幅为2 ResNet块是从VGG过来的 不同的残差块 ResNet网络：类似VGG和GoogLeNet的总体架构，有5个stage，最后有一个全局池化层，但替换成了ResNet块 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# 从零开始实现import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lclass Residual(nn.Module): #@save def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1): super().__init__() self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=strides) self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1) if use_1x1conv: self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides) else: self.conv3 = None self.bn1 = nn.BatchNorm2d(num_channels) self.bn2 = nn.BatchNorm2d(num_channels) def forward(self, X): Y = F.relu(self.bn1(self.conv1(X))) Y = self.bn2(self.conv2(Y)) if self.conv3: X = self.conv3(X) Y += X return F.relu(Y)# 输入和输出形状一致blk = Residual(3,3)X = torch.rand(4, 3, 6, 6)Y = blk(X)Y.shape# 增加输出通道数的同时，减半输出的高和宽blk = Residual(3,6, use_1x1conv=True, strides=2)blk(X).shape# ResNet模型b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))def resnet_block(input_channels, num_channels, num_residuals, first_block=False): blk = [] for i in range(num_residuals): if i == 0 and not first_block: blk.append(Residual(input_channels, num_channels, use_1x1conv=True, strides=2)) else: blk.append(Residual(num_channels, num_channels)) return blkb2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))b3 = nn.Sequential(*resnet_block(64, 128, 2))b4 = nn.Sequential(*resnet_block(128, 256, 2))b5 = nn.Sequential(*resnet_block(256, 512, 2))net = nn.Sequential(b1, b2, b3, b4, b5, nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10))# 观察不同模块的输入形状是如何变化的X = torch.rand(size=(1, 1, 224, 224))for layer in net: X = layer(X) print(layer.__class__.__name__,&#x27;output shape:\\t&#x27;, X.shape)# 训练lr, num_epochs, batch_size = 0.05, 10, 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) 31 深度学习硬件：CPU 和 GPU 提升CPU利用率 在计算a+b之前，需要准备数据 主内存-&gt;L3-&gt;L2-&gt;L1-&gt;寄存器 提升空间和时间的内存本地性 时间：重用数据使得保持它们在缓存 空间：按序读写数据使得可以预读取 如果一个矩阵是按列存储，访问一行会比访问一列要快 CPU会一次读取64字节（缓存线） CPU会提前读取下一个（缓存线） 并行来利用所有核：超线程不一定提升性能，因为它们共享寄存器 提升GPU利用率 并行：使用数千个线程 内存本地性：缓存更小，架构更加简单 少用控制语句：支持有限，同步开销很大 CPU/GPU带宽 带宽受限，并且需要同步开销 不要频繁在CPU和GPU之间传数据 CPU/GPU高性能计算编程 CPU：C++或任何高性能语言 GPU： Nvidia：Cuda，编译器和驱动成熟 OpenCL：质量取决于硬件厂商 QA 全连接层较为耗费内存和性能，且模型占用空间更大，模型的计算复杂度和模型的占用空间不成正比 w-=lr*w.grad计算前后的w的地址相同，而w=w-lr*w.grad计算后右式赋值给一个新的变量，然后赋值给变量 w，地址会发生变化，不推荐使用 32 深度学习硬件：TPU和其他 DSP：数字信号处理 为数字信号处理算法设计：点积，卷积，FFT 低功耗，高性能，比移动GPU快5X，功耗更低 VLIW：一条指令加u四年上百次乘累加 编程和调试困难，编译器质量良莠不齐 可编程阵列（FPGA） 有大量可编程逻辑单元和可配置的连接 可配置成计算复杂函数：VHDL，Verilog 通常比通用硬件更高效 工具链质量良莠不齐 一次编译需要数小时 AI ASIC google TPU是标志性芯片 能够媲美Nvidia GPU性能 核心是systolic array 计算单元(PE)阵列 特别适合做矩阵乘法 设计和制造相对简单 33 单机多卡并行 单机多卡并行 一台机器可以安装多个GPU 在训练和预测时，将小批量计算切分到多个GPU上来达到加速目的 常用切分方案 数据并行：将小批量分成n块，每个GPU拿到完整参数计算一块数据的梯度(通常性能更好) 模型并行：将模型分成n块，每个GPU拿到一块模型计算它的前向和方向结果(通常用于模型大到单GPU放不下) 通道并行（数据+模型并行） 数据并行 读一个数据块 拿回参数 计算梯度 发出梯度 更新梯度 34 多GPU训练实习 34.1 从零开始实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# 多GPu训练%matplotlib inlineimport torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2l# 使用LeNet网络进行实现# 初始化模型参数scale = 0.01W1 = torch.randn(size=(20, 1, 3, 3)) * scaleb1 = torch.zeros(20)W2 = torch.randn(size=(50, 20, 5, 5)) * scaleb2 = torch.zeros(50)W3 = torch.randn(size=(800, 128)) * scaleb3 = torch.zeros(128)W4 = torch.randn(size=(128, 10)) * scaleb4 = torch.zeros(10)params = [W1, b1, W2, b2, W3, b3, W4, b4]# 定义模型def lenet(X, params): h1_conv = F.conv2d(input=X, weight=params[0], bias=params[1]) h1_activation = F.relu(h1_conv) h1 = F.avg_pool2d(input=h1_activation, kernel_size=(2, 2), stride=(2, 2)) h2_conv = F.conv2d(input=h1, weight=params[2], bias=params[3]) h2_activation = F.relu(h2_conv) h2 = F.avg_pool2d(input=h2_activation, kernel_size=(2, 2), stride=(2, 2)) h2 = h2.reshape(h2.shape[0], -1) h3_linear = torch.mm(h2, params[4]) + params[5] h3 = F.relu(h3_linear) y_hat = torch.mm(h3, params[6]) + params[7] return y_hat# 交叉熵损失函数loss = nn.CrossEntropyLoss(reduction=&#x27;none&#x27;)# 向多个设备分发参数def get_params(params, device): new_params = [p.to(device) for p in params] for p in new_params: p.requires_grad_() return new_paramsnew_params = get_params(params, d2l.try_gpu(0))print(&#x27;b1 权重:&#x27;, new_params[1])print(&#x27;b1 梯度:&#x27;, new_params[1].grad)# allreduce函数将所有向量相加，并将结果广播给所有GPUdef allreduce(data): for i in range(1, len(data)): data[0][:] += data[i].to(data[0].device) for i in range(1, len(data)): data[i][:] = data[0].to(data[i].device)data = [torch.ones((1, 2), device=d2l.try_gpu(i)) * (i + 1) for i in range(2)]print(&#x27;allreduce之前：\\n&#x27;, data[0], &#x27;\\n&#x27;, data[1])allreduce(data)print(&#x27;allreduce之后：\\n&#x27;, data[0], &#x27;\\n&#x27;, data[1])# 将小批量数据均匀地分布在多个GPU上data = torch.arange(20).reshape(4, 5)devices = [torch.device(&#x27;cuda:0&#x27;), torch.device(&#x27;cuda:1&#x27;)]split = nn.parallel.scatter(data, devices)print(&#x27;input :&#x27;, data)print(&#x27;load into&#x27;, devices)print(&#x27;output:&#x27;, split)#@savedef split_batch(X, y, devices): &quot;&quot;&quot;将X和y拆分到多个设备上&quot;&quot;&quot; assert X.shape[0] == y.shape[0] return (nn.parallel.scatter(X, devices), nn.parallel.scatter(y, devices))# 在一个小批量上实现多GPU训练def train_batch(X, y, device_params, devices, lr): X_shards, y_shards = split_batch(X, y, devices) # 在每个GPU上分别计算损失 ls = [loss(lenet(X_shard, device_W), y_shard).sum() for X_shard, y_shard, device_W in zip( X_shards, y_shards, device_params)] for l in ls: # 反向传播在每个GPU上分别执行 l.backward() # 将每个GPU的所有梯度相加，并将其广播到所有GPU with torch.no_grad(): for i in range(len(device_params[0])): allreduce( [device_params[c][i].grad for c in range(len(devices))]) # 在每个GPU上分别更新模型参数 for param in device_params: d2l.sgd(param, lr, X.shape[0]) # 在这里，我们使用全尺寸的小批量# 训练函数def train(num_gpus, batch_size, lr): train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) devices = [d2l.try_gpu(i) for i in range(num_gpus)] # 将模型参数复制到num_gpus个GPU device_params = [get_params(params, d) for d in devices] num_epochs = 10 animator = d2l.Animator(&#x27;epoch&#x27;, &#x27;test acc&#x27;, xlim=[1, num_epochs]) timer = d2l.Timer() for epoch in range(num_epochs): timer.start() for X, y in train_iter: # 为单个小批量执行多GPU训练 train_batch(X, y, device_params, devices, lr) torch.cuda.synchronize() timer.stop() # 在GPU0上评估模型 animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu( lambda x: lenet(x, device_params[0]), test_iter, devices[0]),)) print(f&#x27;测试精度：&#123;animator.Y[0][-1]:.2f&#125;，&#123;timer.avg():.1f&#125;秒/轮，&#x27; f&#x27;在&#123;str(devices)&#125;&#x27;)# 在单个GPU上运行train(num_gpus=1, batch_size=256, lr=0.2)# 增加为2个GPUtrain(num_gpus=2, batch_size=256, lr=0.2) 多GPU训练不变快的原因，GPU增加但batch_size不增加，每一次计算不能高效的使用GPU的线程，最好保证每个GPU能拿到与相同相同的batch_size，但收敛速度很有可能会变慢，精度会降低，需要提高学习率 34.2 简洁实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import torchfrom torch import nnfrom d2l import torch as d2l# 使用ResNet18网络进行#@savedef resnet18(num_classes, in_channels=1): &quot;&quot;&quot;稍加修改的ResNet-18模型&quot;&quot;&quot; def resnet_block(in_channels, out_channels, num_residuals, first_block=False): blk = [] for i in range(num_residuals): if i == 0 and not first_block: blk.append(d2l.Residual(in_channels, out_channels, use_1x1conv=True, strides=2)) else: blk.append(d2l.Residual(out_channels, out_channels)) return nn.Sequential(*blk) # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层 net = nn.Sequential( nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU()) net.add_module(&quot;resnet_block1&quot;, resnet_block( 64, 64, 2, first_block=True)) net.add_module(&quot;resnet_block2&quot;, resnet_block(64, 128, 2)) net.add_module(&quot;resnet_block3&quot;, resnet_block(128, 256, 2)) net.add_module(&quot;resnet_block4&quot;, resnet_block(256, 512, 2)) net.add_module(&quot;global_avg_pool&quot;, nn.AdaptiveAvgPool2d((1,1))) net.add_module(&quot;fc&quot;, nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes))) return net# 网络初始化net = resnet18(10)# 获取GPU列表devices = d2l.try_all_gpus()# 我们将在训练代码实现中初始化网络# 训练函数def train(net, num_gpus, batch_size, lr): train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) devices = [d2l.try_gpu(i) for i in range(num_gpus)] def init_weights(m): if type(m) in [nn.Linear, nn.Conv2d]: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) # 在多个GPU上设置模型 net = nn.DataParallel(net, device_ids=devices) # 多GPU训练必备函数,并行获取数据，并且将数据分发给多个GPU,然后并行算梯度，然后更新 # 相当于重新包装forward函数 trainer = torch.optim.SGD(net.parameters(), lr) loss = nn.CrossEntropyLoss() timer, num_epochs = d2l.Timer(), 10 animator = d2l.Animator(&#x27;epoch&#x27;, &#x27;test acc&#x27;, xlim=[1, num_epochs]) for epoch in range(num_epochs): net.train() timer.start() for X, y in train_iter: trainer.zero_grad() X, y = X.to(devices[0]), y.to(devices[0]) l = loss(net(X), y) l.backward() trainer.step() timer.stop() animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(net, test_iter),)) print(f&#x27;测试精度：&#123;animator.Y[0][-1]:.2f&#125;，&#123;timer.avg():.1f&#125;秒/轮，&#x27; f&#x27;在&#123;str(devices)&#125;&#x27;)# 单GPU训练train(net, num_gpus=1, batch_size=256, lr=0.1)# 增加到2个GPUtrain(net, num_gpus=2, batch_size=512, lr=0.2) QA learning rate可能会导致nan问题，导致准确率震荡 35 分布式训练 分布式计算 数据放在分布式文件系统上-&gt;通过网络读取数据-&gt;多个worker&lt;-&gt;多个参数服务器 其中的带宽主要受网络带宽的限制 计算一个小批量 每个计算服务器读取小批量中的一部分 进一步将数据切分到每个GPU上 每个worker从参数服务器获取模型参数 复制参数到每个GPU上 每个GPU计算梯度 将所有GPU上的梯度求和 梯度传回服务器 每个服务器对梯度求和并更新参数 模型需要有好的计算(FLOP)通信(model size)比：Inception&gt;ResNet&gt;AlexNet Inception 比 ResNet更好做并行计算 36 数据增广 数据增强：增加一个已有数据集，使得有更多的多样性 在语言里面加入各种不同的背景噪音 改变图片的颜色和形状 在线生成增强后的数据，随机生成，随后使用增强数据进行训练，可认为一种正则项 常用方法： 左右翻转 上下翻转（不一定都可以） 切割（从图像中切割一块，然后变形到固定形状，使用随机高宽比，随机大小，随机位置） 颜色（改变色调，饱和度，明亮度） github上图片增强的各种方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132# 图片增广%matplotlib inlineimport torchimport torchvisionfrom torch import nnfrom d2l import torch as d2ld2l.set_figsize()img = d2l.Image.open(&#x27;../img/cat1.jpg&#x27;)d2l.plt.imshow(img);def apply(img, aug, num_rows=2, num_cols=4, scale=1.5): Y = [aug(img) for _ in range(num_rows * num_cols)] d2l.show_images(Y, num_rows, num_cols, scale=scale)# 左右翻转图像apply(img, torchvision.transforms.RandomHorizontalFlip())# 上下翻转图像apply(img, torchvision.transforms.RandomVerticalFlip())# 随机裁剪shape_aug = torchvision.transforms.RandomResizedCrop( (200, 200), scale=(0.1, 1), ratio=(0.5, 2))apply(img, shape_aug)# 改变颜色apply(img, torchvision.transforms.ColorJitter( brightness=0.5, contrast=0, saturation=0, hue=0))# 改变色调apply(img, torchvision.transforms.ColorJitter( brightness=0, contrast=0, saturation=0, hue=0.5))# 随机更改图像的亮度、对比度、饱和度和色调color_aug = torchvision.transforms.ColorJitter( brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)apply(img, color_aug)# 结合多种图像增广方法augs = torchvision.transforms.Compose([ torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])apply(img, augs)# 使用图像增广进行训练all_images = torchvision.datasets.CIFAR10(train=True, root=&quot;../data&quot;, download=True)d2l.show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8);# 只是用最简单的随机左右翻转train_augs = torchvision.transforms.Compose([ torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor()])test_augs = torchvision.transforms.Compose([ torchvision.transforms.ToTensor()])# 定义一个辅助函数，以便于读取图像和应用图像增广def load_cifar10(is_train, augs, batch_size): dataset = torchvision.datasets.CIFAR10(root=&quot;../data&quot;, train=is_train, transform=augs, download=True) dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=is_train, num_workers=d2l.get_dataloader_workers()) return dataloader# 定义一个函数，使用多GPU对模型进行评估和训练#@savedef train_batch_ch13(net, X, y, loss, trainer, devices): &quot;&quot;&quot;用多GPU进行小批量训练&quot;&quot;&quot; if isinstance(X, list): # 微调BERT中所需（稍后讨论） X = [x.to(devices[0]) for x in X] else: X = X.to(devices[0]) y = y.to(devices[0]) net.train() trainer.zero_grad() pred = net(X) l = loss(pred, y) l.sum().backward() trainer.step() train_loss_sum = l.sum() train_acc_sum = d2l.accuracy(pred, y) return train_loss_sum, train_acc_sum#@savedef train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices=d2l.try_all_gpus()): &quot;&quot;&quot;用多GPU进行模型训练&quot;&quot;&quot; timer, num_batches = d2l.Timer(), len(train_iter) animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, xlim=[1, num_epochs], ylim=[0, 1], legend=[&#x27;train loss&#x27;, &#x27;train acc&#x27;, &#x27;test acc&#x27;]) net = nn.DataParallel(net, device_ids=devices).to(devices[0]) for epoch in range(num_epochs): # 4个维度：储存训练损失，训练准确度，实例数，特点数 metric = d2l.Accumulator(4) for i, (features, labels) in enumerate(train_iter): timer.start() l, acc = train_batch_ch13( net, features, labels, loss, trainer, devices) metric.add(l, acc, labels.shape[0], labels.numel()) timer.stop() if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.add(epoch + (i + 1) / num_batches, (metric[0] / metric[2], metric[1] / metric[3], None)) test_acc = d2l.evaluate_accuracy_gpu(net, test_iter) animator.add(epoch + 1, (None, None, test_acc)) print(f&#x27;loss &#123;metric[0] / metric[2]:.3f&#125;, train acc &#x27; f&#x27;&#123;metric[1] / metric[3]:.3f&#125;, test acc &#123;test_acc:.3f&#125;&#x27;) print(f&#x27;&#123;metric[2] * num_epochs / timer.sum():.1f&#125; examples/sec on &#x27; f&#x27;&#123;str(devices)&#125;&#x27;)# 定义train_with_data_aug函数，使用图像增广来训练模型batch_size, devices, net = 256, d2l.try_all_gpus(), d2l.resnet18(10, 3)def init_weights(m): if type(m) in [nn.Linear, nn.Conv2d]: nn.init.xavier_uniform_(m.weight)net.apply(init_weights)def train_with_data_aug(train_augs, test_augs, net, lr=0.001): train_iter = load_cifar10(True, train_augs, batch_size) test_iter = load_cifar10(False, test_augs, batch_size) loss = nn.CrossEntropyLoss(reduction=&quot;none&quot;) trainer = torch.optim.Adam(net.parameters(), lr=lr) train_ch13(net, train_iter, test_iter, loss, trainer, 10, devices)# 训练模型train_with_data_aug(train_augs, test_augs, net) 37 微调(迁移学习之一) 微调是CV中深度学习最重要的技术，可以使用迁移学习 网络架构 一个神经网络一般可以分成两块 特征抽取将原始像素变成容易线性分割的特征 线性分类器来做分类 微调 网络架构中，使用源数据集训练好的模型，特征抽取部分可能仍然对目标数据集做特征抽取，线性分类器部分由于标号可能变了故该部分不能使用 微调中的权重初始化：在目标数据集模型初始化中，特征抽取部分的权重的初始化使用源数据集模型的权重，而线性分类器使用随机初始化 训练：是一个目标数据集上的正常训练任务，但使用更强的正则化 使用更小的学习率 使用更小的数据迭代 源数据集远复杂于目标数据集，通常微调效果更好 重用分类器权重 源数据集可能也有目标数据中的部分标号 可以使用预训练好模型分类器中对应标号对应的向量来做初始化 固定一些层 神经网络通常学习有层次地特征表示 低层次的特征更加通用 高层次的特征则更跟数据集相关 可以固定底部一些层的参数，不参与更新：更强的正则 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# 微调%matplotlib inlineimport osimport torchimport torchvisionfrom torch import nnfrom d2l import torch as d2l# 获取数据集，热狗数据集#@saved2l.DATA_HUB[&#x27;hotdog&#x27;] = (d2l.DATA_URL + &#x27;hotdog.zip&#x27;, &#x27;fba480ffa8aa7e0febbb511d181409f899b9baa5&#x27;)data_dir = d2l.download_extract(&#x27;hotdog&#x27;)train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, &#x27;train&#x27;))test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, &#x27;test&#x27;))# 图像的大小和纵横比各有不同hotdogs = [train_imgs[i][0] for i in range(8)]not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4);# 数据增广（匹配ImgNet上的模型）# 使用RGB通道的均值和标准差，以标准化每个通道normalize = torchvision.transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])train_augs = torchvision.transforms.Compose([ torchvision.transforms.RandomResizedCrop(224), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(), normalize])test_augs = torchvision.transforms.Compose([ torchvision.transforms.Resize(256), torchvision.transforms.CenterCrop(224), torchvision.transforms.ToTensor(), normalize])# 定义和初始化模型pretrained_net = torchvision.models.resnet18(pretrained=True) # 将模型下载，并且pretrained=True也下载模型的数据pretrained_net.fcfinetune_net = torchvision.models.resnet18(pretrained=True)finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2) # 将最后一层的输出通道改为2nn.init.xavier_uniform_(finetune_net.fc.weight); # 最后一层随机初始化# 微调模型# 如果param_group=True，输出层中的模型参数将使用十倍的学习率def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True): train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder( os.path.join(data_dir, &#x27;train&#x27;), transform=train_augs), batch_size=batch_size, shuffle=True) test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder( os.path.join(data_dir, &#x27;test&#x27;), transform=test_augs), batch_size=batch_size) devices = d2l.try_all_gpus() loss = nn.CrossEntropyLoss(reduction=&quot;none&quot;) if param_group: params_1x = [param for name, param in net.named_parameters() if name not in [&quot;fc.weight&quot;, &quot;fc.bias&quot;]] trainer = torch.optim.SGD([&#123;&#x27;params&#x27;: params_1x&#125;, &#123;&#x27;params&#x27;: net.fc.parameters(), &#x27;lr&#x27;: learning_rate * 10&#125;], lr=learning_rate, weight_decay=0.001) else: trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001) d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)# 训练模型train_fine_tuning(finetune_net, 5e-5)# 为了进行比较，所有模型参数初始化为随机值scratch_net = torchvision.models.resnet18()scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 2)train_fine_tuning(scratch_net, 5e-4, param_group=False) 最好都是从微调(fine tuning)开始进行训练，而不是从零开始训练 39 实战 Kaggle 比赛：图像分类（CIFAR-10） 比赛网址 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186import collectionsimport mathimport osimport shutilimport pandas as pdimport torchimport torchvisionfrom torch import nnfrom d2l import torch as d2l# 提供包含前1000个训练图像和5个随机测试图像的数据集的小规模样本#@saved2l.DATA_HUB[&#x27;cifar10_tiny&#x27;] = (d2l.DATA_URL + &#x27;kaggle_cifar10_tiny.zip&#x27;, &#x27;2068874e4b9a9f0fb07ebe0ad2b29754449ccacd&#x27;)# 如果你使用完整的Kaggle竞赛的数据集，设置demo为Falsedemo = Trueif demo: data_dir = d2l.download_extract(&#x27;cifar10_tiny&#x27;)else: data_dir = &#x27;../data/cifar-10/&#x27;# 整理数据集#@savedef read_csv_labels(fname): &quot;&quot;&quot;读取fname来给标签字典返回一个文件名&quot;&quot;&quot; with open(fname, &#x27;r&#x27;) as f: # 跳过文件头行(列名) lines = f.readlines()[1:] tokens = [l.rstrip().split(&#x27;,&#x27;) for l in lines] return dict(((name, label) for name, label in tokens))labels = read_csv_labels(os.path.join(data_dir, &#x27;trainLabels.csv&#x27;))print(&#x27;# 训练样本 :&#x27;, len(labels))print(&#x27;# 类别 :&#x27;, len(set(labels.values())))# 将验证集从原始的训练集中拆分出来def copyfile(filename, target_dir): &quot;&quot;&quot;将文件复制到目标目录&quot;&quot;&quot; os.makedirs(target_dir, exist_ok=True) shutil.copy(filename, target_dir)def reorg_train_valid(data_dir, labels, valid_ratio): &quot;&quot;&quot;将验证集从原始的训练集中拆分出来&quot;&quot;&quot; # 训练数据集中样本最少的类别中的样本数 n = collections.Counter(labels.values()).most_common()[-1][1] # 验证集中每个类别的样本数 n_valid_per_label = max(1, math.floor(n * valid_ratio)) label_count = &#123;&#125; for train_file in os.listdir(os.path.join(data_dir, &#x27;train&#x27;)): label = labels[train_file.split(&#x27;.&#x27;)[0]] fname = os.path.join(data_dir, &#x27;train&#x27;, train_file) copyfile(fname, os.path.join(data_dir, &#x27;train_valid_test&#x27;, &#x27;train_valid&#x27;, label)) if label not in label_count or label_count[label] &lt; n_valid_per_label: copyfile(fname, os.path.join(data_dir, &#x27;train_valid_test&#x27;, &#x27;valid&#x27;, label)) label_count[label] = label_count.get(label, 0) + 1 else: copyfile(fname, os.path.join(data_dir, &#x27;train_valid_test&#x27;, &#x27;train&#x27;, label)) return n_valid_per_label# 在预测掐尖整理测试集，以方便读取def reorg_test(data_dir): &quot;&quot;&quot;在预测期间整理测试集，以方便读取&quot;&quot;&quot; for test_file in os.listdir(os.path.join(data_dir, &#x27;test&#x27;)): copyfile(os.path.join(data_dir, &#x27;test&#x27;, test_file), os.path.join(data_dir, &#x27;train_valid_test&#x27;, &#x27;test&#x27;, &#x27;unknown&#x27;))# 调用前面定义的函数def reorg_cifar10_data(data_dir, valid_ratio): labels = read_csv_labels(os.path.join(data_dir, &#x27;trainLabels.csv&#x27;)) reorg_train_valid(data_dir, labels, valid_ratio) reorg_test(data_dir)batch_size = 32 if demo else 128valid_ratio = 0.1reorg_cifar10_data(data_dir, valid_ratio)# 图像增广transform_train = torchvision.transforms.Compose([ # 在高度和宽度上将图像放大到40像素的正方形 torchvision.transforms.Resize(40), # 随机裁剪出一个高度和宽度均为40像素的正方形图像， # 生成一个面积为原始图像面积0.64到1倍的小正方形， # 然后将其缩放为高度和宽度均为32像素的正方形 torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(), # 标准化图像的每个通道 torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])transform_test = torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])# 读取由原始图像组成的数据集train_ds, train_valid_ds = [torchvision.datasets.ImageFolder( os.path.join(data_dir, &#x27;train_valid_test&#x27;, folder), transform=transform_train) for folder in [&#x27;train&#x27;, &#x27;train_valid&#x27;]]valid_ds, test_ds = [torchvision.datasets.ImageFolder( os.path.join(data_dir, &#x27;train_valid_test&#x27;, folder), transform=transform_test) for folder in [&#x27;valid&#x27;, &#x27;test&#x27;]]# 指定上面定义的所有图像增广操作train_iter, train_valid_iter = [torch.utils.data.DataLoader( dataset, batch_size, shuffle=True, drop_last=True) for dataset in (train_ds, train_valid_ds)]valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False, drop_last=True)test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False, drop_last=False)# 模型def get_net(): num_classes = 10 net = d2l.resnet18(num_classes, 3) return netloss = nn.CrossEntropyLoss(reduction=&quot;none&quot;)# 训练函数def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay): trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd) scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay) num_batches, timer = len(train_iter), d2l.Timer() legend = [&#x27;train loss&#x27;, &#x27;train acc&#x27;] if valid_iter is not None: legend.append(&#x27;valid acc&#x27;) animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, xlim=[1, num_epochs], legend=legend) net = nn.DataParallel(net, device_ids=devices).to(devices[0]) for epoch in range(num_epochs): net.train() metric = d2l.Accumulator(3) for i, (features, labels) in enumerate(train_iter): timer.start() l, acc = d2l.train_batch_ch13(net, features, labels, loss, trainer, devices) metric.add(l, acc, labels.shape[0]) timer.stop() if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.add(epoch + (i + 1) / num_batches, (metric[0] / metric[2], metric[1] / metric[2], None)) if valid_iter is not None: valid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter) animator.add(epoch + 1, (None, None, valid_acc)) scheduler.step() measures = (f&#x27;train loss &#123;metric[0] / metric[2]:.3f&#125;, &#x27; f&#x27;train acc &#123;metric[1] / metric[2]:.3f&#125;&#x27;) if valid_iter is not None: measures += f&#x27;, valid acc &#123;valid_acc:.3f&#125;&#x27; print(measures + f&#x27;\\n&#123;metric[2] * num_epochs / timer.sum():.1f&#125;&#x27; f&#x27; examples/sec on &#123;str(devices)&#125;&#x27;)# 训练和验证模型devices, num_epochs, lr, wd = d2l.try_all_gpus(), 20, 2e-4, 5e-4lr_period, lr_decay, net = 4, 0.9, get_net()train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)# 在Kaggle上对测试集进行分类并提交结果net, preds = get_net(), []train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period, lr_decay)for X, _ in test_iter: y_hat = net(X.to(devices[0])) preds.extend(y_hat.argmax(dim=1).type(torch.int32).cpu().numpy())sorted_ids = list(range(1, len(test_ds) + 1))sorted_ids.sort(key=lambda x: str(x))df = pd.DataFrame(&#123;&#x27;id&#x27;: sorted_ids, &#x27;label&#x27;: preds&#125;)df[&#x27;label&#x27;] = df[&#x27;label&#x27;].apply(lambda x: train_valid_ds.classes[x])df.to_csv(&#x27;submission.csv&#x27;, index=False) 40 实战 Kaggle 比赛：狗的品种识别 比赛网址 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160import osimport torchimport torchvisionfrom torch import nnfrom d2l import torch as d2l# 下载数据集d2l.DATA_HUB[&#x27;dog_tiny&#x27;] = (d2l.DATA_URL + &#x27;kaggle_dog_tiny.zip&#x27;, &#x27;0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d&#x27;)# 如果你使用Kaggle比赛的完整数据集，请将下面的变量更改为Falsedemo = Trueif demo: data_dir = d2l.download_extract(&#x27;dog_tiny&#x27;)else: data_dir = os.path.join(&#x27;..&#x27;, &#x27;data&#x27;, &#x27;dog-breed-identification&#x27;)# 整理数据集def reorg_dog_data(data_dir, valid_ratio): labels = d2l.read_csv_labels(os.path.join(data_dir, &#x27;labels.csv&#x27;)) d2l.reorg_train_valid(data_dir, labels, valid_ratio) d2l.reorg_test(data_dir)batch_size = 32 if demo else 128valid_ratio = 0.1reorg_dog_data(data_dir, valid_ratio)# 图像增广transform_train = torchvision.transforms.Compose([ # 随机裁剪图像，所得图像为原始面积的0.08到1之间，高宽比在3/4和4/3之间。 # 然后，缩放图像以创建224x224的新图像 torchvision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0/4.0, 4.0/3.0)), torchvision.transforms.RandomHorizontalFlip(), # 随机更改亮度，对比度和饱和度 torchvision.transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4), # 添加随机噪声 torchvision.transforms.ToTensor(), # 标准化图像的每个通道 torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])transform_test = torchvision.transforms.Compose([ torchvision.transforms.Resize(256), # 从图像中心裁切224x224大小的图片 torchvision.transforms.CenterCrop(224), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])# 读取数据集train_ds, train_valid_ds = [torchvision.datasets.ImageFolder( os.path.join(data_dir, &#x27;train_valid_test&#x27;, folder), transform=transform_train) for folder in [&#x27;train&#x27;, &#x27;train_valid&#x27;]]valid_ds, test_ds = [torchvision.datasets.ImageFolder( os.path.join(data_dir, &#x27;train_valid_test&#x27;, folder), transform=transform_test) for folder in [&#x27;valid&#x27;, &#x27;test&#x27;]]train_iter, train_valid_iter = [torch.utils.data.DataLoader( dataset, batch_size, shuffle=True, drop_last=True) for dataset in (train_ds, train_valid_ds)]valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False, drop_last=True)test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False, drop_last=False)# 微调预训练模型def get_net(devices): finetune_net = nn.Sequential() finetune_net.features = torchvision.models.resnet34(pretrained=True) # 定义一个新的输出网络，共有120个输出类别 finetune_net.output_new = nn.Sequential(nn.Linear(1000, 256), nn.ReLU(), nn.Linear(256, 120)) # 将模型参数分配给用于计算的CPU或GPU finetune_net = finetune_net.to(devices[0]) # 冻结(卷积层)参数 for param in finetune_net.features.parameters(): param.requires_grad = False return finetune_net# 计算损失loss = nn.CrossEntropyLoss(reduction=&#x27;none&#x27;)def evaluate_loss(data_iter, net, devices): l_sum, n = 0.0, 0 for features, labels in data_iter: features, labels = features.to(devices[0]), labels.to(devices[0]) outputs = net(features) l = loss(outputs, labels) l_sum += l.sum() n += labels.numel() return (l_sum / n).to(&#x27;cpu&#x27;)# 训练函数def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay): # 只训练小型自定义输出网络 net = nn.DataParallel(net, device_ids=devices).to(devices[0]) trainer = torch.optim.SGD((param for param in net.parameters() if param.requires_grad), lr=lr, momentum=0.9, weight_decay=wd) scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay) num_batches, timer = len(train_iter), d2l.Timer() legend = [&#x27;train loss&#x27;] if valid_iter is not None: legend.append(&#x27;valid loss&#x27;) animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, xlim=[1, num_epochs], legend=legend) for epoch in range(num_epochs): metric = d2l.Accumulator(2) for i, (features, labels) in enumerate(train_iter): timer.start() features, labels = features.to(devices[0]), labels.to(devices[0]) trainer.zero_grad() output = net(features) l = loss(output, labels).sum() l.backward() trainer.step() metric.add(l, labels.shape[0]) timer.stop() if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.add(epoch + (i + 1) / num_batches, (metric[0] / metric[1], None)) measures = f&#x27;train loss &#123;metric[0] / metric[1]:.3f&#125;&#x27; if valid_iter is not None: valid_loss = evaluate_loss(valid_iter, net, devices) animator.add(epoch + 1, (None, valid_loss.detach().cpu())) scheduler.step() if valid_iter is not None: measures += f&#x27;, valid loss &#123;valid_loss:.3f&#125;&#x27; print(measures + f&#x27;\\n&#123;metric[1] * num_epochs / timer.sum():.1f&#125;&#x27; f&#x27; examples/sec on &#123;str(devices)&#125;&#x27;)# 训练和验证模型devices, num_epochs, lr, wd = d2l.try_all_gpus(), 10, 1e-4, 1e-4lr_period, lr_decay, net = 2, 0.9, get_net(devices)train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)# 对测试集分类并在Kaggle提交结果net = get_net(devices)train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period, lr_decay)preds = []for data, label in test_iter: output = torch.nn.functional.softmax(net(data.to(devices[0])), dim=0) preds.extend(output.cpu().detach().numpy())ids = sorted(os.listdir( os.path.join(data_dir, &#x27;train_valid_test&#x27;, &#x27;test&#x27;, &#x27;unknown&#x27;)))with open(&#x27;submission.csv&#x27;, &#x27;w&#x27;) as f: f.write(&#x27;id,&#x27; + &#x27;,&#x27;.join(train_valid_ds.classes) + &#x27;\\n&#x27;) for i, output in zip(ids, preds): f.write(i.split(&#x27;.&#x27;)[0] + &#x27;,&#x27; + &#x27;,&#x27;.join( [str(num) for num in output]) + &#x27;\\n&#x27;) 41 物体检测和数据集 目标检测中：边缘框 一个边缘框可以通过4个数字定义: (左上x, 左上y, 右下x, 右下y) (左上x, 左上y, 宽, 高) 图像处理从左上到右下遍历图片 目标检测数据集 每行表示一个物体：图片文件名，物体类别，边缘框 COCO 80个物体,330K图片,1.5M物体 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 目标检测和边界框%matplotlib inlineimport torchfrom d2l import torch as d2ld2l.set_figsize()img = d2l.plt.imread(&#x27;../img/catdog.jpg&#x27;)d2l.plt.imshow(img)# 定义在这两种表示之间进行转换的函数def box_corner_to_center(boxes): &quot;&quot;&quot;从（左上，右下）转换到（中间，宽度，高度）&quot;&quot;&quot; x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] cx = (x1 + x2) / 2 cy = (y1 + y2) / 2 w = x2 - x1 h = y2 - y1 boxes = torch.stack((cx, cy, w, h), axis=-1) return boxesdef box_center_to_corner(boxes): &quot;&quot;&quot;从（中间，宽度，高度）转换到（左上，右下）&quot;&quot;&quot; cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] x1 = cx - 0.5 * w y1 = cy - 0.5 * h x2 = cx + 0.5 * w y2 = cy + 0.5 * h boxes = torch.stack((x1, y1, x2, y2), axis=-1) return boxes# 定义图像中狗和猫的边界框dog_bbox, cat_bbox = [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0]boxes = torch.tensor((dog_bbox, cat_bbox))box_center_to_corner(box_corner_to_center(boxes)) == boxes# 将边界框在图中画出def bbox_to_rect(bbox, color): # 将边界框(左上x,左上y,右下x,右下y)格式转换成matplotlib格式： # ((左上x,左上y),宽,高) return d2l.plt.Rectangle( xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1], fill=False, edgecolor=color, linewidth=2)fig = d2l.plt.imshow(img)fig.axes.add_patch(bbox_to_rect(dog_bbox, &#x27;blue&#x27;))fig.axes.add_patch(bbox_to_rect(cat_bbox, &#x27;red&#x27;)) 数据集 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 目标检测数据集# 一个小型数据集 下载数据集%matplotlib inlineimport osimport pandas as pdimport torchimport torchvisionfrom d2l import torch as d2ld2l.DATA_HUB[&#x27;banana-detection&#x27;] = ( d2l.DATA_URL + &#x27;banana-detection.zip&#x27;, &#x27;5de26c8fce5ccdea9f91267273464dc968d20d72&#x27;)# 读取香蕉检测数据集def read_data_bananas(is_train=True): &quot;&quot;&quot;读取香蕉检测数据集中的图像和标签&quot;&quot;&quot; data_dir = d2l.download_extract(&#x27;banana-detection&#x27;) csv_fname = os.path.join(data_dir, &#x27;bananas_train&#x27; if is_train else &#x27;bananas_val&#x27;, &#x27;label.csv&#x27;) csv_data = pd.read_csv(csv_fname) csv_data = csv_data.set_index(&#x27;img_name&#x27;) images, targets = [], [] for img_name, target in csv_data.iterrows(): images.append(torchvision.io.read_image( os.path.join(data_dir, &#x27;bananas_train&#x27; if is_train else &#x27;bananas_val&#x27;, &#x27;images&#x27;, f&#x27;&#123;img_name&#125;&#x27;))) # 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y）， # 其中所有图像都具有相同的香蕉类（索引为0） targets.append(list(target)) return images, torch.tensor(targets).unsqueeze(1) / 256# 创建一个自定义Dataset实例class BananasDataset(torch.utils.data.Dataset): &quot;&quot;&quot;一个用于加载香蕉检测数据集的自定义数据集&quot;&quot;&quot; def __init__(self, is_train): self.features, self.labels = read_data_bananas(is_train) print(&#x27;read &#x27; + str(len(self.features)) + (f&#x27; training examples&#x27; if is_train else f&#x27; validation examples&#x27;)) def __getitem__(self, idx): return (self.features[idx].float(), self.labels[idx]) def __len__(self): return len(self.features)# 为了训练集和测试集返回两个数据加载器实例def load_data_bananas(batch_size): &quot;&quot;&quot;加载香蕉检测数据集&quot;&quot;&quot; train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True), batch_size, shuffle=True) val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False), batch_size) return train_iter, val_iter# 读取一个小批量，并打印其中的图像和标签的形状batch_size, edge_size = 32, 256train_iter, _ = load_data_bananas(batch_size)batch = next(iter(train_iter))batch[0].shape, batch[1].shape# 实例imgs = (batch[0][0:10].permute(0, 2, 3, 1)) / 255axes = d2l.show_images(imgs, 2, 5, scale=2)for ax, label in zip(axes, batch[1][0:10]): d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=[&#x27;w&#x27;]) 42 锚框 跳转至教材 锚框 一类目标检测算法是基于锚框（目前仍为主流算法） 提出多个被称为锚框的区域（边缘框） 预测每个锚框里是否含有有关注的物体 如果是，预测从这个锚框到真实边缘框的偏移 IoU交并比：用来计算两个框之间的相似度 0表示无重叠，1表示重合 是Jacquard指数的一个特殊情况 给定两个集合A和B：J(A,B)=∣A∩B∣∣A∪B∣J(A, B)=\\frac{|A \\cap B|}{|A \\cup B|}J(A,B)=∣A∪B∣∣A∩B∣​ 赋予锚框标号（一种常用算法） 每个锚框是一个训练样本 将每个锚框，要么标注成背景，要么关联上一个真实边缘框 可能会产生大量的锚框，这样会导致大量的负类样本 流程： 首先选取锚框值IoU中间的最大值，随后将其对应的边缘框给锚框，并将锚框所在的行和列的元素删除，重复上述操作，选出所有边缘框对应的锚框 使用非极大抑制(NMS)输出 每个锚框预测一个边缘框 NMS可以合并相似的预测 选中非背景类的最大预测值 去掉所有其它和它的IoU值大于 θ\\thetaθ 的预测 重复上述过程知道所有预测要么被选中，要么被去掉 总结 一类目标检测算法基于锚框来预测 首先生成大量锚框，并赋予标号，每个锚框作为一个样本进行训练 在预测时，使用NMS来去掉冗余的预测 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284%matplotlib inlineimport torchfrom d2l import torch as d2ltorch.set_printoptions(2) # 精简输出精度# 锚框的宽度和高度分别为 ws*sqrt(r) 和 hs*sqrt(r)# s 为锚框占图片的比例, r 为高宽的高低比# 组合为(s1,r1),(s1,r2),...,(s1,rm),(s2,r1),(s3,r1),...,(sn,r1)def multibox_prior(data, sizes, ratios): &quot;&quot;&quot;生成以每个像素为中心具有不同形状的锚框&quot;&quot;&quot; in_height, in_width = data.shape[-2:] device, num_sizes, num_ratios = data.device, len(sizes), len(ratios) boxes_per_pixel = (num_sizes + num_ratios - 1) # 生成锚框的总数量 size_tensor = torch.tensor(sizes, device=device) ratio_tensor = torch.tensor(ratios, device=device) # 为了将锚点移动到像素的中心，需要设置偏移量。 # 因为一个像素的高为1且宽为1，我们选择偏移我们的中心0.5 offset_h, offset_w = 0.5, 0.5 steps_h = 1.0 / in_height # 在y轴上缩放步长 steps_w = 1.0 / in_width # 在x轴上缩放步长 # 生成锚框的所有中心点 center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing=&#x27;ij&#x27;) shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1) # 生成“boxes_per_pixel”个高和宽， # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax) w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]), sizes[0] * torch.sqrt(ratio_tensor[1:])))\\ * in_height / in_width # 处理矩形输入 h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]), sizes[0] / torch.sqrt(ratio_tensor[1:]))) # 除以2来获得半高和半宽 anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat( in_height * in_width, 1) / 2 # 每个中心点都将有“boxes_per_pixel”个锚框， # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次 out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y], dim=1).repeat_interleave(boxes_per_pixel, dim=0) output = out_grid + anchor_manipulations return output.unsqueeze(0)# 返回锚框变量Y的形状img = d2l.plt.imread(&#x27;../img/catdog.jpg&#x27;)h, w = img.shape[:2]print(h, w)X = torch.rand(size=(1, 3, h, w))Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])Y.shape# 访问以(250,250)为中心的第一个锚框boxes = Y.reshape(h, w, 5, 4)boxes[250, 250, 0, :]# 显示以图像中的一个像素为中心的所有锚框def show_bboxes(axes, bboxes, labels=None, colors=None): &quot;&quot;&quot;显示所有边界框&quot;&quot;&quot; def _make_list(obj, default_values=None): if obj is None: obj = default_values elif not isinstance(obj, (list, tuple)): obj = [obj] return obj labels = _make_list(labels) colors = _make_list(colors, [&#x27;b&#x27;, &#x27;g&#x27;, &#x27;r&#x27;, &#x27;m&#x27;, &#x27;c&#x27;]) for i, bbox in enumerate(bboxes): color = colors[i % len(colors)] rect = d2l.bbox_to_rect(bbox.detach().numpy(), color) axes.add_patch(rect) if labels and len(labels) &gt; i: text_color = &#x27;k&#x27; if color == &#x27;w&#x27; else &#x27;w&#x27; axes.text(rect.xy[0], rect.xy[1], labels[i], va=&#x27;center&#x27;, ha=&#x27;center&#x27;, fontsize=9, color=text_color, bbox=dict(facecolor=color, lw=0))# 以(250，250)为中心的所有锚框d2l.set_figsize()bbox_scale = torch.tensor((w, h, w, h))fig = d2l.plt.imshow(img)show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale, [&#x27;s=0.75, r=1&#x27;, &#x27;s=0.5, r=1&#x27;, &#x27;s=0.25, r=1&#x27;, &#x27;s=0.75, r=2&#x27;, &#x27;s=0.75, r=0.5&#x27;])# 交并比(IoU)def box_iou(boxes1, boxes2): &quot;&quot;&quot;计算两个锚框或边界框列表中成对的交并比&quot;&quot;&quot; box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])) # boxes1,boxes2,areas1,areas2的形状: # boxes1：(boxes1的数量,4), # boxes2：(boxes2的数量,4), # areas1：(boxes1的数量,), # areas2：(boxes2的数量,) areas1 = box_area(boxes1) areas2 = box_area(boxes2) # inter_upperlefts,inter_lowerrights,inters的形状: # (boxes1的数量,boxes2的数量,2) inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2]) inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:]) inters = (inter_lowerrights - inter_upperlefts).clamp(min=0) # inter_areasandunion_areas的形状:(boxes1的数量,boxes2的数量) inter_areas = inters[:, :, 0] * inters[:, :, 1] union_areas = areas1[:, None] + areas2 - inter_areas return inter_areas / union_areas# 将真实边界框分配给锚框def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5): &quot;&quot;&quot;将最接近的真实边界框分配给锚框&quot;&quot;&quot; num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0] # 位于第i行和第j列的元素x_ij是锚框i和真实边界框j的IoU jaccard = box_iou(anchors, ground_truth) # 对于每个锚框，分配的真实边界框的张量 anchors_bbox_map = torch.full((num_anchors,), -1, dtype=torch.long, device=device) # 根据阈值，决定是否分配真实边界框 max_ious, indices = torch.max(jaccard, dim=1) anc_i = torch.nonzero(max_ious &gt;= iou_threshold).reshape(-1) box_j = indices[max_ious &gt;= iou_threshold] anchors_bbox_map[anc_i] = box_j col_discard = torch.full((num_anchors,), -1) row_discard = torch.full((num_gt_boxes,), -1) for _ in range(num_gt_boxes): max_idx = torch.argmax(jaccard) box_idx = (max_idx % num_gt_boxes).long() anc_idx = (max_idx / num_gt_boxes).long() anchors_bbox_map[anc_idx] = box_idx jaccard[:, box_idx] = col_discard jaccard[anc_idx, :] = row_discard return anchors_bbox_map# 标记类和偏移def offset_boxes(anchors, assigned_bb, eps=1e-6): &quot;&quot;&quot;对锚框偏移量的转换&quot;&quot;&quot; &quot;&quot;&quot;书中有详细介绍，最好使offest好预测，将值分散开而不是聚在一起，较好预测&quot;&quot;&quot; c_anc = d2l.box_corner_to_center(anchors) c_assigned_bb = d2l.box_corner_to_center(assigned_bb) offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:] offset_wh = 5 * torch.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:]) offset = torch.cat([offset_xy, offset_wh], axis=1) return offsetdef multibox_target(anchors, labels): &quot;&quot;&quot;使用真实边界框标记锚框&quot;&quot;&quot; batch_size, anchors = labels.shape[0], anchors.squeeze(0) batch_offset, batch_mask, batch_class_labels = [], [], [] device, num_anchors = anchors.device, anchors.shape[0] for i in range(batch_size): label = labels[i, :, :] anchors_bbox_map = assign_anchor_to_bbox( label[:, 1:], anchors, device) bbox_mask = ((anchors_bbox_map &gt;= 0).float().unsqueeze(-1)).repeat( 1, 4) # 将类标签和分配的边界框坐标初始化为零 class_labels = torch.zeros(num_anchors, dtype=torch.long, device=device) assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32, device=device) # 使用真实边界框来标记锚框的类别。 # 如果一个锚框没有被分配，我们标记其为背景（值为零） indices_true = torch.nonzero(anchors_bbox_map &gt;= 0) bb_idx = anchors_bbox_map[indices_true] class_labels[indices_true] = label[bb_idx, 0].long() + 1 assigned_bb[indices_true] = label[bb_idx, 1:] # 偏移量转换 offset = offset_boxes(anchors, assigned_bb) * bbox_mask batch_offset.append(offset.reshape(-1)) batch_mask.append(bbox_mask.reshape(-1)) batch_class_labels.append(class_labels) bbox_offset = torch.stack(batch_offset) bbox_mask = torch.stack(batch_mask) class_labels = torch.stack(batch_class_labels) return (bbox_offset, bbox_mask, class_labels)# 在图像中绘制这些地面真相边界框和锚框ground_truth = torch.tensor([[0, 0.1, 0.08, 0.52, 0.92], [1, 0.55, 0.2, 0.9, 0.88]])anchors = torch.tensor([[0, 0.1, 0.2, 0.3], [0.15, 0.2, 0.4, 0.4], [0.63, 0.05, 0.88, 0.98], [0.66, 0.45, 0.8, 0.8], [0.57, 0.3, 0.92, 0.9]])fig = d2l.plt.imshow(img)show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, [&#x27;dog&#x27;, &#x27;cat&#x27;], &#x27;k&#x27;)show_bboxes(fig.axes, anchors * bbox_scale, [&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;]);# 根据狗和猫的真实边界框，标注这些锚框的分类和偏移量labels = multibox_target(anchors.unsqueeze(dim=0), ground_truth.unsqueeze(dim=0))labels[2]labels[1]labels[0]# 应用逆偏移变换来返回预测的边界框坐标def offset_inverse(anchors, offset_preds): &quot;&quot;&quot;根据带有预测偏移量的锚框来预测边界框&quot;&quot;&quot; anc = d2l.box_corner_to_center(anchors) pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2] pred_bbox_wh = torch.exp(offset_preds[:, 2:] / 5) * anc[:, 2:] pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), axis=1) predicted_bbox = d2l.box_center_to_corner(pred_bbox) return predicted_bbox# 以下num函数按降序对置信度进行排序并返回其索引def nms(boxes, scores, iou_threshold): &quot;&quot;&quot;对预测边界框的置信度进行排序&quot;&quot;&quot; B = torch.argsort(scores, dim=-1, descending=True) keep = [] # 保留预测边界框的指标 while B.numel() &gt; 0: i = B[0] keep.append(i) if B.numel() == 1: break iou = box_iou(boxes[i, :].reshape(-1, 4), boxes[B[1:], :].reshape(-1, 4)).reshape(-1) inds = torch.nonzero(iou &lt;= iou_threshold).reshape(-1) B = B[inds + 1] return torch.tensor(keep, device=boxes.device)# 将极大值抑制应用于预测边界框def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5, pos_threshold=0.009999999): &quot;&quot;&quot;使用非极大值抑制来预测边界框&quot;&quot;&quot; device, batch_size = cls_probs.device, cls_probs.shape[0] anchors = anchors.squeeze(0) num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2] out = [] for i in range(batch_size): cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4) conf, class_id = torch.max(cls_prob[1:], 0) predicted_bb = offset_inverse(anchors, offset_pred) keep = nms(predicted_bb, conf, nms_threshold) # 找到所有的non_keep索引，并将类设置为背景 all_idx = torch.arange(num_anchors, dtype=torch.long, device=device) combined = torch.cat((keep, all_idx)) uniques, counts = combined.unique(return_counts=True) non_keep = uniques[counts == 1] all_id_sorted = torch.cat((keep, non_keep)) class_id[non_keep] = -1 class_id = class_id[all_id_sorted] conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted] # pos_threshold是一个用于非背景预测的阈值 below_min_idx = (conf &lt; pos_threshold) class_id[below_min_idx] = -1 conf[below_min_idx] = 1 - conf[below_min_idx] pred_info = torch.cat((class_id.unsqueeze(1), conf.unsqueeze(1), predicted_bb), dim=1) out.append(pred_info) return torch.stack(out)# 将上述算法应用到一个带四个锚框的具体示例中anchors = torch.tensor([[0.1, 0.08, 0.52, 0.92], [0.08, 0.2, 0.56, 0.95], [0.15, 0.3, 0.62, 0.91], [0.55, 0.2, 0.9, 0.88]])offset_preds = torch.tensor([0] * anchors.numel())cls_probs = torch.tensor([[0] * 4, # 背景的预测概率 [0.9, 0.8, 0.7, 0.1], # 狗的预测概率 [0.1, 0.2, 0.3, 0.9]]) # 猫的预测概率# 在图像上绘制这些预测边界框和置信度fig = d2l.plt.imshow(img)show_bboxes(fig.axes, anchors * bbox_scale, [&#x27;dog=0.9&#x27;, &#x27;dog=0.8&#x27;, &#x27;dog=0.7&#x27;, &#x27;cat=0.9&#x27;])output = multibox_detection(cls_probs.unsqueeze(dim=0), offset_preds.unsqueeze(dim=0), anchors.unsqueeze(dim=0), nms_threshold=0.5)outputfig = d2l.plt.imshow(img)for i in output[0].detach().numpy(): if i[0] == -1: continue label = (&#x27;dog=&#x27;, &#x27;cat=&#x27;)[int(i[0])] + str(i[1]) show_bboxes(fig.axes, [torch.tensor(i[2:]) * bbox_scale], label) 43 树叶分类竞赛技术总结 相比于课程介绍的代码，主要做了下面的加强 数据增强，在测试时多次使用稍弱的增强然后取平均 使用多个模型预测，最后结果加权平均 训练算法和学习率 清理数据 数据方面 有重复图片，可以手动去除 图片背景较多，而且树叶没有方向性，可以做更多增强 跨图片增强 Mixup：随机叠加两张图片 CutMix：随机组合来自不同图片的块 模型方面 模型多为ResNet变种 DenseNet,ResNeXt,ResNest,… EfficientNet 优化算法多为Adam或其变种 学习率一般使Cosine或者训练不同时往下调（存在相关代码） AutoGluon 15行代码，安装加训练化花时100分钟.跳转 精度96% 可以通过定制化提升精度 下一版本将搜索更多的模型超参数 AG目前仍是关注工业界上，非比赛 总结 提升精度思路：根据数据挑选增强，使用新模型，新优化算法，多个模型融合，测试时使用增强 在工业界应用中： 少使用模型融合和测试时增强，计算代价过高 通常固定模型超参数，而将精力主要花在提升数据质量 44 物体检测算法：R-CNN，SSD，YOLO R-CNN 使用启发式搜索算法来选择锚框 使用与训练模型来对每个锚框抽取特征 训练一个SVM来对类别分类 训练一个线性回归模型来预测边缘框偏移 兴趣区域(RoI)池化层 给定一个锚框,均匀分割成n∗mn*mn∗m块，输出每块里的最大值 不管锚框多大，总是输出 nmnmnm 个值 Fast RCNN 上述模型每次一张图片需要抽取特征，一张图片需要抽取特征变成大量的小图片，而Fast RCNN在一整张图片上抽取特征给定锚框，在锚框内使用RoI池化，最后输出一个矩阵 不对每个锚框进行CNN抽取特征，而是对整张图片抽取特征 使用CNN对图片抽取特征 使用RoI池化层对每个锚框生成固定长度特征 Faster R-CNN：使用一个区域提议网络(RPN)来替代启发式搜索来获得更好的锚框 使用一个神经网络来代替上述的选择性搜索算法，相当于进行一次粗糙的目标检测 Mask R-CNN 如果有像素级别的标号，使用FCN来利用这些信息 RoI池化层改为RoI align 在像素级别预测时，切分为等分，像素值为加权平均数 总结 Fast/Faster RCNN持续提升性能 Fast/Faster RCNN和Mask RCNN是在追求高精度场景下的常用算法 单发多框检测(SSD) 生成锚框 对每个像素，生成多个以它为中心的锚框 给定n个大小x1,s2,...snx_1,s_2,...s_nx1​,s2​,...sn​和mmm个高宽比，那么生成n+m−1n+m-1n+m−1个锚框，其大小和高宽比分别为(s1,r1),(s2,r1),...,(sn,r1),(s1,r2),...,(s1,rm)(s_1,r_1),(s_2,r_1),...,(s_n,r_1),(s_1,r_2),...,(s_1,r_m)(s1​,r1​),(s2​,r1​),...,(sn​,r1​),(s1​,r2​),...,(s1​,rm​) SSD模型 一个基础网络来抽取特征，然后多个卷积层块来减半高宽 在每段都生成锚框：底部段来拟合小物体，顶部段来拟合大物体 对每个锚框预测类别和边缘框 总结 SSD通过单神经网络来检测模型 以每个像素为中心的产生多个锚框 在多个段的输出上进行多尺度的检测 YOLO模型 SSD中锚框大量重叠，因此浪费了很多计算 YOLO将图片均匀分成s∗ss*ss∗s个锚框 每个锚框预测B个边缘框 45 SSD实现 跳转至Bilibili视频 45.1 多尺度锚框 跳转至教材 123456789101112131415161718192021222324252627# 多尺度目标检测%matplotlib inlineimport torchfrom d2l import torch as d2limg = d2l.plt.imread(&#x27;../img/catdog.jpg&#x27;)h, w = img.shape[:2]h, w# 在特征图(fmap)上生成锚框(anchors),每个单位(像素)作为锚框中心def display_anchors(fmap_w, fmap_h, s): d2l.set_figsize() # 前两个维度上的值不影响输出 fmap = torch.zeros((1, 10, fmap_h, fmap_w)) anchors = d2l.multibox_prior(fmap, sizes=s, ratios=[1, 2, 0.5]) bbox_scale = torch.tensor((w, h, w, h)) d2l.show_bboxes(d2l.plt.imshow(img).axes, anchors[0] * bbox_scale)# 探测小目标display_anchors(fmap_w=4, fmap_h=4, s=[0.15])# 将特征图的高宽减半，然后使用较大的锚框来检测较大的目标display_anchors(fmap_w=2, fmap_h=2, s=[0.4])# 将特征图的高宽减半，然后使用较大的锚框来检测较大的目标display_anchors(fmap_w=1, fmap_h=1, s=[0.8]) 45.2 SSD 跳转至教材 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219%matplotlib inlineimport torchimport torchvisionfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2l# 类别预测层(每个锚框都需要预测(num_classes + 1)类)def cls_predictor(num_inputs, num_anchors, num_classes): return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1), kernel_size=3, padding=1) # 该组合不会改变图像的尺寸# 预测的类别数为H*w*num_anchors*(num_class+1)# 需要对每一个像素生成的锚框进行检测，3*3的视野# 边界框预测层def bbox_predictor(num_inputs, num_anchors): return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)# 输出通道数：每个像素的锚框大小*4(锚框有4个值)# 连接多尺度的预测def forward(x, block): return block(x)Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))Y1.shape, Y2.shape# 将4-D转换为1-D# 将通道数丢到最后，将后面的3个维度拉成一个向量def flatten_pred(pred): return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)# 在宽上contactdef concat_preds(preds): return torch.cat([flatten_pred(p) for p in preds], dim=1)concat_preds([Y1, Y2]).shape# 高和宽减半块def down_sample_blk(in_channels, out_channels): blk = [] for _ in range(2): blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)) blk.append(nn.BatchNorm2d(out_channels)) blk.append(nn.ReLU()) in_channels = out_channels blk.append(nn.MaxPool2d(2)) return nn.Sequential(*blk)forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape# 基本网络层def base_net(): blk = [] num_filters = [3, 16, 32, 64] for i in range(len(num_filters) - 1): blk.append(down_sample_blk(num_filters[i], num_filters[i+1])) return nn.Sequential(*blk)forward(torch.zeros((2, 3, 256, 256)), base_net()).shape# 完整的模型# 在5个尺度上进行目标检测def get_blk(i): if i == 0: blk = base_net() elif i == 1: blk = down_sample_blk(64, 128) elif i == 4: blk = nn.AdaptiveMaxPool2d((1,1)) #global max pooling else: blk = down_sample_blk(128, 128) return blk# 为每个块定义前向传播# 与图像分类任务不同，此处的输出包括：CNN特征图Y；在当前尺度下根据Y生成的锚框；预测的这些锚框的类别和偏移量（基于Y）def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor): Y = blk(X) anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio) cls_preds = cls_predictor(Y) bbox_preds = bbox_predictor(Y) return (Y, anchors, cls_preds, bbox_preds)# 超参数sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79], [0.88, 0.961]]ratios = [[1, 2, 0.5]] * 5num_anchors = len(sizes[0]) + len(ratios[0]) - 1# 定义完整的模型TinySSDclass TinySSD(nn.Module): def __init__(self, num_classes, **kwargs): super(TinySSD, self).__init__(**kwargs) self.num_classes = num_classes idx_to_in_channels = [64, 128, 128, 128, 128] for i in range(5): # 即赋值语句self.blk_i=get_blk(i) setattr(self, f&#x27;blk_&#123;i&#125;&#x27;, get_blk(i)) setattr(self, f&#x27;cls_&#123;i&#125;&#x27;, cls_predictor(idx_to_in_channels[i], num_anchors, num_classes)) setattr(self, f&#x27;bbox_&#123;i&#125;&#x27;, bbox_predictor(idx_to_in_channels[i], num_anchors)) def forward(self, X): anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5 for i in range(5): # getattr(self,&#x27;blk_%d&#x27;%i)即访问self.blk_i X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward( X, getattr(self, f&#x27;blk_&#123;i&#125;&#x27;), sizes[i], ratios[i], getattr(self, f&#x27;cls_&#123;i&#125;&#x27;), getattr(self, f&#x27;bbox_&#123;i&#125;&#x27;)) anchors = torch.cat(anchors, dim=1) cls_preds = concat_preds(cls_preds) cls_preds = cls_preds.reshape( cls_preds.shape[0], -1, self.num_classes + 1) bbox_preds = concat_preds(bbox_preds) return anchors, cls_preds, bbox_preds# 创建一个模型实例，然后使用它执行前向计算net = TinySSD(num_classes=1)X = torch.zeros((32, 3, 256, 256))anchors, cls_preds, bbox_preds = net(X)print(&#x27;output anchors:&#x27;, anchors.shape)print(&#x27;output class preds:&#x27;, cls_preds.shape)print(&#x27;output bbox preds:&#x27;, bbox_preds.shape)# ---------# 2 训练模型# 读取数据集并初始化batch_size = 32train_iter, _ = d2l.load_data_bananas(batch_size)# 初始化其参数并定义优化函数device, net = d2l.try_gpu(), TinySSD(num_classes=1)trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)# 定义损失函数和评价函数cls_loss = nn.CrossEntropyLoss(reduction=&#x27;none&#x27;)bbox_loss = nn.L1Loss(reduction=&#x27;none&#x27;) # 不使用L2的原因，当预测偏差太大时，损失函数较小def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks): batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2] cls = cls_loss(cls_preds.reshape(-1, num_classes), cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1) bbox = bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks).mean(dim=1) # mask=0时不需要计算loss函数，只需要计算mask=1时的loss函数 return cls + bboxdef cls_eval(cls_preds, cls_labels): # 由于类别预测结果放在最后一维，argmax需要指定最后一维。 return float((cls_preds.argmax(dim=-1).type(cls_labels.dtype) == cls_labels).sum())def bbox_eval(bbox_preds, bbox_labels, bbox_masks): return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())# 训练模型num_epochs, timer = 20, d2l.Timer()animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, xlim=[1, num_epochs], legend=[&#x27;class error&#x27;, &#x27;bbox mae&#x27;])net = net.to(device)for epoch in range(num_epochs): # 训练精确度的和，训练精确度的和中的示例数 # 绝对误差的和，绝对误差的和中的示例数 metric = d2l.Accumulator(4) net.train() for features, target in train_iter: timer.start() trainer.zero_grad() X, Y = features.to(device), target.to(device) # 生成多尺度的锚框，为每个锚框预测类别和偏移量 anchors, cls_preds, bbox_preds = net(X) # 为每个锚框标注类别和偏移量 bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, Y) # 根据类别和偏移量的预测和标注值计算损失函数 l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks) l.mean().backward() trainer.step() metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(), bbox_eval(bbox_preds, bbox_labels, bbox_masks), bbox_labels.numel()) cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3] animator.add(epoch + 1, (cls_err, bbox_mae))print(f&#x27;class err &#123;cls_err:.2e&#125;, bbox mae &#123;bbox_mae:.2e&#125;&#x27;)print(f&#x27;&#123;len(train_iter.dataset) / timer.stop():.1f&#125; examples/sec on &#x27; f&#x27;&#123;str(device)&#125;&#x27;)# 预测目标X = torchvision.io.read_image(&#x27;../img/banana.jpg&#x27;).unsqueeze(0).float()img = X.squeeze(0).permute(1, 2, 0).long()def predict(X): net.eval() anchors, cls_preds, bbox_preds = net(X.to(device)) cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1) output = d2l.multibox_detection(cls_probs, bbox_preds, anchors) idx = [i for i, row in enumerate(output[0]) if row[0] != -1] return output[0, idx]output = predict(X)# 筛选所有置信度不低于0.9的边界框，作为最终输出def display(img, output, threshold): d2l.set_figsize((5, 5)) fig = d2l.plt.imshow(img) for row in output: score = float(row[1]) if score &lt; threshold: continue h, w = img.shape[0:2] bbox = [row[2:6] * torch.tensor((w, h, w, h), device=row.device)] d2l.show_bboxes(fig.axes, bbox, &#x27;%.2f&#x27; % score, &#x27;w&#x27;)display(img, output.cpu(), threshold=0.9) 46 语义分割和数据集 语义分割将图片中的每个像素分类到对应的类别 应用：背景虚化，路面分割 实例分割：区别每一个实例，目标检测的进化版本 最重要的语义分割数据集之一时Pascal VOC2012 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144%matplotlib inlineimport osimport torchimport torchvisionfrom d2l import torch as d2l#@saved2l.DATA_HUB[&#x27;voc2012&#x27;] = (d2l.DATA_URL + &#x27;VOCtrainval_11-May-2012.tar&#x27;, &#x27;4e443f8a2eca6b1dac8a6c57641b67dd40621a49&#x27;)voc_dir = d2l.download_extract(&#x27;voc2012&#x27;, &#x27;VOCdevkit/VOC2012&#x27;)# 将所有输入的图像和标签读入内存#@savedef read_voc_images(voc_dir, is_train=True): &quot;&quot;&quot;读取所有VOC图像并标注&quot;&quot;&quot; txt_fname = os.path.join(voc_dir, &#x27;ImageSets&#x27;, &#x27;Segmentation&#x27;, &#x27;train.txt&#x27; if is_train else &#x27;val.txt&#x27;) mode = torchvision.io.image.ImageReadMode.RGB with open(txt_fname, &#x27;r&#x27;) as f: images = f.read().split() features, labels = [], [] for i, fname in enumerate(images): features.append(torchvision.io.read_image(os.path.join( voc_dir, &#x27;JPEGImages&#x27;, f&#x27;&#123;fname&#125;.jpg&#x27;))) labels.append(torchvision.io.read_image(os.path.join( voc_dir, &#x27;SegmentationClass&#x27; ,f&#x27;&#123;fname&#125;.png&#x27;), mode)) return features, labelstrain_features, train_labels = read_voc_images(voc_dir, True)# 绘制前5个输入图像及其标签n = 5imgs = train_features[0:n] + train_labels[0:n]imgs = [img.permute(1,2,0) for img in imgs]d2l.show_images(imgs, 2, n);# 列举RGB颜色值和类名VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]]VOC_CLASSES = [&#x27;background&#x27;, &#x27;aeroplane&#x27;, &#x27;bicycle&#x27;, &#x27;bird&#x27;, &#x27;boat&#x27;, &#x27;bottle&#x27;, &#x27;bus&#x27;, &#x27;car&#x27;, &#x27;cat&#x27;, &#x27;chair&#x27;, &#x27;cow&#x27;, &#x27;diningtable&#x27;, &#x27;dog&#x27;, &#x27;horse&#x27;, &#x27;motorbike&#x27;, &#x27;person&#x27;, &#x27;potted plant&#x27;, &#x27;sheep&#x27;, &#x27;sofa&#x27;, &#x27;train&#x27;, &#x27;tv/monitor&#x27;]# 查找标签中每个像素的类标签def voc_colormap2label(): &quot;&quot;&quot;构建从RGB到VOC类别索引的映射&quot;&quot;&quot; colormap2label = torch.zeros(256 ** 3, dtype=torch.long) for i, colormap in enumerate(VOC_COLORMAP): colormap2label[ (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i return colormap2labeldef voc_label_indices(colormap, colormap2label): &quot;&quot;&quot;将VOC标签中的RGB值映射到它们的类别索引&quot;&quot;&quot; colormap = colormap.permute(1, 2, 0).numpy().astype(&#x27;int32&#x27;) idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256 + colormap[:, :, 2]) return colormap2label[idx]# 例如y = voc_label_indices(train_labels[0], voc_colormap2label())y[105:115, 130:140], VOC_CLASSES[1]# 使用图片增广中的随机裁剪，裁剪输入图像和标签的相同区域def voc_rand_crop(feature, label, height, width): &quot;&quot;&quot;随机裁剪特征和标签图像&quot;&quot;&quot; rect = torchvision.transforms.RandomCrop.get_params( feature, (height, width)) feature = torchvision.transforms.functional.crop(feature, *rect) label = torchvision.transforms.functional.crop(label, *rect) return feature, labelimgs = []for _ in range(n): imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300)imgs = [img.permute(1, 2, 0) for img in imgs]d2l.show_images(imgs[::2] + imgs[1::2], 2, n);# 自定义语义分割数据集类class VOCSegDataset(torch.utils.data.Dataset): &quot;&quot;&quot;一个用于加载VOC数据集的自定义数据集&quot;&quot;&quot; def __init__(self, is_train, crop_size, voc_dir): self.transform = torchvision.transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) self.crop_size = crop_size features, labels = read_voc_images(voc_dir, is_train=is_train) self.features = [self.normalize_image(feature) for feature in self.filter(features)] self.labels = self.filter(labels) self.colormap2label = voc_colormap2label() print(&#x27;read &#x27; + str(len(self.features)) + &#x27; examples&#x27;) def normalize_image(self, img): return self.transform(img.float() / 255) def filter(self, imgs): return [img for img in imgs if ( img.shape[1] &gt;= self.crop_size[0] and img.shape[2] &gt;= self.crop_size[1])] def __getitem__(self, idx): feature, label = voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size) return (feature, voc_label_indices(label, self.colormap2label)) def __len__(self): return len(self.features)# 读取数据集crop_size = (320, 480)voc_train = VOCSegDataset(True, crop_size, voc_dir)voc_test = VOCSegDataset(False, crop_size, voc_dir)batch_size = 64train_iter = torch.utils.data.DataLoader(voc_train, batch_size, shuffle=True, drop_last=True, num_workers=d2l.get_dataloader_workers())for X, Y in train_iter: print(X.shape) print(Y.shape) break# 整合所有组件def load_data_voc(batch_size, crop_size): &quot;&quot;&quot;加载VOC语义分割数据集&quot;&quot;&quot; voc_dir = d2l.download_extract(&#x27;voc2012&#x27;, os.path.join( &#x27;VOCdevkit&#x27;, &#x27;VOC2012&#x27;)) num_workers = d2l.get_dataloader_workers() train_iter = torch.utils.data.DataLoader( VOCSegDataset(True, crop_size, voc_dir), batch_size, shuffle=True, drop_last=True, num_workers=num_workers) test_iter = torch.utils.data.DataLoader( VOCSegDataset(False, crop_size, voc_dir), batch_size, drop_last=True, num_workers=num_workers) return train_iter, test_iter 47 转置卷积 47.1 转置卷积 转置卷积(在语义分割中常用) 卷积不会增大输入的高宽，通常要么不变，要么减半 转置卷积则可以用来增大输入高宽 为什么称为转置 对于卷积Y=X⋆WY = X \\star WY=X⋆W，可以对W构造一个V使得卷积等价于Y′=VX′,Y′,X′Y^{&#x27;} = VX^{&#x27;},Y^{&#x27;},X^{&#x27;}Y′=VX′,Y′,X′对应Y,XY,XY,X的向量版本 转置卷积则等价于Y′=VTX′Y^{&#x27;} = V^TX^{&#x27;}Y′=VTX′ 如果卷积将输入从(h,w)(h,w)(h,w)变成了(h′,w′)(h^{&#x27;},w^{&#x27;})(h′,w′)，同样超参数下它将(h′,w′)(h^{&#x27;},w^{&#x27;})(h′,w′)变成(h,w)(h,w)(h,w) 47.2 转置卷积也是一种卷积 转置卷积是一种卷积 将输入和核进行了重新排列 同卷积一般是做下采样不同，通常用作上采样 如果卷积将输入从(h,w)(h,w)(h,w)变成了(h′,w′)(h^{&#x27;},w^{&#x27;})(h′,w′)，同样超参数下它将(h′,w′)(h^{&#x27;},w^{&#x27;})(h′,w′)变成(h,w)(h,w)(h,w) 重新排列输入和核 当填充为0步幅为1时 将输入填充k-1（k是核窗口） 将核矩阵上下，左右翻转 然后正常卷积(填充0,步幅1) 当填充为p步幅为1时 将输入填充k-p-1（k是核窗口） 将核矩阵上下，左右翻转 然后正常卷积(填充0,步幅1) 当填充为p步幅为s时 在行和列之间插入s-1行或列 将输入填充k-p-1（k是核窗口） 将核矩阵上下，左右翻转 然后正常卷积(填充0,步幅1) 形状换算 输入高(宽)为n,核k，填充p，步幅s 转置卷积:n′=sn+k−2p−sn^{&#x27;}=sn+k-2p-sn′=sn+k−2p−s 卷积:n′=[(n−k−2p+s)/s]→n&gt;=sn′+k−2p−sn^{&#x27;}=[(n-k-2p+s)/s] \\rightarrow n &gt;= sn^{&#x27;} +k-2p-sn′=[(n−k−2p+s)/s]→n&gt;=sn′+k−2p−s 当(n−k−2p+s)/s(n-k-2p+s)/s(n−k−2p+s)/s可以整除,则n&gt;=sn′+k−2p−sn &gt;= sn^{&#x27;} +k-2p-sn&gt;=sn′+k−2p−s 与转置卷积公式互为逆公式，当卷积在不能整除时，转置卷积时的nnn为能整除的最小的nnn 如果让高宽成倍增加,那么k=2p+sk=2p+sk=2p+s 同反卷积的关系 数学上的反卷积是卷积的逆运算：若Y=conv(X,K)Y = conv(X,K)Y=conv(X,K)则X=deconv(Y,K)X=deconv(Y,K)X=deconv(Y,K) 反卷积与转置卷积并相同，反卷积很少用在深度学习中，反卷积神经网络指用了转置卷积的神经网络 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 转置卷积的实现import torchfrom torch import nnfrom d2l import torch as d2ldef trans_conv(X, K): h, w = K.shape Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1)) for i in range(X.shape[0]): for j in range(X.shape[1]): Y[i: i + h, j: j + w] += X[i, j] * K return Y# 验证上述实现输出X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])trans_conv(X, K)# 使用高级API获得相同的结果X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)tconv.weight.data = Ktconv(X)# 填充，步幅和多通道tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, padding=1, bias=False)tconv.weight.data = Ktconv(X)tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, bias=False)tconv.weight.data = Ktconv(X)X = torch.rand(size=(1, 10, 16, 16))conv = nn.Conv2d(10, 20, kernel_size=5, padding=2, stride=3)tconv = nn.ConvTranspose2d(20, 10, kernel_size=5, padding=2, stride=3)tconv(conv(X)).shape == X.shape# 与矩阵变换的关系X = torch.arange(9.0).reshape(3, 3)K = torch.tensor([[1.0, 2.0], [3.0, 4.0]])Y = d2l.corr2d(X, K)Ydef kernel2matrix(K): k, W = torch.zeros(5), torch.zeros((4, 9)) k[:2], k[3:5] = K[0, :], K[1, :] W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k return WW = kernel2matrix(K)WY == torch.matmul(W, X.reshape(-1)).reshape(2, 2)Z = trans_conv(Y, K)Z == torch.matmul(W.T, Y.reshape(-1)).reshape(3, 3) 转置卷积不是进行上采样，可以对卷积核的参数进行训练 48 全连接卷积神经网络 FCN 全连接神经网络(FCN) 是用深度神经网络来做语义分割的奠基性工作 用转置卷积层替换CNN最后的全连接层，从而可以实现每个像素的预测 将CNN中的最后的全连接层和全局池化层去除 1*1卷积层合并通道，降低通道数，减小计算量 转置卷积层，将图片扩大 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596%matplotlib inlineimport torchimport torchvisionfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2l# 使用在ImageNet数据集上与训练的ResNet18模型来提取图像特征pretrained_net = torchvision.models.resnet18(pretrained=True)list(pretrained_net.children())[-3:]# 创建一个全卷积网络实例netnet = nn.Sequential(*list(pretrained_net.children())[:-2])X = torch.rand(size=(1, 3, 320, 480))net(X).shape# 使用1*1卷基层将输出通道转换为Pascal VOC2012数据集的类数# 将要素地图的高宽增加32倍num_classes = 21net.add_module(&#x27;final_conv&#x27;, nn.Conv2d(512, num_classes, kernel_size=1))net.add_module(&#x27;transpose_conv&#x27;, nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, padding=16, stride=32))# 初始化转置卷积层def bilinear_kernel(in_channels, out_channels, kernel_size): factor = (kernel_size + 1) // 2 if kernel_size % 2 == 1: center = factor - 1 else: center = factor - 0.5 og = (torch.arange(kernel_size).reshape(-1, 1), torch.arange(kernel_size).reshape(1, -1)) filt = (1 - torch.abs(og[0] - center) / factor) * \\ (1 - torch.abs(og[1] - center) / factor) weight = torch.zeros((in_channels, out_channels, kernel_size, kernel_size)) weight[range(in_channels), range(out_channels), :, :] = filt return weight# 双线性插值的上采样实验conv_trans = nn.ConvTranspose2d(3, 3, kernel_size=4, padding=1, stride=2, bias=False)conv_trans.weight.data.copy_(bilinear_kernel(3, 3, 4));img = torchvision.transforms.ToTensor()(d2l.Image.open(&#x27;../img/catdog.jpg&#x27;))X = img.unsqueeze(0)Y = conv_trans(X)out_img = Y[0].permute(1, 2, 0).detach()d2l.set_figsize()print(&#x27;input image shape:&#x27;, img.permute(1, 2, 0).shape)d2l.plt.imshow(img.permute(1, 2, 0));print(&#x27;output image shape:&#x27;, out_img.shape)d2l.plt.imshow(out_img);# 用双线性插值的上采样初始化转置卷积层# 对于卷积层，使用Xavier初始化参数W = bilinear_kernel(num_classes, num_classes, 64)net.transpose_conv.weight.data.copy_(W);# 读取数据集batch_size, crop_size = 32, (320, 480)train_iter, test_iter = d2l.load_data_voc(batch_size, crop_size)# 训练def loss(inputs, targets): return F.cross_entropy(inputs, targets, reduction=&#x27;none&#x27;).mean(1).mean(1)num_epochs, lr, wd, devices = 5, 0.001, 1e-3, d2l.try_all_gpus()trainer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)# 预测def predict(img): X = test_iter.dataset.normalize_image(img).unsqueeze(0) pred = net(X.to(devices[0])).argmax(dim=1) return pred.reshape(pred.shape[1], pred.shape[2])# 可视化预测的类别def label2image(pred): colormap = torch.tensor(d2l.VOC_COLORMAP, device=devices[0]) X = pred.long() return colormap[X, :]voc_dir = d2l.download_extract(&#x27;voc2012&#x27;, &#x27;VOCdevkit/VOC2012&#x27;)test_images, test_labels = d2l.read_voc_images(voc_dir, False)n, imgs = 4, []for i in range(n): crop_rect = (0, 0, 320, 480) X = torchvision.transforms.functional.crop(test_images[i], *crop_rect) pred = label2image(predict(X)) imgs += [X.permute(1,2,0), pred.cpu(), torchvision.transforms.functional.crop( test_labels[i], *crop_rect).permute(1,2,0)]d2l.show_images(imgs[::3] + imgs[1::3] + imgs[2::3], 3, n, scale=2); 49 样式迁移 样式迁移：将样式图片中的样式迁移到内容图片上，得到合成图片（类似滤镜） 基于CNN的样式迁移 内容图片计算其CNN的特征的内容损失 样式图片计算其CNN的特征的样式损失 训练的生成的图片的CNN的特征的内容损失和样式损失,同时计算图像上的噪点 训练内容为图片，不是损失函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136%matplotlib inlineimport torchimport torchvisionfrom torch import nnfrom d2l import torch as d2ld2l.set_figsize()content_img = d2l.Image.open(&#x27;../img/rainier.jpg&#x27;)d2l.plt.imshow(content_img);style_img = d2l.Image.open(&#x27;../img/autumn-oak.jpg&#x27;)d2l.plt.imshow(style_img);# 预处理和后处理rgb_mean = torch.tensor([0.485, 0.456, 0.406])rgb_std = torch.tensor([0.229, 0.224, 0.225])def preprocess(img, image_shape): transforms = torchvision.transforms.Compose([ torchvision.transforms.Resize(image_shape), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=rgb_mean, std=rgb_std)]) return transforms(img).unsqueeze(0)def postprocess(img): #上述过程的反过程 img = img[0].to(rgb_std.device) img = torch.clamp(img.permute(1, 2, 0) * rgb_std + rgb_mean, 0, 1) return torchvision.transforms.ToPILImage()(img.permute(2, 0, 1))# 抽取图像特征,使用VGG19(VGG系列对抽取特征效果较好)pretrained_net = torchvision.models.vgg19(pretrained=True)style_layers, content_layers = [0, 5, 10, 19, 28], [25]net = nn.Sequential(*[pretrained_net.features[i] for i in range(max(content_layers + style_layers) + 1)])# 抽取特征的函数def extract_features(X, content_layers, style_layers): contents = [] styles = [] for i in range(len(net)): X = net[i](X) if i in style_layers: styles.append(X) if i in content_layers: contents.append(X) return contents, stylesdef get_contents(image_shape, device): content_X = preprocess(content_img, image_shape).to(device) contents_Y, _ = extract_features(content_X, content_layers, style_layers) return content_X, contents_Ydef get_styles(image_shape, device): style_X = preprocess(style_img, image_shape).to(device) _, styles_Y = extract_features(style_X, content_layers, style_layers) return style_X, styles_Y# 定义损失函数def content_loss(Y_hat, Y): # 我们从动态计算梯度的树中分离目标： # 这是一个规定的值，而不是一个变量。 return torch.square(Y_hat - Y.detach()).mean()def gram(X): num_channels, n = X.shape[1], X.numel() // X.shape[1] X = X.reshape((num_channels, n)) return torch.matmul(X, X.T) / (num_channels * n)def style_loss(Y_hat, gram_Y): return torch.square(gram(Y_hat) - gram_Y.detach()).mean()def tv_loss(Y_hat): return 0.5 * (torch.abs(Y_hat[:, :, 1:, :] - Y_hat[:, :, :-1, :]).mean() + torch.abs(Y_hat[:, :, :, 1:] - Y_hat[:, :, :, :-1]).mean())# 风格转移的损失函数是内容损失，风格损失和总变化损失的加权和content_weight, style_weight, tv_weight = 1, 1e3, 10def compute_loss(X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram): # 分别计算内容损失、风格损失和全变分损失 contents_l = [content_loss(Y_hat, Y) * content_weight for Y_hat, Y in zip( contents_Y_hat, contents_Y)] styles_l = [style_loss(Y_hat, Y) * style_weight for Y_hat, Y in zip( styles_Y_hat, styles_Y_gram)] tv_l = tv_loss(X) * tv_weight # 对所有损失求和 l = sum(10 * styles_l + contents_l + [tv_l]) return contents_l, styles_l, tv_l, l# 初始化合成图像class SynthesizedImage(nn.Module): def __init__(self, img_shape, **kwargs): super(SynthesizedImage, self).__init__(**kwargs) self.weight = nn.Parameter(torch.rand(*img_shape)) def forward(self): return self.weightdef get_inits(X, device, lr, styles_Y): gen_img = SynthesizedImage(X.shape).to(device) gen_img.weight.data.copy_(X.data) trainer = torch.optim.Adam(gen_img.parameters(), lr=lr) styles_Y_gram = [gram(Y) for Y in styles_Y] return gen_img(), styles_Y_gram, trainer# 训练模型def train(X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch): X, styles_Y_gram, trainer = get_inits(X, device, lr, styles_Y) scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_decay_epoch, 0.8) animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss&#x27;, xlim=[10, num_epochs], legend=[&#x27;content&#x27;, &#x27;style&#x27;, &#x27;TV&#x27;], ncols=2, figsize=(7, 2.5)) for epoch in range(num_epochs): trainer.zero_grad() contents_Y_hat, styles_Y_hat = extract_features( X, content_layers, style_layers) contents_l, styles_l, tv_l, l = compute_loss( X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram) l.backward() trainer.step() scheduler.step() if (epoch + 1) % 10 == 0: animator.axes[1].imshow(postprocess(X)) animator.add(epoch + 1, [float(sum(contents_l)), float(sum(styles_l)), float(tv_l)]) return X# 训练模型device, image_shape = d2l.try_gpu(), (300, 450)net = net.to(device)content_X, contents_Y = get_contents(image_shape, device)_, styles_Y = get_styles(image_shape, device)output = train(content_X, contents_Y, styles_Y, device, 0.3, 500, 50) VGG系列对抽取特征效果较好 51 序列模型 序列数据：实际中很多数据是有时序结构 统计工具 在时间ttt观察到xtx_txt​,那么得到T个不独立的随机变量(x1,…xT)∼p(x)\\left(x_1, \\ldots x_T\\right) \\sim p(\\mathbf{x})(x1​,…xT​)∼p(x) 使用条件概率展开：p(a,b)=p(a)p(b∣a)=p(b)p(a∣b)p(a, b)=p(a) p(b \\mid a)=p(b) p(a \\mid b)p(a,b)=p(a)p(b∣a)=p(b)p(a∣b) 序列模型 -p(x)=p(x1)⋅p(x2∣x1)⋅p(x3∣x1,x2)⋅…p(xT∣x1,…xT−1)p(\\mathbf{x})=p\\left(x_1\\right) \\cdot p\\left(x_2 \\mid x_1\\right) \\cdot p\\left(x_3 \\mid x_1, x_2\\right) \\cdot \\ldots p\\left(x_T \\mid x_1, \\ldots x_{T-1}\\right)p(x)=p(x1​)⋅p(x2​∣x1​)⋅p(x3​∣x1​,x2​)⋅…p(xT​∣x1​,…xT−1​) 对条件概率建模：p(xt∣x1,…xt−1)=p(xt∣f(x1,…xt−1))p\\left(x_t \\mid x_1, \\ldots x_{t-1}\\right)=p\\left(x_t \\mid f\\left(x_1, \\ldots x_{t-1}\\right)\\right)p(xt​∣x1​,…xt−1​)=p(xt​∣f(x1​,…xt−1​)) 对见过的数据建模，也称自回归模型 方案A——马尔可夫假设 假设当前数据只跟τ\\tauτ个数据点相关：p(xt∣x1,…xt−1)=p(xt∣xt−τ,…xt−1)=p(xt∣f(xt−τ,…xt−1))p\\left(x_t \\mid x_1, \\ldots x_{t-1}\\right)=p\\left(x_t \\mid x_{t-\\tau}, \\ldots x_{t-1}\\right)=p\\left(x_t \\mid f\\left(x_{t-\\tau}, \\ldots x_{t-1}\\right)\\right)p(xt​∣x1​,…xt−1​)=p(xt​∣xt−τ​,…xt−1​)=p(xt​∣f(xt−τ​,…xt−1​)) 方案B——潜变量模型 引入潜变量hth_tht​来表示过去信息ht=f(x1,...,xt−1)h_t=f(x_1,...,x_{t-1})ht​=f(x1​,...,xt−1​)：xt=p(xt∣ht)x_t=p(x_t|h_t)xt​=p(xt​∣ht​) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# 使用正弦函数和一些可加性噪声来生成序列数据%matplotlib inlineimport torchfrom torch import nnfrom d2l import torch as d2lT = 1000 # 总共产生1000个点time = torch.arange(1, T + 1, dtype=torch.float32)x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))d2l.plot(time, [x], &#x27;time&#x27;, &#x27;x&#x27;, xlim=[1, 1000], figsize=(6, 3))# 将数据映射为数据对y_t=x_t和x_t=[...]tau = 4features = torch.zeros((T - tau, tau))for i in range(tau): features[:, i] = x[i: T - tau + i]labels = x[tau:].reshape((-1, 1))batch_size, n_train = 16, 600# 只有前n_train个样本用于训练train_iter = d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train=True)# 使用一个相当简单的结构：只是一个拥有两个全连接层的多层感知机# 初始化网络权重的函数def init_weights(m): if type(m) == nn.Linear: nn.init.xavier_uniform_(m.weight)# 一个简单的多层感知机def get_net(): net = nn.Sequential(nn.Linear(4, 10), nn.ReLU(), nn.Linear(10, 1)) net.apply(init_weights) return net# 平方损失。注意：MSELoss计算平方误差时不带系数1/2loss = nn.MSELoss(reduction=&#x27;none&#x27;)# 训练模型def train(net, train_iter, loss, epochs, lr): trainer = torch.optim.Adam(net.parameters(), lr) for epoch in range(epochs): for X, y in train_iter: trainer.zero_grad() l = loss(net(X), y) l.sum().backward() trainer.step() print(f&#x27;epoch &#123;epoch + 1&#125;, &#x27; f&#x27;loss: &#123;d2l.evaluate_loss(net, train_iter, loss):f&#125;&#x27;)net = get_net()train(net, train_iter, loss, 5, 0.01)# 模型预测下一个时间步onestep_preds = net(features)d2l.plot([time, time[tau:]], [x.detach().numpy(), onestep_preds.detach().numpy()], &#x27;time&#x27;, &#x27;x&#x27;, legend=[&#x27;data&#x27;, &#x27;1-step preds&#x27;], xlim=[1, 1000], figsize=(6, 3))# 进行多步预测multistep_preds = torch.zeros(T)multistep_preds[: n_train + tau] = x[: n_train + tau]for i in range(n_train + tau, T): multistep_preds[i] = net( multistep_preds[i - tau:i].reshape((1, -1)))d2l.plot([time, time[tau:], time[n_train + tau:]], [x.detach().numpy(), onestep_preds.detach().numpy(), multistep_preds[n_train + tau:].detach().numpy()], &#x27;time&#x27;, &#x27;x&#x27;, legend=[&#x27;data&#x27;, &#x27;1-step preds&#x27;, &#x27;multistep preds&#x27;], xlim=[1, 1000], figsize=(6, 3))# 每次预测有误差，导致误差累积，预测效果较差# 更仔细地看k预测max_steps = 64features = torch.zeros((T - tau - max_steps + 1, tau + max_steps))# 列i（i&lt;tau）是来自x的观测，其时间步从（i）到（i+T-tau-max_steps+1）for i in range(tau): features[:, i] = x[i: i + T - tau - max_steps + 1]# 列i（i&gt;=tau）是来自（i-tau+1）步的预测，其时间步从（i）到（i+T-tau-max_steps+1）for i in range(tau, tau + max_steps): features[:, i] = net(features[:, i - tau:i]).reshape(-1)steps = (1, 4, 16, 64)d2l.plot([time[tau + i - 1: T - max_steps + i] for i in steps], [features[:, (tau + i - 1)].detach().numpy() for i in steps], &#x27;time&#x27;, &#x27;x&#x27;, legend=[f&#x27;&#123;i&#125;-step preds&#x27; for i in steps], xlim=[5, 1000], figsize=(6, 3)) 52 文本预处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110# 文本预处理import collectionsimport refrom d2l import torch as d2l# 将数据集读取到由多条文本行组成的列表中d2l.DATA_HUB[&#x27;time_machine&#x27;] = (d2l.DATA_URL + &#x27;timemachine.txt&#x27;, &#x27;090b5e7e70c295757f55df93cb0a180b9691891a&#x27;)def read_time_machine(): &quot;&quot;&quot;将时间机器数据集加载到文本行的列表中&quot;&quot;&quot; with open(d2l.download(&#x27;time_machine&#x27;), &#x27;r&#x27;) as f: lines = f.readlines() return [re.sub(&#x27;[^A-Za-z]+&#x27;, &#x27; &#x27;, line).strip().lower() for line in lines]lines = read_time_machine()print(f&#x27;# 文本总行数: &#123;len(lines)&#125;&#x27;)print(lines[0])print(lines[10])# 每个文本序列又被拆分成一个标记列表def tokenize(lines, token=&#x27;word&#x27;): #@save &quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot; if token == &#x27;word&#x27;: return [line.split() for line in lines] elif token == &#x27;char&#x27;: return [list(line) for line in lines] else: print(&#x27;错误：未知词元类型：&#x27; + token)tokens = tokenize(lines)for i in range(11): print(tokens[i])# 构建一个字典，通常也叫做词汇表，用来将字符串类型的标记映射到从0开始的数字索引中class Vocab: #@save &quot;&quot;&quot;文本词表&quot;&quot;&quot; def __init__(self, tokens=None, min_freq=0, reserved_tokens=None): if tokens is None: tokens = [] if reserved_tokens is None: reserved_tokens = [] # 按出现频率排序 counter = count_corpus(tokens) self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True) # 未知词元的索引为0 self.idx_to_token = [&#x27;&lt;unk&gt;&#x27;] + reserved_tokens self.token_to_idx = &#123;token: idx for idx, token in enumerate(self.idx_to_token)&#125; for token, freq in self._token_freqs: if freq &lt; min_freq: break if token not in self.token_to_idx: self.idx_to_token.append(token) self.token_to_idx[token] = len(self.idx_to_token) - 1 def __len__(self): return len(self.idx_to_token) def __getitem__(self, tokens): if not isinstance(tokens, (list, tuple)): return self.token_to_idx.get(tokens, self.unk) return [self.__getitem__(token) for token in tokens] def to_tokens(self, indices): if not isinstance(indices, (list, tuple)): return self.idx_to_token[indices] return [self.idx_to_token[index] for index in indices] @property def unk(self): # 未知词元的索引为0 return 0 @property def token_freqs(self): return self._token_freqsdef count_corpus(tokens): #@save &quot;&quot;&quot;统计词元的频率&quot;&quot;&quot; # 这里的tokens是1D列表或2D列表 if len(tokens) == 0 or isinstance(tokens[0], list): # 将词元列表展平成一个列表 tokens = [token for line in tokens for token in line] return collections.Counter(tokens)# 构建词汇表vocab = Vocab(tokens)print(list(vocab.token_to_idx.items())[:10])# 将每一条文本行转换成一个数字索引列表for i in [0, 10]: print(&#x27;文本:&#x27;, tokens[i]) print(&#x27;索引:&#x27;, vocab[tokens[i]])# 将所有功能打包到函数中def load_corpus_time_machine(max_tokens=-1): #@save &quot;&quot;&quot;返回时光机器数据集的词元索引列表和词表&quot;&quot;&quot; lines = read_time_machine() tokens = tokenize(lines, &#x27;char&#x27;) vocab = Vocab(tokens) # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落， # 所以将所有文本行展平到一个列表中 corpus = [vocab[token] for line in tokens for token in line] if max_tokens &gt; 0: corpus = corpus[:max_tokens] return corpus, vocabcorpus, vocab = load_corpus_time_machine()len(corpus), len(vocab) 53 语言模型 语言模型 给定文本序列x1,...xtx_1,...x_tx1​,...xt​，语言模型的目的是估计联合概率p(x1,...xT)p(x_1,...x_T)p(x1​,...xT​) 应用： 做与训练模型(BERT,GPT-3) 生成文本，给定前面几个词，不断地生成后续文本 判断多个序列中哪个更常见 使用计数来建模 假定序列长度为2,预测p(x,x′)=p(x)p(x′∣x)=n(x)nn(x,x′)n(x)p\\left(x, x^{\\prime}\\right)=p(x) p\\left(x^{\\prime} \\mid x\\right)=\\frac{n(x)}{n} \\frac{n\\left(x, x^{\\prime}\\right)}{n(x)}p(x,x′)=p(x)p(x′∣x)=nn(x)​n(x)n(x,x′)​ n是总词数，n(x),n(x,x′)n(x),n(x,x^{&#x27;})n(x),n(x,x′)是单个单词和连续单词对的出现次数 很容易扩展到长为3的情况p(x,x′,x′′)=p(x)p(x′∣x)p(x′′∣x,x′)=n(x)nn(x,x′)n(x)n(x,x′,x′′)n(x,x′)p\\left(x, x^{\\prime}, x^{\\prime \\prime}\\right)=p(x) p\\left(x^{\\prime} \\mid x\\right) p\\left(x^{\\prime \\prime} \\mid x, x^{\\prime}\\right)=\\frac{n(x)}{n} \\frac{n\\left(x, x^{\\prime}\\right)}{n(x)} \\frac{n\\left(x, x^{\\prime}, x^{\\prime \\prime}\\right)}{n\\left(x, x^{\\prime}\\right)}p(x,x′,x′′)=p(x)p(x′∣x)p(x′′∣x,x′)=nn(x)​n(x)n(x,x′)​n(x,x′)n(x,x′,x′′)​ N元语法 当序列很长时，因为文本量不够大，很可能n(x1,...xT)&lt;=1n(x_1,...x_T) &lt;= 1n(x1​,...xT​)&lt;=1 使用马尔可夫假设缓解这个问题 一元语法：p(x1,x2,x3,x4)=p(x1)p(x2)p(x3)p(x4)=n(x1)nn(x2)nn(x3)nn(x4)np\\left(x_1, x_2, x_3, x_4\\right)=p\\left(x_1\\right) p\\left(x_2\\right) p\\left(x_3\\right) p\\left(x_4\\right)=\\frac{n\\left(x_1\\right)}{n} \\frac{n\\left(x_2\\right)}{n} \\frac{n\\left(x_3\\right)}{n} \\frac{n\\left(x_4\\right)}{n}p(x1​,x2​,x3​,x4​)=p(x1​)p(x2​)p(x3​)p(x4​)=nn(x1​)​nn(x2​)​nn(x3​)​nn(x4​)​ 二元语法:p(x1,x2,x3,x4)=p(x1)p(x2∣x1)p(x3∣x2)p(x4∣x3)=n(x1)nn(x1,x2)n(x1)n(x2,x3)n(x2)n(x3,x4)n(x3)p\\left(x_1, x_2, x_3, x_4\\right)=p\\left(x_1\\right) p\\left(x_2 \\mid x_1\\right) p\\left(x_3 \\mid x_2\\right) p\\left(x_4 \\mid x_3\\right)=\\frac{n\\left(x_1\\right)}{n} \\frac{n\\left(x_1, x_2\\right)}{n\\left(x_1\\right)} \\frac{n\\left(x_2, x_3\\right)}{n\\left(x_2\\right)} \\frac{n\\left(x_3, x_4\\right)}{n\\left(x_3\\right)}p(x1​,x2​,x3​,x4​)=p(x1​)p(x2​∣x1​)p(x3​∣x2​)p(x4​∣x3​)=nn(x1​)​n(x1​)n(x1​,x2​)​n(x2​)n(x2​,x3​)​n(x3​)n(x3​,x4​)​ 三元语法：p(x1,x2,x3,x4)=p(x1)p(x2∣x1)p(x3∣x1,x2)p(x4∣x2,x3)p\\left(x_1, x_2, x_3, x_4\\right)=p\\left(x_1\\right) p\\left(x_2 \\mid x_1\\right) p\\left(x_3 \\mid x_1, x_2\\right) p\\left(x_4 \\mid x_2, x_3\\right)p(x1​,x2​,x3​,x4​)=p(x1​)p(x2​∣x1​)p(x3​∣x1​,x2​)p(x4​∣x2​,x3​) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103import randomimport torchfrom d2l import torch as d2ltokens = d2l.tokenize(d2l.read_time_machine())# 因为每个文本行不一定是一个句子或一个段落，因此我们把所有文本行拼接到一起corpus = [token for line in tokens for token in line]vocab = d2l.Vocab(corpus)vocab.token_freqs[:10]# 最流行的次词被称为停用词 画出词频图freqs = [freq for token, freq in vocab.token_freqs]d2l.plot(freqs, xlabel=&#x27;token: x&#x27;, ylabel=&#x27;frequency: n(x)&#x27;, xscale=&#x27;log&#x27;, yscale=&#x27;log&#x27;)# 其他的次元组合，比如二元语法bigram_tokens = [pair for pair in zip(corpus[:-1], corpus[1:])]bigram_vocab = d2l.Vocab(bigram_tokens)bigram_vocab.token_freqs[:10]# 三元语法trigram_tokens = [triple for triple in zip( corpus[:-2], corpus[1:-1], corpus[2:])]trigram_vocab = d2l.Vocab(trigram_tokens)trigram_vocab.token_freqs[:10]# 直观对比一元语法，二元语法，三元语法bigram_freqs = [freq for token, freq in bigram_vocab.token_freqs]trigram_freqs = [freq for token, freq in trigram_vocab.token_freqs]d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=&#x27;token: x&#x27;, ylabel=&#x27;frequency: n(x)&#x27;, xscale=&#x27;log&#x27;, yscale=&#x27;log&#x27;, legend=[&#x27;unigram&#x27;, &#x27;bigram&#x27;, &#x27;trigram&#x27;])# 随机地生成一个小批量数据的特征和标签以供读取# 在随机采样中，每个样本都是在原始的长序列上任意获取的子序列def seq_data_iter_random(corpus, batch_size, num_steps): #@save &quot;&quot;&quot;使用随机抽样生成一个小批量子序列&quot;&quot;&quot; # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1 corpus = corpus[random.randint(0, num_steps - 1):] # 减去1，是因为我们需要考虑标签 num_subseqs = (len(corpus) - 1) // num_steps # 长度为num_steps的子序列的起始索引 initial_indices = list(range(0, num_subseqs * num_steps, num_steps)) # 在随机抽样的迭代过程中， # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻 random.shuffle(initial_indices) def data(pos): # 返回从pos位置开始的长度为num_steps的序列 return corpus[pos: pos + num_steps] num_batches = num_subseqs // batch_size for i in range(0, batch_size * num_batches, batch_size): # 在这里，initial_indices包含子序列的随机起始索引 initial_indices_per_batch = initial_indices[i: i + batch_size] X = [data(j) for j in initial_indices_per_batch] Y = [data(j + 1) for j in initial_indices_per_batch] yield torch.tensor(X), torch.tensor(Y)# 生成一个0到34的序列my_seq = list(range(35))for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5): print(&#x27;X: &#x27;, X, &#x27;\\nY:&#x27;, Y)# 保证两个相邻的小批量中的子序列在原始序列上时连续的def seq_data_iter_sequential(corpus, batch_size, num_steps): #@save &quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot; # 从随机偏移量开始划分序列 offset = random.randint(0, num_steps) num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size Xs = torch.tensor(corpus[offset: offset + num_tokens]) Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens]) Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1) num_batches = Xs.shape[1] // num_steps for i in range(0, num_steps * num_batches, num_steps): X = Xs[:, i: i + num_steps] Y = Ys[:, i: i + num_steps] yield X, Yfor X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5): print(&#x27;X: &#x27;, X, &#x27;\\nY:&#x27;, Y)# 将上面的两个采样函数包装到一个类中class SeqDataLoader: #@save &quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot; def __init__(self, batch_size, num_steps, use_random_iter, max_tokens): if use_random_iter: self.data_iter_fn = d2l.seq_data_iter_random else: self.data_iter_fn = d2l.seq_data_iter_sequential self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens) self.batch_size, self.num_steps = batch_size, num_steps def __iter__(self): return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)# 定义总函数，同时返回数据迭代器和词汇表def load_data_time_machine(batch_size, num_steps, #@save use_random_iter=False, max_tokens=10000): &quot;&quot;&quot;返回时光机器数据集的迭代器和词表&quot;&quot;&quot; data_iter = SeqDataLoader( batch_size, num_steps, use_random_iter, max_tokens) return data_iter, data_iter.vocab 54 循环神经网络 RNN 潜变量自回归模型：使用潜变量hth_tht​总结过去信息 循环神经网络 更新隐藏状态：ht=ϕ(Whhht−1+Whxxt−1+bh)\\mathbf{h}_t=\\phi\\left(\\mathbf{W}_{h h} \\mathbf{h}_{t-1}+\\mathbf{W}_{h x} \\mathbf{x}_{t-1}+\\mathbf{b}_h\\right)ht​=ϕ(Whh​ht−1​+Whx​xt−1​+bh​) 输出ot=ϕ(Whoht+bo)\\mathbf{o}_t=\\phi\\left(\\mathbf{W}_{h o} \\mathbf{h}_t+\\mathbf{b}_o\\right)ot​=ϕ(Who​ht​+bo​) 困惑度 衡量一个语言模型的好坏可以用平均交叉熵：π=1n∑i=1n−log⁡p(xt∣xt−1,…)\\pi=\\frac{1}{n} \\sum_{i=1}^n-\\log p\\left(x_t \\mid x_{t-1}, \\ldots\\right)π=n1​∑i=1n​−logp(xt​∣xt−1​,…),p时语言模型预测概率,xtx_txt​是真实词 历史原因NLP使用困惑度exp(π)exp(\\pi)exp(π)来衡量，是平均每次可能选项：1表示完美，无穷大是最差情况 梯度裁剪 迭代中计算这T个时间步上的梯度，在反向传播过程中产生长度为O(T)O(T)O(T)的矩阵乘法链，导致数值不稳定 梯度剪裁能有效预防梯度爆炸,如果梯度长度超过θ\\thetaθ,那拖影回长度g←min⁡(1,θ∥g∥)g\\mathbf{g} \\leftarrow \\min \\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}g←min(1,∥g∥θ​)g 55 循环神经网络 RNN 的实现 55.1 从零开始实现 跳转至教材 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172%matplotlib inlineimport mathimport torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lbatch_size, num_steps = 32, 35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# one-hot编码F.one_hot(torch.tensor([0, 2]), len(vocab))# 小批量数据形状是(批量大小,时间步数)X = torch.arange(10).reshape((2, 5))F.one_hot(X.T, 28).shape# (时间步数, 批量大小, 字典长度)# 初始化循环神经网络模型的模型参数def get_params(vocab_size, num_hiddens, device): num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device) * 0.01 # 隐藏层参数 W_xh = normal((num_inputs, num_hiddens)) W_hh = normal((num_hiddens, num_hiddens)) b_h = torch.zeros(num_hiddens, device=device) # 输出层参数 W_hq = normal((num_hiddens, num_outputs)) b_q = torch.zeros(num_outputs, device=device) # 附加梯度 params = [W_xh, W_hh, b_h, W_hq, b_q] for param in params: param.requires_grad_(True) return params# 在初始化时返回隐藏状态def init_rnn_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device=device), )# 定义了如何在一个时间步内计算隐藏状态和输出def rnn(inputs, state, params): # inputs的形状：(时间步数量，批量大小，词表大小) W_xh, W_hh, b_h, W_hq, b_q = params H, = state outputs = [] # X的形状：(批量大小，词表大小) for X in inputs: H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h) Y = torch.mm(H, W_hq) + b_q outputs.append(Y) return torch.cat(outputs, dim=0), (H,) # 行数为批量大小*时间# 创建一个类包装这些函数class RNNModelScratch: &quot;&quot;&quot;从零开始实现的循环神经网络模型&quot;&quot;&quot; def __init__(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn): self.vocab_size, self.num_hiddens = vocab_size, num_hiddens self.params = get_params(vocab_size, num_hiddens, device) self.init_state, self.forward_fn = init_state, forward_fn def __call__(self, X, state): X = F.one_hot(X.T, self.vocab_size).type(torch.float32) return self.forward_fn(X, state, self.params) def begin_state(self, batch_size, device): return self.init_state(batch_size, self.num_hiddens, device)# 检查输出是否具有正确的形状num_hiddens = 512net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,init_rnn_state, rnn)state = net.begin_state(X.shape[0], d2l.try_gpu())Y, new_state = net(X.to(d2l.try_gpu()), state)Y.shape, len(new_state), new_state[0].shape# 定义预测函数来生成prefix之后的新字符def predict_ch8(prefix, num_preds, net, vocab, device): #@save &quot;&quot;&quot;在prefix后面生成新字符&quot;&quot;&quot; state = net.begin_state(batch_size=1, device=device) outputs = [vocab[prefix[0]]] get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1)) for y in prefix[1:]: # 预热期 _, state = net(get_input(), state) outputs.append(vocab[y]) for _ in range(num_preds): # 预测num_preds步 y, state = net(get_input(), state) outputs.append(int(y.argmax(dim=1).reshape(1))) return &#x27;&#x27;.join([vocab.idx_to_token[i] for i in outputs])predict_ch8(&#x27;time traveller &#x27;, 10, net, vocab, d2l.try_gpu())# 梯度剪裁def grad_clipping(net, theta): &quot;&quot;&quot;裁剪梯度&quot;&quot;&quot; if isinstance(net, nn.Module): params = [p for p in net.parameters() if p.requires_grad] else: params = net.params norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params)) if norm &gt; theta: for param in params: param.grad[:] *= theta / norm# 定义一个函数在一个迭代周期内训练模型def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter): &quot;&quot;&quot;训练网络一个迭代周期（定义见第8章）&quot;&quot;&quot; state, timer = None, d2l.Timer() metric = d2l.Accumulator(2) # 训练损失之和,词元数量 for X, Y in train_iter: if state is None or use_random_iter: # 在第一次迭代或使用随机抽样时初始化state state = net.begin_state(batch_size=X.shape[0], device=device) else: if isinstance(net, nn.Module) and not isinstance(state, tuple): # state对于nn.GRU是个张量 state.detach_() else: # state对于nn.LSTM或对于我们从零开始实现的模型是个张量 for s in state: s.detach_() y = Y.T.reshape(-1) X, y = X.to(device), y.to(device) y_hat, state = net(X, state) l = loss(y_hat, y.long()).mean() #为什么将输出contact成一个维度，在loss角度上是一个多分类问题 if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.backward() grad_clipping(net, 1) updater.step() else: l.backward() grad_clipping(net, 1) # 因为已经调用了mean函数 updater(batch_size=1) metric.add(l * y.numel(), y.numel()) return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()# 训练函数即支持从零开始实现，也可以使用高级API来实现def train_ch8(net, train_iter, vocab, lr, num_epochs, device, use_random_iter=False): &quot;&quot;&quot;训练模型（定义见第8章）&quot;&quot;&quot; loss = nn.CrossEntropyLoss() animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, ylabel=&#x27;perplexity&#x27;, legend=[&#x27;train&#x27;], xlim=[10, num_epochs]) # 初始化 if isinstance(net, nn.Module): updater = torch.optim.SGD(net.parameters(), lr) else: updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size) predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device) # 训练和预测 for epoch in range(num_epochs): ppl, speed = train_epoch_ch8( net, train_iter, loss, updater, device, use_random_iter) if (epoch + 1) % 10 == 0: print(predict(&#x27;time traveller&#x27;)) animator.add(epoch + 1, [ppl]) print(f&#x27;困惑度 &#123;ppl:.1f&#125;, &#123;speed:.1f&#125; 词元/秒 &#123;str(device)&#125;&#x27;) print(predict(&#x27;time traveller&#x27;)) print(predict(&#x27;traveller&#x27;))# 训练循环神经网络模型num_epochs, lr = 500, 1train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,init_rnn_state, rnn)train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(), use_random_iter=True) 55.2 简洁实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lbatch_size, num_steps = 32, 35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# 定义模型num_hiddens = 256rnn_layer = nn.RNN(len(vocab), num_hiddens)# 使用张量来初始化隐藏状态state = torch.zeros((1, batch_size, num_hiddens))state.shape# 通过一个隐藏状态和一个输入，就可以用更新后的隐藏状态计算输出X = torch.rand(size=(num_steps, batch_size, len(vocab)))Y, state_new = rnn_layer(X, state)Y.shape, state_new.shape# 一个完整的循环网络模型定义了一个RNNModel类class RNNModel(nn.Module): &quot;&quot;&quot;循环神经网络模型&quot;&quot;&quot; def __init__(self, rnn_layer, vocab_size, **kwargs): super(RNNModel, self).__init__(**kwargs) self.rnn = rnn_layer self.vocab_size = vocab_size self.num_hiddens = self.rnn.hidden_size # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1 if not self.rnn.bidirectional: self.num_directions = 1 self.linear = nn.Linear(self.num_hiddens, self.vocab_size) else: self.num_directions = 2 self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size) def forward(self, inputs, state): X = F.one_hot(inputs.T.long(), self.vocab_size) X = X.to(torch.float32) Y, state = self.rnn(X, state) # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数) # 它的输出形状是(时间步数*批量大小,词表大小)。 output = self.linear(Y.reshape((-1, Y.shape[-1]))) return output, state def begin_state(self, device, batch_size=1): if not isinstance(self.rnn, nn.LSTM): # nn.GRU以张量作为隐状态 return torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device) else: # nn.LSTM以元组作为隐状态 return (torch.zeros(( self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device), torch.zeros(( self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))# 训练device = d2l.try_gpu()net = RNNModel(rnn_layer, vocab_size=len(vocab))net = net.to(device)d2l.predict_ch8(&#x27;time traveller&#x27;, 10, net, vocab, device)num_epochs, lr = 500, 1d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device) 56 门控循环单元（GRU） 关注一个序列 不是每个观察值都是同等重要 想只记住相关的观察需要 能关注的机制（更新门） 能遗忘的机制（重置门） 候选隐藏状态：H~t=tanh⁡(XtWxh+(Rt⊙Ht−1)Whh+bh)\\tilde{\\boldsymbol{H}}_t=\\tanh \\left(\\boldsymbol{X}_t \\boldsymbol{W}_{x h}+\\left(\\boldsymbol{R}_t \\odot \\boldsymbol{H}_{t-1}\\right) \\boldsymbol{W}_{h h}+\\boldsymbol{b}_h\\right)H~t​=tanh(Xt​Wxh​+(Rt​⊙Ht−1​)Whh​+bh​) 隐状态：Ht=Zt⊙Ht−1+(1−Zt)⊙H~t\\boldsymbol{H}_t=\\boldsymbol{Z}_t \\odot \\boldsymbol{H}_{t-1}+\\left(1-\\boldsymbol{Z}_t\\right) \\odot \\tilde{\\boldsymbol{H}}_tHt​=Zt​⊙Ht−1​+(1−Zt​)⊙H~t​ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import torchfrom torch import nnfrom d2l import torch as d2lbatch_size, num_steps = 32, 35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# 初始化模型参数def get_params(vocab_size, num_hiddens, device): num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device)) W_xz, W_hz, b_z = three() # 更新门参数 W_xr, W_hr, b_r = three() # 重置门参数 W_xh, W_hh, b_h = three() # 候选隐状态参数 # 输出层参数 W_hq = normal((num_hiddens, num_outputs)) b_q = torch.zeros(num_outputs, device=device) # 附加梯度 params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q] for param in params: param.requires_grad_(True) return params# 定义隐藏状态的初始化函数def init_gru_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device=device), )# 定义门控循环单元模型def gru(inputs, state, params): W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params H, = state outputs = [] for X in inputs: Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z) R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r) H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h) H = Z * H + (1 - Z) * H_tilda Y = H @ W_hq + b_q outputs.append(Y) return torch.cat(outputs, dim=0), (H,)# 训练GRUvocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()num_epochs, lr = 500, 1model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params, init_gru_state, gru)d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)# 简洁实现num_inputs = vocab_sizegru_layer = nn.GRU(num_inputs, num_hiddens)model = d2l.RNNModel(gru_layer, len(vocab))model = model.to(device)d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) 57 长短期记忆网络（LSTM） 长短期记忆网络 忘记门：将值朝0减少,\\boldsymbol{F}_t &amp;=\\sigma\\left(\\boldsymbol{X}_t \\boldsymbol{W}_{x f}+\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{h f}+\\boldsymbol{b}_f\\right) 输入门：决定不是忽略掉输入数据,\\begin{aligned} \\boldsymbol{I}_t &amp;=\\sigma\\left(\\boldsymbol{X}_t \\boldsymbol{W}_{x i}+\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{h i}+\\boldsymbol{b}_i\\right) 输出门：决定是不是使用隐状态,\\boldsymbol{O}_t &amp;=\\sigma\\left(\\boldsymbol{X}_t \\boldsymbol{W}_{x \\jmath}+\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{h o}+\\boldsymbol{b}_o\\right) \\end{aligned} 候选记忆单元：C~t=tanh⁡(XtWxc+Ht−1Whc+bc)\\tilde{\\boldsymbol{C}}_t=\\tanh \\left(\\boldsymbol{X}_t \\boldsymbol{W}_{x c}+\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{h c}+\\boldsymbol{b}_c\\right)C~t​=tanh(Xt​Wxc​+Ht−1​Whc​+bc​) 记忆单元：Ct=Ft⊙Ct−1+It⊙C~t\\boldsymbol{C}_t=\\boldsymbol{F}_t \\odot \\boldsymbol{C}_{t-1}+\\boldsymbol{I}_t \\odot \\tilde{\\boldsymbol{C}}_tCt​=Ft​⊙Ct−1​+It​⊙C~t​ 隐藏状态：Ht=Ot⊙tanh⁡(Ct)\\boldsymbol{H}_t=\\boldsymbol{O}_t \\odot \\tanh \\left(\\boldsymbol{C}_t\\right)Ht​=Ot​⊙tanh(Ct​) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import torchfrom torch import nnfrom d2l import torch as d2l# 从零开始实现batch_size, num_steps = 32, 35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# 初始化模型参数def get_lstm_params(vocab_size, num_hiddens, device): num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device)) W_xi, W_hi, b_i = three() # 输入门参数 W_xf, W_hf, b_f = three() # 遗忘门参数 W_xo, W_ho, b_o = three() # 输出门参数 W_xc, W_hc, b_c = three() # 候选记忆元参数 # 输出层参数 W_hq = normal((num_hiddens, num_outputs)) b_q = torch.zeros(num_outputs, device=device) # 附加梯度 params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] for param in params: param.requires_grad_(True) return params# 初始化函数def init_lstm_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device=device), torch.zeros((batch_size, num_hiddens), device=device))# 实际模型def lstm(inputs, state, params): [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params (H, C) = state outputs = [] for X in inputs: I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i) F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f) O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o) C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c) C = F * C + I * C_tilda H = O * torch.tanh(C) Y = (H @ W_hq) + b_q outputs.append(Y) return torch.cat(outputs, dim=0), (H, C)# 训练vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()num_epochs, lr = 500, 1model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm)d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)# 简洁实现num_inputs = vocab_sizelstm_layer = nn.LSTM(num_inputs, num_hiddens)model = d2l.RNNModel(lstm_layer, len(vocab))model = model.to(device)d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) 58 深层循环神经网络 回顾循环神经网络 更深 浅RNN：输入，隐层，输出 深RNN：输入，隐层，隐层，…，输出 -Ht1=f1(Ht−11,Xt)\\mathbf{H}_t^1=f_1\\left(\\mathbf{H}_{t-1}^1, \\mathbf{X}_t\\right)Ht1​=f1​(Ht−11​,Xt​)，⋯\\quad \\cdots⋯，Htj=fj(Ht−1j,Htj−1)\\mathbf{H}_t^j=f_j \\left(\\mathbf{H}_{t-1}^j, \\mathbf{H}_t^{j-1}\\right)Htj​=fj​(Ht−1j​,Htj−1​)，⋯\\quad \\cdots⋯，Ot=g(HtL)\\mathbf{O}_t=g\\left(\\mathbf{H}_t^L\\right)Ot​=g(HtL​) 12345678910111213141516171819# 简洁实现import torchfrom torch import nnfrom d2l import torch as d2lbatch_size, num_steps = 32, 35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# 通过num_layers的值来设定隐藏层数vocab_size, num_hiddens, num_layers = len(vocab), 256, 2num_inputs = vocab_sizedevice = d2l.try_gpu()lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)model = d2l.RNNModel(lstm_layer, len(vocab))model = model.to(device)# 训练num_epochs, lr = 500, 2d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) 59 双向循环神经网络 双向RNN 一个前向RNN隐层 一个方向RNN隐层 合并两个隐状态得到输出 -H→t=ϕ(XtWxh(f)+H→t−1Whh(f)+bh(f)),H←t=ϕ(XtWxh(b)+H←t+1Whh(b)+bh(b)),Ht=[H→tH←t],Ot=HtWhq+bq\\overrightarrow{\\mathbf{H}}_t=\\phi\\left(\\mathbf{X}_t \\mathbf{W}_{x h}^{(f)}+\\overrightarrow{\\mathbf{H}}_{t-1} \\mathbf{W}_{h h}^{(f)}+\\mathbf{b}_h^{(f)}\\right), \\overleftarrow{\\mathbf{H}}_t=\\phi\\left(\\mathbf{X}_t \\mathbf{W}_{x h}^{(b)}+\\overleftarrow{\\mathbf{H}}_{t+1} \\mathbf{W}_{h h}^{(b)}+\\mathbf{b}_h^{(b)}\\right), \\mathbf{H}_t=\\left[\\overrightarrow{\\mathbf{H}}_t \\overleftarrow{\\mathbf{H}}_t\\right], \\mathbf{O}_t=\\mathbf{H}_t \\mathbf{W}_{h q}+\\mathbf{b}_qHt​=ϕ(Xt​Wxh(f)​+Ht−1​Whh(f)​+bh(f)​),Ht​=ϕ(Xt​Wxh(b)​+Ht+1​Whh(b)​+bh(b)​),Ht​=[Ht​Ht​],Ot​=Ht​Whq​+bq​ 总结 双向循环神经网络通过反向更新的隐藏层来利用方向时间信息 通常用来对序列抽取特征,填空,而不是预测未来 123456789101112131415161718# 双向神经网络的错误应用# bidirectional = True 即可使用双向循环神经网络import torchfrom torch import nnfrom d2l import torch as d2l# 加载数据batch_size, num_steps, device = 32, 35, d2l.try_gpu()train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# 通过设置“bidirective=True”来定义双向LSTM模型vocab_size, num_hiddens, num_layers = len(vocab), 256, 2num_inputs = vocab_sizelstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=True)model = d2l.RNNModel(lstm_layer, len(vocab))model = model.to(device)# 训练模型num_epochs, lr = 500, 1d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) 60 机器翻译数据集 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113import osimport torchfrom d2l import torch as d2l# 下载和预处理数据集d2l.DATA_HUB[&#x27;fra-eng&#x27;] = (d2l.DATA_URL + &#x27;fra-eng.zip&#x27;, &#x27;94646ad1522d915e7b0f9296181140edcf86a4f5&#x27;)def read_data_nmt(): &quot;&quot;&quot;载入“英语－法语”数据集&quot;&quot;&quot; data_dir = d2l.download_extract(&#x27;fra-eng&#x27;) with open(os.path.join(data_dir, &#x27;fra.txt&#x27;), &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f: return f.read()raw_text = read_data_nmt()print(raw_text[:75])# 几个预处理步骤def preprocess_nmt(text): &quot;&quot;&quot;预处理“英语－法语”数据集&quot;&quot;&quot; def no_space(char, prev_char): return char in set(&#x27;,.!?&#x27;) and prev_char != &#x27; &#x27; # 使用空格替换不间断空格 # 使用小写字母替换大写字母 text = text.replace(&#x27;\\u202f&#x27;, &#x27; &#x27;).replace(&#x27;\\xa0&#x27;, &#x27; &#x27;).lower() # 在单词和标点符号之间插入空格 out = [&#x27; &#x27; + char if i &gt; 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)] return &#x27;&#x27;.join(out)text = preprocess_nmt(raw_text)print(text[:80])# 词元化def tokenize_nmt(text, num_examples=None): &quot;&quot;&quot;词元化“英语－法语”数据数据集&quot;&quot;&quot; source, target = [], [] for i, line in enumerate(text.split(&#x27;\\n&#x27;)): if num_examples and i &gt; num_examples: break parts = line.split(&#x27;\\t&#x27;) if len(parts) == 2: source.append(parts[0].split(&#x27; &#x27;)) target.append(parts[1].split(&#x27; &#x27;)) return source, targetsource, target = tokenize_nmt(text)source[:6], target[:6]# 绘制每个文本序列所包含的标记数量的直方图def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist): &quot;&quot;&quot;绘制列表长度对的直方图&quot;&quot;&quot; d2l.set_figsize() _, _, patches = d2l.plt.hist( [[len(l) for l in xlist], [len(l) for l in ylist]]) d2l.plt.xlabel(xlabel) d2l.plt.ylabel(ylabel) for patch in patches[1].patches: patch.set_hatch(&#x27;/&#x27;) d2l.plt.legend(legend)show_list_len_pair_hist([&#x27;source&#x27;, &#x27;target&#x27;], &#x27;# tokens per sequence&#x27;, &#x27;count&#x27;, source, target);# 词汇表src_vocab = d2l.Vocab(source, min_freq=2, reserved_tokens=[&#x27;&lt;pad&gt;&#x27;, &#x27;&lt;bos&gt;&#x27;, &#x27;&lt;eos&gt;&#x27;])len(src_vocab)# 序列样本都有一个固定的长度 截断或填充文本序列def truncate_pad(line, num_steps, padding_token): &quot;&quot;&quot;截断或填充文本序列&quot;&quot;&quot; if len(line) &gt; num_steps: return line[:num_steps] # 截断 return line + [padding_token] * (num_steps - len(line)) # 填充truncate_pad(src_vocab[source[0]], 10, src_vocab[&#x27;&lt;pad&gt;&#x27;])# 转换成小批量数据集用于训练def build_array_nmt(lines, vocab, num_steps): &quot;&quot;&quot;将机器翻译的文本序列转换成小批量&quot;&quot;&quot; lines = [vocab[l] for l in lines] lines = [l + [vocab[&#x27;&lt;eos&gt;&#x27;]] for l in lines] array = torch.tensor([truncate_pad( l, num_steps, vocab[&#x27;&lt;pad&gt;&#x27;]) for l in lines]) valid_len = (array != vocab[&#x27;&lt;pad&gt;&#x27;]).type(torch.int32).sum(1) return array, valid_len# 训练模型def load_data_nmt(batch_size, num_steps, num_examples=600): &quot;&quot;&quot;返回翻译数据集的迭代器和词表&quot;&quot;&quot; text = preprocess_nmt(read_data_nmt()) source, target = tokenize_nmt(text, num_examples) src_vocab = d2l.Vocab(source, min_freq=2, reserved_tokens=[&#x27;&lt;pad&gt;&#x27;, &#x27;&lt;bos&gt;&#x27;, &#x27;&lt;eos&gt;&#x27;]) tgt_vocab = d2l.Vocab(target, min_freq=2, reserved_tokens=[&#x27;&lt;pad&gt;&#x27;, &#x27;&lt;bos&gt;&#x27;, &#x27;&lt;eos&gt;&#x27;]) src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps) tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps) data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len) data_iter = d2l.load_array(data_arrays, batch_size) return data_iter, src_vocab, tgt_vocab# 读出&quot;英语-法语&quot;数据集中的第一个小批量数据train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8)for X, X_valid_len, Y, Y_valid_len in train_iter: print(&#x27;X:&#x27;, X.type(torch.int32)) print(&#x27;X的有效长度:&#x27;, X_valid_len) print(&#x27;Y:&#x27;, Y.type(torch.int32)) print(&#x27;Y的有效长度:&#x27;, Y_valid_len) break 61 编码器-解码器架构 重新考察CNN 编码器：将输入编程成中间表达形式（特征） 将文本表示成向量 解码器：将中间表示解码成输出 向量表示成输出 编码器-解码器架构 一个模型被分为两块：编码器处理输出，解码器生成输出 123456789101112131415161718192021222324252627282930313233343536from torch import nn#@saveclass Encoder(nn.Module): &quot;&quot;&quot;编码器-解码器架构的基本编码器接口&quot;&quot;&quot; def __init__(self, **kwargs): super(Encoder, self).__init__(**kwargs) def forward(self, X, *args): raise NotImplementedError#@saveclass Decoder(nn.Module): &quot;&quot;&quot;编码器-解码器架构的基本解码器接口&quot;&quot;&quot; def __init__(self, **kwargs): super(Decoder, self).__init__(**kwargs) def init_state(self, enc_outputs, *args): raise NotImplementedError def forward(self, X, state): raise NotImplementedError#@saveclass EncoderDecoder(nn.Module): &quot;&quot;&quot;编码器-解码器架构的基类&quot;&quot;&quot; def __init__(self, encoder, decoder, **kwargs): super(EncoderDecoder, self).__init__(**kwargs) self.encoder = encoder self.decoder = decoder def forward(self, enc_X, dec_X, *args): enc_outputs = self.encoder(enc_X, *args) dec_state = self.decoder.init_state(enc_outputs, *args) return self.decoder(dec_X, dec_state) 62 序列到序列学习（seq2seq） Seq2Seq 编码器是一个RNN,读取输入句子:可以是双向的 双向RNN经常用在解码器中 解码器使用另一个RNN来输出 上一个时刻的翻译输出传递给下一时刻，同时结合此时刻的输入进行输出 编码器-解码器细节 编码器是没有输出的RNN 编码器最后时间步的隐状态用作解码器的初始隐状态 编码器将最后一层的RNN，最后时间步的隐状态结合解码器的Embedding用作解码器的初始隐状态 训练：训练时解码器使用目标句子作为输入 推理时使用上一时刻的输出作为输入 衡量生成序列的好坏 -pnp_npn​是预测中所有n-gram的精度 标签序列 A B C D E F 和预测序列 A B B C D ,有p1=4/5,p2=3/4,p3=1/3,p4=0p_1=4/5, p_2=3/4, p_3=1/3, p_4=0p1​=4/5,p2​=3/4,p3​=1/3,p4​=0 BLEU定义:exp⁡(min⁡(0,1−len⁡label len⁡pred ))∏n=1kpn1/2n\\exp \\left(\\min \\left(0,1-\\frac{\\operatorname{len}_{\\text {label }}}{\\operatorname{len}_{\\text {pred }}}\\right)\\right) \\prod_{n=1}^k p_n^{1 / 2^n}exp(min(0,1−lenpred ​lenlabel ​​))∏n=1k​pn1/2n​,该值越大越好 -\\frac{\\operatorname{len}_{\\text {label }}为惩罚过短的预测,pn1/2np_n^{1 / 2^n}pn1/2n​长匹配有高权重 跳转至教材 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217import collectionsimport mathimport torchfrom torch import nnfrom d2l import torch as d2l# 实现循环神经网络编码器class Seq2SeqEncoder(d2l.Encoder): &quot;&quot;&quot;用于序列到序列学习的循环神经网络编码器&quot;&quot;&quot; def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs): super(Seq2SeqEncoder, self).__init__(**kwargs) # 嵌入层 self.embedding = nn.Embedding(vocab_size, embed_size) self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout) def forward(self, X, *args): # 输出&#x27;X&#x27;的形状：(batch_size,num_steps,embed_size) X = self.embedding(X) # 在循环神经网络模型中，第一个轴对应于时间步 X = X.permute(1, 0, 2) # 如果未提及状态，则默认为0 output, state = self.rnn(X) # output的形状:(num_steps,batch_size,num_hiddens) # state的形状:(num_layers,batch_size,num_hiddens) return output, state# 上述编码器的实现encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)encoder.eval()X = torch.zeros((4, 7), dtype=torch.long)output, state = encoder(X)output.shapestate.shape# 解码器class Seq2SeqDecoder(d2l.Decoder): &quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器&quot;&quot;&quot; def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs): super(Seq2SeqDecoder, self).__init__(**kwargs) self.embedding = nn.Embedding(vocab_size, embed_size) self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout) self.dense = nn.Linear(num_hiddens, vocab_size) def init_state(self, enc_outputs, *args): return enc_outputs[1] def forward(self, X, state): # 输出&#x27;X&#x27;的形状：(batch_size,num_steps,embed_size) X = self.embedding(X).permute(1, 0, 2) # 广播context，使其具有与X相同的num_steps context = state[-1].repeat(X.shape[0], 1, 1) X_and_context = torch.cat((X, context), 2) output, state = self.rnn(X_and_context, state) output = self.dense(output).permute(1, 0, 2) # output的形状:(batch_size,num_steps,vocab_size) # state的形状:(num_layers,batch_size,num_hiddens) return output, state# 实例化解码器decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)decoder.eval()state = decoder.init_state(encoder(X))output, state = decoder(X, state)output.shape, state.shape# 通过零值化屏蔽不相关的项def sequence_mask(X, valid_len, value=0): &quot;&quot;&quot;在序列中屏蔽不相关的项&quot;&quot;&quot; maxlen = X.size(1) mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] &lt; valid_len[:, None] X[~mask] = value return XX = torch.tensor([[1, 2, 3], [4, 5, 6]])sequence_mask(X, torch.tensor([1, 2]))X = torch.ones(2, 3, 4)sequence_mask(X, torch.tensor([1, 2]), value=-1)# 通过扩展softmax交叉熵损失函数来屏蔽不相关的预测class MaskedSoftmaxCELoss(nn.CrossEntropyLoss): &quot;&quot;&quot;带遮蔽的softmax交叉熵损失函数&quot;&quot;&quot; # pred的形状：(batch_size,num_steps,vocab_size) # label的形状：(batch_size,num_steps) # valid_len的形状：(batch_size,) def forward(self, pred, label, valid_len): weights = torch.ones_like(label) weights = sequence_mask(weights, valid_len) self.reduction=&#x27;none&#x27; unweighted_loss = super(MaskedSoftmaxCELoss, self).forward( pred.permute(0, 2, 1), label) weighted_loss = (unweighted_loss * weights).mean(dim=1) return weighted_loss# 代码健全性检查loss = MaskedSoftmaxCELoss()loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long), torch.tensor([4, 2, 0]))# 训练def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device): &quot;&quot;&quot;训练序列到序列模型&quot;&quot;&quot; def xavier_init_weights(m): if type(m) == nn.Linear: nn.init.xavier_uniform_(m.weight) if type(m) == nn.GRU: for param in m._flat_weights_names: if &quot;weight&quot; in param: nn.init.xavier_uniform_(m._parameters[param]) net.apply(xavier_init_weights) net.to(device) optimizer = torch.optim.Adam(net.parameters(), lr=lr) loss = MaskedSoftmaxCELoss() net.train() animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss&#x27;, xlim=[10, num_epochs]) for epoch in range(num_epochs): timer = d2l.Timer() metric = d2l.Accumulator(2) # 训练损失总和，词元数量 for batch in data_iter: optimizer.zero_grad() X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch] bos = torch.tensor([tgt_vocab[&#x27;&lt;bos&gt;&#x27;]] * Y.shape[0], device=device).reshape(-1, 1) dec_input = torch.cat([bos, Y[:, :-1]], 1) # 强制教学 Y_hat, _ = net(X, dec_input, X_valid_len) l = loss(Y_hat, Y, Y_valid_len) l.sum().backward() # 损失函数的标量进行“反向传播” d2l.grad_clipping(net, 1) num_tokens = Y_valid_len.sum() optimizer.step() with torch.no_grad(): metric.add(l.sum(), num_tokens) if (epoch + 1) % 10 == 0: animator.add(epoch + 1, (metric[0] / metric[1],)) print(f&#x27;loss &#123;metric[0] / metric[1]:.3f&#125;, &#123;metric[1] / timer.stop():.1f&#125; &#x27; f&#x27;tokens/sec on &#123;str(device)&#125;&#x27;)# 创建和训练一个循环卷积神经网络&quot;编码器-解码器&quot;模型embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1batch_size, num_steps = 64, 10lr, num_epochs, device = 0.005, 300, d2l.try_gpu()train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)net = d2l.EncoderDecoder(encoder, decoder)train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)# 预测def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False): &quot;&quot;&quot;序列到序列模型的预测&quot;&quot;&quot; # 在预测时将net设置为评估模式 net.eval() src_tokens = src_vocab[src_sentence.lower().split(&#x27; &#x27;)] + [ src_vocab[&#x27;&lt;eos&gt;&#x27;]] enc_valid_len = torch.tensor([len(src_tokens)], device=device) src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[&#x27;&lt;pad&gt;&#x27;]) # 添加批量轴 enc_X = torch.unsqueeze( torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0) enc_outputs = net.encoder(enc_X, enc_valid_len) dec_state = net.decoder.init_state(enc_outputs, enc_valid_len) # 添加批量轴 dec_X = torch.unsqueeze(torch.tensor( [tgt_vocab[&#x27;&lt;bos&gt;&#x27;]], dtype=torch.long, device=device), dim=0) output_seq, attention_weight_seq = [], [] for _ in range(num_steps): Y, dec_state = net.decoder(dec_X, dec_state) # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入 dec_X = Y.argmax(dim=2) pred = dec_X.squeeze(dim=0).type(torch.int32).item() # 保存注意力权重（稍后讨论） if save_attention_weights: attention_weight_seq.append(net.decoder.attention_weights) # 一旦序列结束词元被预测，输出序列的生成就完成了 if pred == tgt_vocab[&#x27;&lt;eos&gt;&#x27;]: break output_seq.append(pred) return &#x27; &#x27;.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq# BLEU的代码实现def bleu(pred_seq, label_seq, k): #@save &quot;&quot;&quot;计算BLEU&quot;&quot;&quot; pred_tokens, label_tokens = pred_seq.split(&#x27; &#x27;), label_seq.split(&#x27; &#x27;) len_pred, len_label = len(pred_tokens), len(label_tokens) score = math.exp(min(0, 1 - len_label / len_pred)) for n in range(1, k + 1): num_matches, label_subs = 0, collections.defaultdict(int) for i in range(len_label - n + 1): label_subs[&#x27; &#x27;.join(label_tokens[i: i + n])] += 1 for i in range(len_pred - n + 1): if label_subs[&#x27; &#x27;.join(pred_tokens[i: i + n])] &gt; 0: num_matches += 1 label_subs[&#x27; &#x27;.join(pred_tokens[i: i + n])] -= 1 score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n)) return score# 将几个英语句子翻译成法语engs = [&#x27;go .&#x27;, &quot;i lost .&quot;, &#x27;he\\&#x27;s calm .&#x27;, &#x27;i\\&#x27;m home .&#x27;]fras = [&#x27;va !&#x27;, &#x27;j\\&#x27;ai perdu .&#x27;, &#x27;il est calme .&#x27;, &#x27;je suis chez moi .&#x27;]for eng, fra in zip(engs, fras): translation, attention_weight_seq = predict_seq2seq( net, eng, src_vocab, tgt_vocab, num_steps, device) print(f&#x27;&#123;eng&#125; =&gt; &#123;translation&#125;, bleu &#123;bleu(translation, fra, k=2):.3f&#125;&#x27;) 63 束搜索 贪心搜索 Seq2Seq中使用了贪心搜索来预测序列：将当时时刻预测概率最大的词输出 但贪心很可能不是最优的：当前选取的在全局时间上可能不是最优的 穷举搜索 最优算法：对所有可能的序列，计算它的概率，然后选取最好的那个 如果输出字典大小为n, 序列最长为T,那么需要考虑nTn^TnT个序列：计算上不可行 束搜索 做法 保存最好的k个候选 在每个时刻，对每个候选新加一项(n种可能),在knknkn个选项中选出最好的k个 时间复杂度O(knT)O(knT)O(knT) 每个候选的最终分数：1Lαlog⁡p(y1,…,yL)=1Lα∑t′=1Llog⁡p(yt′∣y1,…,yt′−1,c)\\frac{1}{L^\\alpha} \\log p\\left(y_1, \\ldots, y_L\\right)=\\frac{1}{L^\\alpha} \\sum_{t^{\\prime}=1}^L \\log p\\left(y_{t^{\\prime}} \\mid y_1, \\ldots, y_{t^{\\prime}-1}, \\boldsymbol{c}\\right)Lα1​logp(y1​,…,yL​)=Lα1​∑t′=1L​logp(yt′​∣y1​,…,yt′−1​,c) 通常:α=0.75\\alpha=0.75α=0.75 64 注意力机制 注意力机制 卷积,全连接,池化层都只考虑不随意线索 注意力机制则显示的考虑随意线索 随意线索被称之为查询(query) 每个输入是一个值(value)和不随意线索(key)的对 通过注意力池化层来有偏向性的选项选择某些输入 非参注意力池化层 给定数据(xi,yi),i=1,...,n(x_i,y_i),i=1,...,n(xi​,yi​),i=1,...,n 平均池化是最简单的方案:f(x)=1n∑iyif(x)=\\frac{1}{n} \\sum_i y_if(x)=n1​∑i​yi​ 更好的方案是Nadaraya-Watson核回归：f(x)=∑i=1nK(x−xi)∑j=1nK(x−xj)yif(x)=\\sum_{i=1}^n \\frac{K\\left(x-x_i\\right)}{\\sum_{j=1}^n K\\left(x-x_j\\right)} y_if(x)=∑i=1n​∑j=1n​K(x−xj​)K(x−xi​)​yi​ K是核为衡量x与xix与x_ix与xi​距离的量,yiy_iyi​为value,xjx_jxj​为key Nadaraya-Watson核回归 使用高斯核:K(u)=12πexp⁡(−u22)K(u)=\\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{u^2}{2}\\right)K(u)=2π​1​exp(−2u2​) 则:f(x)=∑i=1nexp⁡(−12(x−xi)2)∑j=1nexp⁡(−12(x−xj)2)yi=∑i=1nsoftmax⁡(−12(x−xi)2)yi\\begin{aligned} f(x) &amp;=\\sum_{i=1}^n \\frac{\\exp \\left(-\\frac{1}{2}\\left(x-x_i\\right)^2\\right)}{\\sum_{j=1}^n \\exp \\left(-\\frac{1}{2}\\left(x-x_j\\right)^2\\right)} y_i \\\\ &amp;=\\sum_{i=1}^n \\operatorname{softmax}\\left(-\\frac{1}{2}\\left(x-x_i\\right)^2\\right) y_i \\end{aligned}f(x)​=i=1∑n​∑j=1n​exp(−21​(x−xj​)2)exp(−21​(x−xi​)2)​yi​=i=1∑n​softmax(−21​(x−xi​)2)yi​​ 参数化的注意力机制 在之前基础上引入可学习的 w :f(x)=∑i=1nsoftmax⁡(−12((x−xi)w)2)yif(x)=\\sum_{i=1}^n \\operatorname{softmax}\\left(-\\frac{1}{2}\\left(\\left(x-x_i\\right) w\\right)^2\\right) y_if(x)=∑i=1n​softmax(−21​((x−xi​)w)2)yi​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# 注意力汇集Nadaraya-Watson核回归import torchfrom torch import nnfrom d2l import torch as d2l# 生成数据集n_train = 50 # 训练样本数x_train, _ = torch.sort(torch.rand(n_train) * 5) # 排序后的训练样本def f(x): return 2 * torch.sin(x) + x**0.8y_train = f(x_train) + torch.normal(0.0, 0.5, (n_train,)) # 训练样本的输出x_test = torch.arange(0, 5, 0.1) # 测试样本y_truth = f(x_test) # 测试样本的真实输出n_test = len(x_test) # 测试样本数n_testdef plot_kernel_reg(y_hat): d2l.plot(x_test, [y_truth, y_hat], &#x27;x&#x27;, &#x27;y&#x27;, legend=[&#x27;Truth&#x27;, &#x27;Pred&#x27;], xlim=[0, 5], ylim=[-1, 5]) d2l.plt.plot(x_train, y_train, &#x27;o&#x27;, alpha=0.5);y_hat = torch.repeat_interleave(y_train.mean(), n_test)plot_kernel_reg(y_hat)# 非参数注意力汇聚# X_repeat的形状:(n_test,n_train),# 每一行都包含着相同的测试输入（例如：同样的查询）X_repeat = x_test.repeat_interleave(n_train).reshape((-1, n_train))# x_train包含着键。attention_weights的形状：(n_test,n_train),# 每一行都包含着要在给定的每个查询的值（y_train）之间分配的注意力权重attention_weights = nn.functional.softmax(-(X_repeat - x_train)**2 / 2, dim=1)# y_hat的每个元素都是值的加权平均值，其中的权重是注意力权重y_hat = torch.matmul(attention_weights, y_train)plot_kernel_reg(y_hat)# 注意力权重d2l.show_heatmaps(attention_weights.unsqueeze(0).unsqueeze(0), xlabel=&#x27;Sorted training inputs&#x27;, ylabel=&#x27;Sorted testing inputs&#x27;)# 带参数注意力汇聚，假定两个张量的形状分别为(n,a,b)和(n,b,c),它们的批量矩阵乘法输出形状为(n,a,c)X = torch.ones((2, 1, 4))Y = torch.ones((2, 4, 6))torch.bmm(X, Y).shape# 使用小批量矩阵乘法来计算小批量数据中的加权平均值weights = torch.ones((2, 10)) * 0.1values = torch.arange(20.0).reshape((2, 10))torch.bmm(weights.unsqueeze(1), values.unsqueeze(-1))# 带参数的注意力汇聚class NWKernelRegression(nn.Module): def __init__(self, **kwargs): super().__init__(**kwargs) self.w = nn.Parameter(torch.rand((1,), requires_grad=True)) def forward(self, queries, keys, values): # queries和attention_weights的形状为(查询个数，“键－值”对个数) queries = queries.repeat_interleave(keys.shape[1]).reshape((-1, keys.shape[1])) self.attention_weights = nn.functional.softmax( -((queries - keys) * self.w)**2 / 2, dim=1) # values的形状为(查询个数，“键－值”对个数) return torch.bmm(self.attention_weights.unsqueeze(1), values.unsqueeze(-1)).reshape(-1)# 将训练数据集转换为键和值# X_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输入X_tile = x_train.repeat((n_train, 1))# Y_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输出Y_tile = y_train.repeat((n_train, 1))# keys的形状:(&#x27;n_train&#x27;，&#x27;n_train&#x27;-1)keys = X_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))# values的形状:(&#x27;n_train&#x27;，&#x27;n_train&#x27;-1)values = Y_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))# 训练带参数的注意力汇聚模型net = NWKernelRegression()loss = nn.MSELoss(reduction=&#x27;none&#x27;)trainer = torch.optim.SGD(net.parameters(), lr=0.5)animator = d2l.Animator(xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss&#x27;, xlim=[1, 5])for epoch in range(5): trainer.zero_grad() l = loss(net(x_train, keys, values), y_train) l.sum().backward() trainer.step() print(f&#x27;epoch &#123;epoch + 1&#125;, loss &#123;float(l.sum()):.6f&#125;&#x27;) animator.add(epoch + 1, float(l.sum()))# 预测结果绘制# keys的形状:(n_test，n_train)，每一行包含着相同的训练输入（例如，相同的键）keys = x_train.repeat((n_test, 1))# value的形状:(n_test，n_train)values = y_train.repeat((n_test, 1))y_hat = net(x_test, keys, values).unsqueeze(1).detach()plot_kernel_reg(y_hat)d2l.show_heatmaps(net.attention_weights.unsqueeze(0).unsqueeze(0), xlabel=&#x27;Sorted training inputs&#x27;, ylabel=&#x27;Sorted testing inputs&#x27;) 65 注意力分数 回顾：f(x)=∑iα(x,xi)yi=∑i=1nsoftmax⁡(−12(x−xi)2)yi,αf(x)=\\sum_i \\alpha\\left(x, x_i\\right) y_i=\\sum_{i=1}^n \\operatorname{softmax}\\left(-\\frac{1}{2}\\left(x-x_i\\right)^2\\right) y_i, \\alphaf(x)=∑i​α(x,xi​)yi​=∑i=1n​softmax(−21​(x−xi​)2)yi​,α为注意力权重,−12(x−xi)2-\\frac{1}{2}\\left(x-x_i\\right)^2−21​(x−xi​)2为注意力分数 拓展到高维度 假设queryq∈Rqq \\in \\R^qq∈Rq, m对key-value(k1,v1),ki∈Rk,vi∈Rv(k_1,v_1),k_i \\in \\R^k, v_i \\in \\R^v(k1​,v1​),ki​∈Rk,vi​∈Rv 注意力池化层: -f(q,(k1,v1),…,(km,vm))=∑i=1mα(q,ki)vi∈Rvf\\left(\\mathbf{q},\\left(\\mathbf{k}_1, \\mathbf{v}_1\\right), \\ldots,\\left(\\mathbf{k}_m, \\mathbf{v}_m\\right)\\right)=\\sum_{i=1}^m \\alpha\\left(\\mathbf{q}, \\mathbf{k}_i\\right) \\mathbf{v}_i \\in \\mathbb{R}^vf(q,(k1​,v1​),…,(km​,vm​))=∑i=1m​α(q,ki​)vi​∈Rv -α(q,ki)=softmax⁡(a(q,ki))=exp⁡(a(q,ki))∑j=1mexp⁡(a(q,kj))∈R\\alpha\\left(\\mathbf{q}, \\mathbf{k}_i\\right)=\\operatorname{softmax}\\left(a\\left(\\mathbf{q}, \\mathbf{k}_i\\right)\\right)=\\frac{\\exp \\left(a\\left(\\mathbf{q}, \\mathbf{k}_i\\right)\\right)}{\\sum_{j=1}^m \\exp \\left(a\\left(\\mathbf{q}, \\mathbf{k}_j\\right)\\right)} \\in \\mathbb{R}α(q,ki​)=softmax(a(q,ki​))=∑j=1m​exp(a(q,kj​))exp(a(q,ki​))​∈R 此处a为注意力分数 Additive Attention(加性注意力) 可学参数:Wk∈Rh×k,Wq∈Rh×q,v∈Rh,a(k,q)=vTtanh⁡(Wkk+Wqq)\\mathbf{W}_k \\in \\mathbb{R}^{h \\times k}, \\mathbf{W}_q \\in \\mathbb{R}^{h \\times q}, \\mathbf{v} \\in \\mathbb{R}^h, a(\\mathbf{k}, \\mathbf{q})=\\mathbf{v}^T \\tanh \\left(\\mathbf{W}_k \\mathbf{k}+\\mathbf{W}_q \\mathbf{q}\\right)Wk​∈Rh×k,Wq​∈Rh×q,v∈Rh,a(k,q)=vTtanh(Wk​k+Wq​q) 等价于将query和key合并起来后放入到一个隐藏大小为h输出大小为1的单隐藏层MLP 好处：key和value可以为任意长度 scaled dot-product attention 如果query和key都是同样的长度q,ki∈Rdq,k_i \\in \\R^dq,ki​∈Rd,那么可以a(q,ki)=⟨q,ki⟩/da\\left(\\mathbf{q}, \\mathbf{k}_{\\mathbf{i}}\\right)=\\left\\langle\\mathbf{q}, \\mathbf{k}_{\\mathbf{i}}\\right\\rangle / \\sqrt{d}a(q,ki​)=⟨q,ki​⟩/d​ 向量化版本 -Q∈Rn×d,K∈Rm×d,V∈Rm×v\\mathbf{Q} \\in \\mathbb{R}^{n \\times d}, \\mathbf{K} \\in \\mathbb{R}^{m \\times d}, \\mathbf{V} \\in \\mathbb{R}^{m \\times v}Q∈Rn×d,K∈Rm×d,V∈Rm×v 注意力分数：a(Q,K)=QKT/d∈Rn×ma(\\mathbf{Q}, \\mathbf{K})=\\mathbf{Q K}^T / \\sqrt{d} \\in \\mathbb{R}^{n \\times m}a(Q,K)=QKT/d​∈Rn×m 注意力池化：f=softmax⁡(a(Q,K))V∈Rn×vf=\\operatorname{softmax}(a(\\mathbf{Q}, \\mathbf{K})) \\mathbf{V} \\in \\mathbb{R}^{n \\times v}f=softmax(a(Q,K))V∈Rn×v 总结 注意力分数是query和key的相似度，注意力权重是分数的softmax的结果 两种常见的分数计算 将query和key合并起来放入一个单输出单隐层的MLP 直接将query和key做内积 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import mathimport torchfrom torch import nnfrom d2l import torch as d2l# 遮掩softmax操作def masked_softmax(X, valid_lens): &quot;&quot;&quot;通过在最后一个轴上掩蔽元素来执行softmax操作&quot;&quot;&quot; # X:3D张量，valid_lens:1D或2D张量 if valid_lens is None: return nn.functional.softmax(X, dim=-1) else: shape = X.shape if valid_lens.dim() == 1: valid_lens = torch.repeat_interleave(valid_lens, shape[1]) else: valid_lens = valid_lens.reshape(-1) # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0 X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6) return nn.functional.softmax(X.reshape(shape), dim=-1)masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]]))# 加性注意力class AdditiveAttention(nn.Module): &quot;&quot;&quot;加性注意力&quot;&quot;&quot; def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs): super(AdditiveAttention, self).__init__(**kwargs) self.W_k = nn.Linear(key_size, num_hiddens, bias=False) self.W_q = nn.Linear(query_size, num_hiddens, bias=False) self.w_v = nn.Linear(num_hiddens, 1, bias=False) self.dropout = nn.Dropout(dropout) def forward(self, queries, keys, values, valid_lens): queries, keys = self.W_q(queries), self.W_k(keys) # 在维度扩展后， # queries的形状：(batch_size，查询的个数，1，num_hidden) # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens) # 使用广播方式进行求和 features = queries.unsqueeze(2) + keys.unsqueeze(1) features = torch.tanh(features) # self.w_v仅有一个输出，因此从形状中移除最后那个维度。 # scores的形状：(batch_size，查询的个数，“键-值”对的个数) scores = self.w_v(features).squeeze(-1) self.attention_weights = masked_softmax(scores, valid_lens) # values的形状：(batch_size，“键－值”对的个数，值的维度) return torch.bmm(self.dropout(self.attention_weights), values)queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))# values的小批量，两个值矩阵是相同的values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat( 2, 1, 1)valid_lens = torch.tensor([2, 6])attention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8, dropout=0.1)attention.eval()attention(queries, keys, values, valid_lens)d2l.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)), xlabel=&#x27;Keys&#x27;, ylabel=&#x27;Queries&#x27;)# 缩放点和注意力class DotProductAttention(nn.Module): &quot;&quot;&quot;缩放点积注意力&quot;&quot;&quot; def __init__(self, dropout, **kwargs): super(DotProductAttention, self).__init__(**kwargs) self.dropout = nn.Dropout(dropout) # queries的形状：(batch_size，查询的个数，d) # keys的形状：(batch_size，“键－值”对的个数，d) # values的形状：(batch_size，“键－值”对的个数，值的维度) # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数) def forward(self, queries, keys, values, valid_lens=None): d = queries.shape[-1] # 设置transpose_b=True为了交换keys的最后两个维度 scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d) self.attention_weights = masked_softmax(scores, valid_lens) return torch.bmm(self.dropout(self.attention_weights), values)queries = torch.normal(0, 1, (2, 1, 2))attention = DotProductAttention(dropout=0.5)attention.eval()attention(queries, keys, values, valid_lens)d2l.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)), xlabel=&#x27;Keys&#x27;, ylabel=&#x27;Queries&#x27;) 66 使用注意力机制的seq2seq 跳转至Bilibili视频 跳转至教材 67 自注意力 跳转至Bilibili视频 跳转至教材 68 Transformer 跳转至Bilibili视频 跳转至教材 69 BERT预训练 跳转至Bilibili视频 跳转至教材 70 BERT微调 跳转至Bilibili视频 跳转至教材 71 优化算法 跳转至教材 动量法：使用平滑过的梯度对权重更新 -gt=1b∑i∈It∇ℓi(xt−1)\\mathbf{g}_t=\\frac{1}{b} \\sum_{i \\in I_t} \\nabla \\ell_i\\left(\\mathbf{x}_{t-1}\\right)gt​=b1​∑i∈It​​∇ℓi​(xt−1​) -vt=βvt−1+gtwt=wt−1−ηvt\\mathbf{v}_t=\\beta \\mathbf{v}_{t-1}+\\mathbf{g}_t \\quad \\mathbf{w}_t=\\mathbf{w}_{t-1}-\\eta \\mathbf{v}_tvt​=βvt−1​+gt​wt​=wt−1​−ηvt​ 梯度平滑：vt=gt+βgt−1+β2gt−2+β3gt−3+…\\mathbf{v}_t=\\mathbf{g}_t+\\beta \\mathbf{g}_{t-1}+\\beta^2 \\mathbf{g}_{t-2}+\\beta^3 \\mathbf{g}_{t-3}+\\ldotsvt​=gt​+βgt−1​+β2gt−2​+β3gt−3​+… -β\\betaβ常见取值[0.5,0.9,0.95,0.99][0.5, 0.9, 0.95, 0.99][0.5,0.9,0.95,0.99] 最简单的算法中都实现了该方法,pytorch 中 SGD 中具有 momentum 选项即为动量法 Adam 记录vt=β1vt−1+(1−β1)gt\\mathbf{v}_t=\\beta_1 \\mathbf{v}_{t-1}+\\left(1-\\beta_1\\right) \\mathbf{g}_tvt​=β1​vt−1​+(1−β1​)gt​通常β1=0.9\\beta_1=0.9β1​=0.9 展开vt=(1−β1)(gt+β1gt−1+β12gt−2+β13gt−3+…\\mathbf{v}_t=\\left(1-\\beta_1\\right)\\left(\\mathbf{g}_t+\\beta_1 \\mathbf{g}_{t-1}+\\beta_1^2 \\mathbf{g}_{t-2}+\\beta_1^3 \\mathbf{g}_{t-3}+\\ldots\\right.vt​=(1−β1​)(gt​+β1​gt−1​+β12​gt−2​+β13​gt−3​+… 因为∑i=0∞β1i=11−β1\\sum_{i=0}^{\\infty} \\beta_1^i=\\frac{1}{1-\\beta_1}∑i=0∞​β1i​=1−β1​1​, 所以权重和为 1 由于v0=0\\mathbf{v}_0=0v0​=0, 且∑i=0tβ1t=1−β1t1−β1\\sum_{i=0}^t \\beta_1^t=\\frac{1-\\beta_1^t}{1-\\beta_1}∑i=0t​β1t​=1−β1​1−β1t​​, 修正v^t=vt1−β1t\\hat{\\mathbf{v}}_t=\\frac{\\mathbf{v}_t}{1-\\beta_1^t}v^t​=1−β1t​vt​​ 类似记录st=β2st−1+(1−β2)gt2\\mathbf{s}_t=\\beta_2 \\mathbf{s}_{t-1}+\\left(1-\\beta_2\\right) \\mathbf{g}_t^2st​=β2​st−1​+(1−β2​)gt2​, 通常β2=0.999\\beta_2=0.999β2​=0.999, 且修正s^t=st1−β2t\\hat{\\mathbf{s}}_t=\\frac{\\mathbf{s}_t}{1-\\beta_2^t}s^t​=1−β2t​st​​ 计算重新调整后的梯度gt′=v^ts^t+ϵ\\mathbf{g}_t^{\\prime}=\\frac{\\hat{\\mathbf{v}}_t}{\\sqrt{\\hat{\\mathbf{s}}_t+\\epsilon}}gt′​=s^t​+ϵ​v^t​​ 最后更新wt=wt−1−ηgt′\\mathbf{w}_t=\\mathbf{w}_{t-1}-\\eta \\mathbf{g}_t^{\\prime}wt​=wt−1​−ηgt′​","categories":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/categories/deeplearning/"}],"tags":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/tags/deeplearning/"}]},{"title":"吴恩达deeplearning","slug":"深度学习相关/吴恩达deeplearning","date":"2022-09-09T01:27:54.000Z","updated":"2023-04-16T12:15:50.273Z","comments":true,"path":"2022/09/09/深度学习相关/吴恩达deeplearning/","link":"","permalink":"http://jay1060950003.github.io/2022/09/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BEdeeplearning/","excerpt":"引言 吴恩达老师deeplearning学习笔记","text":"引言 吴恩达老师deeplearning学习笔记 L1 神经网络和深度学习 吴恩达老师的深度学习课程笔记 1.3 用神经网络进行监督学习 神经网络的基本结构 通用标准神经网络架构(universally standard neural network) 卷积神经网络(CNN) : 常用于图像任务 循环神经网络(RNN) : 常用于以为时间序列的任务(语音处理和机器翻译) *混合神经网络架构(Hybrid neural network) : 处理更加复杂高级的任务 数据 结构化数据：每个特征都有清晰的定义 非结构化数据：特征没有明确的定义，例如音频，图像 1.4 为什么深度学习会兴起 常用表示 m 表示带标签的数据量 amount of labeled data 在数据量(m)较小时,对图像而言，各神经网络的性能排名不分先后，重点在大数据量时，才会显现出性能差距 2 神经网络基础知识 2.1 二分分类 神经网络的计算过程可以分为前向传播过程和后向传播过程 logistic回归是一个用于二分分类的算法 常用符号表示 特征向量x的大小n=nx特征向量x的大小n = n_x特征向量x的大小n=nx​ 用一对(x,y)(x,y)(x,y)表示一个单独的样本， x∈Rnx,y∈{0,1}x \\in \\R^{n_x}, y \\in \\{0,1\\}x∈Rnx​,y∈{0,1} m个训练样本的个数:(x(1),y(1)),...,(x(m),y(m))m个训练样本的个数 : {(x^{(1)}, y^{(1)}),...,(x^{(m)}, y^{(m)})}m个训练样本的个数:(x(1),y(1)),...,(x(m),y(m)) m=mtrain,mtest=test_examplem = m_{train}, m_{test} = test\\_examplem=mtrain​,mtest​=test_example X={x(1),x(2),...,x(m)},X∈Rn∗m,X.shape=(nx,m)X = \\{x^{(1)}, x^{(2)},...,x^{(m)}\\} , X \\in \\R^{n*m}, X.shape = (n_x, m)X={x(1),x(2),...,x(m)},X∈Rn∗m,X.shape=(nx​,m) Y={Y(1),Y(2),...,Y(m)},Y∈R1∗m,Y.shape=(1,m)Y = \\{Y^{(1)}, Y^{(2)},...,Y^{(m)}\\} , Y \\in \\R^{1*m}, Y.shape = (1, m)Y={Y(1),Y(2),...,Y(m)},Y∈R1∗m,Y.shape=(1,m) 2.2 logistic回归 在线性回归中： 给了一个 x,x∈Rnxx, x \\in \\R^{n_x}x,x∈Rnx​，需要得到 yyy的预测值 y^=P(y=1∣x),0⩽y^⩽1\\hat{y} = P(y=1|x), 0 \\leqslant \\hat{y} \\leqslant 1y^​=P(y=1∣x),0⩽y^​⩽1 其中线性回归的两个参数 w∈Rnx,b∈Rw \\in \\R^{n_x}, b \\in \\Rw∈Rnx​,b∈R z=wTx+bz = w^Tx+bz=wTx+b 线性回归输出为 y^=σ(wTx+b),σ(z)=11+e−z\\hat{y} = \\sigma(w^Tx+b) , \\sigma(z) = \\frac{1}{1+e^{-z}}y^​=σ(wTx+b),σ(z)=1+e−z1​，其中σ(−inf⁡)=0,σ(inf⁡)=1其中 \\sigma(-\\inf) = 0 , \\sigma(\\inf) = 1其中σ(−inf)=0,σ(inf)=1 *在有些项目中的表示,x0=1,x∈Rnx+1,y^=σ(θTx),θ=[θ0,θ1,...θnx],其中θ0=b,[θ1,...θnx]=wx_0=1, x\\in\\R^{nx+1},\\hat{y}=\\sigma(\\theta^Tx),\\theta = [\\theta_0,\\theta_1,...\\theta_nx], 其中\\theta_0 = b,[\\theta_1,...\\theta_nx] = wx0​=1,x∈Rnx+1,y^​=σ(θTx),θ=[θ0​,θ1​,...θn​x],其中θ0​=b,[θ1​,...θn​x]=w 2.3 回归损失函数 为了训练参数w和参数b参数w和参数b参数w和参数b，需要定义一个代价函数 损失函数或误差函数（可用来衡量算法的运行情况） L(y^,y)=12(y^2−y)2L(\\hat{y}, y) = \\frac{1}{2}(\\hat{y}^2-y)^2L(y^​,y)=21​(y^​2−y)2: 该损失函数常会导致优化是非凸的，会导致梯度下降法可能找不到最优解，不常用 L(y^,y)=−ylog⁡y^+(1−y)log⁡(1−y^)L(\\hat{y}, y) = -y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})L(y^​,y)=−ylogy^​+(1−y)log(1−y^​) 损失函数是衡量单个样本的表现 代价函数(cost function)衡量的是在全体训练样本上的表现 J(w,b)=1m∑L(y^,y)=−1m∑[ylog⁡y^+(1−y)log⁡(1−y^)]J(w, b) = \\frac{1}{m} \\sum L(\\hat{y}, y) = -\\frac{1}{m} \\sum [y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})]J(w,b)=m1​∑L(y^​,y)=−m1​∑[ylogy^​+(1−y)log(1−y^​)] 训练线性回归的过程就是寻找合适的 w 和 b 参数使代价函数最小的过程 2.4 梯度下降法 代价函数是一个凸函数，因此该代价函数是线性回归代价函数的重要原因之一 梯度下降法要做的是从初始点开始朝最陡的下坡方向走一步，在梯度下降一步后或在该点停止，因为它正试图沿着最快下降的方向向下走（或者说尽可能快地往下走），这是梯度下降地一次迭代，经过几次迭代后尽可能收敛到全局最优解 使用 :=:=:=表示更新某个值 在算法收敛之前，重复 w:=w−αdJ(w)dw,α为学习率w:= w-\\alpha \\frac{d J(w)}{d w}, \\alpha为学习率w:=w−αdwdJ(w)​,α为学习率 学习率可以控制每一次迭代或梯度下降法中的步长 在线性回归中,w:=w−α∂J(w,b)∂w,b:=b−α∂J(w,b)∂bw:= w-\\alpha \\frac{\\partial J(w, b)}{\\partial w}, b:= b-\\alpha \\frac{\\partial J(w, b)}{\\partial b}w:=w−α∂w∂J(w,b)​,b:=b−α∂b∂J(w,b)​ 对z=w1x1+w2x2+b,a=σ(z),L(a,y)z = w_1x_1+w_2x_2+b, a=\\sigma(z), L(a,y)z=w1​x1​+w2​x2​+b,a=σ(z),L(a,y) y^=a,L(a,y)=−ylog⁡(a)+(1−y)log⁡(1−a)\\hat{y} = a, L(a, y) = -y\\log(a)+(1-y)\\log(1-a)y^​=a,L(a,y)=−ylog(a)+(1−y)log(1−a) da=dLda=−ya1−y1−a,dz=dLdz=dLdadadz=a−y,其中dadz=a(1−a),a=σ(z)da = \\frac{dL}{da} = -\\frac{y}{a}\\frac{1-y}{1-a}, dz=\\frac{dL}{dz} = \\frac{dL}{da} \\frac{da}{dz} = a-y, 其中\\frac{da}{dz} = a(1-a),a=\\sigma(z)da=dadL​=−ay​1−a1−y​,dz=dzdL​=dadL​dzda​=a−y,其中dzda​=a(1−a),a=σ(z) dw1=dLdw1=x1dz,dw2=x2dz,db=dzdw_1 = \\frac{dL}{dw_1}= x_1dz, dw_2 = x_2dz, db = dzdw1​=dw1​dL​=x1​dz,dw2​=x2​dz,db=dz 2.11 向量化 使用向量化代替for循环可以使运行速度大大提高 CPU和GPU含有并行化指令(SIMD指令) numpy 可以实现并行化计算，提高运算速度 np.exp(), np.log(), np.abs(), np.maximum() logistic回归的向量化 X=[x(1),...,x(m)],X∈Rnx∗mX = [x^{(1)},..., x^{(m)}], X \\in \\R^{n_x*m}X=[x(1),...,x(m)],X∈Rnx​∗m Z=WT[x(1),...,x(m)]+[b,...,b],Z∈Rnx∗mZ = W^T[x^{(1)},..., x^{(m)}] + [b,..., b], Z \\in \\R^{n_x*m}Z=WT[x(1),...,x(m)]+[b,...,b],Z∈Rnx​∗m 在numpy中 Z=np.dot(w.T,X)+bZ = np.dot(w.T,X) + bZ=np.dot(w.T,X)+b A=σ(Z)A = \\sigma(Z)A=σ(Z) 向量化logistic回归的梯度输出 dZ=[dz(1),...,dz(m)],A=[a(1),...,a(m)],Y=[y(1),...,y(m)]dZ = [dz^{(1)}, ..., dz^{(m)}], A = [a^{(1)},..., a^{(m)}], Y = [y^{(1)},..., y^{(m)}]dZ=[dz(1),...,dz(m)],A=[a(1),...,a(m)],Y=[y(1),...,y(m)] dZ=A−Y,db=1m∑dz(i)=1mnp.sum(dZ),dw=1mnp.dot(x,dZ.T)dZ = A-Y, db = \\frac{1}{m} \\sum dz^{(i)} = \\frac{1}{m} np.sum(dZ), dw = \\frac{1}{m} np.dot(x,dZ.T)dZ=A−Y,db=m1​∑dz(i)=m1​np.sum(dZ),dw=m1​np.dot(x,dZ.T) w:=w−αdw,b:=b−αdbw:=w-\\alpha dw, b:=b-\\alpha dbw:=w−αdw,b:=b−αdb 向量化后的整个logistic流程 Z=wTX+b=np.dot(w.T,X)+bZ = w^T X+b = np.dot(w.T, X)+bZ=wTX+b=np.dot(w.T,X)+b A=σ(Z)A = \\sigma(Z)A=σ(Z) dZ=A−Y,db=1m∑dz(i)=1mnp.sum(dZ),dw=1mnp.dot(x,dZ.T)dZ = A-Y, db = \\frac{1}{m} \\sum dz^{(i)} = \\frac{1}{m} np.sum(dZ), dw = \\frac{1}{m} np.dot(x,dZ.T)dZ=A−Y,db=m1​∑dz(i)=m1​np.sum(dZ),dw=m1​np.dot(x,dZ.T) w:=w−αdw,b:=b−αdbw:=w-\\alpha dw, b:=b-\\alpha dbw:=w−αdw,b:=b−αdb 2.15 python的广播 python中 (m,n) 矩阵加上 (1,n) 矩阵，python会将 (1,n) 矩阵广播为 (m,n) 然后执行相加 python中 (m,n) 矩阵加上 (m,1) 矩阵，python会将 (m,1) 矩阵广播为 (m,n) 然后执行相加 123456789101112import numpy as npa = np.random.randn(5)print(a)print(a.shape)# (5,)# 该矩阵秩为 1 ，无法看出ndarray是行向量还是列向量a = np.random.randn(5,1)print(a)print(a.shape)# (5, 1)# 建议使用该shape的数组进行操作， 方便看出是行向量还是列向量 在使用numpy进行编程时，尽量不要使用秩1阵 若使用秩1阵，最好使用reshape命令转换为行向量或列向量 2.18 logistic损失函数的解释 单个样本的最小化损失函数就是最大化log⁡(P(y∣x))\\log(P(y|x))log(P(y∣x)) P(y∣x)=y^y(1−y^)1−yP(y|x) = \\hat{y}^{y}(1-\\hat{y})^{1-y}P(y∣x)=y^​y(1−y^​)1−y log⁡P(y∣x)=ylog⁡y^+(1−y)log⁡(1−y^)=−L(y^,y)\\log P(y|x) = y\\log \\hat{y} + (1-y) \\log (1-\\hat{y}) = -L(\\hat{y}, y)logP(y∣x)=ylogy^​+(1−y)log(1−y^​)=−L(y^​,y) 整个样本m 使用最大似然估计进行 log⁡P(labelsintrainingset)=log⁡∏i=1mp(y(i)∣x(i))=−∑i=1mL(y^(i)∣y(i))\\log P(labels in training set) = \\log \\prod_{i=1}^m p(y^{(i)} | x^{(i)}) = - \\sum_{i=1}^m L(\\hat{y}^{(i)} | y^{(i)})logP(labelsintrainingset)=log∏i=1m​p(y(i)∣x(i))=−∑i=1m​L(y^​(i)∣y(i)) logistic回归的代价函数 J(w,b)=1m∑L(y^(i)∣y(i))J(w, b) = \\frac{1}{m} \\sum L(\\hat{y}^{(i)} | y^{(i)})J(w,b)=m1​∑L(y^​(i)∣y(i))，需要最小化代价函数，因此将上述公式的负号去掉，为了方便因此加上缩放系数1m\\frac{1}{m}m1​ 3 浅层神经网络 3.2 神经网络的表示 使用[i][i][i]上标表示层,使用(i)(i)(i)表示训练的单个样本 输入特征x1,x2,x3x_1, x_2,x_3x1​,x2​,x3​称为输入层，包含了神经网络的输入 中间的称为隐藏层:在训练集中无法看到数值，隐藏层无法看到值 隐藏层具有参数 w(4,3)[l−1],b(4,1)[l−1]w^{[l-1]}_{(4,3)},b^{[l-1]}_{(4,1)}w(4,3)[l−1]​,b(4,1)[l−1]​表示具有4个节点，3个输入特征 最后的一个为输出层，输出 y^\\hat{y}y^​ 具有参数 w(1,4)[2],b(1,1)[2]w^{[2]}_{(1,4)},b^{[2]}_{(1,1)}w(1,4)[2]​,b(1,1)[2]​ 使用监督学习进行训练时，一个训练集包括输入和目标输出，(x,y)(x,y)(x,y) 计算神经网络的层数 输入层为第0层，不计入神经网络的层数，因此上图为2层神经网络 3.3 计算神经网络的输出 神经网络的每个节点都进行两步计算 第一步计算z=wTxz = w^T xz=wTx 第二步计算a=σ(y)a = \\sigma(y)a=σ(y) 在神经网络的计算中，ai[l],l表示层，i表示该层中第几个节点a^{[l]}_i,l表示层，i表示该层中第几个节点ai[l]​,l表示层，i表示该层中第几个节点 上述计算过程使用向量化后：Z[l−1]=[w1[1]T,...,w4[1]T]T[x1,x2,x3]T+[b1[l−1],...,b4[l−1]]T=W[l−1]X+b[l−1]Z^{[l-1]}=[w_1^{[1]T},...,w_4^{[1]T}]^T[x_1,x_2,x_3]^T + [b_1^{[l-1]},...,b_4^{[l-1]}]^T=W^{[l-1]}X+b^{[l-1]}Z[l−1]=[w1[1]T​,...,w4[1]T​]T[x1​,x2​,x3​]T+[b1[l−1]​,...,b4[l−1]​]T=W[l−1]X+b[l−1] a称为激活值，a[l−1]=[a1[1]T,...,a4[1]T]T=σ(z[l−1]),σ(z)函数为激活函数a^{[l-1]} = [a_1^{[1]T},...,a_4^{[1]T}]^T = \\sigma(z^{[l-1]}), \\sigma(z)函数为激活函数a[l−1]=[a1[1]T​,...,a4[1]T​]T=σ(z[l−1]),σ(z)函数为激活函数 在单隐层神经网络中，需要代码实现的就是z[l−1],a[l−1],z[2],a[2]z^{[l-1]},a^{[l-1]},z^{[2]},a^{[2]}z[l−1],a[l−1],z[2],a[2]的计算 3.4 多个样本的向量化 a[l](i),其中i表示第i个样本，l表示层数a^{[l](i)},其中i表示第i个样本，l表示层数a[l](i),其中i表示第i个样本，l表示层数 令X=[x(1),...,x(m)]X=[x^{(1)},...,x^{(m)}]X=[x(1),...,x(m)], 则Z[l−1]=W[l−1]X+b[l−1],A[l−1]=σ(Z[l−1]),...Z^{[l-1]}=W^{[l-1]}X+b^{[l-1]}, A^{[l-1]} = \\sigma(Z^{[l-1]}),...Z[l−1]=W[l−1]X+b[l−1],A[l−1]=σ(Z[l−1]),... 上述矩阵横向表示不同的样本，纵向表示不同的隐藏单元的指标(不同的指标) 输入矩阵的横向表示不同的训练样本，纵向表示不同的输入特征，即不同的节点 3.6 激活函数 激活函数 σ\\sigmaσ函数 tanh函数 a=tanh(z)=ez−e−zez+e−z∈(−1,1)a=tanh(z) = \\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}} \\in (-1, 1)a=tanh(z)=ez+e−zez−e−z​∈(−1,1) σ\\sigmaσ函数为tanh函数平移之后的版本 使用该tanh函数可以达到类似数据中心化的效果，该激活函数的中心值为0，可以使下一层的学习方便点 tanh函数在几乎所有场合都更优越，σ\\sigmaσ函数几乎不使用 tanh函数在z很大或很小时，函数的斜率较小，会影响梯度下降的速度 修正线性单元(ReLu)a(z)=max(0,z)a(z) = max(0,z)a(z)=max(0,z) 目前大多数使用 唯一的缺点是在 z 为负数时，导数为 0 好处：在z空间中，0 处的导数和其他地方的导数相差很大，使用该激活函数，神经网络的学习速度会快很多(比tanh函数和σ\\sigmaσ函数快) 原因：在接近0时的导数不会变化 泄漏ReLu函数: a(z)=max(0.01z,z)a(z)=max(0.01z,z)a(z)=max(0.01z,z) 3.7 为什么需要非线性激活函数 恒等激活函数 g(z)=zg(z)=zg(z)=z 使用恒等激活函数，则输出 y 是 x 的线性组合，因此无论神经网络有多少层，都想等于进行线性运算，可以将中间的隐藏层删除 线性隐藏层一点用没有 只有在机器学习的回归问题或输出层或其他特殊情况时，使用恒等激活函数 3.8 激活函数的导数 g(z)=σ(z)=11+e−z,g′(z)=g(z)(1−g(z))g(z) = \\sigma(z) = \\frac{1}{1+e^{-z}}, g^{&#x27;}(z) = g(z)(1- g(z))g(z)=σ(z)=1+e−z1​,g′(z)=g(z)(1−g(z)) g(z)=tanh(z)=ez−e−zez+e−z,g′(z)=1−g2(z)g(z) = tanh(z) = \\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}, g^{&#x27;}(z) = 1- g^{2}(z)g(z)=tanh(z)=ez+e−zez−e−z​,g′(z)=1−g2(z) 3.9 神经网络的梯度下降 单隐层神经网络 参数: W[l−1],b[l−1],W[2],b[2]W^{[l-1]},b^{[l-1]},W^{[2]},b^{[2]}W[l−1],b[l−1],W[2],b[2] 输入特征: nx=n[0],n[l−1],n[2]=1n_x = n^{[0]},n^{[l-1]}, n^{[2]}=1nx​=n[0],n[l−1],n[2]=1 代价函数: J(W[l−1],b[l−1],W[2],b[2])=1m∑L(y^,y)J(W^{[l-1]},b^{[l-1]},W^{[2]},b^{[2]}) = \\frac{1}{m} \\sum L(\\hat{y},y)J(W[l−1],b[l−1],W[2],b[2])=m1​∑L(y^​,y) 梯度下降循环计算: dW[l−1]=dJdW[l−1],db[l−1]=dJdb[l−1],...dW^{[l-1]} = \\frac{dJ}{dW^{[l-1]}}, db^{[l-1]} = \\frac{dJ}{db^{[l-1]}},...dW[l−1]=dW[l−1]dJ​,db[l−1]=db[l−1]dJ​,... W[l−1]:=W[l−1]−αdW[l−1],b[l−1]:=b[l−1]−αdb[l−1],W[2]:=W[2]−αdW[2],b[2]:=b[2]−αdb[2]W^{[l-1]} := W^{[l-1]}-\\alpha dW^{[l-1]},b^{[l-1]} := b^{[l-1]}-\\alpha db^{[l-1]},W^{[2]} := W^{[2]}-\\alpha dW^{[2]},b^{[2]} := b^{[2]}-\\alpha db^{[2]}W[l−1]:=W[l−1]−αdW[l−1],b[l−1]:=b[l−1]−αdb[l−1],W[2]:=W[2]−αdW[2],b[2]:=b[2]−αdb[2] 3.11 随机初始化 将权重都初始化为0，所有的隐藏单元都等效，都在计算完全一样的函数 需要将权重随机初始化 为什么设置参数为0.01:通常将权重矩阵初始化成非常非常小的随机值 因为使用tanh或sigma激活函数，若激活函数权重过大，在计算时值会落在函数较平缓的地带，意味着梯度下降法会非常慢，学习速度非常慢 训练一个单隐层或简单的神经网络时，选择0.01参数较为合适，若使用其他网络应尝试其他参数 1234W_1 = np.random.randn((2,2)) * 0.01 # 为什么使用0.01参数b_1 = np.zero((2,1))W_2 = np.random.randn((1,2)) * 0.01b_2 = 0 4 深层神经网络 4.1 深层神经网络 l 表示层数 n[l]n^{[l]}n[l]表示第l层上的节点数 a[l]a^{[l]}a[l]表示第l层的激活函数 x=a[0]x=a^{[0]}x=a[0] W[l],b[l]W^{[l]},b^{[l]}W[l],b[l]表示第l层的权重 4.2 前向和反向传播 前向传播 Input a[l−1]a^{[l-1]}a[l−1] Output a[l]a^{[l]}a[l], cache(z[l]z^{[l]}z[l]) Z[l]=W[l]A[l−1]+b[l]Z^{[l]} = W^{[l]}A^{[l-1]}+b^{[l]}Z[l]=W[l]A[l−1]+b[l] A[l]=g[l](Z[l])A^{[l]} = g^{[l]}(Z^{[l]})A[l]=g[l](Z[l]) 反向传播 Input da[l]da^{[l]}da[l] Output da[l−1],dW[l],db[l]da^{[l-1]},dW^{[l]},db^{[l]}da[l−1],dW[l],db[l] dZ[l]=dA[l]∗g[l]′(Z[l])dZ^{[l]} = dA^{[l]} * g^{[l]&#x27;}(Z^{[l]})dZ[l]=dA[l]∗g[l]′(Z[l]) dW[l]=1mdZ[l]A[l−1]TdW^{[l]} = \\frac{1}{m} dZ^{[l]} A^{[l-1]T}dW[l]=m1​dZ[l]A[l−1]T db[l]=1mnp.sum(dZ[l],asix=1,keepdims=True)db^{[l]} = \\frac{1}{m} np.sum(dZ^{[l]}, asix = 1, keepdims = True)db[l]=m1​np.sum(dZ[l],asix=1,keepdims=True) dA[l−1]=W[l]TdZ[l]dA^{[l-1]} = W^{[l]T} dZ^{[l]}dA[l−1]=W[l]TdZ[l] 4.6 搭建深层神经网络块 4.7 参数和超参数 参数为W,bW,bW,b 超参数 learning rate(学习率) α\\alphaα iterations(梯度下降法的循环次数) hidden layers(隐层数) l hidden units(隐层节点) n[l]n^{[l]}n[l] choice of activation function(激活函数) momentun mini batch size regularization parameters(正则化参数) …… 深度学习的训练是一个经验性的过程 通常 α=0.01\\alpha=0.01α=0.01效果较好，但在训练中可以逐渐调整大小，并观察代价函数 L2 改善深层神经网络：超参数调试、正则化以及优化 1.1 训练_开发_测试集 数据集通常分为：训练集，简单交叉验证集（验证集），测试集 交叉验证集用于选择最佳模型 在传统的机器学习时代（数据量较小），通常使用3/7分，即70%验证集,30%测试集 或者60/20/20分，即60%训练集,20%验证集,20%测试集 在大数据时代(百万级别)，验证集和测试集的数据量不需要占据过多 训练集98%,验证集1%,测试集1% 或 训练集99.5%,验证集0.4%,测试集0.1% 经验：在组织数据集时，需要确保验证集和测试集来自同一分布 没有测试集也是没有关系的（测试集主要用于无偏估计），当没有测试集时，验证集被成为测试集 1.2 偏差和方差 一般来说最优误差也被称为基本误差 训练集算法产生的偏差(bias)和验证集验证算法产生的方差(variance)来诊断算法是否存在高偏差或高误差的情况 训练集错误率为1%,验证集的错误率为11%:可能过度拟合了训练集，验证集并没有充分利用交叉验证集的作用，称为高方差(high variance) 训练集错误率为15%,验证集的错误率为16%:训练集数据欠拟合，称为高偏差(high bias) 训练集错误率为15%,验证集的错误率为30%:训练集数据欠拟合，验证集并没有充分利用交叉验证集的作用,称为高偏差(high bias)高偏差(high variance) 训练集错误率为0.5%,验证集的错误率为1%:称为低偏差(low bias)高偏差(low variance) 1.3 机器学习基础 训练神经网络的常用方法： 初始化模型训练完成后，首先要知道算法的偏差，若偏差较高，评估训练集的性能 如果偏差确实很高甚至无法拟合训练集，需要选择一个新的网络或花费更多时间训练算法，或选择更先进的优化算法 反复尝试直至拟合数据为止，至少可以拟合训练集 偏差降低至可接受的数值，随后检查方差，需要查看验证集 若方差较高，最好的解决方法就是采用更多的数据，或者使用正则化来减少过拟合 重复上述操作直至找到低偏差和低方差的网络 深度学习对监督学习的一个好处是：可以有更多的选择在不影响另一个指标的前提下，改变偏差或方差 1.4 正则化 神经网络过度拟合数据（高方差）的一个解决方法就是正则化，另一个方法是准备更多的数据 正则化可以避免过度拟合或减小网络误差 一个神经网络线性回归问题，就是求解 minJ(w,b),w∈Rnx,b∈Rmin J(w,b), w \\in \\R^{n_x}, b \\in \\RminJ(w,b),w∈Rnx​,b∈R J(w,b)=1m∑L(y^(i),y(i))+λ2m∣∣w∣∣22J(w,b) = \\frac{1}{m} \\sum L(\\hat{y}^{(i)}, y^{(i)}) + \\frac{\\lambda}{2m} ||w||_2^2J(w,b)=m1​∑L(y^​(i),y(i))+2mλ​∣∣w∣∣22​ λ\\lambdaλ为正则化参数，通常使用验证集交叉验证，尝试各种数据寻找最好的参数 其中L2正则化(L2范数)：∣∣w∣∣22=∑wj2=wTwL2正则化(L2范数)：||w||_2^2 = \\sum w_j^2 = w^TwL2正则化(L2范数)：∣∣w∣∣22​=∑wj2​=wTw 为什么只正则化参数W w通常是一个高维参数矢量，已经可以表达高方差问题，而b仅为一个数字，可省略不记 L1正则化：λ2m∑∣∣w∣∣1=λ2m∣∣w∣∣1L1正则化： \\frac{\\lambda}{2m}\\sum ||w||_1 = \\frac{\\lambda}{2m} ||w||_1L1正则化：2mλ​∑∣∣w∣∣1​=2mλ​∣∣w∣∣1​ L1正则化后，w 为稀疏的，即w向量中有很多 0 J(w[l−1],b[l−1],...,w[l],b[l])=1m∑L(y^(i),y(i))+λ2m∑∣∣w[l]∣∣2J(w^{[l-1]},b^{[l-1]},...,w^{[l]},b^{[l]}) = \\frac{1}{m} \\sum L(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m} \\sum ||w^{[l]}||^2J(w[l−1],b[l−1],...,w[l],b[l])=m1​∑L(y^​(i),y(i))+2mλ​∑∣∣w[l]∣∣2 其中∣∣w[l]∣∣2=∑∑(wij[l])2,w:(n[n−l],n[l])||w^{[l]}||^2 = \\sum \\sum (w_{ij}^{[l]})^2, w:(n^{[n-l]},n^{[l]})∣∣w[l]∣∣2=∑∑(wij[l]​)2,w:(n[n−l],n[l]) 该范数称为弗罗贝尼乌斯范数（F范数）∣∣.∣∣F||.||_F∣∣.∣∣F​ 正则化也称为权重衰减，因为w更新时，正则化项影响梯度的下降速度 dW[l]=backprop+λmW[l]dW^{[l]} = backprop + \\frac{\\lambda}{m} W^{[l]}dW[l]=backprop+mλ​W[l] W[l]:=W[l]−αdW[l]=W[l]−αλmW[l]−α(backprop)W^{[l]} := W^{[l]} - \\alpha dW^{[l]} = W^{[l]} - \\frac{\\alpha \\lambda}{m} W^{[l]} - \\alpha (backprop)W[l]:=W[l]−αdW[l]=W[l]−mαλ​W[l]−α(backprop) 1.5 为什么正则化可以减少过拟合 正则化可以使隐藏层的影响减小，神经网络变得更加简单，不易产生过拟合，方差减小 假定使用tanh激活函数，该函数在z较小时激活函数为一条直线，而z较大或较小时激活函数变得非线性 若正则化参数较大，则激活函数的参数会相对小，因为代价函数中的参数变大.z[l]=W[l]a[l]+b[l]z^{[l]}=W^{[l]}a^{[l]}+b^{[l]}z[l]=W[l]a[l]+b[l]。当w较小时，忽略b的影响，z也会较小，则激活函数几乎呈现线性。当每层都呈现线性时，最终网络趋于线性网络 在进行梯度下降时，必须使用带有正则化项的代价函数，使梯度单调递减 1.6 dropout正则化 dropout正则化过程 遍历网络的每一层并设置消除神经网络中节点的概率，在每层中每个节点得以保留和消除，消除节点后删除从该节点进出的线，最后得到一个节点更少规模更小的网络，然后用backprop方法进行训练，随后使用不用的训练样本进行训练 实施dropout的方法 反向随机失活方法：通过除以keep_prob确保a的期望值不变 在测试过程中不使用dropout函数 1234567# 反向随机失活方法# 3层神经网络keep_prob = 0.8 # 表示保留某个隐藏单元的概率d3 = np.random.rand(a3.shape[0],a3.shape(1)) &lt; keep_proba3 = np.multpy(a3,d3) # a3*d3# 向外扩展a3a3 /= keep_prob # 为了保证其期望值不变 1.7 理解dropout 实施dropout后，每次迭代之后，神经网络都会变得比之前更小，因此采用较小的神经网络和使用正则化的效果使一样的 对单个神经元实施dropout，该单元的输入几乎被消除，神经元不能依赖任何特征，并为单元的输入都增加一点权重，通过传播所有权重dropout将产生收缩权重的平方范数的效果 dropout功能类似L2正则化，其更适合不同的输入范围 不同层的keep_prob可不同，该值越小该层的dropout效果越强，但在交叉验证时需要搜索更多的超级参数 在实际中，通常不对输入层进行dropout 在CV领域经常使用dropout函数 dropout的唯一缺点就是代价函数J不再被明确的定义或很难计算，难以调试 1.8 其他正则化方法 扩大数据集（数据扩增）达到正则化效果 水平翻转图片 将原图旋转随意放大裁剪 不能进行垂直翻转图片 对数字进行强变形处理 early stopping 达到正则化效果 训练中，绘制训练误差或代价函数的优化过程，呈现单调递减 绘制验证集误差或代价函数逻辑损失和对数损失等 early stopping就是在训练时在中间点停止训练，得到一个W值中等大小的F范数 优点：运行一次梯度下降就可以找到w的较小值，中间值，较大值 ==缺点:不能独立的处理代价函数和过拟合的问题，提早停止梯度下降，代价函数停止减小，同时不希望出现过拟合，使用一个方法解决两个问题 使用L2正则化 训练神经网络的时间更长，导致超参数偶所空间更容易分解，缺点在于必须尝试很多正则化参数λ\\lambdaλ的值，导致搜索λ\\lambdaλ的代价变大 在神经网路的训练过程中，其中的一步就是选择算法来优化代价函数J，另一步为防止过拟合（减小方差），这个原理有时候称为正交化 可以选择梯度下降算法 momentum算法 RMSprop算法 Adam算法 1.9 归一化输入 归一化输入可以提升神经网络的训练速度 归一化输入的两个步骤： 1 均值0化 μ=1m∑x(i)x:=x−μ\\mu = \\frac{1}{m} \\sum x^{(i)} x:=x-\\muμ=m1​∑x(i)x:=x−μ 2 归一化方差 σ2=1m∑(x(i))2\\sigma^2 = \\frac{1}{m} \\sum (x^{(i)})^2σ2=m1​∑(x(i))2 x=xσ2x = \\frac{x}{\\sigma^2}x=σ2x​ 经过归一化后，代价函数的函数图形更加对称，必须使用一个非常小的学习率，无论从哪个方向进行梯度下降都可以较快找到最优解 当特征值处于相似范围内，归一化不是很重要，但一般还是进行归一化处理 1.10 梯度消失或梯度爆炸 W参数在神经网络中，若只比1稍大一点，激活函数将以指数级爆炸；若只比1稍小一点(例如0.9)，激活函数将以指数级递减 梯度消失和梯度爆炸对训练速度影响较大，且没有彻底解决该问题的方法，但其指导了权重的初始化 1.11 神经网络的权重初始化 希望将WiW_iWi​变小，因为z是WiXiW_iX_iWi​Xi​的和 最合理的方法是将WiW_iWi​的方差设置为1n\\frac{1}{n}n1​ ReLu激活函数时:2n\\frac{2}{n}n2​ W[l]=np.random.rand(shape)∗np.sqrt(1n[l−1])W^{[l]} = np.random.rand(shape) * np.sqrt(\\frac{1}{n^{[l-1]}})W[l]=np.random.rand(shape)∗np.sqrt(n[l−1]1​) ReLu激活函数时:W[l]=np.sqrt(1n[l−1])W^{[l]} = np.sqrt(\\frac{1}{n^{[l-1]}})W[l]=np.sqrt(n[l−1]1​) 将WiW_iWi​的值设置合理，可以减慢梯度消失和梯度爆炸的速度 使用tanh激活函数时 W[l]=np.sqrt(1n[l−1])W^{[l]} = np.sqrt(\\frac{1}{n^{[l-1]}})W[l]=np.sqrt(n[l−1]1​) 或 W[l]=np.sqrt(2n[l−1]+n[l])W^{[l]} = np.sqrt(\\frac{2}{n^{[l-1]} + n^{[l]}})W[l]=np.sqrt(n[l−1]+n[l]2​) 以上所有公式都只是一个起点，会给出初始化权重矩阵的方差的默认值，若想添加方差，可使用方差超参数给公式添加一个乘数参数进行调优 该参数的优先级较低 1.14 关于梯度检验实现的注记 不要在训练中使用梯度检验，只在debug时使用梯度检验 若算法的梯度检验失败，要检查所有项定位错误 如果使用正则化，则需要注意 梯度检验和dropout不能同时使用 2 优化算法 2.1 mini-batch梯度下降法 向量化允许较快的处理整个训练集而无需某个明确的公式 在对整个训练集执行梯度下降之前必须处理数据集，可以将训练集分割成小一点的子训练集，子集称为 mini-batch 例如500万数据的训练集，将mini-batch设置为1000,则每个5000个mini-batch，其中每个mini-batch构成一个新的输入变量其中包含1000个样本 Mini−batcht:X{t},Y{t},X:(nx,mini−batch),Y:(1,mini−batch)Mini-batch t : X^{\\{t\\}}, Y^{\\{t\\}}, X: (n_x, mini-batch), Y: (1,mini-batch)Mini−batcht:X{t},Y{t},X:(nx​,mini−batch),Y:(1,mini−batch) mini-batch算法是每个同时处理的是单个的 Mini−batcht:X{t},Y{t}Mini-batch t : X^{\\{t\\}}, Y^{\\{t\\}}Mini−batcht:X{t},Y{t} 对所有的mini-batch循环处理： 首先，对X和Y执行一步梯度下降法（使用向量化处理） 首先对输入X执行前向传播Z[l]=W[l]X{t}+b[l],A[l]=g[l](Z[l])Z^{[l]} = W^{[l]}X^{\\{t\\}}+b^{[l]}, A^{[l]} = g^{[l]}(Z^{[l]})Z[l]=W[l]X{t}+b[l],A[l]=g[l](Z[l]) 计算代价函数J{t}=11000∑L(y^(i),y(i))+λ2∗1000∑∣∣w[l]∣∣2J^{\\{t\\}} = \\frac{1}{1000} \\sum L(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2*1000} \\sum ||w^{[l]}||^2J{t}=10001​∑L(y^​(i),y(i))+2∗1000λ​∑∣∣w[l]∣∣2 反向传播，更新加权值 W[l]:=W[l]−αdW[l],b[l]:=b[l]−αdb[l]W^{[l]} := W^{[l]} - \\alpha dW^{[l]}, b^{[l]} := b^{[l]} - \\alpha db^{[l]}W[l]:=W[l]−αdW[l],b[l]:=b[l]−αdb[l] 以上是mini-batch梯度下降法训练样本的一步，称为 “1 epoch”，经历了一次遍历训练集，经历了5000循环，做了5000次梯度下降 若需要多次遍历训练集，“times epoch”，需要设置一个while循环，多次遍历训练集，直至收缩到合适的需求 2.2 理解mini-batch下降法 mini-batch 每次循环，训练的是不同的数据，因此代价函数曲线会存在类似噪声的现象，走势向下 存在噪声的原因： 每次的mini-batch的训练难度不同，所以会出现来回摆动的现象 选择合适的mini-batch-size，m为训练集的大小 mini-batch-size = m ：batch梯度下降法 单次迭代时间过长 mini-batch-size = 1 ：随机梯度下降法，每个样本都是独立的mini-batch 不会收敛至最优解，而是在最优解附近来回摆动 减小学习率可以减小噪声，但会失去向量化带来的加速效果，效率过于低下 mini-batch-size = (1,m)中的数值 学习率得到最快，发挥向量化的最大效率，且不需要等待所有训练集处理完 2.3 指数加权平均(指数加权移动平均) Vt=βVt−1+(1−β)θtV_t = \\beta V_{t-1} + (1-\\beta) \\theta_tVt​=βVt−1​+(1−β)θt​ 相当于是前 11−β\\frac{1}{1-\\beta}1−β1​个数据的平均值 2.5 指数平均的偏差修正 在机器学习的初始时刻，大多数人不关注初始时期的偏差；但若需要关注初始时期的偏差，在开始计算指数加权移动平均数的时候，偏差修正可以帮助在早期获得更好的估测 在初期的计算中使用 vt1−βt\\frac{v_t}{1-\\beta^t}1−βtvt​​代替 vtv_tvt​ 2.6 动量梯度下降法 momentum梯度下降法：运行速度快于标准的梯度下降算法 基本思想：计算梯度的梯度加权平均数并利用该梯度更新权重 使用batch或mini-batch算法梯度下降 使用较大的学习率，可能使梯度摆动偏离范围 使用较小的学习率，影响学习速度 动量梯度下降法：希望在水平方向梯度下降速度快，在垂直方向梯度下降慢;使用momentum算法，最终纵轴方向的摆动减小，横轴方向运动更快，在抵达最小值的路上减小摆动 Vdw=βVdw+(1−β)dwV_{dw} = \\beta V_{dw} + (1-\\beta) dwVdw​=βVdw​+(1−β)dw Vdb=βVdb+(1−β)dbV_{db} = \\beta V_{db} + (1-\\beta) dbVdb​=βVdb​+(1−β)db W:=W−αVdw,b:=b−αdVdbW := W - \\alpha V_{dw}, b := b - \\alpha dV_{db}W:=W−αVdw​,b:=b−αdVdb​ 超参数： 学习率 α\\alphaα, 参数 β\\betaβ控制指数加权平均数(β=0.9\\beta=0.9β=0.9为好的鲁棒数) 偏差修正：Vdw1−βt,Vdb1−βt\\frac{V_{dw}}{1-\\beta^t}, \\frac{V_{db}}{1-\\beta^t}1−βtVdw​​,1−βtVdb​​ 在使用梯度下降法或momentum时可以不用考虑偏差修正的问题 最小化碗状代价函数，使用momentum算法进行优化，dw,dbdw, dbdw,db微分项相当于加速度，Vdw,VdbV_{dw}, V_{db}Vdw​,Vdb​相当于速度，β\\betaβ系数相当于加上摩擦系数，不会无限加速，不会像梯度下降一样无限加速 在部分文献中，删除了1−β1-\\beta1−β，即Vdw=βVdw+dw,...V_{dw} = \\beta V_{dw} + dw,...Vdw​=βVdw​+dw,...,使用梯度下降时 α\\alphaα也根据此处变化11−β\\frac{1}{1-\\beta}1−β1​ 2.7 RMSprop(root mean square prop) RMSprop(均方根)算法 可以减缓纵轴的下降速度，同时加快，至少不是减缓横轴的下降速度 算法流程： 首先在mini-batch中计算dw,dbdw,dbdw,db Sdw=β2Sdw+(1−β2)(dW)2S_{dw} = \\beta_2 S_dw + (1-\\beta_2) (dW)^2Sdw​=β2​Sd​w+(1−β2​)(dW)2 Sdb=β2Sdb+(1−β2)(db)2S_{db} = \\beta_2 S_db + (1-\\beta_2) (db)^2Sdb​=β2​Sd​b+(1−β2​)(db)2 W:=W−αdwSdw,b:=b−αdbSdbW := W - \\alpha \\frac{dw}{\\sqrt{S_dw}}, b := b - \\alpha \\frac{db}{\\sqrt{S_db}}W:=W−αSd​w​dw​,b:=b−αSd​b​db​ 在横轴(W)方向上，希望学习速度快，希望SdWS_{dW}SdW​相对较小，故要除以一个较小的数 在垂直(b)方向上，希望学习速度慢，减缓纵轴上的摆动，希望SdbS_{db}Sdb​较大，需要除以较大的数字，可以减缓纵轴上的变化 在这些微分项中，因为函数的倾斜程度，在纵轴(b方向)上要大于在横轴(W方向)上，(db)2(db)^2(db)2较大，SdbS_{db}Sdb​也较大，因此纵轴上需要一个较大的数相除而消除摆动，因此纵轴方向上摆动较小，横轴方向上继续推进 可以用一个更大的学习率 α\\alphaα加快学习，而无需在纵轴上垂直方向偏离 为了确保数值稳定避免除以0，需要在分母加上一个小量 W:=W−αdwSdw+ϵ,b:=b−αdbSdb+ϵ,ϵ=10−8是一个较好的选择W := W - \\alpha \\frac{dw}{\\sqrt{S_dw + \\epsilon}}, b := b - \\alpha \\frac{db}{\\sqrt{S_db + \\epsilon}}, \\epsilon = 10^{-8}是一个较好的选择W:=W−αSd​w+ϵ​dw​,b:=b−αSd​b+ϵ​db​,ϵ=10−8是一个较好的选择 RMSprop和momentum有相似的一点：可以消除梯度下降中的摆动，包括mini-batch梯度下降，并允许使用一个更大的学习率α\\alphaα，从而加快算法学习速度 2.8 Adam优化算法 Adam优化算法基本上就是将Momentum和RMSprop结合在一起 Adam算法 首先要初始化VdW=0,SdW=0,Vdb=0,Sdb=0V_{dW}=0,S_{dW}=0,V_{db}=0,S_{db}=0VdW​=0,SdW​=0,Vdb​=0,Sdb​=0 在第 t 次迭代中，要计算微分用当前的mini-batch计算dW,dbdW,dbdW,db，一般会用mini-batch梯度下降法，接下来计算momentum指数加权平均数 所以VdW=β1Vdw+(1−β1)dw,Vdb=β1Vdb+(1−β2)db,momentun参数β1V_{dW}=\\beta_1 V_{dw}+(1-\\beta_1) dw, V_{db}=\\beta_1 V_{db}+(1-\\beta_2) db,momentun参数\\beta_1VdW​=β1​Vdw​+(1−β1​)dw,Vdb​=β1​Vdb​+(1−β2​)db,momentun参数β1​；Sdw=β2Sdw+(1−β2)(dW)2,Sdb=β2Sdb+(1−β2)(db)2,RMSprop参数β2S_{dw}=\\beta_2 S_{dw}+(1-\\beta_2) (dW)^2, S_{db}=\\beta_2 S_{db}+(1-\\beta_2) (db)^2,RMSprop参数\\beta_2Sdw​=β2​Sdw​+(1−β2​)(dW)2,Sdb​=β2​Sdb​+(1−β2​)(db)2,RMSprop参数β2​ 修正参数Vdwcorrected=Vdw1−β1t,Vdbcorrected=Vdb1−β1t,Sdwcorrected=Sdw1−β2t,Sdbcorrected=Sdb1−β2tV_{dw}^{corrected}=\\frac{V_{dw}}{1-\\beta_1^t}, V_{db}^{corrected}=\\frac{V_{db}}{1-\\beta_1^t}, S_{dw}^{corrected}=\\frac{S_{dw}}{1-\\beta_2^t}, S_{db}^{corrected}=\\frac{S_{db}}{1-\\beta_2^t}Vdwcorrected​=1−β1t​Vdw​​,Vdbcorrected​=1−β1t​Vdb​​,Sdwcorrected​=1−β2t​Sdw​​,Sdbcorrected​=1−β2t​Sdb​​ 更新参数W:=W−αVdwcorrectedSdwcorrected+ϵ,b:=b−αVdbcorrectedSdbcorrected+ϵW:=W-\\alpha \\frac{V_{dw}^{corrected}}{\\sqrt{S_{dw}^{corrected}}+\\epsilon}, b:=b-\\alpha \\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\epsilon}W:=W−αSdwcorrected​​+ϵVdwcorrected​​,b:=b−αSdbcorrected​​+ϵVdbcorrected​​ Adam算法结合了Momentum和RMSprop算法，并且时一种极其常用的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构 其中，超参数学习率 α\\alphaα很重要，需要经常调试 β1=0.9\\beta_1 = 0.9β1​=0.9为缺省值，为dWdWdW的移动平均数(加权平均数)，为momentum涉及的项 β2=0.999,作者推荐\\beta_2 = 0.999, 作者推荐β2​=0.999,作者推荐, 为(dW)2,(db)2(dW)^2,(db)^2(dW)2,(db)2的移动平均数(加权平均数) ϵ=10−8,作者推荐\\epsilon = 10^{-8}, 作者推荐ϵ=10−8,作者推荐，没有人推荐调整该参数 2.9 学习率衰减 加快学习速度的一种方法是随着时间学习率衰减，称为学习率衰减 在学习初期采用较大的学习率，当开始收敛的时候，采用较小的学习率，能让步伐减小，更加收敛于最优解 方法： 将学习率设置为α=11+decayrate∗epoch_numα0\\alpha = \\frac{1}{1 + decay_rate * epoch\\_num} \\alpha_0α=1+decayr​ate∗epoch_num1​α0​ decayratedecay_ratedecayr​ate为另一个需要调整的超参数 其他学习率衰减公式： 指数衰减: α=0.95epoch_numα\\alpha = 0.95^{epoch\\_num} \\alphaα=0.95epoch_numα α=kepoch_numα0或ktα0,t为mini_batch的大小\\alpha = \\frac{k}{\\sqrt{epoch\\_num}} \\alpha_0 或 \\frac{k}{\\sqrt{t}} \\alpha_0, t为mini\\_batch的大小α=epoch_num​k​α0​或t​k​α0​,t为mini_batch的大小 离散衰减 手动衰减：训练的时间较长，只有模型数据量较小时使用 2.10 局部最优的问题 在神经网络中，梯度为 0 的点，通常不是全局最优点，通常是鞍点 在高维空间更容易碰到鞍点而不是局部最优点 在平稳段学习速度会降低，在该段梯度接近0，因此梯度下降会特别慢（在平稳段使用adam算法可以帮助更早地走出平稳段） 3 超参数调试、Batch正则化和程序框架 3.1 调试处理 超参数 learning rate(学习率) α\\alphaα momentun:β=0.9momentun : \\beta = 0.9momentun:β=0.9 β1,β2,ϵ\\beta_1, \\beta_2, \\epsilonβ1​,β2​,ϵ hidden layers(隐层数) l hidden units(隐层节点) n[l]n^{[l]}n[l] learning rate deca mini batch size regularization parameters(正则化参数) …… 在以上地超参数中，最重要的是 学习率α\\alphaα, 其他还需要调试momentun:β=0.9momentun : \\beta = 0.9momentun:β=0.9, 另外 mini-batch size 和 隐藏单元，此外层数和学习率衰减为第三个重要因素 使用adam算法时: β1=0.9,β2=0.999,ϵ=10−8\\beta_1=0.9, \\beta_2=0.999, \\epsilon=10^{-8}β1​=0.9,β2​=0.999,ϵ=10−8 重要性:学习率α\\alphaα&gt; momentun:βmomentun : \\betamomentun:β,mini-batch_size,隐藏单元 &gt; 层数,学习率衰减 在传统的机器学习中，超参数使用网格形式进行尝试；而在深度学习中，超参数随机生成，试验超参数的效果，如下图右边的选择 原因：对解决的问题而言，很难提前知道哪个超参数最重要 以上策略总结为随机选取参数，而不是采用网格均匀选取数据 另一个策略就是采用从粗糙到精细，在大范围中搜索然后缩小范围，在小范围中筛选出最优解 3.2 为超参数选择合适的范围 随机取值并不是在有效值范围内随机均匀取值，而是选择合适的步进值用来探索合适的参数 例如在α=0.0001,...,1\\alpha = 0.0001,..., 1α=0.0001,...,1中选择合适的参数 若采用均匀取值，则90%的数据都集中在0.1到1的范围内 因此采用对数轴进行取值，在对数轴上均匀取值，会有更多的搜索空间 123# 使用对数轴进行取值r = -4 * np.random.rand() # r属于[-4,0]a = 10**r 给β\\betaβ取值用于计算指数的加权平均值，当β\\betaβ接近1时，β\\betaβ即使有微小变化，所得结果的灵敏度会变化, 在该区间内需要更加密集地取值 使用1−β1-\\beta1−β进行取值，随后使用对数轴 如β=0.9,...,0.999,最终在[−3,−1]中均匀取值\\beta = 0.9,...,0.999, 最终在[-3, -1]中均匀取值β=0.9,...,0.999,最终在[−3,−1]中均匀取值 指数平均选取的数据量11−β\\frac{1}{1-\\beta}1−β1​ 3.3 超参数训练的实践：pandas vs caviar 如何组织超参数寻找 熊猫(pandas)方法：照料一个模型，观察它的表现，耐心地调试学习率（没有足够的计算能力，不能再同一时间试验大量模型） 鱼子酱(caviar)方法：同时试验多种模型 3.4 正则化网络的激活函数 batch归一化，使参数搜索问题更加容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也会更好 输入特征归一化有助于学习速度的提高：跳转至归一化输入 更深层次的输入特征进行归一化也有助于隐藏层参数的训练：batch的基本思想 实践中推荐：归一化的是Z[l]Z^{[l]}Z[l],而不是A[l]A^{[l]}A[l] 方法： 隐藏层中的:Z(1),...,Z(m)Z^{(1)},...,Z^{(m)}Z(1),...,Z(m) 计算平均值μ=1m∑Z(i)\\mu = \\frac{1}{m} \\sum Z^{(i)}μ=m1​∑Z(i)，计算方差σ2=1m∑(Z(i)−μ)2\\sigma^2 = \\frac{1}{m} \\sum (Z^{(i)}-\\mu)^2σ2=m1​∑(Z(i)−μ)2 归一化：Znorm(i)=Z(i)−μσ2+ϵZ^{(i)}_{norm} = \\frac{Z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}Znorm(i)​=σ2+ϵ​Z(i)−μ​ 不想让隐藏单元总含有平均值0和方差1，而是有不同的分布，故计算z~=γZnorm(i)+β,γ和β\\tilde{\\mathbf{z}} = \\gamma Z^{(i)}_{norm} + \\beta, \\gamma和\\betaz~=γZnorm(i)​+β,γ和β为模型的学习参数，使用优化算法优化超参数时，同时会优化上述两个参数 γ和β\\gamma和\\betaγ和β允许设置z~\\tilde{z}z~的平均值和方差，若γ=μ2+ϵ\\gamma=\\sqrt{\\mu^2+\\epsilon}γ=μ2+ϵ​且 β=μ\\beta=\\muβ=μ则 z~=z(i)\\tilde{z} = z^{(i)}z~=z(i) batch归一化不仅适用于输入层，且适用于隐藏层 γ和β\\gamma和\\betaγ和β可以确保z值为任何需要的值，以便更好的利用非线性的激活函数(sigmoid函数或其他函数) 3.5 将batch norm拟合进神经网络 该算法的参数为W[l],b[l],β[l],γ[l]W^{[l]},b^{[l]},\\beta^{[l]},\\gamma^{[l]}W[l],b[l],β[l],γ[l] 可以使用优化算法进行优化，对于某层的dβ[l]d\\beta^{[l]}dβ[l]，计算β[l]=β[l]−αdβ[l]\\beta^{[l]}=\\beta^{[l]}-\\alpha d\\beta^{[l]}β[l]=β[l]−αdβ[l] 在深度学习编程框架中，不必将batch归一化步骤放在一个batch归一化层中（tensorflow中tf.nn.batch_normalization进行），而是一行代码即可 ==实践中，batch归一化经常和训练集的mini-batch一起使用 在mini-batch中Z[l]=W[l]a[l−1]+b[l]Z^{[l]} = W^{[l]}a^{[l-1]}+b^{[l]}Z[l]=W[l]a[l−1]+b[l]的常数项b[l]b^{[l]}b[l]毫无作用，因为在batch归一化时需要减去均值而被抵消，因此b[l]b^{[l]}b[l]参数可忽略不记 mini-batch和batch norm的流程总结 对于t次mini-batch的遍历，首先前向传播计算X{t}X^{\\{t\\}}X{t}，其中使用batch norm算法将Z[l]Z^{[l]}Z[l]归一化至Z[l]~\\tilde{Z^{[l]}}Z[l]~ 随后使用后向传播计算dW[l],dβ[l],dγ[l]dW^{[l]},d \\beta^{[l]},d \\gamma^{[l]}dW[l],dβ[l],dγ[l] 使用梯度下降法，或momentu或RMSprop或Adam等方法更新参数进行优化 3.6 batch norm为什么奏效 batch norm可以使权重比网络更滞后或更深层 batch norm保证无论数据怎么改变，Z[l]Z^{[l]}Z[l]的均值和方差保持不变，其限制了在前层的参数更新影响数值分布的程度，减少了输入值改变的问题 其减弱了前层参数与后层参数的作用之间的联系，使得每层都能自己学习，稍稍独立于其他层，有助于加速整个网络的学习 另外batch norm还有一定的正则化的作用 每个mini-batch计算的均值和方差有一部分噪声（由一小部分数据计算而来），故计算的Z~\\tilde{Z}Z~存在一些噪声，类似dropout操作，因为标准偏差的缩放带来的几重噪声和减去均值带来的额外噪声（均值和标准偏差都具有噪声），故存在一定的正则化的作用；因为给隐藏单元添加了噪声迫使后部单元不会过分依赖任何一个隐藏单元 可以将batch norm和dropout一起使用增强正则化效果 dropout的奇怪特性：使用较大的mini-batch-size会减小噪声，因此会减弱正则化效果 3.7 测试时的batch norm μ=1m∑iz(i)σ2=1m∑i(z(i)−μ)2znorm (i)=z(i)−μσ2+εz~(i)=γznorm (i)+β\\begin{aligned} \\mu &amp;=\\frac{1}{m} \\sum_i z^{(i)} \\\\ \\sigma^2 &amp;=\\frac{1}{m} \\sum_i\\left(z^{(i)}-\\mu\\right)^2 \\\\ z_{\\text {norm }}^{(i)} &amp;=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}} \\\\ \\tilde{z}^{(i)} &amp;=\\gamma z_{\\text {norm }}^{(i)}+\\beta \\end{aligned}μσ2znorm (i)​z~(i)​=m1​i∑​z(i)=m1​i∑​(z(i)−μ)2=σ2+ε​z(i)−μ​=γznorm (i)​+β​ 在上述公式中，需要注意 μ,σ\\mu, \\sigmaμ,σ是在整个mini-batch上进行计算，但在测试时，不能将一个mini-batch中的6428或2056个样本同时处理，因此需要使用其他方法得到 μ,σ\\mu, \\sigmaμ,σ 单独计算μ,σ\\mu, \\sigmaμ,σ：在典型应用中需要用一个指数加权平均数来估算，这个平均值涵盖了所有的mini-batch，该指数加权平均数跟踪在训练过程中看到的 μ\\muμ和 σ2\\sigma_2σ2​的值，来粗略估算 μ\\muμ和 σ\\sigmaσ 使用深度学习框架，其中通常具有默认的估算 μ\\muμ和 σ2\\sigma_2σ2​的方式 3.8 softmax回归 logistic回归的一般形式为softmax回归，可以在试图识别某一分类时做出预测 在上图的网络中，最后一层的计算为Z[l]=W[l]a[l]+b[l]Z^{[l]}=W^{[l]}a^{[l]}+b^{[l]}Z[l]=W[l]a[l]+b[l] 随后使用softmax激活函数为:t=ez[l],a[l]=ez[l]∑tit=e^{z^{[l]}}, a^{[l]} = \\frac{e^{z^{[l]}}}{\\sum t_i}t=ez[l],a[l]=∑ti​ez[l]​，最终输出的为归一化的概率向量 3.9 训练一个softmax分类器 hardmax分类器将最大值的位置上放上1，其他位置为0 softmax分类器或softmax激活函数将logistic回归推广至C类，而不是2类 若C=2，则softmax分类器将重新回归至logistic回归 softmax的损失函数:L(y^,y)=1∑yjlog⁡yj^L(\\hat{y},y) = 1\\sum y_j \\log \\hat{y_j}L(y^​,y)=1∑yj​logyj​^​ 需要将对应项的输出概率尽可能地大，概括来讲：损失函数就是找到训练集中的真实类别，并试图将该类别的输出概率足够大（类似最大似然估计） 整个训练集的代价函数:J=1m∑L(y^,y)J=\\frac{1}{m} \\sum L(\\hat{y},y)J=m1​∑L(y^​,y) 随后在最后一层Z[l]=y^−yZ^{[l]} = \\hat{y}-yZ[l]=y^​−y,反向传播后利用梯度下降法等优化算法进优化学习 在深度学习框架中，通常后向传播过程会根据前向传播过程自动实现 3.11 tensorflow 12345678910111213141516171819202122232425import numpy as npimport tensorflow as tfcoefficients = np.array([[1.],[-10.],[25.]])w = tf.Variable(0,dtype=tf.float32)x = tf.placeholder(tf.float32, [3,1])# cost = tf.add(w**2, tf.multiply(-10,w),25)# cost = w**2 - 10*w + 25cost = x[0][0]*2**2 +x[1][0]*w + x[2][0]train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)init = tf.global_variables_initializer()# 以下三行为建立计算图session = tf.Session()session.run(init)print(session.run(w))session.run(train, feed_dict=(x:coefficients))print(session.run(w))for i in range(1000): session.run(train, feed_dict=(x:coefficients))print(session.run(w)) L3 结构化机器学习项目 1.1 为什么是ML策略 什么是机器学习策略 一些分析机器学习问题的方法，可以指引朝着最有希望的方向前进 1.2 正交化 机器学习中有许多参数、超参数需要调试。通过每次只调试一个参数，保持其它参数不变，而得到的模型某一性能改变是一种最常用的调参策略，称之为正交化方法（Orthogonalization） 核心在于每次调试一个参数只会影响模型得某一个性能 对应到机器学习监督式学习模型中，可以大致分成四个独立的&quot;功能&quot;： Fit training set well on cost function 可通过训练更复杂NN，使用Adam等优化算法实现 Fit dev set well on cost function 优化验证集，通过正则化或更多训练样本实现 Fit test set well on cost function 优化测试集，通过更多验证集实现 Performs well in real world 可通过更换验证集，或使用新的代价函数实现 另：当训练神经网络时，一般不用早期停止(early stopping)，该方法难以分析,同时会影响对训练集的拟合，同时早期停止那么对训练集的拟合不太好，同时用来改善开发集的表现 1.3 单一数字评估指标 构建或优化机器学习模型时，单值评价指标非常必要 无论是调整超参数或者在搭建机器学习系统时尝试不同手段，若有一个单实数评估指标，进展会快得多，可以得出新的尝试手段比之前好还是坏 在一个分类器中，具有查准率和查全率两个评价指标，若使用两个评价指标，就很难快速地从二者中间选择一个，故不推荐使用两个评估指标来选择一个分类器 通常使用F1分数：21P+1R(调和平均数)\\frac{2}{\\frac{1}{P}+\\frac{1}{R}} (调和平均数)P1​+R1​2​(调和平均数)作为单值评价指标来对模型进行评估 使用单实数评估指标，迭代速度会快很多 1.4 满足和优化指标 有时候，要把所有的性能指标都综合在一起，构成单值评价指标是比较困难的 解决办法：可以把某些性能作为优化指标（Optimizing metic），寻求最优化值；而某些性能作为满意指标（Satisficing metic），满足阈值 例如将Accuracy作为优化指标,将Running time作为满意指标 优化指标越优越好，满意指标符合阈值即可 1.5 训练_开发_测试集划分 跳转至 [训练_开发_测试集] 前文部分 合理设置训练集_验证集_测试集对机器学习模型训练非常重要，可以提高训练效率和模型质量 原则上应该尽量保证验证集和测试集来源于同一分布且都反映了实际样本的情况 如果验证集和测试集不来自同一分布，那么从验证集上选择的“最佳”模型往往不能够在测试集上表现得很好 1.6 开发集和测试集的大小 样本数量小于一万时，Train/dev/test sets的比例设为60%/20%/20% 在没有dev sets的情况下，Train/test sets的比例设为70%/30% 样本数量百万级别时，通常将比例设为 98%/1%/1% 或者 99%/1% 对于dev sets数量的设置，遵循的准则是通过dev sets能够检测不同算法或模型的区别，以便选择出更好的模型 对于test sets数量的设置，遵循的准则是通过test sets能够反映出模型在实际中的表现。 实际应用中，可能只有train/dev_sets，而没有test_sets; 只要算法模型没有对dev sets过拟合。但最好是有test sets以实现无偏估计 1.7 什么时候改变开发_测试集和指标 算法模型的评价标准有时候需要根据实际情况进行动态调整，目的是让算法模型在实际应用中有更好的效果 若需要更新评价指标，增加新情况的权重，增加其代价，改变代价函数为: J=1w(i)∑i=1mw(i)L(y^(i),y(i))w(i)={1,x(i) is non − porn 10,x(i) is porn \\begin{aligned} J &amp;=\\frac{1}{w^{(i)}} \\sum_{i=1}^m w^{(i)} L\\left(\\hat{y}^{(i)}, y^{(i)}\\right) \\\\ w^{(i)} &amp;= \\begin{cases}1, &amp; x^{(i)} \\text { is non }-\\text { porn } \\\\ 10, &amp; x^{(i)} \\text { is porn }\\end{cases} \\end{aligned}Jw(i)​=w(i)1​i=1∑m​w(i)L(y^​(i),y(i))={1,10,​x(i) is non − porn x(i) is porn ​​ 概括来说，机器学习的第一步是寻找靶心，第二步为通过训练射中靶心 但在训练过程中可能根据实际情况改变算法模型的评价标准，动态调整 另外，若验证集/测试集与实际使用的样本分布不一致，则也需要动态改变评价标准 1.9 可避免偏差 实际中，需要关注human-level error, training error 和dev error的相对值 training error与human-level error之间的差值称为bias，也称作avoidable bias dev error与training error之间的差值称为variance 根据bias和variance值的相对大小，可知道算法模型是否发生了欠拟合或者过拟合 1.12 改善你的模型的表现 提高机器学习模型性能主要要解决两个问题：avoidable bias和variance 解决 avoidable bias 的常用方法： Train bigger model Train longer/better optimization algorithms: momentum, RMSprop, Adam NN architecture/hyperparameters search 解决variance的常用方法： More data Regularization: L2, dropout, data augmentation NN architecture/hyperparameters search 2 机器学习策略 2.1 进行误差分析 对已经建立的机器学习模型进行错误分析（error analysis）十分必要，而且有针对性地、正确地进行error analysis更加重要 通过扩大某类样本改进模型降低错误率，但其识别率没有显著改善，这种性能限制称为ceiling on performance 通常来说，比例越大，影响越大，越应该花费时间和精力着重解决这一问题 2.2 清除错误标记的数据 监督式学习中，训练样本有时候会出现输出y标注错误的情况，即incorrectly labeled examples 如果这些label标错的情况是随机性的（random errors），DL算法对其包容性是比较强的，即健壮性好，一般可以直接忽略，无需修复 如果是系统错误（systematic errors），这将对DL算法造成影响，降低模型性能 若在验证集或测试集中出现label标错的情况，则需要根据error analysis进行分析，根据所占比例大小决定是否进行修正 如果有incorrectly labeled data的存在，当不同算法错误率比较接近的时无法仅仅根据Overall dev set error准确指出哪个算法模型更好，必须修正incorrectly labeled data 建议： 将相同的过程应用到你的开发和测试集，以确保它们继续来自相同的版本 考虑检查算法正确的例子和错误的例子 训练和开发/测试数据现在可能来自略有不同的版本 2.3 快速搭建一个系统并进行迭代 先快速搭建一个简单模型，然后再反复迭代优化 Set up dev/test set and metric Build initial system quickly Use Bias/Variance analysis &amp; Error analysis to prioritize next steps 2.4 在不同的划分上进行训练并测试 当train set与dev/test set 不来自同一个分布的时候，如何解决问题 第一种方法是将train set和dev/test set完全混合，然后在随机选择一部分作为train set，另一部分作为dev/test set 优点：实现train set和dev/test set分布一致 缺点：dev/test set中某一种的样本占比过高 不是很好 将原来的train set和一部分dev/test set组合当成train set，剩下的dev/test set分别作为dev set和test set 较为常用，且性能表现较好 2.5 不匹配数据划分的偏差和方差 如果train set和dev/test set来源于不同分布，则无法直接根据相对值大小来判断 利用training error、training-dev error和dev error三种error 其中，training error与training-dev error的差值反映了variance training-dev error与dev error的差值反映了data mismatch problem，即样本分布不一致 一般情况下，human-level error、training error、training-dev error、dev error以及test error的数值是递增的，但是也会出现dev error和test error下降的情况(训练样本比验证/测试样本更加复杂，难以训练) 2.6 解决数据不匹配 解决train set与dev/test set样本分布不一致 进行手动错误分析，以了解训练集和测试集之间的差异 使训练数据更加相似;或者收集更多类似于开发/测试集的数据 为了让train set与dev/test set类似，可以使用人工数据合成的方法，可以在train set上人工添加背景噪声，这样会让模型训练的效果更准确 但是，需要注意的是添加的背景噪声需要不一致 2.7 迁移学习 深度学习非常强大的功能之一：利用已经训练好的模型的一部分知识（网络结构）直接应用到另一个类似模型中，这种学习方法叫做迁移学习 迁移学习的做法：无需重新构建新的模型，而是利用之前的神经网络模型，只改变样本输入,输出以及输出层的权重系数W[L],b[L]W^{[L]},b^{[L]}W[L],b[L].即对新的样本(X,Y)(X,Y)(X,Y)，重新训练输出层权重系数W[L],bLW^{[L]},b^{L}W[L],bL, 而其他层所有权重系数W[l],b[l]W^{[l]},b^{[l]}W[l],b[l]保持不变 若样本数量足够多，也可以只保留网络结构，重新训练所有层的权重系数，其初始W[l],b[l]W^{[l]},b^{[l]}W[l],b[l]由之前的模型训练得到，过程pre-training；调试优化W[l],b[l]W^{[l]},b^{[l]}W[l],b[l]过程为fine-tuning== 原因：浅层部分能检测出固有特征，且迁移之后的神经网络 迁移学习可以保留神经网络的一部分，再添加新的网络层 适用于三种数据 任务A和任务B有相同的输入x 任务A比任务B有更多的数据 来自A的低级特征可能对学习B有帮助 2.8 多任务学习 多任务学习：构建神经网络同时执行多个任务 类似将多个神经网络融合起来，用一个网络网络来实现多种分类效果 多任务学习模型的代价函数:1m∑i=1m∑j=1cL(y^j(i),yj(i)),j表示任务下标,总共有c个任务\\frac{1}{m} \\sum_{i=1}^m \\sum_{j=1}^c L\\left(\\hat{y}_j^{(i)}, y_j^{(i)}\\right), j表示任务下标,总共有c个任务m1​∑i=1m​∑j=1c​L(y^​j(i)​,yj(i)​),j表示任务下标,总共有c个任务 L(y^j(i),yj(i))=−yj(i)log⁡y^j(i)−(1−yj(i))log⁡(1−y^j(i))L\\left(\\hat{y}_j^{(i)}, y_j^{(i)}\\right)=-y_j^{(i)} \\log \\hat{y}_j^{(i)}-\\left(1-y_j^{(i)}\\right) \\log \\left(1-\\hat{y}_j^{(i)}\\right)L(y^​j(i)​,yj(i)​)=−yj(i)​logy^​j(i)​−(1−yj(i)​)log(1−y^​j(i)​) 多任务学习与Softmax回归的区别在于Softmax回归是单标签的，即输出向量y只有一个元素为1；而多任务学习是多标签的，即输出向量y可以有多个元素为1 多任务学习是使用单个神经网络模型来实现多个任务；实际上，也可以分别构建多个神经网络来实现 多任务学习的场景 在一组任务上进行训练，这些任务可以受益于共享较低级别的特性 通常情况下，每个任务的数据量相当相似 可以训练一个足够大的神经网络来完成所有的任务 2.9 什么是端到端深度学习 端到端学习：将所有不同阶段的数据处理系统或学习系统模块组合在一起，用一个单一的神经网络模型来实现所有功能，将所有模块混合在一起，只关心输入和输出 训练样本足够大时，神经网络模型足够复杂，则端到端模型性能比传统机器学习分块模型更好 端到端模型内部自我训练模型特征，自我调节，增加了模型整体契合度 2.10 是否使用端到端深度学习 端到端学习的优点 让数据说话 较少需要手工设计的组件 端到端学习的缺点 需要大量数据 不包括可能有用的手工设计 L4 卷积神经网络 1.2 边缘检测示例 图片的边缘检测可以通过与相应滤波器进行卷积实现，滤波器有时候也称为核 *表示卷积操作，python中使用conv_forward()表示;tensorflow中使用tf.nn.conv2d()表示;keras中使用Conv2D()表示 1.3 更多边缘检测细节 图片边缘有两种渐变方式：一种是由明到暗，另一种是由暗到明 实际中可对两种方式进行绝对值处理得到相同的效果 常用的边缘滤波器算子除了简单的vertical滤波器和horizontal滤波器 还有sobel和scharr滤波器（增强图片中心区域的权重） ==上述算子顺时针翻转 90 度即可得到水平边缘检测算子 在深度学习中，如果想检测图片的各种边缘特征，而不仅限于垂直边缘和水平边缘，那么filter的数值一般需要通过模型训练得到，类似于标准神经网络中的权重W一样由梯度下降算法反复迭代求得 CNN的主要目的就是计算出这些filter的数值，随后CNN浅层网络也就实现了对图片所有边缘特征的检测 1.4 padding 原始图片的尺寸为 n∗nn*nn∗n, filter尺寸为 f∗ff*ff∗f, 卷积后的图片为 (n−f+1)∗(n−f+1)(n-f+1)*(n-f+1)(n−f+1)∗(n−f+1)，f一般为奇数 卷积运算后，输出图片尺寸缩小 原始图片边缘信息对输出贡献少，输出图片丢失边缘信息 为了解决图片缩小的问题，使用padding方法，将原始图片进行扩展，进行补 0 操作，用p表示每个方向扩展的宽度 padding之后原始图片尺寸为(n+2p)∗(n+2p)(n+2p)*(n+2p)(n+2p)∗(n+2p)，filter尺寸为f∗ff*ff∗f, 卷积后的图片尺寸为 (n+2p−f+1)∗(n+2p−f+1)(n+2p-f+1)*(n+2p-f+1)(n+2p−f+1)∗(n+2p−f+1) 要保证卷积前后图片尺寸不变，p=f−12p=\\frac{f-1}{2}p=2f−1​ 没有padding操作称之为“Valid convolutions”；有padding操作称之为“Same convolutions” 1.5 卷积步长 卷积步长(stride)表示卷积核在原图中水平方向和垂直方向每次的步进长度 用s表示stride步长,p表示padding长度,原始图片尺寸为n*n,filter尺寸为f*f,卷积后图片的尺寸为[n+2p−fs+1]∗[n+2p−fs+1],[...][\\frac{n+2p-f}{s}+1]*[\\frac{n+2p-f}{s}+1],[...][sn+2p−f​+1]∗[sn+2p−f​+1],[...]表示向下取整 相关系数与卷积之间有区别 卷积运算会先将filter绕中心旋转180度，然后再将旋转后的filter在原始图片上滑动计算 相关系数的计算过程不会对filter进行旋转，而是直接在原始图片上进行滑动计算 CNN卷积实际上计算的是相关系数，而不是数学意义上的卷积，为了简化计算把相关系数称作卷积运算 因为滤波器算子一般是水平或垂直对称的，180度旋转影响不大 最终滤波器算子需要通过CNN网络梯度下降算法计算得到，旋转部分可以看作是包含在CNN模型算法中 总的来说，忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能 卷积运算服从结合律(A∗B)∗C=A∗(B∗C)(A*B)*C=A*(B*C)(A∗B)∗C=A∗(B∗C) 1.6 三维卷积 3通道图片的卷积运算与单通道图片的卷积运算基本一致 将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值 不同通道的滤波算子可以不相同 例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组 输入图片尺寸为n∗n∗ncn*n*n_cn∗n∗nc​,filter尺寸为f∗f∗ncf*f*n_cf∗f∗nc​,卷积后图片为(n−f+1)∗(n−f+1)∗nc′,nc′为滤波器组个数(n-f+1)*(n-f+1)*n_c^{&#x27;},n_c^{&#x27;}为滤波器组个数(n−f+1)∗(n−f+1)∗nc′​,nc′​为滤波器组个数 1.7 单层卷积网络 CNN单层结构增加了激活函数ReLu和偏移量b 在CNN中参数数目仅由滤波器组决定，数目相对来说要少得多(CNN的优势之一) CNN单层结构的标记符号，层数为 lll f[l−1]=filter_size,p[l]=padding,s[l]=stride,nc[l]=number_of_filters\\mathrm{f}^{[l-1]}=filter\\_size, \\mathrm{p}^{[l]}=padding, \\mathrm{s}^{[l]}=stride, \\mathrm{n}_{\\mathrm{c}}^{[l]}=number\\_of\\_filtersf[l−1]=filter_size,p[l]=padding,s[l]=stride,nc[l]​=number_of_filters 输入维度为: nH[l−1]×nW[l−1]×nc[l−1]\\mathrm{n}_{\\mathrm{H}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{W}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]}nH[l−1]​×nW[l−1]​×nc[l−1]​ 每个滤波器组维度为: f[l−1]×f[l−1]×nc[l−1]\\mathrm{f}^{[l-1]} \\times \\mathrm{f}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]}f[l−1]×f[l−1]×nc[l−1]​ 权重维度为: f[l−1]×f[l−1]×nc[l−1]×nc[l−1]\\mathrm{f}^{[l-1]} \\times \\mathrm{f}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]}f[l−1]×f[l−1]×nc[l−1]​×nc[l−1]​ 偏置维度为: 1×1×1×nc[l−1]1 \\times 1 \\times 1 \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]}1×1×1×nc[l−1]​ 输出维度为: nH[l−1]×nW[l−1]×nc[l−1]\\mathrm{n}_{\\mathrm{H}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{W}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]}nH[l−1]​×nW[l−1]​×nc[l−1]​ 其中 nH[l−1]=⌊nH[l−1]+2p[l−1]−f[l−1]s[l−1]+1⌋\\mathrm{n}_{\\mathrm{H}}^{[l-1]}=\\left\\lfloor\\frac{\\mathrm{n}_{\\mathrm{H}}^{[l-1]}+2 \\mathrm{p}^{[l-1]}-\\mathrm{f}^{[l-1]}}{\\mathrm{s}^{[l-1]}}+1\\right\\rfloornH[l−1]​=⌊s[l−1]nH[l−1]​+2p[l−1]−f[l−1]​+1⌋ nW[l−1]=⌊nW[l−1]+2p[l−1]−f[l−1]s[l−1]+1⌋\\mathrm{n}_{\\mathrm{W}}^{[l-1]}=\\left\\lfloor\\frac{\\mathrm{n}_{\\mathrm{W}}^{[l-1]}+2 \\mathrm{p}^{[l-1]}-\\mathrm{f}^{[l-1]}}{\\mathrm{s}^{[l-1]}}+1\\right\\rfloornW[l−1]​=⌊s[l−1]nW[l−1]​+2p[l−1]−f[l−1]​+1⌋ 如果有m个样本，进行向量化运算，相应的输出维度为m×nH[l−1]×nW[l−1]×nc[l−1]\\mathrm{m} \\times \\mathrm{n}_{\\mathrm{H}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{W}}^{[l-1]} \\times \\mathrm{n}_{\\mathrm{c}}^{[l-1]}m×nH[l−1]​×nW[l−1]​×nc[l−1]​ 1.8 简单卷积网络示例 随着CNN层数增加，nH[l]\\mathrm{n}_{\\mathrm{H}}^{[l]}nH[l]​和 nW[l]\\mathrm{n}_{\\mathrm{W}}^{[l]}nW[l]​一般逐渐减小，而 nc[l]\\mathrm{n}_{\\mathrm{c}}^{[l]}nc[l]​一般逐渐增大 CNN有三种类型的layer: Convolution(CONV)层 Pooling(POOL)层 Fully connected(FC)层 1.9 池化层 池化层是CNN中用来减小尺寸，提升运算速度的，同样能减小噪声的影响提高健壮性 没有卷积操作，仅在滤波器算子滑动区域内取最大值，即max pooling, 超参数p很少在pooling layers中使用 Max pooling的好处是只保留区域内的最大值特征，忽略其它值，降低noise影响，提高模型健壮性 Max pooling需要的超参数仅为滤波器尺寸f和滤波器步进长度s,计算量很小 对多通道而言，每个通道单独进行max pooling操作 除了max pooling之外还有average pooling 实际应用中，max pooling 比 average pooling 更为常用 1.11 为什么使用卷积 CNN的优势之一就是参数数目要少得多，原因有两个： 参数共享：一个特征检测器（例如垂直边缘检测）对图片某块区域有用，同时也可能作用在图片其它区域 连接的稀疏性：因为滤波器算子尺寸限制，每一层的每个输出只与输入部分区域内有关 除此之外，由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上不容易发生过拟合现象 CNN比较擅长捕捉区域位置偏移，即进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性 2 深度卷积模型:案例研究 2.1 为什么进行案例探索 典型CNN模型： LeNet5 AlexNet VGG ResNet: 可以构建很深很深的神经网络 Inception Neural Network 2.2 经典网络 LeNet5模式包括conv layer, pool layer和fc layer conv layer-&gt;pool layer-&gt;conv layer-&gt;pool layer-&gt;fc layer-&gt;fc layer-&gt;output layer 池化层使用的是 average pool ；激活函数一般是 sigmoid 和 tanh 现在可以改进为 max pool ；激活函数为 ReLu AlexNet模型 与LeNet5模型类似，只是更加复杂，可根据实际情况使用激活函数ReLu 该模型提出时，GPU性能较差，AlexNet采用了非常复杂的方法在两个GPU上进行训练 大致想法是将这些层拆到两个不同的GPUs上，同时还有一个专门的方法用于两个GPUs进行交流 提出了LRN(局部相应归一化层Local Response Normalization)优化技巧，但实际应用中效果不突出 VGG-16网络 参数多达1亿3千万 2.3 残差网络(ResNets) 如果神经网络层数越多，网络越深，源于梯度消失和梯度爆炸的影响，整个模型难以训练成功 解决的方法之一：人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系，该神经网络被称为Residual Networks(ResNets) ResNets由许多隔层相连的神经王子模块组成，称为Residual block，结构如上图所示 红色部分为skip connection,直接建立 a[l]a^{[l]}a[l]与 a[l+2]a^{[l+2]}a[l+2]之间的隔层联系，a[l]a^{[l]}a[l]直接隔层与下一层的线性输出相连，与 z[l+2]z^{[l+2]}z[l+2]共同通过激活函数(ReLu)输出 a[l+2]a^{[l+2]}a[l+2] z[l+1]=W[l+1]a[l]+b[l+1]z^{[l+1]}=W^{[l+1]} a^{[l]}+b^{[l+1]}z[l+1]=W[l+1]a[l]+b[l+1] a[l+1]=g(z[l+1])a^{[l+1]}=g\\left(z^{[l+1]}\\right)a[l+1]=g(z[l+1]) z[l+2]=W[l+2]a[l+1]+b[l+2]z^{[l+2]}=W^{[l+2]} a^{[l+1]}+b^{[l+2]}z[l+2]=W[l+2]a[l+1]+b[l+2] a[l+2]=g(z[l+2]+a[l])a^{[l+2]}=g\\left(z^{[l+2]}+a^{[l]}\\right)a[l+2]=g(z[l+2]+a[l]) ResNet结构对于训练非常深的神经网络效果非常好，将非Residual Networks称为Plain Network 与Plain Network相比，Residual Network能够训练更深层的神经网络，有效避免发生发生梯度消失和梯度爆炸 2.4 残差网络为什么有用 输入x经过很多层神经网络后输出 a[l]a^{[l]}a[l], 经过一个Residual block后输出 a[l+2]=g(z[l+2]+a[l])=g(W[l+2]a[l+1]+b[l+2]+a[l])a^{[l+2]} = g(z^{[l+2]}+a^{[l]}) = g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})a[l+2]=g(z[l+2]+a[l])=g(W[l+2]a[l+1]+b[l+2]+a[l]), 输出x经过Big NN后,若W[l+2]≈0,b[l+2]≈0W^{[l+2]} \\approx 0, b^{[l+2]} \\approx 0W[l+2]≈0,b[l+2]≈0, 则a[l+2]=g(a[l])=ReLU⁡(a[l])=a[l] ,当a[l]≥0a^{[l+2]}=g\\left(a^{[l]}\\right)=\\operatorname{ReLU}\\left(a^{[l]}\\right)=a^{[l]}\\text{ ,当}a^{[l]} \\geq 0a[l+2]=g(a[l])=ReLU(a[l])=a[l] ,当a[l]≥0 即使发生了梯度消失W[l+2]≈0,b[l+2]≈0W^{[l+2]} \\approx 0, b^{[l+2]} \\approx 0W[l+2]≈0,b[l+2]≈0，也可以建立a[l+2]a^{[l+2]}a[l+2]与a[l]a^{[l]}a[l]之间的关系a[l+2]=a[l]a^{[l+2]} = a^{[l]}a[l+2]=a[l] 从效果上说相当于直接忽略了a[l]a^{[l]}a[l]之后的两层神经层，由于Residual blocks的存在，弱化削减了某些神经层之间的联系，实现隔层线性传递，而不是一味追求非线性关系，模型本身也就能“容忍”更深层的神经网络了 从性能上说额外的Residual blocks不会降低Big NN的性能 如果Residual blocks能训练得到非线性关系，那么也会忽略short cut，跟Plain Network起到同样的效果 如果Residual block中 a[l]a^{[l]}a[l]和 a[l+2]a^{[l+2]}a[l+2]的维度不同，可引入矩阵 WsW_sWs​相乘得到 Ws∗a[l]W_s * a^{[l]}Ws​∗a[l]的维度与 a[l+2]a^{[l+2]}a[l+2]一致 可将 WsW^sWs作为学习参数，通过模型训练得到 固定 WsW^sWs值，无需训练，其与 a[l]a^{[l]}a[l]的乘积仅仅使得 a[l]a^{[l]}a[l]截断或补零 2.5 网络中的网络以及1*1卷积 新的CNN结构，即 1*1卷积，也称为网络中的网络(Networks in Networks) 结构的特点:滤波器算子filter的维度为1x1 对于单个filter,1x1的维度，意味着卷积操作等同于乘积操作 对于多个filter,作用类似于全连接层的神经网络结构 可以用来缩减输入图片的通道数目 2.6 谷歌Inception网络简介 Inception网络在单层网络上可以使用多个不同尺寸的filters, 进行same Convolutions， 把各filter下得到的输出拼接起来 ==还可以将conv layer与pool layer混合，同时实现各种效果，但需要注意使用same pool Inception Network在提升性能的同时会带来计算量大的问题 使用1*1卷积核(瓶颈层)减少卷积层的计算量 如下图所示，若不使用1*1卷积层,则计算量为28x28x32x5x5x192=120M，而加入卷积层后28x28x16x192+28x28x32x5x5x16=12.4M，计算量降低了近90% 2.7 Inception网络 引入1*1卷积后的Inception模型 Inception网络 由许多Inception模块组成，网络中间隐藏层可作为输出层softmax，有利于防止发生过拟合 2.10 数据扩充 常用的数据扩充方法是对已有样本集进行Mirroring(垂直镜像对称)和Random Cropping(随机裁剪) 另可以进行color shifting: 对图片的RGB捅到数值随意增加或减少，改变图片色调 对图片的RGB通道进行主成分分析(PCA color augmentation)，对主要的通道颜色进行增加或减少，可以采用高斯扰动做法 在构建大型神经网络时，数据扩充和训练可以由两个不同的线程来进行 2.11 计算机视觉现状 Object dection，Image recognition，Speech recognition所需的数据量依次增加 如果data较少，那么就需要更多的hand-engineering，模型算法也会相对要复杂一些 如果data很多，可以构建深层神经网络，不需要太多的hand-engineering，模型算法也就相对简单一些 3 目标检测 3.1 目标定位 原始图片经过CONV卷积层后，softmax层输出8×18 \\times 18×1向量 包含目标中心位置坐标(bx,by)(bx,by)(bx,by)，矩形区域的宽和高bh,bwbh,bwbh,bw，还包含了表示是目标的概率PcPcPc,以及类标签 输出label为[Pcbxbybhbwc1c2c3][\\begin{array}{l}Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3\\end{array}][Pcbxbybhbwc1c2c3​] 损失函数，使用平方误差形式 Pc=1,即y1=1:L(y^,y)=(y^1−y1)2+(y^2−y2)2+⋯+(y^8−y8)2Pc = 1,即y_1=1:L(\\hat{y}, y)=\\left(\\hat{y}_1-y_1\\right)^2+\\left(\\hat{y}_2-y_2\\right)^2+\\cdots+\\left(\\hat{y}_8-y_8\\right)^2Pc=1,即y1​=1:L(y^​,y)=(y^​1​−y1​)2+(y^​2​−y2​)2+⋯+(y^​8​−y8​)2 Pc=0,即y1=0:L(y^,y)=(y^1−y1)2Pc = 0,即y_1=0:L(\\hat{y}, y)=\\left(\\hat{y}_1-y_1\\right)^2Pc=0,即y1​=0:L(y^​,y)=(y^​1​−y1​)2 除了使用平方误差外，可以使用逻辑回归损失函数,类标签c1,c2,c3c_1,c_2,c_3c1​,c2​,c3​可以通过softmax输出，平方误差可以取得较好效果 3.2 特征点检测 可以使用目标的关键特征点坐标进行定位，关键点称为landmarks 人脸部分特征点 人体姿态动作 3.3 目标检测 目标检测的简单方法是滑动窗算法：在训练样本集上搜索相应的各种目标图片和非目标图片(训练集图片尺寸较小，仅包含相应目标) 使用这些训练集构建CNN模型，使模型有较高的识别率 在测试图片上，选择大小适宜的窗口、合适的步进长度，进行从左到右、从上倒下的滑动 每个窗口区域都送入之前构建好的CNN模型进行识别判断 若判断有目标，则此窗口即为目标区域；若判断没有目标，则此窗口为非目标区域 滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域） 缺点：首先滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。而且，每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长 滑动窗算法虽然简单，但是性能不佳，不够快，不够灵活 3.4 卷积的滑动窗口实现 滑动窗算法可以使用卷积方式实现，以提高运行速度，节约重复运算成本 单个滑动窗口区域进入CNN网络模型时，包含全连接层。那么滑动窗口算法卷积实现的第一步就是将全连接层转变成为卷积层 全连接层转变成卷积层的操作很简单，只需要使用与上层尺寸一致的滤波算子进行卷积运算即可 单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算 利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分大大节约了运算成本 窗口步进长度与选择的MAX POOL大小有关 3.5 Bounding Box预测 滑动窗口算法会出现滑动窗不能完全涵盖目标的问题 yolo算法可以生成更加准确的目标区域 yolo算法 首先将原始图片分割成n*n网格，每个网格代表一块区域 然后利用卷积形式话哦的滑动窗口算法的思想，对原始图片构建CNN网络，输出层维度为n∗n∗8n*n*8n∗n∗8,n∗nn*nn∗n个网格，每个网格输出包含8个元素 y=[Pcbxbybhbwc1c2c3]y=\\left[\\begin{array}{c}P c \\\\ b x \\\\ b y \\\\ b h \\\\ b w \\\\ c 1 \\\\ c 2 \\\\ c 3\\end{array}\\right]y=⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡​Pcbxbybhbwc1c2c3​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤​ 目标可能超出该网格，横跨多个区域，但目标中心坐标必然在一个网格之内 划分的网格可以更密一些。网格越小，则多个目标的中心坐标被划分到一个网格内的概率就越小 3.6 交并化 IOU即交集与并集之比，用来评价目标检测区域的准确性 红色方框为真实目标区域，蓝色方框为检测目标区域。两块区域的交集为绿色部分，并集为紫色部分，蓝色方框与红色方框的接近程度可以用IoU比值来定义 IoU=IUIoU=\\frac{I}{U}IoU=UI​ IoU值介于0-1之间，越接近1表示两块区域越接近 3.7 非极大值抑制 使用非极大值抑制：用来解决多个网格都检测到同一目标的情况，决定哪个网格最为准确 Pc值反映了该网格包含目标中心坐标的可信度 首先选取Pc最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域，保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信(剔除Pc值小于某阈值的所有网格) 再从剩下的网格中选取Pc最大的网格(选取Pc值最大的网格，利用IoU，摒弃与该网格交叠较大的网格) 重复上一步的操作，最后，就能使得每个目标都仅由一个网格和区域对应 3.8 Anchor Boxes 解决多目标重叠问题：使用不同形状的Anchor Boxes 为了同时检测两个目标，设置两个Anchor Boxes：Anchor box 1检测人，Anchor box 2检测车 每个网格多加了一层输出，网络输出由 3 x 3 x 8 变为 3 x 3 x 2 x 8 2表示有两个Anchor Boxes，用来在一个网格中同时检测多个目标，每个Anchor box都有一个Pc值，若两个Pc值均大于某阈值，则检测到了两个目标 在使用yolo算法时，只需对每个Anchor Boxes使用非最大值抑制即可，Anchor Boxes之间并行实现 Anchor Boxes的形状可人为选取，也可使用其他机器学习方法(K聚类算法对待检测的所有目标进行形状分类选取主要形状为Anchor Boxes) 3.9 yolo算法 对于每个网格调用，获取 2 个预测的边界框 摆脱低概率预测 对于每个类（行人、汽车、摩托车），使用非最大抑制来生成最终预测 3.10 候选区域 使用Region Proposals(候选区域)避免对无用区域的扫描 先对原始图片进行分割算法处理，然后只对分割后的图片中的块进行目标检测 Region Proposals有三种方法 R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢 Fast R-CNN: 利用卷积实现滑动窗算法 Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度 Faster R-CNN的运行速度还是比YOLO慢一些 4 人脸识别与神经网络风格迁移 4.1 什么是人脸识别 人脸验证和人脸识别 人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题 人脸识别：输入一张人脸图片，验证输出是否为K各模板中的某一个，即一对多问题 一般而言，人脸识别较难，一对多问题的错误率会增加，模板个数越多，错误率越大 4.2 one-shot学习 one-shot学习是从数据库中每个人的训练样本只包含一张照片，然后训练一个CNN模型进行人脸识别 若数据库有K个人则CNN模型输出softmax层是K维的 one-shot性能不好，且包含的缺点 每个人只有一张图片，训练样本少，构建的CNN网络不够健壮 若数据库增加另一个人，输出层softmax的维度就要发生变化，相当于要重新构建CNN网络，使模型计算量大大增加，不够灵活 使用相似函数表示两张图片的相似程度 d(img1,img2)d(img1, img2)d(img1,img2)来表示 d(img1,img2)≤τd(img1, img2) \\leq \\taud(img1,img2)≤τ: 图片相似 d(img1,img2)&gt;τd(img1, img2) &gt; \\taud(img1,img2)&gt;τ: 图片不同 对人脸识别问题，需要计算测试图片与数据库中K个目标的相似函数,取其中d(img1,img2)d(img1,img2)d(img1,img2)最小的目标为匹配对象 4.3 Siamese网络 若一张图片经过一般的CNN网络(包括CONV层、POOL层、FC层),最终得到全连接层FC，该FC层可以看成是原始图片的编码encoding，表征了原始图片的关键特征,该网络结构称之为Siamese network 每张图片经过Siamese network后，由FC层每个神经元来表征 建立Siamese网络后,两张图片 x(1)x^{(1)}x(1)和 x(2)x^{(2)}x(2)的相似度函数可由各自FC层 f(x(1))f(x^{(1)})f(x(1))与 f(x(2))f(x^{(2)})f(x(2))之差的范数来表示：d(x(1),x(2))=∥f(x(1))−f(x(2))∥2d\\left(x^{(1)}, x^{(2)}\\right)=\\left\\|f\\left(x^{(1)}\\right)-f\\left(x^{(2)}\\right)\\right\\|^2d(x(1),x(2))=∥∥∥​f(x(1))−f(x(2))∥∥∥​2 不同图片的CNN网络所有结构和参数都是一样的，目标是利用梯度下降算法，不断调网络参数，使得同一人的图片之间d(x(1),x(2))d(x^{(1)},x^{(2)})d(x(1),x(2))很小，不同人之间很大 4.4 Triplet损失函数 搭建人脸识别的CNN模型，需要定义合适的损失函数，引入Triplet损失函数 Triplet损失函数需要每个样本包含三张图片:靶目标(Anchor),正例(Positive),反例(Negative),靶目标和正例是同一人组成一组样本，靶目标和反例不是同一人组成另一组样本 希望构建的CNN网络输出编码 f(A)f(A)f(A)接近 f(D)f(D)f(D),即 ∥f(A)−f(D)∥2\\|f(A)-f(D)\\|^2∥f(A)−f(D)∥2尽可能小, 而 ∥f(A)−f(N)∥2\\|f(A)-f(N)\\|^2∥f(A)−f(N)∥2尽可能大，数学上满足 ∥f(A)−f(P)∥2≤∥f(A)−F(N)∥2\\|f(A)-f(P)\\|^2 \\leq\\|f(A)-F(N)\\|^2∥f(A)−f(P)∥2≤∥f(A)−F(N)∥2 ∥f(A)−f(P)∥2−∥f(A)−F(N)∥2≤0\\|f(A)-f(P)\\|^2-\\|f(A)-F(N)\\|^2 \\leq 0∥f(A)−f(P)∥2−∥f(A)−F(N)∥2≤0 上述不等式，若各项为 0 同样成立，但没有作用，故添加一个超参数：(边界margin)α,α&gt;0(边界margin) \\alpha,\\alpha&gt;0(边界margin)α,α&gt;0,对上述公式进行修改 ∥f(A)−f(P)∥2−∥f(A)−F(N)∥2≤−α\\|f(A)-f(P)\\|^2-\\|f(A)-F(N)\\|^2 \\leq-\\alpha∥f(A)−f(P)∥2−∥f(A)−F(N)∥2≤−α ∥f(A)−f(P)∥2−∥f(A)−F(N)∥2+α≤0\\|f(A)-f(P)\\|^2-\\|f(A)-F(N)\\|^2+\\alpha \\leq 0∥f(A)−f(P)∥2−∥f(A)−F(N)∥2+α≤0 根据A,P,N三张图片，定义损失函数为:L(A,P,N)=max⁡(∥f(A)−f(P)∥2−∥f(A)−F(N)∥2+α,0)L(A, P, N)=\\max \\left(\\|f(A)-f(P)\\|^2-\\|f(A)-F(N)\\|^2+\\alpha, 0\\right)L(A,P,N)=max(∥f(A)−f(P)∥2−∥f(A)−F(N)∥2+α,0), 相应地，对于m组训练样本，代价函数为:J=∑i=1mL(A(i),P(i),N(i))J=\\sum_{i=1}^m L\\left(A^{(i)}, P^{(i)}, N^{(i)}\\right)J=∑i=1m​L(A(i),P(i),N(i)) 随后使用梯度下降算法，不断训练优化CNN网络参数，使代价函数不断减小接近 0 4.5 面部验证与二分类 除了构造triplet损失函数，还可以使用二分类结构 做法是将两个siamese网络组合在一起，将各自得编码层输出经过一个逻辑输出单元使用sigmoid函数，输出1表示同一人，输出0表示不同人 每组训练样本包含两张图片，每个siamese网络结构和参数完全相同，该问题转换为二分类问题，输出 y^\\hat{y}y^​表达式为:y^=σ(∑k=1Kwk∣f(x(i))k−f(x(j))k∣+b)\\hat{y}=\\sigma\\left(\\sum_{k=1}^K w_k\\left|f\\left(x^{(i)}\\right)_k-f\\left(x^{(j)}\\right)_k\\right|+b\\right)y^​=σ(∑k=1K​wk​∣∣∣​f(x(i))k​−f(x(j))k​∣∣∣​+b) 另一种表达式为:y^=σ(∑k=1Kwk(f(x(i))k−f(x(j))k)2f(x(i))k+f(x(j))k+b)\\hat{y}=\\sigma\\left(\\sum_{k=1}^K w_k \\frac{\\left(f\\left(x^{(i)}\\right)_k-f\\left(x^{(j)}\\right)_k\\right)^2}{f\\left(x^{(i)}\\right)_k+f\\left(x^{(j)}\\right)_k}+b\\right)y^​=σ(∑k=1K​wk​f(x(i))k​+f(x(j))k​(f(x(i))k​−f(x(j))k​)2​+b),，为 κ\\kappaκ方公式，也叫κ\\kappaκ方相似度 在训练好网络之后，进行人脸识别的常规方法是测试图片与模板分别进行网络计算，编码层输出比较，计算逻辑输出单元 为了减少计算量，可以使用预计算的方式在训练时就将数据库每个模板的编码层输出 f(x)f(x)f(x)保存下来 因为编码层输出 f(x)f(x)f(x)比原始图片数据量少很多，所以无须保存模板图片，只要保存每个模板的 f(x)f(x)f(x)即可，节约存储空间 测试过程中，无须计算模板的siamese网络，只要计算测试图片的siamese网络，得到的f(x(i))f(x^{(i)})f(x(i))直接与存储的模板 f(x(j))f(x^{(j)})f(x(j))进行下一步的逻辑输出单元计算即可，计算时间减小了接近一半 4.6 什么是神经风格转换 神经风格迁移是CNN模型一个非常有趣的应用,可以实现将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片 C 表示内容图片, S 表示风格图片, G 表示生成的图片 4.8 代价函数 神经风格迁移生成图片 G 的代价函数由两部分组成, C与G的相似程度和S与G的相似程度 J(G)=α⋅Jcontent (C,G)+β⋅Jstyle (S,G)J(G)=\\alpha \\cdot J_{\\text {content }}(C, G)+\\beta \\cdot J_{\\text {style }}(S, G)J(G)=α⋅Jcontent ​(C,G)+β⋅Jstyle ​(S,G), 其中α,β\\alpha, \\betaα,β是超参数，用来调整 Jcontent(C,G)J_{content}(C,G)Jcontent​(C,G)与 Jstyle(S,G)J_{style}(S,G)Jstyle​(S,G)的相对比重 基本流程：首先令G为随机像素点，然后使用梯度下降算法，不断修正G的所有像素点，使得 J(G)J(G)J(G)不断减小，从而使G逐渐有C的内容和G的风格 4.9 内容代价函数 J(G)J(G)J(G)的第一部分Jcontent(C,G)J_{content}(C,G)Jcontent​(C,G)表示内容图片C与生成图片G之间的相似度 使用的CNN网络是之前训练好的模型，首先需要选择合适的层数 lll来计算 Jcontent(C,G)J_{content}(C,G)Jcontent​(C,G)，CNN的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂 若lll太小则G与C在像素上非常接近,没有迁移效果 若lll太深则G上某个区域将直接会出现C中的物体 随后比较C和G在lll层的激活函数输出a[l](C)a^{[l](C)}a[l](C)与a[l](G)a^{[l](G)}a[l](G),相应的表达式Jcontent (C,G)=12∥a[l](C)−a[l](G)∥2J_{\\text {content }}(C, G)=\\frac{1}{2}\\left\\|a^{[l](C)}-a^{[l](G)}\\right\\|^2Jcontent ​(C,G)=21​∥∥∥​a[l](C)−a[l](G)∥∥∥​2, 两者越相似，Jcontent(C,G)J_{content}(C,G)Jcontent​(C,G)越小 使用梯度下降算法，不断迭代修正G的像素值,使 Jcontent(C,G)J_{content}(C,G)Jcontent​(C,G)不断减小 4.10 风格代价函数 图片的风格：利用CNN网络模型，图片的风格为第 lll层隐藏层不同通道间激活函数的乘积(相关性) 图片的风格矩阵：Gkk′[l]=∑i=1nH[l∑j=1nW[l]aijk[l]aijk′[l]G_{k k^{\\prime}}^{[l]}=\\sum_{i=1}^{n_H^{[l}} \\sum_{j=1}^{n_W^{[l]}} a_{i j k}^{[l]} a_{i j k^{\\prime}}^{[l]}Gkk′[l]​=∑i=1nH[l​​∑j=1nW[l]​​aijk[l]​aijk′[l]​ 其中,[l][l][l]表示第 lll层隐藏层,kkk,k′k^{\\prime}k′分别表示不同通道,总共通道数为 nC[l]n_C^{[l]}nC[l]​, i,ji,ji,j分别表示该隐藏层的高度和宽度 风格矩阵 Gkk′[l]G_{k k^{&#x27;}}^{[l]}Gkk′[l]​计算第lll层隐藏层不同通道对应的所有激活函数输出和 Gkk′[l]G_{k k^{\\prime}}^{[l]}Gkk′[l]​的维度为 nc[l]×nc[l]n_c^{[l]} \\times n_c^{[l]}nc[l]​×nc[l]​, 两个通道之间相似性高对应值大 生成图片G的风格矩阵Gkk′[l](G)G_{k k^{\\prime}}^{[l](G)}Gkk′[l](G)​,Gkk′[l]G_{k k^{\\prime}}^{[l]}Gkk′[l]​与 Gkk′[l](G)G_{k k^{\\prime}}^{[l](G)}Gkk′[l](G)​越接近，两者风格接近 损失函数: Jstyle[l](S,G)=1(2nH[l]nW[l]nC[l])∑k=1nC[l]∑k′=1nC[l]∥Gkk′[l][S]−Gkk′[l][G]∥2J_{style}^{[l]}(S, G)=\\frac{1}{(2 n_H^{[l]} n_W^{[l]} n_C^{[l]})}\\sum_{k=1}^{n_C^{[l]}} \\sum_{k^{\\prime}=1}^{n_C^{[l]}}\\|G_{k k^{\\prime}}^{[l][S]}-G_{k k^{\\prime}}^{[l][G]}\\|^2Jstyle[l]​(S,G)=(2nH[l]​nW[l]​nC[l]​)1​∑k=1nC[l]​​∑k′=1nC[l]​​∥Gkk′[l][S]​−Gkk′[l][G]​∥2 随后使用梯度下降算法，不断迭代修正 G 的像素值，使 Jstyle[l](S,G)J_{style}^{[l]}(S,G)Jstyle[l]​(S,G)不断减小 为了提取的风格更多，可以使用多层隐藏层，然后相加，表达式为 Jstyle (S,G)=∑lλ[l]⋅Jstyle [l](S,G)J_{\\text {style }}(S, G)=\\sum_l \\lambda^{[l]} \\cdot J_{\\text {style }}^{[l]}(S, G)Jstyle ​(S,G)=∑l​λ[l]⋅Jstyle [l]​(S,G)，其中 λ[l]\\lambda^{[l]}λ[l]表示累加过程中各层损失函数的权重系数，为超参数 最终代价函数为: J(G)=α⋅Jcontent (C,G)+β⋅Jstyle (S,G)J(G)=\\alpha \\cdot J_{\\text {content }}(C, G)+\\beta \\cdot J_{\\text {style }}(S, G)J(G)=α⋅Jcontent ​(C,G)+β⋅Jstyle ​(S,G), 使用梯度下降算法进行迭代优化","categories":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/categories/deeplearning/"}],"tags":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/tags/deeplearning/"}]},{"title":"Ubuntu深度学习环境配置","slug":"深度学习相关/Ubuntu深度学习环境配置","date":"2022-07-26T02:52:23.000Z","updated":"2023-04-09T13:33:49.917Z","comments":true,"path":"2022/07/26/深度学习相关/Ubuntu深度学习环境配置/","link":"","permalink":"http://jay1060950003.github.io/2022/07/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/Ubuntu%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"引言 Windows环境下深度学习环境配置","text":"引言 Windows环境下深度学习环境配置 0 前置环境 123456789101112# 安装gitsudo apt install git# 配置gitgit config --global user.name &#x27;your name&#x27;git config --global user.email &#x27;your email&#x27;# 安装miniconda(需重启)wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh #下载sh Miniconda3-latest-Linux-x86_64.sh #执行安装文件sudo rm Miniconda3-latest-Linux-x86_64.sh #删除安装文件conda update -n base -c defaults conda 1 简单安装 该方法的方案是使用conda + conda cudatoolkit + pytorch的方案 该方案会使显存占用过高(可能是没有安装nvidia的nsight模块导致的) 123456789101112131415# 配置Tensorflow，并使用conda创建自带cuda和cuDnn的虚拟环境conda create -n tf-gpu tensorflow-gpu #安装最新TF，自动配置合适的cuda和cudnn# 配置Pytorch，并使用conda创建自带cuda和cuDnn的虚拟环境conda create -n pyt #创建环境，命名可自定义conda activate pyt #进入pyt虚拟环境conda install pytorch torchvision cudatoolkit=10.1 -c pytorch #选择合适的参数# PS：建议首先conda install cudatoolkit查看适合的cudatoolkit版本随后下载指定版本的pytorchconda install cudatoolkit # 查看cudatoolkit版本，但不安装# 随后选择合适的版本下载，注意下载GPU版本https://download.pytorch.org/whl/torch_stable.html# 随后 pip install 安装指定文件# 随后 安装cudatoolkit和cudnnconda install cudatoolkit cudnn 2 完整安装(推荐) 1234567891011121314151617181920212223242526272829303132333435363738# (0)安装前检查# 1. 检查nvidia支持的cuda版本, 在bash中输入以下命令检查cuda版本，若cuda版本过低，则升级显卡驱动nvidia-smi# 2. 随后在pytorch官网查看支持的cuda版本,https://pytorch.org/get-started/locally/# (1)安装cuda# 1. 下载安装合适的nvidia的cuda版本,https://developer.nvidia.com/cuda-toolkit-archive寻找合适的版本,参考官网的安装命令# 参考官网样例：安装cuda 11.7wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pinsudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600wget https://developer.download.nvidia.com/compute/cuda/11.7.1/local_installers/cuda-repo-ubuntu2204-11-7-local_11.7.1-515.65.01-1_amd64.debsudo dpkg -i cuda-repo-ubuntu2204-11-7-local_11.7.1-515.65.01-1_amd64.debsudo cp /var/cuda-repo-ubuntu2204-11-7-local/cuda-*-keyring.gpg /usr/share/keyrings/sudo apt-get updatesudo apt-get -y install cuda# 2. 添加环境变量，在bash中输入命令以打开bashrc文件gedit ~/.bashrc# ------在文件的最后添加以下命令export PATH=/usr/local/cuda-11.7/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;export LD_LIBRARY_PATH=/usr/local/cuda-11.7/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;# (2)安装合适的cudnn# 1 在官网下载合适的cudnn版本,需要nvidia账户,https://developer.nvidia.com/rdp/cudnn-archive# ------推荐下载(Local Installer for Linux x86_64 (Tar))的tar压缩文件# 2 解压缩文件tar -xvf cudnn-linux-x86_64-8.x.x.x_cudaX.Y-archive.tar.xz# 3 复制文件到cuda目录sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda/include sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda/lib64 chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*# 4. 添加环境变量，在bash中输入命令以打开bashrc文件gedit ~/.bashrc# ------在文件的最后添加以下命令export LD_LIBRARY_PATH=/usr/local/cuda-11.7/targets/x86_64-linux/lib$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;# (3) 在conda对应的环境中安装pytorchconda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"Ubuntu使用帮助","slug":"小工具记录/Ubuntu使用帮助","date":"2022-07-26T02:52:23.000Z","updated":"2023-04-16T12:15:50.273Z","comments":true,"path":"2022/07/26/小工具记录/Ubuntu使用帮助/","link":"","permalink":"http://jay1060950003.github.io/2022/07/26/%E5%B0%8F%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/Ubuntu%E4%BD%BF%E7%94%A8%E5%B8%AE%E5%8A%A9/","excerpt":"引言 Ubuntu系统的一些使用技巧","text":"引言 Ubuntu系统的一些使用技巧 使用Clash 123456789101112131415161718# github上clash_for_windows下载合适的版本https://github.com/Fndroid/clash_for_windows_pkg/releases# 将下载额clash文件解压在opt文件夹中sudo tar -zx Clash.for.Windows-0.17.1-x64-linux.tar.gz -C /opt# 在opt文件夹下将文件夹重名cd /optsudo mv &#x27;Clash.for.Windows-0.17.1-x64-linux&#x27; clashcd clash# 运行clash./cfw# 在设置中将代理设置为手动，并填入以下地址地址：127.0.0.1端口：7890 简单美化（安装gnome插件） 123456789101112131415# 安装以下插件sudo apt updatesudo apt install gnome-tweaks chrome-gnome-shellsudo apt install gtk2-engines-murrine gtk2-engines-pixbuf sudo apt install sassc optipng inkscape libcanberra-gtk-module libglib2.0-dev libxml2-utils# 浏览器打开网页https://extensions.gnome.org# 安装插件user themes# dash to dock 22可不装netspeedhide top barproxy switch 公钥问题 12345678# 问题：无对应的公钥W: GPG error: http://mirrors.163.com jessie-updates InRelease: The following signatures couldn\\&#x27;t be verified because the public key is not available: NO_PUBKEY 8B48AD6246925553 NO_PUBKEY 7638D0442B90D010# 1 去官网的服务器获取对应的公钥gpg --keyserver keyserver.ubuntu.com --recv-keys 8B48AD6246925553# 2 将获取的公钥添加到系统密钥列表gpg -a --export 8B48AD6246925553 | sudo apt-key add - 双系统蓝牙问题 使用PSTools, psexec -s -i C:\\Windows\\regedit.exe 以使用管理员权限运行注册表编辑器 进入HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\BTHPORT\\Parameters\\Keys路径，会看到蓝牙配对的信息 重置Windows蓝牙配对信息（管理员运行cmd并执行代码）reg delete HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\BTHPORT\\Parameters\\Keys Xshell连接CentOS 配置静态ip ip addr #查看网络地址 vi /etc/sysconfig/network-scripts/ifcfg-ens33 #修改配置 PS: 进入编辑状态进去后按 “i” 退出编辑状态按ESC，输入”:wq&quot;即保存退出，“:q&quot;退出，”:q!&quot;强制退出 service network restart #重启服务 修改虚拟网络适配器 ping x.x.x.x #测试连接 Xshell配置 12345678910# centos7中的防火墙改成了firewall，使用iptables无效systemctl stop firewalld.service # 关闭防火墙systemctl restart firewalld.servic # 重启防火墙# 查看ssh服务ps -ef | grep ssh#查看ssh服务有没有运行,如果有,可以看到类似以下内容# root 2659 1 0 18:31 ? 00:00:00 /usr/sbin/sshd# root 2702 2618 0 18:38 pts/0 00:00:00 grep ssh service sshd start # 运行ssh 更新 snap-store 123kill snap-storesudo snap refresh snap-store","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"C++内存管理","slug":"计算机基础知识/C++内存管理","date":"2022-07-13T02:42:17.000Z","updated":"2023-04-16T12:15:50.274Z","comments":true,"path":"2022/07/13/计算机基础知识/C++内存管理/","link":"","permalink":"http://jay1060950003.github.io/2022/07/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/C++%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","excerpt":"引言 侯捷老师C++内存管理学习笔记","text":"引言 侯捷老师C++内存管理学习笔记 1 基础 分配 释放 类型 可否重载 malloc() free() C函数 不可 new delete C++表达式 不可 ::operator new() ::operator delete() C++函数 可 allocator&lt;T&gt;::allocate() allocator&lt;T&gt;::deallocate() C++标准库 可自由设计并以之搭配各种容器 1.1 四个层面的具体用法 1234567891011121314151617181920212223242526272829303132333435363738394041void* p1 = malloc(512); // 512bytesfree p1;complex&lt;int&gt;* p2 = new complex&lt;int&gt;; // one objectdelete p2;void* p3 = ::operator new(512); // 512 bytes，其中实质为调用 malloc 和 free::operator delete(p3);// 以下使用C++标准库提供的allocators// 器接口具有标准规范，但实现规范并非完全遵守，下面三者形式不同#ifdef _MSC_VER // 以下两函数都是 non-static ，定要通过object调用，以下分配3个ints int* p4 = allocator&lt;int&gt;().allocate(3, (int*)0); allocator&lt;int&gt;().deallocate(p4,3); #endif#ifdef _BORLANDC_ // 以下两函数都是 non-static ，定要通过object调用，以下分配5个ints int* p4 = allocator&lt;int&gt;().allocate(5); allocator&lt;int&gt;().deallocate(p4,5); #endif// GUNC 2.7#ifdef _GUNC_ // 以下两函数都是 non-static ，定要通过object调用，以下分配512bytes int* p4 = allocator&lt;int&gt;().allocate(512); allocator&lt;int&gt;().deallocate(p4,512); #endif// 使用分配器的困扰，在释放时需要记住分配时的分配个数，只有容器可以做到// GUNC 4.9// GUNC的分配的函数的用法改变了，且名字也发生了改变#ifdef _GUNC_ // 以下两函数都是 non-static ，定要通过object调用，以下分配7个ints void* p4 = allocator&lt;int().allocate(7); allocator&lt;int().deallocate((int*)p4,7) // 以下两函数都是 non-static ，定要通过object调用，以下分配9个ints void* p5 = __gnu_cxx::__pool_alloc&lt;int&gt;().allocate(9); __gnu_cxx::__pool_alloc&lt;int&gt;().deallocate((int*)p5,9) #endif 1.2 基本构件 new delete expression 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// --------------// new expression// --------------Complex* pc = new Complex(1,2);// 编译器转换为Complex *pc;try&#123; void* mem = operator new(sizeof(Complex)); // alloc pc = static_cast&lt;Complex*&gt;(mem); // cast pc -&gt; Complex::Complex(1,2); // construct // 注意只有编译器才可以像上面那样直接呼叫ctor // 欲直接调用ctor，可以连用placement new：new(p) Complex(1,2);&#125;catch(std::bad_alloc)&#123; // 若allocation失败就不执行constructor&#125;// 其中operator new的源代码..\\vc98\\crt\\src\\newop2.cpp// std::nothrow_t&amp;为保证不抛出异常的操作void* operator new(size_t size, const std::nothrow_t&amp;) __THROW0()&#123; // try to allocate size bytes void *p; while((p = malloc(size) == 0))&#123; // buy morw memory or return null pointer _TRY_BEGIN if(_callnewh(size) == 0) break; //new handle 当内存分配完时，会释放掉一些不重要的内存（C++的机制） _CATCH(std::bad_alloc) return(0); _CATCH_END &#125; return(p);&#125;// ------------------// delete expression// ------------------Complex* pc = new Complex(1,2);...delete pc;// 编译器转换为pc-&gt;~Complex() // 先析构operator delete(pc); // 然后释放内存// 其中operator delete的源码,..\\vc98\\crt\\src\\delop.cppvoid __cdecl operator delete(void *p) _THROW0()&#123; // free an allocated object free(p);&#125; 构造函数和析构函数不能通过指针直接调用(在GNC4.9中) 但在vc中可以正常通过指针调用构造函数和析构函数，但在string中无法使用 1.3 Array new 不对应写new和delete可能会导致内存泄漏 123456Complex* pca = new Complex[3];// 唤起三次ctor// 无法借由参数给予初值...delete[] pca; // 唤起3次dtor// 若使用 delete pca; 则只会调用1次dtor； 没对每个对象调用dtor，有什么影响 对class without ptr member可能没有影响 对class with pointer member通常有影响 在array new时，系统会分配一个cookie记录着整块的长度等重要的信息(malloc和free设计的) 在左边的例子中，cookie的长度不会发生变化，在delete时不加[]不会产生影响 在右边的例子中，string的设计中带有指针，因此在delete时不加[]时，其绿色的str1,str2和str3会被释放，但其中指针指向的区域不能被正确释放，产生内存泄漏 在构造时，顺序构造，析构时，逆反析构 1234567891011121314151617181920// array在构造时，没办法赋初值，因此必须有默认构造函数class A&#123; public: int id; A() :id(0)&#123;cout &lt;&lt; &quot;default ctor.this=&quot; &lt;&lt; this &lt;&lt; &quot;id=&quot; &lt;&lt; endl;&#125; A(int i) :id(i)&#123;cout &lt;&lt; &quot;default ctor.this=&quot; &lt;&lt; this &lt;&lt; &quot;id=&quot; &lt;&lt; endl;&#125; ~A()&#123;cout &lt;&lt; &quot;dtor.this=&quot; &lt;&lt; this &lt;&lt; &quot;id=&quot; &lt;&lt; endl;&#125;&#125;A* buf = new A[size]; // 调用3次ctorA* tmp = buf;cout &lt;&lt; &quot;buf=&quot; &lt;&lt; buf &quot; tmp=&quot; &lt;&lt; tmp &lt;&lt; endl;for(int i = 0; i&lt;sizze;++i)&#123; new (tmp++)A(i); // ctor 3次&#125;cout &lt;&lt; &quot;buf=&quot; &lt;&lt; buf &quot; tmp=&quot; &lt;&lt; tmp &lt;&lt; endl;delete[] buf; // 调用3次析构函数，次序逆反 在创建array时会具有上cookie(32bytes)和下cookie(4bytes)记录整块的大小，并且在整块内存上需要调整至16的倍数(本例中添加12bytes) 在创建array时，其中array内容为对象,且对象的析构函数有意义时，内存布局发生变化（会增加一个对象个数的字段），使用delete释放会报错，需要使用delete[] placement new placement new或指new(p),或::operator new(size,void*) placement new允许将object建立在已经分配的内存中，即定点创建，等同于调用构造函数 没有placement delete，因为placement new根本没有分配内存（用placement new对应的operator delete为placement delete） 123456789101112131415161718#include &lt;new&gt;char* buf = new char[sizeof(Complex)*3];Complex* pc = new(buf)Complex(1,2);...delete[] buf;// 上述第3行编译器转换为Complex* pc;try&#123; void* mem = operator new(sizeof(Complex),buf); // allocate pc = static_cast&lt;Complex*&gt;(mem); // cast pc-&gt;Complex::Complex(1,2); // construct&#125;catch(std::bad_alloc)&#123; // 若alloc失败就不执行constructor&#125;// operator new调用void* operator new(size_t, void* loc)&#123;return loc;&#125; 1.4 重载 C++应用程序分配内存的途径 12345678910111213141516171819202122232425262728293031323334// C++应用程序分配内存的途径Foo* p = new Foo(x);...delete p;// 表达式不可更改，不可以重载// 在编译器中转换为Foo* p = (Foo*)operator new (sizeof(Foo));new (p)Foo(x);...p-&gt;~Foo();operator delete(p);// 上述代码中 operator new 和 operator delete 其有两条路线可走// 其中一条为全局的函数，调用::operator new(size_t);::operator delete(void*);// 以上代码可重载，但很少见// 其调用的为CRT函数malloc(size_t);free(void*)// 另一条路线为调用成员函数（优先权较高）// 可重载Foo::operator new(size_t);Foo::operator delete(void*);// 内存管理：可自己开辟内存池做小切割，避免cookie浪费资源// 可以利用以下代码模拟编译器的代码Foo* p = (Foo*)malloc(sizeof(Foo));new (p)Foo(x);...p-&gt;~Foo();free(p); C++容器分配内存的途径 其中容器的allocate()与deallocate()调用由std::allocator继承而来的new_allocator(后面第二讲着重讲解)；其中，还是需要调用::operator new(size_t)与::operator delete(void*)函数调用CRT函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// 重载::operator new / ::operator delete// 重载全局版本影响无解void* myAlloc(size_t size)&#123; return malloc(size);&#125;void myFree(void* ptr)&#123; return free(ptr);&#125;// 它们不可以被声明于一个namespaceinline void* operator new(size_t size)&#123; cout &lt;&lt; &quot;jjhou global new() \\n&quot;; return myAlloc(size);&#125;inline void* operator new[](size_t size)&#123; cout &lt;&lt; &quot;jjhou global new[]() \\n&quot;; return myAlloc(size);&#125;inline void* operator delete(void* ptr)&#123; cout &lt;&lt; &quot;jjhou global delete() \\n&quot;; return myFree(ptr);&#125;inline void* operator delete[](void* ptr)&#123; cout &lt;&lt; &quot;jjhou global delete[]() \\n&quot;; return myFree(ptr);&#125;// ---------------------------------------------------// 源代码中的版本// ---------------------------------------------------void* operator new(size_t size, const std::nothrow_t&amp;) __THROW0()&#123; // try to allocate size bytes void *p; while((p = malloc(size) == 0))&#123; // buy morw memory or return null pointer _TRY_BEGIN if(_callnewh(size) == 0) break; //new handle 当内存分配完时，会释放掉一些不重要的内存（C++的机制） _CATCH(std::bad_alloc) return(0); _CATCH_END &#125; return(p);&#125;void __cdecl operator delete(void *p) _THROW0()&#123; // free an allocated object free(p);&#125;// 根据上文对象的 new与delete在编译器中的转换代码// 更重要的是在对象中进行重载class Foo&#123;public: void* operator new(size_t); void operator delete(void*,size_t); // size_t为可选参数 // ...&#125;// 两个函数为 static 静态函数，调用该函数为正在创建对象的过程中，此时没有对象，故需要为静态函数类型（不通过对象调用）// 在C++中该两个函数默认为静态函数，故有些情况可不加 static 声明，但实际为静态函数// 重载array版本class Foo&#123;public: void* operator new[](size_t); void operator delete[](void*,size_t); // size_t为可选参数 // ...&#125; 1.4.1 重载示例（上） 在对象创建时会先调用构造函数再调用operator new函数；再析构时，会先调用operator delete函数再调用析构函数 使用::new 或 ::delete 会绕过所有对象重载的版本，调用全局版本 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Foo&#123; public: int _id; long _data; string _str; public: Foo() : _id(0) &#123;cout &lt;&lt; &quot;deafult ctor.this=&quot; &lt;&lt; this &lt;&lt; &quot;id=&quot; &lt;&lt; _id &lt;&lt; endl;&#125; Foo(int i) : _id(i) &#123;cout &lt;&lt; &quot;ctor.this=&quot; &lt;&lt; this &lt;&lt; &quot;id=&quot; &lt;&lt; _id &lt;&lt; endl;&#125; // virtual ~Foo() &#123;cout &lt;&lt; &quot;dtor.this=&quot; &lt;&lt; this &lt;&lt; &quot;id=&quot; &lt;&lt; _id &lt;&lt; endl;&#125; // 加上virtual会使对象变大一些 static void* operator new(size_t size); static void* operator delete(void* pdead, size_t size); static void* operator new[](size_t size); static void* operator delete[](void* pdead, size_t size);&#125;;void* Foo::operator new(size_t size)&#123; Foo* p = (Foo*)malloc(size); cout &lt;&lt; .... return p;&#125;void* Foo::operator delete(void* pdead, size_t size)&#123; cout &lt;&lt; .... free(pdead);&#125;void* Foo::operator new[](size_t size)&#123; Foo* p = (Foo*)malloc(size); cout &lt;&lt; .... return p;&#125;void* Foo::operator delete[](void* pdead, size_t size)&#123; cout &lt;&lt; .... free(pdead);&#125;Foo* pf = new Foo;delete pf;// 下面版本绕过对象的重载版本，强制调用全局版本Foo* pf = ::new Foo;::delete pf; 1.4.2 重载实例（下） 重载new()/delete() 可以重载class member operator new()产生多个版本 前提是每一个版本都必须由独特的参数列，且第一个参数必须为size_t，其余参数是以new所指定的placement arguments为初值 出现于new(…)小括号内的便是所谓的placement arguments Foo* pf = new(300,‘c’)Foo; 可以重载class member operator delete()产生多个版本 绝不会被delete调用，只有当new所调用的ctor抛出异常时才会调用重载版本的operator delete() 只可以被上述方式调用，主要用于处理未能完全创建成功对象的内存 operator delete与operator new未能意义对应也不会抛出报错 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class Foo&#123; public: Foo() &#123;cout &lt;&lt; &quot;Foo::Foo()&quot; &lt;&lt; endl;&#125; Foo(int) &#123;cout &lt;&lt; &quot;Foo::Foo(int)&quot; &lt;&lt; endl;throw bad;&#125; // 刻意抛出异常，测试placement operator delete // 版本1：一般的operator new()的重载 void* operator new(size_t size)&#123; return malloc(size); &#125; // 版本2：标准库提供的placement new()的重载 void* operator new(size_t size, void* start)&#123; return start; &#125; // 版本3：崭新的placement new() void* operator new(size_t size, long extra)&#123; return malloc(size+extra); &#125; // 版本4：一个placement new void* operator new(size_t size, long extra, char init)&#123; return malloc(size+extra); &#125; // 版本5：一个placement new;故意写错第一个参数 // ! void* operator new(long extra, char init)&#123; // return malloc(extra); // &#125; private: int m_i;&#125;;// 在G4.9中没有调用operator delete(void* long),但G2.9中确实调用// 标准库中string实质为basic_string// 在其中重载了operator new与operator delete// string在创建时会增加一段extra内存，其多带了一段内容referencetemplate&lt;...&gt;class basic_string&#123; private: struct Rep&#123; ... void release() &#123;if(--ref==0) delete this;&#125; inline static void* operator new(size_t, size_t); inline static void operator delete(void*); inline static Rep* create(size_t); ... &#125;&#125;;template&lt;class charT, class traits, class Allocator&gt;inline void* basic_string&lt;charT,traits,Allocator&gt;::Rep::operator new(size_t s, size_t extra)&#123; return Allocator::allocate(s+extra * sizeof(charT));&#125;template&lt;class charT, class traits, class Allocator&gt;inline void* basic_string&lt;charT,traits,Allocator&gt;::Rep::operator delete(void* ptr)&#123; // ...&#125;template&lt;class charT, class traits, class Allocator&gt;inline basic_string&lt;charT,traits,Allocator&gt;::Rep* basic_string&lt;charT,traits,Allocator&gt;::Rep::create(size_t extra)&#123; extra = frob_size(extra+1); Rep *p = new(extra)Rep; ... return p;&#125; 1.5 Per-class allocator 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175#include &lt;cstddef&gt;#include &lt;iostream&gt;using namespace std;class Screen &#123; public: Screen(int x) : i(x) &#123; &#125;; int get() &#123; return i; &#125; void* operator new(size_t); void operator delete(void*, size_t); private: // 这种设计会引起多耗用一个next Screen* next; static Screen* freeStore; static const int screenChunk; private: int i;&#125;;Screen* Screen::freeStore = 0;const int Screen::screenChunk = 24;void* Screen::operator new(size_t size)&#123; Screen *p; if (!freeStore) &#123; //linked list 是空的，所以攫取一大塊 memory //以下呼叫的是 global operator new size_t chunk = screenChunk * size; freeStore = p = reinterpret_cast&lt;Screen*&gt;(new char[chunk]); //將分配得來的一大塊 memory 當做 linked list 般小塊小塊串接起來 for (; p != &amp;freeStore[screenChunk-1]; ++p) p-&gt;next = p+1; p-&gt;next = 0; &#125; p = freeStore; freeStore = freeStore-&gt;next; return p;&#125;// 没有对应的delete，但这不算内存泄漏void Screen::operator delete(void *p, size_t)&#123; //將 deleted object 收回插入 free list 前端 (static_cast&lt;Screen*&gt;(p))-&gt;next = freeStore; freeStore = static_cast&lt;Screen*&gt;(p);&#125;//-------------// 测试程序// ------------cout &lt;&lt; sizeof(Screen) &lt;&lt; endl; //8size_t const N = 100;Screen* p[N];for (int i=0; i&lt; N; ++i) p[i] = new Screen(i); //輸出前 10 個 pointers, 用以比較其間隔 for (int i=0; i&lt; 10; ++i) cout &lt;&lt; p[i] &lt;&lt; endl; for (int i=0; i&lt; N; ++i) delete p[i];//-------// 版本2//-------class Airplane &#123; //支援 customized memory management private: struct AirplaneRep &#123; unsigned long miles; char type; &#125;; private: union &#123; AirplaneRep rep; //此針對 used object Airplane* next; //此針對 free list &#125;; public: unsigned long getMiles() &#123; return rep.miles; &#125; char getType() &#123; return rep.type; &#125; void set(unsigned long m, char t) &#123; rep.miles = m; rep.type = t; &#125; public: static void* operator new(size_t size); static void operator delete(void* deadObject, size_t size); private: static const int BLOCK_SIZE; static Airplane* headOfFreeList;&#125;;Airplane* Airplane::headOfFreeList;const int Airplane::BLOCK_SIZE = 512;void* Airplane::operator new(size_t size)&#123; // 如果大小錯誤，轉交給 ::operator new() // 如果由继承发生，则有可能产生错误 if (size != sizeof(Airplane)) return ::operator new(size); Airplane* p = headOfFreeList; //如果 p 有效，就把list頭部移往下一個元素 if (p) headOfFreeList = p-&gt;next; else &#123; //free list 已空。配置一塊夠大記憶體， //令足夠容納 BLOCK_SIZE 個 Airplanes Airplane* newBlock = static_cast&lt;Airplane*&gt; (::operator new(BLOCK_SIZE * sizeof(Airplane))); //組成一個新的 free list：將小區塊串在一起，但跳過 //#0 元素，因為要將它傳回給呼叫者。 for (int i = 1; i &lt; BLOCK_SIZE-1; ++i) newBlock[i].next = &amp;newBlock[i+1]; newBlock[BLOCK_SIZE-1].next = 0; //以null結束 // 將 p 設至頭部，將 headOfFreeList 設至 // 下一個可被運用的小區塊。 p = newBlock; headOfFreeList = &amp;newBlock[1]; &#125; return p;&#125;// operator delete 接獲一塊記憶體。// 如果它的大小正確，就把它加到 free list 的前端void Airplane::operator delete(void* deadObject, size_t size)&#123; if (deadObject == 0) return; if (size != sizeof(Airplane)) &#123; ::operator delete(deadObject); return; &#125; Airplane *carcass = static_cast&lt;Airplane*&gt;(deadObject); carcass-&gt;next = headOfFreeList; headOfFreeList = carcass;&#125;//-------------// 测试代码//-------------cout &lt;&lt; sizeof(Airplane) &lt;&lt; endl; //8size_t const N = 100;Airplane* p[N]; for (int i=0; i&lt; N; ++i) p[i] = new Airplane; //隨機測試 object 正常否 p[1]-&gt;set(1000,&#x27;A&#x27;); p[5]-&gt;set(2000,&#x27;B&#x27;);p[9]-&gt;set(500000,&#x27;C&#x27;);cout &lt;&lt; p[1] &lt;&lt; &#x27; &#x27; &lt;&lt; p[1]-&gt;getType() &lt;&lt; &#x27; &#x27; &lt;&lt; p[1]-&gt;getMiles() &lt;&lt; endl;cout &lt;&lt; p[5] &lt;&lt; &#x27; &#x27; &lt;&lt; p[5]-&gt;getType() &lt;&lt; &#x27; &#x27; &lt;&lt; p[5]-&gt;getMiles() &lt;&lt; endl;cout &lt;&lt; p[9] &lt;&lt; &#x27; &#x27; &lt;&lt; p[9]-&gt;getType() &lt;&lt; &#x27; &#x27; &lt;&lt; p[9]-&gt;getMiles() &lt;&lt; endl; //輸出前 10 個 pointers, 用以比較其間隔 for (int i=0; i&lt; 10; ++i) cout &lt;&lt; p[i] &lt;&lt; endl; for (int i=0; i&lt; N; ++i) delete p[i]; 1.6 static allocator 当需要为不同的classes重写一遍几乎相同的member operator new和member operator delete时，应该有方法将一个总是分配特定尺寸区域的memory allocator概念包装起来，使之容易被重复使用 每个allocator object都是个分配器，内部有一个free-lists；不同的allocator objects维持不同的free-lists 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081class allocator&#123; public: struct obj&#123; struct obj* next; // 嵌入式指针 &#125; public: void* allocate(size_t); void deallocate(void*, size_t); private: obj* freeStore = nullptr; const int CHUNK = 5; // 小一些以便观察;标准库为20&#125;// 使每CHUNK个元素的空间是相邻的void* allocator::allocate(size_t size)&#123; obj* p; if(!freeStore)&#123; // linked list 为空，于是申请一大块 size_t chunk = CHUNK * size; freeStore = p = (obj*)malloc(chunk); // 将分配得来的一大块当作linked list般小块小块串接起来 for(int i = 0; i&lt;(CHUNK-1);++i)&#123; p-&gt;next = (obj*)((char*)p+size); p = p-&gt;next; &#125; p-&gt;next = nullptr; // last &#125; p = freeStore; freeStore = freeStore-&gt;next; return p;&#125;void* allocator::deallocate(void* p, size_t)&#123; // 将*p回收插入free list前端 ((obj*)p)-&gt;next = freeStore; freeStore = (obj*)p;&#125;// 使用上述allocatorclass Foo&#123; public: long L; string str; static allocator myAlloc; public: Foo(long l) :L(l)&#123;&#125; static void* operator new(size_t size)&#123; return myAlloc.allocate(size); &#125; static void* operator delete(void* pdead, size_t size)&#123; return myAlloc.deallocate(pdead, size); &#125;&#125;;allocator Foo::myAlloc; // 由于myAlloc为静态类型，故需要在类外定义class Goo&#123; public: complex&lt;double&gt; c; string str; static allocator myAlloc; public: Goo(const complex&lt;double&gt;&amp; x) :c(x)&#123;&#125; static void* operator new(size_t size)&#123; return myAlloc.allocate(size); &#125; static void* operator delete(void* pdead, size_t size)&#123; return myAlloc.deallocate(pdead, size); &#125;&#125;;allocator Goo::myAlloc; // 由于myAlloc为静态类型，故需要在类外定义// 测试程序Foo* p[100];cout &lt;&lt; &quot;sizeof(Foo)=&quot; &lt;&lt; sizeof(Foo) &lt;&lt; endl;for (int i=O; i&lt;23; ++i) &#123; ／／随意看看秸果 p[i] =new Foo(i); cout &lt;&lt; p[i] &lt;&lt; &#x27;&#x27; &lt;&lt; p[i]-&gt;L &lt;&lt; endl;&#125;for (int i=O; i&lt;23; ++i) &#123; delete p[i];&#125; 1.7 macro for static allocator 12345678910111213141516171819202122232425262728293031323334353637383940414243class Foo&#123; public: long L; string str; static allocator myAlloc; // 固定写法 public: Foo(long l) :L(l)&#123;&#125; // 固定写法 static void* operator new(size_t size)&#123; return myAlloc.allocate(size); &#125; // 固定写法 static void* operator delete(void* pdead, size_t size)&#123; return myAlloc.deallocate(pdead, size); &#125;&#125;;allocator Foo::myAlloc; // 由于myAlloc为静态类型，故需要在类外定义// 以上写法非常固定，可以将其转换为macro写法// DECLARE_POOL_ALLOC#define DECLARE_POOL_ALLOC() \\public: \\ void* operator new(size_t size)&#123;return myAlloc.allocate(size);&#125; void* operator delete(void* pdead, size_t size)&#123;return myAlloc.deallocate(pdead, size);&#125;protected: static allocator myAlloc;// IMPLEMENT_POOL_ALLOC#define IMPLEMENT_POOL_ALLOC(class_name) \\allocator class_name::myAlloc;// 可将上述类的写法转换为class Foo&#123; DECLARE_POOL_ALLOC()s public: long L; string str; public: Foo(long l) :L(l)&#123;&#125;&#125;;IMPLEMENT_POOL_ALLOC(Foo)// 使用上述程序进行测试，与上述版本的结果一致 1.8 global allocator 将版本3的allocator进一步发展为16条free-lists，并且不再以application classes内的static呈现，而是标准库的global allocator 1.9 new handler 在内存分配结束之后，需要检查内存是否分配成功 当operator new没能力分配申请的内存，会抛出std::bad_alloc 异常。某些老编译器返回0 new (nothrow) Foo; 可以指定程序返回0，而不是抛出异常 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 抛出异常之前，会先调用一个可由client指定的handlertypedef void(*new_handler)();new_handler set_new_handler(new_handler p) throw();// 设计良好的new handler只有两个选择// 让更多内存可用// 调用abort或exit()// ---------------------------------------------------// 源代码中的版本// ---------------------------------------------------void* operator new(size_t size, const std::nothrow_t&amp;) __THROW0()&#123; // try to allocate size bytes void *p; while((p = malloc(size) == 0))&#123; // buy morw memory or return null pointer _TRY_BEGIN if(_callnewh(size) == 0) break; //new handle 当内存分配完时，会释放掉一些不重要的内存（C++的机制） _CATCH(std::bad_alloc) return(0); _CATCH_END &#125; return(p);&#125;// 其中_callnewh为调用new handler函数// -------// 使用实例// -------#include &lt;new&gt;#include &lt;iostream&gt;#include &lt;cassert&gt;using namespace std;void noMoreMemory()&#123; cerr &lt;&lt; &quot;out of memory&quot;; abort();&#125;void main()&#123; set_new_handler(noMoreMemory); int* p = new int[10000000000000]; // well, so big assert(p);&#125;// 本例中 new handler 若无调用abort()，执行后cerr会不断出现&quot;out of memory&quot;，需要强制中断（原因在于会不断调用new handler直至获得足够的内存） 1.10 =default,=delete 在C++中只有拷贝构造函数，拷贝赋值函数，析构函数具有编译器合成版本（默认版本） 12345678class Foo&#123; public: Foo() = default; Foo(const Foo&amp;) = delete; Foo&amp; operator=(const Foo&amp;) = delete; ~Foo() = delete; ...&#125;; 2 std::allocator 2.1 VC6 malloc() 内存管理的目的：管理效率提高，内存利用率提高（去除cookie） 2.2 VC6标准分配器的实现 12345678910111213141516171819202122#ifndef _FARQ#define _FARQ#define _PDFT ptrdiff_t#define SIZT size t#endiftemplate&lt;class _Ty&gt;class allocator&#123; public: typedef _SIZT size_type; typedef _PDFT difference_type; typedef _Ty _FARQ *pointer; typedef _Ty value_type; pointer allocate(size_type _N, const void *)&#123;return (_Allocate((difference_type) _N, (pointer)0));&#125; void deallocate(void _FARQ * _P, size_type)&#123;operator delete(_P);&#125;&#125;template&lt;class _Ty&gt;inline _Ty _FARQ * _Allocate(_PDFT _N, _Ty _FARQ *)&#123; if (_N &lt; 0) _N = 0; return ((_Ty _FARQ*)operator new((_SIZT)_N * sizeof(_Ty)));&#125;// VC6的allocator只是以::operator new和::operator delete完成allocate()和deallocate(),没有任何特殊设计 5 the others 5.1 const 当成员函数的const和non-const版本同时存在 const对象只能调用const版本 non-const对象只能调用non-const版本 const member functions保证不更改data members non-const member functions不保证data members不变 non-const object可调用const members functions，反之常量对象调用非常量函数不行","categories":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/tags/C/"}]},{"title":"设计模式","slug":"计算机基础知识/设计模式","date":"2022-07-06T11:10:30.000Z","updated":"2023-04-16T12:15:50.189Z","comments":true,"path":"2022/07/06/计算机基础知识/设计模式/","link":"","permalink":"http://jay1060950003.github.io/2022/07/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"引言 C++设计模式学习笔记","text":"引言 C++设计模式学习笔记 1 设计模式简介 如何解决复杂性 分解：分而治之，将大问题分为多个小问题，将复杂问题分解成多个简单问题 抽象：由于不能掌握全部的复杂信息，选择忽略非本质细节，而去处理返回和理想化了的对象模型 使用抽象的方法,代码的复用性得到了提高 抽象使得可以使用通用的方法统一处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246// 分解的实现方法// Shape1.cppclass Point&#123;public: int x; int y;&#125;;class Line&#123; public: Point start; Point end; Line(const Point&amp; start, const Point&amp; end)&#123; this-&gt;start = start; this-&gt;end = end; &#125;&#125;;class Rect&#123;public: Point leftUp; int width; int height; Rect(const Point&amp; leftUp, int width, int height)&#123; this-&gt;leftUp = leftUp; this-&gt;width = width; this-&gt;height = height; &#125;&#125;;//增加class Circle&#123; // ....&#125;; // MainForm1.cppclass MainForm : public Form &#123;private: Point p1; Point p2; vector&lt;Line&gt; lineVector; vector&lt;Rect&gt; rectVector; //改变 vector&lt;Circle&gt; circleVector;public: MainForm()&#123; //... &#125;protected: virtual void OnMouseDown(const MouseEventArgs&amp; e); virtual void OnMouseUp(const MouseEventArgs&amp; e); virtual void OnPaint(const PaintEventArgs&amp; e);&#125;;void MainForm::OnMouseDown(const MouseEventArgs&amp; e)&#123; p1.x = e.X; p1.y = e.Y; //... Form::OnMouseDown(e);&#125;void MainForm::OnMouseUp(const MouseEventArgs&amp; e)&#123; p2.x = e.X; p2.y = e.Y; if (rdoLine.Checked)&#123; Line line(p1, p2); lineVector.push_back(line); &#125; else if (rdoRect.Checked)&#123; int width = abs(p2.x - p1.x); int height = abs(p2.y - p1.y); Rect rect(p1, width, height); rectVector.push_back(rect); &#125; //改变 else if (...)&#123; //... circleVector.push_back(circle); &#125; //... this-&gt;Refresh(); Form::OnMouseUp(e);&#125;void MainForm::OnPaint(const PaintEventArgs&amp; e)&#123; //针对直线 for (int i = 0; i &lt; lineVector.size(); i++)&#123; e.Graphics.DrawLine(Pens.Red, lineVector[i].start.x, lineVector[i].start.y, lineVector[i].end.x, lineVector[i].end.y); &#125; //针对矩形 for (int i = 0; i &lt; rectVector.size(); i++)&#123; e.Graphics.DrawRectangle(Pens.Red, rectVector[i].leftUp, rectVector[i].width, rectVector[i].height); &#125; //改变 //针对圆形 for (int i = 0; i &lt; circleVector.size(); i++)&#123; e.Graphics.DrawCircle(Pens.Red,circleVector[i]); &#125; //... Form::OnPaint(e);&#125;// 抽象的实现方法// Shape2.cppclass Shape&#123; public: virtual void Draw(const Graphics&amp; g)=0; virtual ~shape()&#123;&#125; // 声明虚析构函数，保证多态后的子类可以正确的调用析构函数实现析构&#125;class Point&#123; public: int x; int y;&#125;class Line: public Shape&#123; public: Point start; Point end; Line(const Point&amp; start, const Point&amp; end)&#123; this-&gt;start = start; this-&gt;end = end; &#125; // 实现自己的Draw函数 virtual void Draw(const Graphics&amp; g)&#123; g.DrawLine(Pens.Red,start.x,start.y,end.x,end.y); &#125;&#125;class Rect: public Shape&#123; public: Point leftUp; int width; int height; Rect(const Point&amp; leftUp, int width, int height)&#123; this -&gt; leftUp = leftUp; this -&gt; width = width; this -&gt; height = height; &#125; virtual void Draw(const Graphics&amp; g)&#123; g.DrawLine(Pens.Red, leftUp, width, height); &#125;&#125;// 改变class Circle : public Shape&#123; // ....&#125;// MainForm2.cppclass MainForm : public Form &#123; private: Point p1; Point p2; //针对所有形状 vector&lt;Shape*&gt; shapeVector; // 为了支持多态性,存放父类的指针 public: MainForm()&#123; //... &#125; protected: virtual void OnMouseDown(const MouseEventArgs&amp; e); virtual void OnMouseUp(const MouseEventArgs&amp; e); virtual void OnPaint(const PaintEventArgs&amp; e);&#125;;void MainForm::OnMouseDown(const MouseEventArgs&amp; e)&#123; p1.x = e.X; p1.y = e.Y; //... Form::OnMouseDown(e);&#125;void MainForm::OnMouseUp(const MouseEventArgs&amp; e)&#123; p2.x = e.X; p2.y = e.Y; if (rdoLine.Checked)&#123; // 因为存放的是指针,故需要new一个对象 // 需要放一个堆对象的指针,而不是栈对象 // 对内存管理有要求,在合适的时候需要负责释放Vector中的对象 shapeVector.push_back(new Line(p1,p2)); &#125; else if (rdoRect.Checked)&#123; int width = abs(p2.x - p1.x); int height = abs(p2.y - p1.y); shapeVector.push_back(new Rect(p1, width, height)); &#125; //改变 // 使用工厂设计模式后,变化可以消除 else if (...)&#123; //... shapeVector.push_back(circle); &#125; //... this-&gt;Refresh(); Form::OnMouseUp(e);&#125;void MainForm::OnPaint(const PaintEventArgs&amp; e)&#123; //针对所有形状 for (int i = 0; i &lt; shapeVector.size(); i++)&#123; shapeVector[i]-&gt;Draw(e.Graphics); //多态调用，各负其责 &#125; //... Form::OnPaint(e);&#125; 2 面向对象设计原则 面向对象设计的最大优势:抵御变化 认识面向对象(抽象思维层面) 理解隔离机制:面向对象的构建方式更能适应软件的变化能将变化所带来的影响减为最小 各司其职 微观层面上面向对象方式强调各个类的责任 由于需要变化导致的新增类型不应该影响原来类型的实现(各负其责) 对象是什么 语言实现层面:对象封装了代码和数据 规格层面:可被使用的公共接口 概念层面:是某种拥有责任的对象 面向对象设计原则(8大设计原则) 依赖倒置原则(DIP) 高层模块(稳定)不应该依赖于低层模块（变化），两者都应该基于抽象（稳定） 抽象（稳定）不应该依赖于实现细节（变化），实现细节应该依赖于抽象（稳定） 需要实现隔离变化 开放封闭原则(OCP) 对扩展开放，对更改封闭 类模块应该是可扩展的，但是不可修改 单一职责原则（SRP） 一个类应该仅有一个引起它变化的原因 变化的方向隐含着类的责任 Liskov替换原则（LSP） 子类必须能够替换它们的基类（IS-A） 继承表达类型抽象 接口隔离原则（ISP） 不应该强迫客户程序依赖它们不用的方法 接口应该小而完备 优先使用对象组合，而不是类继承 类继承通常为白箱复用，对象组合通常为黑箱复用 继承在某种程序上破坏了封装性，子类父类耦合度高 对象组合只要求被组合的对象具有良好定义的接口，耦合度低 封装变化点 使用封装来创建对象之间的分界层，让设计者可以在分界层一侧进行修改，而不会对另一侧产生不良影响，从而实现层次间的松耦合 针对接口编程，而不是针对实现编程 不将变量类型声明为某个特定的具体类，而是声明为某个接口 客户程序无需获知对象的具体类型，只需要知道对象所具有的接口 减少系统中各部分的依赖关系，从而实现“高内聚、松耦合”的类型设计方案 GOF-23模板分类 从目的来看 创建型模式：将对象的部分创建工作延迟到子类或其他对象，从而应对需求变化为对象创建时具体类型实现引来的冲击 结构型模式：通过类继承或对象组合获得更灵活的结构，从而应对需求变化为对象的结构带来的冲击 行为型模式：通过类继承或对象组合来划分类与对象间的职责，从而应对需求变化为多个交互的对象带来的冲击 从范围来看 类模式处理类与子类的静态关系（继承方案） 对象模式处理对象间的动态关系（组合方案） 从封装变化角度对模式分类 - - - 组件协作 模板方法 接口隔离 门面模式 - 观察者模式 - 代理模式 - 策略模式 - 适配器 单一职责 装饰模式 - 中介器* - 桥模式 状态变化 状态模式* 对象创建 工厂方法 - 备忘录 - 抽象工厂 数据结构 组合模式 - 原型模式 - 迭代器* - 构建器* - 职责链* 对象性能 单件模式 行为变化 命令模式* - 享元模式 - 访问器* 领域问题 解析器* *为C++中不常用的模式 重构关键技法 静态-&gt;动态 早绑定-&gt;晚绑定 继承-&gt;组合 编译时依赖-&gt;运行时依赖 紧耦合-&gt;松耦合 3 组件协作 组件协作模式 现代软件专业分工后是框架与应用程序的划分 组件协作模式是通过晚期绑定来实现框架与应用程序之间的松耦合，是两者之间协作时常用的模式 其中包括：模板方法，观察者模式(事件模式)，策略模式 3.1 模板方法 动机 在软件构建过程中，对于某一项任务，常常有稳定的整体操作结构，但各个子步骤却有很多改变的需求，或者由于固定的原因而无法和任务的整体结构同时实现 如何在确定稳定操作结构的前提下，来灵活应对各个子步骤的变化或者晚期实现需求 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// 程序库开发人员class Library&#123; public: void Step1()&#123; // .... &#125; void Step3()&#123; // .... &#125; void Step5()&#123; // .... &#125;&#125;// 应用开发人员class Application&#123; public: void Step2()&#123; // .... &#125; void Step4()&#123; // .... &#125;&#125;// 程序的整体流程int main()&#123; Library lib(); Application app(); lib.step1(); if(app.Step2())&#123; lib.Step3(); &#125; for(int i = 0; i&lt;4; i++) app.Step4(); lib.Step5();&#125;// --------------// 改进（使用模板方法）// --------------// 程序库开发人员class Library&#123; public: // 稳定模板方法 void Run()&#123; Step1(); if(Step2())&#123; //支持变化==&gt;虚函数的多态调用 Step3(); &#125; for(int i = 0; i&lt;4;++i) Step4(); //支持变化==&gt;虚函数的多态调用 Step5(); &#125; // Run方法中，稳定有变化，稳定的函数写成非虚函数，变化的函数写成虚函数 virtual ~Library(); //基类的析构函数为虚函数，在delete时可调用到子类的析构函数 protected: void Step1()&#123; // .... &#125; void Step3()&#123; // .... &#125; void Step5()&#123; // .... &#125; virtual bool Step2() =0; //变化 virtual void Step4() =0; //变化&#125;// 应用程序开发人员class Application : public Library&#123; protected: virtual bool Step2()&#123; // ...子类重写实现 &#125; virtual void Step4()&#123; // ...子类重写实现 &#125;&#125;int main()&#123; Library* pLib = new Application(); pLib-&gt;Run(); delete pLib;&#125; 程序库Library一般书写的早，而应用Application实现的晚 Application调用Libaray为晚绑定 晚绑定机制包括函数指针和虚函数机制 Libaray调用Application为早绑定 定义一个操作中的算法的骨架（稳定，Run函数），而将一些步骤延迟（变化）到子类中，模板方法使得子类可以不改变（复用）一个算法的结构即可重定义（override重写）该算法的某些特定步骤 模板方法必须有一个稳定的骨架才可以适用该模式 设计模式的假设条件必须有一个稳定点 设计模式主要在稳定和变化中寻找稳定点，隔离变化和稳定 图中TemplateMethod()为稳定的，而PrimitiveOperation1(),PrimitiveOperation2()为变化的 要点总结 模板方法模式是一种非常基础性的设计模式，面向系统中有大量的应用，用最简洁的机制（虚函数的多态性）为很多应用程序框架提供了灵活的扩展点，是代码复用方面的基本实现结构 除了可以灵活应对子步骤的变化外，内含的反向控制结构式模板方法模式的典型应用 在具体实现方面，被模板方法模式调用的虚方法可以具有实现，也可以没有任何实现，但一般推荐将其设置为protected方法 3.2 策略模式 动机 在软件构建过程中，某些对象使用的算法可能多种多样，经常改变，如果将这些算法都编码到对象中，将会使对象变得异常复杂；而且有时候支持不使用的算法也是一种性能负担 如果在运行时根据需要透明地更改对象的算法？将算法与对象本身解耦，从而避免上述问题？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475enum TaxBase&#123; CN_Tax, US_Tax, DE_Tax&#125;;class SalesOrder&#123; TaxBase tax; public: double CalculateTax()&#123; // ... if(tax == CN_Tax)&#123; // CN******** &#125; else if(tax == US_Tax)&#123; // US******** &#125; else if(tax == DE_Tax)&#123; // DE******** &#125; // ... &#125;&#125;// 以上代码违反开放封闭原则// -----------// 使用策略模式// -----------class TaxStrategy&#123; public: virtual double Calculate(const Contex&amp; contex) =0; virtual ~TaxStrategy()&#123;&#125;&#125;;class CNTax : public TaxStrategy&#123; public: virtual double Calculate(const Contex&amp; contex)&#123; // ************ &#125;&#125;;class USTax : public TaxStrategy&#123; public: virtual double Calculate(const Contex&amp; contex)&#123; // ************ &#125;&#125;;class DETax : public TaxStrategy&#123; public: virtual double Calculate(const Contex&amp; contex)&#123; // ************ &#125;&#125;;class SalesOrder&#123; private: TaxStrategy* strategy; public: SalesOrder(StrategyFactory* strategyFactory)&#123; this-&gt;strategy = strategyFactory -&gt; NewStrategy(); //使用工厂模式 &#125; ~SalesOrder()&#123; delete this-&gt;strategy; &#125; public double CalculateTax()&#123; // ... Contex contex(); double val = strategy-&gt;Calculate(contex); //多态调用 &#125;&#125; 模式定义:定义一系列算法，将他们一个个封装起来，并且使它们可互相替换（变化）。该模式使得算法可独立于它的客户程序（稳定，SalesOrder）而变化（扩展，子类化） Context(SalesOrder)与Strategy(TaxStrategy)为稳定的，而ConcreteStrategyA，ConcreteStrategyB，ConcreteStrategyC为变化的部分（子类） 要点总结 策略模式及其子类为组件提供了一系列可重用的算法，从而可以使得类型在运行时方便地根据需要在各个算法之间进行切换 策略模式提供了用条件判断语句以外得另一种选择，消除条件判断语句就是在解耦合。含有许多条件判断语句的代码通常都需要策略模式 在判断条件绝对不变时，可不使用策略模式 如果策略对象没有实例变量，那么各个上下文可以共享同一个策略对象（单例模式），从而节省对象开销 3.3 观察者模式 动机 在软件构建过程中，需要为某些对象建立一种“通知依赖关系”——一个对象（目标对象）的状态发生变化，所有的依赖对象（观察者对象）都将得到通知。如果这样的依赖关系过于紧密，将使软件不能很好地抵御变化 使用面向对象技术，可以将依赖关系弱化，并形成一种稳定的依赖关系。从而实现软件体系结构的松耦合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177// MainForm.cppclass MainForm : public Form&#123; TextBox* txtFilePath; TextBox* txtFileNumber; // 增加processbar的需求 ProgressBar* progressBar; public: void Button1_Click()&#123; string filePath = txtFilePath -&gt; getPath(); int number = atoi(txtFileNumber-&gt;getText().c_str()); FileSplitter splitter(filePath, number, processBar); splitter.split(); &#125;&#125;;// 更改，使用多继承// 不推荐使用多继承，但推荐一个是主继承类，而其他的继承类为接口class MainForm : public Form, public IProgress&#123; TextBox* txtFilePath; TextBox* txtFileNumber; // 增加processbar的需求 ProgressBar* progressBar; public: void Button1_Click()&#123; string filePath = txtFilePath -&gt; getPath(); int number = atoi(txtFileNumber-&gt;getText().c_str()); FileSplitter splitter(filePath, number, this); // 当前this实现了IProgress接口 splitter.split(); &#125; virtual void DoProgress(float value)&#123; processBar -&gt; setValue(value); &#125;&#125;;// 更改，支持多个通知class MainForm : public Form, public IProgress&#123; TextBox* txtFilePath; TextBox* txtFileNumber; // 增加processbar的需求 ProgressBar* progressBar; public: void Button1_Click()&#123; string filePath = txtFilePath -&gt; getPath(); int number = atoi(txtFileNumber-&gt;getText().c_str()); ConsoleNotifier cn; FileSplitter splitter(filePath, number); splitter.add_IProgress(this); splitter.add_IProgress(&amp;cn); splitter.split(); splitter.remove_IProgress(this); &#125; virtual void DoProgress(float value)&#123; processBar -&gt; setValue(value); &#125;&#125;;// 添加，支持多个通知class ConsoleNotifier : public IProgress&#123; public: virtual void DoProgress(float value)&#123; cout &lt;&lt; &quot;.&quot;; &#125;&#125;;// FileSplitter.cpp// 更改：增加class IProgress&#123; public: virtual void DoProgress(float value) = 0; virtual ~IProgress()&#123;&#125;&#125;;class FileSplitter&#123; string m_filePath; int m_fileNumber; // 违反DIP依赖倒置原则 // ProcessBar编译时依赖其他文件(ProcessBar为实现细节) // ProcessBar实现细节易发生变化 ProgressBar* m_progressBar; // 扮演通知角色(通知控件) // 更改：使用更加抽象的方式表达而不是用控件表达 IProgress* m_iprogress; // 抽象通知机制 // 更改：支持多个观察者 List&lt;IProgress*&gt; m_iprogressList; //支持多个观察者 // 根据删除和添加的性能选择数据结构 public: FileSplitter(const string&amp; filePath, int fileNumber, ProgressBar* progressBar) : m_filePath(filePath), m_fileNumber(fileNumber) m_progressBar(progressBar)&#123; &#125; // 更改 FileSplitter(const string&amp; filePath, int fileNumber, IProgress* iprogress) : m_filePath(filePath), m_fileNumber(fileNumber) m_iprogress(iprogress)&#123; &#125; // 更改，支持多个观察者 FileSplitter(const string&amp; filePath, int fileNumber) : m_filePath(filePath), m_fileNumber(fileNumber)&#123; &#125; void add_IProgress(IProgress* iprogress)&#123; m_iprogressList.push_back(iprogress); &#125; void remove_IProgress(IProgress* iprogress)&#123; m_iprogressList.remove(iprogress); &#125; void split()&#123; // 1.读取大文件 // 2.分批次向小文件中写入 for(int i = 0; i&lt; m_fileNumber; i++)&#123; // ... if(m_progressBar != nullptr)&#123; m_progressBar -&gt; setValue((i+1)/m_fileNumber); // 更新进度条 &#125; &#125; &#125; // 更改 void split()&#123; // 1.读取大文件 // 2.分批次向小文件中写入 for(int i = 0; i&lt; m_fileNumber; i++)&#123; // ... if(m_iprogress != nullptr)&#123; float progressValue = m_fileNumber; progressValue = (i+1)/progressValue; onProgress(progressValue); &#125; &#125; &#125; // 优化 protected: virtual void onProgress(float value)&#123; //声明为虚函数以供子类重写 m_iprogress -&gt; DoProgress(progressValue); // 更新进度条 &#125; // 更改，支持多个观察者 virtual void onProgress(float value)&#123; //声明为虚函数以供子类重写 List&lt;IProgress*&gt;::Iterator start = m_iprogressList.begin(); while(itor != m_iprogressList.end())&#123; (*itor)-&gt;DoProgress(value); itor++; &#125; &#125;&#125;;// 该设计中若需要支持多个通知(需要支持多个观察者) 模式定义：定义对象间的==一种一对多【【（变化）的依赖关系，以便当一个对象（Subject）的状态发生改变时，所有依赖于它的对象都得到通知并自动更新 subject和observer为稳定不变的，而ConcreteSubject，COncreteObserver为变化的为具体的实现部分 要点总结 使用面向对象的抽象，观察者模式使得可以独立地改变目标与观察者，从而使两者之间的依赖关系达到松耦合 目标发送通知时，无需指定观察者，通知会自动传播 观察者自己决定是否订阅通知，目标对象对此一无所知 观察者模式使基于事件的UI框架中非常常用的设计模式，也是MVC模式的一个重要组成部分 4 单一职责 单一职责模式 在软件组件的设计中，如果责任划分的不清晰，使用继承得到的结果往往是随着需求的变化，子类急剧膨胀，同时充斥着重复代码，这时候的关键是划清责任 典型模式 装饰模式 桥模式 4.1 装饰模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247// 业务操作class Stream&#123; public: virtual char Read(int number) = 0; virtual void Seek(int position) = 0; virtual void Write(char data) = 0; virtual ~Stream()&#123;&#125;&#125;;// 主体类class FileStream : public Stream&#123; public: virtual char Read(int number)&#123; // 读文件流 &#125; virtual void Seek(int position)&#123; // 定位文件流 &#125; virtual void Write(char data)&#123; // 写文件流 &#125;&#125;;class NetworkStream : public Stream&#123; public: virtual char Read(int number)&#123; // 读网络流 &#125; virtual void Seek(int position)&#123; // 定位网络流 &#125; virtual void Write(char data)&#123; // 写网络流 &#125;&#125;;class MemoryStream : public Stream&#123; public: virtual char Read(int number)&#123; // 读内存流 &#125; virtual void Seek(int position)&#123; // 定位内存流 &#125; virtual void Write(char data)&#123; // 写内存流 &#125;&#125;;// 扩展操作class CryptoFileStream : public FileStream&#123; public: virtual char Read(int number)&#123; // 额外的加密操作 FileStream::Read(number); //读文件流 // 额外的加密操作 &#125; virtual void Seek(int position)&#123; // 额外的加密操作 FileStream::Seek(position); //定位文件流 // 额外的加密操作 &#125; virtual void Write(byte data)&#123; // 额外的加密操作 FileStream::Write(data); //写文件流 // 额外的加密操作 &#125;&#125;;class CryptoNetworkStream : public NetworkStream&#123; public: virtual char Read(int number)&#123; // 额外的加密操作 NetworkStream::Read(number); //读网络流 // 额外的加密操作 &#125; virtual void Seek(int position)&#123; // 额外的加密操作 NetworkStream::Seek(position); //定位网络流 // 额外的加密操作 &#125; virtual void Write(byte data)&#123; // 额外的加密操作 NetworkStream::Write(data); //写网络流 // 额外的加密操作 &#125;&#125;;class CryptoMemoryStream : public MemoryStream&#123; public: virtual char Read(int number)&#123; // 额外的加密操作 MemoryStream::Read(number); //读内存流 // 额外的加密操作 &#125; virtual void Seek(int position)&#123; // 额外的加密操作 MemoryStream::Seek(position); //定位内存流 // 额外的加密操作 &#125; virtual void Write(byte data)&#123; // 额外的加密操作 MemoryStream::Write(data); //写内存流 // 额外的加密操作 &#125;&#125;;class BufferFileStream : public FileStream&#123; // ...&#125;;class BufferNetworkStream : public FileStream&#123; // ...&#125;;class BufferMemoryStream : public FileStream&#123; // ...&#125;;class CryptoBufferFileStream : public FileStream&#123; public: virtual char Read(int number)&#123; // 额外的加密操作 // 额外的缓冲操作 FileStream::Read(number); //读文件流 // 额外的加密操作 &#125; virtual void Seek(int position)&#123; // 额外的加密操作 // 额外的缓冲操作 FileStream::Seek(position); //定位文件流 // 额外的加密操作 &#125; virtual void Write(byte data)&#123; // 额外的加密操作 // 额外的缓冲操作 FileStream::Write(data); //写文件流 // 额外的加密操作 &#125;&#125;;void Process()&#123; // 编译时装配 CryptoFileStream *fs1 = new CryptoFileStream(); BufferFileStream *fs2 = new BufferFileStream(); CryptoBufferFileStream *fs3 = new CryptoBufferFileStream();&#125;;// 上述代码，通过继承，使得子类的规模越来越大// ------------------// 使用装饰模式进行重构// ------------------// 业务操作class Stream&#123; public: virtual char Read(int number) = 0; virtual void Seek(int position) = 0; virtual void Write(char data) = 0; virtual ~Stream()&#123;&#125;&#125;;// 主体类class FileStream : public Stream&#123; public: virtual char Read(int number)&#123; // 读文件流 &#125; virtual void Seek(int position)&#123; // 定位文件流 &#125; virtual void Write(char data)&#123; // 写文件流 &#125;&#125;;class NetworkStream : public Stream&#123; public: virtual char Read(int number)&#123; // 读网络流 &#125; virtual void Seek(int position)&#123; // 定位网络流 &#125; virtual void Write(char data)&#123; // 写网络流 &#125;&#125;;class MemoryStream : public Stream&#123; public: virtual char Read(int number)&#123; // 读内存流 &#125; virtual void Seek(int position)&#123; // 定位内存流 &#125; virtual void Write(char data)&#123; // 写内存流 &#125;&#125;;// 扩展操作// 需要中间类，当两个类之间具有相同的字段，需要将相同的字段提升到基类中DecoratorStream : public Stream&#123; protected: Stream* stream; DecoratorStream(Stream* stream) : stream(stream)&#123;&#125; &#125;// 使用多态，在编译时重用，而在运行时不同class CryptoStream : public DecoratorStream&#123; //加上基类Stream，为了完善接口规范 Stream* stream; //=new FileStream();=new NetworkStream();=new MemoryStream(); public: // 需要构造器 CryptoStream(Stream* stream): DecoratorStream(stream)&#123;&#125; virtual char Read(int number)&#123; // 额外的加密操作 stream -&gt; Read(number); //读文件流 // 额外的加密操作 &#125; virtual void Seek(int position)&#123; // 额外的加密操作 stream::Seek(position); //定位文件流 // 额外的加密操作 &#125; virtual void Write(byte data)&#123; // 额外的加密操作 stream::Write(data); //写文件流 // 额外的加密操作 &#125;&#125;;class BufferStream : public DecoratorStream&#123; Stream* stream; public: BufferStream(Stream* stream): DecoratorStream(stream)&#123;&#125; // ...&#125;;void Process()&#123; FileStream* s1 = new FileStream(); CryptoStream* s2 = new CryptoStream(s1); BufferStream* s3 = new BufferStream(s1); BufferStream* s3 = new BufferStream(s2);&#125;; 经装饰模式转换之后 动机 在某些情况下可能会过度地使用继承来扩展对象地功能，由于继承为类引入过多的静态特质，使得这种扩展方式缺乏灵活性；并且随着子类的增多（扩展功能的增多），各种子类的组合（扩展功能的组合）会导师更多的子类的膨胀 使用装饰模式可以使对象功能的扩展能够根据需要来动态地实现，同时避免了扩展功能的增多带来的子类膨胀问题，从而使得任何功能扩展变化所导致的影响为最低 定义：动态（组合）地给一个对象增加一些额外地职责。就增加功能而言，装饰模式比生成子类（继承）更为灵活（消除重复代码&amp;减少子类个数） Component,Decorator为稳定的,ConcreteComponent、ConcreteDecoratorA和ConcreteDecoratorB为变化的 要点总结 通过采用组合而非继承的手法，装饰模式是实现了在运行时动态扩展对象功能的能力，而且可以根据需要扩展多个功能。避免了使用继承带来的灵活性差的和多个子类衍生的问题 装饰类在接口上表现为is-a COmponent的继承关系；即装饰类继承了Component类所具有的接口，但在实现上又表现为has-a Component的组合关系，即装饰类又使用了另外一个Component类 在设计中，若一个类继承了父类，并且在类中有一个父类的成员变量则怀疑该类为装饰类，使用的是装饰模式 装饰模式的目的并非解决多子类衍生问题，其要点在于解决主体类在多个方向上的扩展功能（装饰） 4.2 桥模式 动机 由于某些类型的固有的实现逻辑，使得它们具有两个变化的维度乃至多个纬度的变化 解决多维度变化，利用面向对象技术使类型可以轻松沿着两个乃至多个方向变化，而不引入额外的复杂度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322class Messager&#123; public: virtual void Login(string username, string password)=0; virtual void SendMessage(string message)=0; virtual void SendPicture(Image image)=0; // 以下代码频繁实现 virtual void PlaySound()=0; virtual void DrawShape()=0; virtual void WriteText()=0; virtual void Connect()=0; virtual ~Messager()&#123;&#125;&#125;;// 平台实现class PCMessagerBase : public Messager&#123; public: virtual void PlaySound()&#123; // ************ &#125; virtual void DrawShape()&#123; // ************ &#125; virtual void WriteText()&#123; // ************ &#125; virtual void Connect()&#123; // ************ &#125;&#125;;class MobileMessagerBase : public Messager&#123; public: virtual void PlaySound()&#123; // ============ &#125; virtual void DrawShape()&#123; // ============ &#125; virtual void WriteText()&#123; // ============ &#125; virtual void Connect()&#123; // ============ &#125;&#125;// 业务对象class PCMessagerLite : public PCMessagerBase&#123; public: virtual void Login(string username, string password)&#123; PCMessagerBase::Connect(); // ...... &#125; virtual void SendMessage(string message)&#123; PCMessagerBase::WriteText(); // ...... &#125; virtual void SendPicture(Image image)&#123; PCMessagerBase::DrawShape(); // ...... &#125;&#125;;class PCMessagerPerfect : public PCMessagerBase&#123; public: virtual void Login(string username, string password)&#123; PCMessagerBase::PlaySound(); // ******* PCMessagerBase::Connect(); &#125; virtual void SendMessage(string message)&#123; PCMessagerBase::PlaySound(); // ******* PCMessagerBase::WriteText(); &#125; virtual void SendPicture(Image image)&#123; PCMessagerBase::PlaySound(); // ******* PCMessagerBase::DrawShape(); &#125;&#125;;class MobileMessagerLite : public MobileMessagerBase&#123; public: virtual void Login(string username, string password)&#123; MobileMessagerBase::Connect(); // ...... &#125; virtual void SendMessage(string message)&#123; MobileMessagerBase::WriteText(); // ...... &#125; virtual void SendPicture(Image image)&#123; MobileMessagerBase::DrawShape(); // ...... &#125;&#125;;class MobileMessagerPerfect : public MobileMessagerBase&#123; public: virtual void Login(string username, string password)&#123; MobileMessagerBase::PlaySound(); // ******* MobileMessagerBase::Connect(); &#125; virtual void SendMessage(string message)&#123; MobileMessagerBase::PlaySound(); // ******* MobileMessagerBase::WriteText(); &#125; virtual void SendPicture(Image image)&#123; MobileMessagerBase::PlaySound(); // ******* MobileMessagerBase::DrawShape(); &#125;&#125;;void Process()&#123; // 编译时装配 Messager *m = new MobileMessagerPerfect();&#125;// -----------// 使用装饰模式// -----------class Messager&#123; public: virtual void Login(string username, string password)=0; virtual void SendMessage(string message)=0; virtual void SendPicture(Image image)=0; // 以下代码频繁实现 virtual void PlaySound()=0; virtual void DrawShape()=0; virtual void WriteText()=0; virtual void Connect()=0; virtual ~Messager()&#123;&#125;&#125;;// 平台实现class PCMessagerBase : public Messager&#123; public: virtual void PlaySound()&#123; // ************ &#125; virtual void DrawShape()&#123; // ************ &#125; virtual void WriteText()&#123; // ************ &#125; virtual void Connect()&#123; // ************ &#125;&#125;;class MobileMessagerBase : public Messager&#123; public: virtual void PlaySound()&#123; // ============ &#125; virtual void DrawShape()&#123; // ============ &#125; virtual void WriteText()&#123; // ============ &#125; virtual void Connect()&#123; // ============ &#125;&#125;// 业务对象class MessagerLite&#123; Messager* messager; // new PCMessagerBase()不成立 // 出现问题，PCMessagerBase为抽象类，纯虚基类 public: virtual void Login(string username, string password)&#123; message-&gt;Connect(); // ...... &#125; virtual void SendMessage(string message)&#123; messager-&gt;WriteText(); // ...... &#125; virtual void SendPicture(Image image)&#123; messager-&gt;DrawShape(); // ...... &#125;&#125;;class MessagerPerfect&#123; Messager* messager; public: virtual void Login(string username, string password)&#123; messager -&gt; PlaySound(); // ******* messager -&gt; Connect(); &#125; virtual void SendMessage(string message)&#123; messager -&gt; PlaySound(); // ******* messager -&gt; WriteText(); &#125; virtual void SendPicture(Image image)&#123; messager -&gt; PlaySound(); // ******* messager -&gt; DrawShape(); &#125;&#125;;void Process()&#123; // 编译时装配 Messager *m = new MobileMessagerPerfect();&#125;// ------------------------------------------------------------// 由上述纯虚基类的问题，发现将两部分塞到一个类中不合理，将两部分拆分// 且上述函数两部分为两个方向的实现，一个为平台实现，另一个为业务实现// ------------------------------------------------------------// 修改class Messager&#123; protected: MessagerImp* messagerImp; //重构 Messager(MessagerImp* messagerImp) : messagerImp(messagerImp)&#123;&#125;; // 构造器 public: virtual void Login(string username, string password)=0; virtual void SendMessage(string message)=0; virtual void SendPicture(Image image)=0; virtual ~Messager()&#123;&#125;&#125;;class MessagerImp&#123; public: // 以下代码频繁实现 virtual void PlaySound()=0; virtual void DrawShape()=0; virtual void WriteText()=0; virtual void Connect()=0; virtual ~Messager()&#123;&#125;&#125;;// 平台实现class PCMessagerImp : public MessagerImp&#123; public: virtual void PlaySound()&#123; // ************ &#125; virtual void DrawShape()&#123; // ************ &#125; virtual void WriteText()&#123; // ************ &#125; virtual void Connect()&#123; // ************ &#125;&#125;;class MobileMessagerImp : public MessagerImp&#123; public: virtual void PlaySound()&#123; // ============ &#125; virtual void DrawShape()&#123; // ============ &#125; virtual void WriteText()&#123; // ============ &#125; virtual void Connect()&#123; // ============ &#125;&#125;// 业务对象class MessagerLite : public Messager&#123; MessagerImp* messagerImp; public: MessagerLite(MessagerImp* messagerImp) : messagerImp(messagerImp)&#123;&#125;; virtual void Login(string username, string password)&#123; messagerImp-&gt;Connect(); // ...... &#125; virtual void SendMessage(string message)&#123; messagerImp-&gt;WriteText(); // ...... &#125; virtual void SendPicture(Image image)&#123; messagerImp-&gt;DrawShape(); // ...... &#125;&#125;;class MessagerPerfect : public Messager&#123; MessagerImp* messagerImp; public: MessagerPerfect(MessagerImp* messagerImp) : messagerImp(messagerImp)&#123;&#125;; virtual void Login(string username, string password)&#123; messagerImp -&gt; PlaySound(); // ******* messagerImp -&gt; Connect(); &#125; virtual void SendMessage(string message)&#123; messagerImp -&gt; PlaySound(); // ******* messagerImp -&gt; WriteText(); &#125; virtual void SendPicture(Image image)&#123; messagerImp -&gt; PlaySound(); // ******* messagerImp -&gt; DrawShape(); &#125;&#125;;void Process()&#123; // 编译时装配 MessagerImp* messagerImp = new PCMessagerImp(); Messager* m = new Messager(messagerImp);&#125; 定义 将抽象部分（业务功能）与实现部分（平台实现）分离，使它们可以独立地变化 Abstraction与Implementor为稳定的，其中Abstraction中含有Imp指针指向Implementor，RefinedAbstraction、ConcreteImplementorA与ConcreteImplementorB为变化的 要点总结 桥模式使用对象间的组合关系解耦了抽象和实现之间固有的绑定关系，使得抽象和实现可以沿着各自的维度变化。所谓抽象和实现沿着各自维度的变化，即子类化它们 桥模式有时候类似于多继承方案，但是多继承方案往往违背单一职责原则（即一个类只有一个变化的原因），复用性比较差。桥模式是比多继承方案更好的解决方法 桥模式的应用一般在两个非常强的变化维度，有时一个类也有多于两个的变化维度也可以使用桥模式的扩展模式 5 对象创建 对象创建模式 通过对象创建模式绕开（new），来避免对象创建（new）过程中所导致的紧耦合（依赖具体类），从而支持对象创建的稳定。它是接口抽象之后的第一步工作 其中包括：工厂模式，抽象工厂，原型模式和构建器 5.1 工厂模式 动机 在软件系统中，经常面临着创建对象的工作；由于需求的变化，需要创建的对象的具体类型经常变化 应对变化：需要绕过常规的对象创建方法（new），提供一种“封装机制”来避免客户程序和这种“具体对象创建工作”的紧耦合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160// MainForm1.cppclass MainForm ： public Form&#123; TextBox* txtFilePath; TextBox* txtFileNumber; ProgressBar* processBar; public: void Button1_Click()&#123; string filePath = txtFilePath -&gt; getText(); int number = atoi(txtFileNumber -&gt; getText().c_str()); ISplitter* splitter = new BinarySplitter(filePath,number); // 依赖具体类 // 需要进行面向接口的设计(依赖倒置原则，依赖抽象而不是依赖细节) // 不能用new或在栈上创建对象，但可以使用返回一个对象的方法 splitter -&gt; split(); &#125;&#125;;// ISplitterFactory.cppclass SplitterFactory&#123; public: ISplitter* CreateSplitter()&#123; return new BinarySplitter(); &#125;&#125;class ISplitter&#123; public: virtual void split()=0; virtual ~ISplitter()&#123;&#125;&#125;// FileSplitter1.cppclass BinarySplitter : public ISplitter&#123; // ....&#125;;class TxtSplitter : public ISplitter&#123; // ....&#125;class PictureSplitter : public ISplitter&#123; // ....&#125;class VideoSplitter : public ISplitter&#123; // ....&#125;// ------------// 更改// ------------// MainForm2.cppclass MainForm ： public Form&#123; TextBox* txtFilePath; TextBox* txtFileNumber; ProgressBar* processBar; public: void Button1_Click()&#123; string filePath = txtFilePath -&gt; getText(); int number = atoi(txtFileNumber -&gt; getText().c_str()); SplitterFactory factory; ISplitter* splitter = factory.CreateSplitter(); splitter -&gt; split(); &#125;&#125;;// ISplitterFactory.cppclass SplitterFactory&#123; public: ISplitter* CreateSplitter()&#123; return new BinarySplitter(); // SplitterFactory依赖BinarySplitter // MainForm依赖SplitterFactory // 仍然产生编译时依赖 // 启发：使用虚函数（延迟到运行）产生运行时依赖 &#125;&#125;// ----------------// 使用虚函数进行修改// ----------------// ISplitterFactory.cpp// 抽象类class ISplitter&#123; public: virtual void split()=0; virtual ~ISplitter()&#123;&#125;&#125;// 工厂基类class SplitterFactory&#123; public: virtual ISplitter* CreateSplitter() =0; virtual ~SplitterFactory()&#123;&#125;&#125;// MainForm2.cpp(只依赖抽象类和工厂基类)class MainForm ： public Form&#123; TextBox* txtFilePath; TextBox* txtFileNumber; ProgressBar* processBar; SplitterFactory* factory; // 工厂 public: // 使用构造器决定创建哪个 MainForm(SplitterFactory* factory)&#123; this -&gt; factory = factory; &#125; void Button1_Click()&#123; string filePath = txtFilePath -&gt; getText(); int number = atoi(txtFileNumber -&gt; getText().c_str()); ISplitter* splitter = factory-&gt;CreateSplitter(); // 通过虚函数实现多态new splitter -&gt; split(); &#125;&#125;;// FileSplitter2.cpp// 具体类class BinarySplitter : public ISplitter&#123; // ....&#125;;class TxtSplitter : public ISplitter&#123; // ....&#125;class PictureSplitter : public ISplitter&#123; // ....&#125;class VideoSplitter : public ISplitter&#123; // ....&#125;// 具体工厂BinarySplitterFactory : public SplitterFactory&#123; public: virtual ISplitter* CreateSplitter()&#123; return new BinarySplitter(); &#125;&#125;TxtSplitterFactory : public SplitterFactory&#123; public: virtual ISplitter* CreateSplitter()&#123; return new TxtSplitter(); &#125;&#125;PictureSplitterFactory : public SplitterFactory&#123; public: virtual ISplitter* CreateSplitter()&#123; return new PictureSplitter(); &#125;&#125;VideoSplitterFactory : public SplitterFactory&#123; public: virtual ISplitter* CreateSplitter()&#123; return new VideoSplitter(); &#125;&#125; 模式定义 定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂模式使得一个类的实例化延迟（目的：解耦，手段：虚函数）到子类 Product和Creator是稳定的，而ConcreteProduct和ConcreteCreator为变化的 要点总结 工厂模式用于隔离类对象的使用者和具体类型之间的耦合关系。面对一个经常变化的具体类型，紧耦合（new）会导致软件的脆弱 工厂模式通过面向对象的手法（多态），将所要创建的具体对象工作延迟到子类，从而实现一种==扩展（而非更改）==的策略，较好地解决了紧耦合关系 工厂模式解决了“单个对象”的需求变化。缺点在于要求创建方法/参数相同 5.2 抽象工厂 动机：在软件系统中，经常面临着一系列相互依赖的对象的创建工作；同时由于需求的变化，往往存在更多系列对象的创建工作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193// EmployeeDAO.cppclass EmployeeDAO&#123; public: vector&lt;EmployeeDAO&gt; GetEmployees()&#123; SqlConnection* connection = new SqlConnection(); connection -&gt; ConnectionString = &quot;...&quot;; SqlCommand* command = new SqlCommand(); command -&gt; CommandText = &quot;...&quot;; SqlDataReader* reader = command -&gt; ExecuteReader(); while(reader-&gt;Read())&#123;&#125; &#125;&#125;;// ----------------------------// 实现多数据库的支持，面向接口设计// ----------------------------// 数据库有关的基类class IDBConnection&#123; // 虚基类&#125;;class IDBConnectionFactory &#123; public: virtual IDBConnectionFactory* CreateDBConnection()=0; virtual ~IDBConnectionFactory()&#123;&#125;&#125;;class IDBCommand&#123;&#125;;class IDBCommandFactory &#123; public: virtual IDBCommandFactory* CreateDBCommand()=0; virtual ~IDBCommandFactory()&#123;&#125;&#125;;class IDataReader&#123;&#125;;class IDataReaderFactory &#123; public: virtual IDataReaderFactory* CreateDBReader()=0; virtual ~IDataReaderFactory()&#123;&#125;&#125;;// 支持Sql Serverclass SqlConnection : public IDBConnection&#123;&#125;;class SqlConnectionFactory &#123; public: virtual SqlConnectionFactory* CreateDBConnection()=0; virtual ~SqlConnectionFactory()&#123;&#125;&#125;;class SqlCommand : public IDBCommand&#123;&#125;;class SqlCommandFactory &#123; public: virtual SqlCommandFactory* CreateDBCommand()=0; virtual ~SqlCommandFactory()&#123;&#125;&#125;;class SqlDataReader : public IDataReader&#123;&#125;class SqlDataReaderFactory &#123; public: virtual SqlDataReaderFactory* CreateDBReader()=0; virtual ~SqlDataReaderFactory()&#123;&#125;&#125;;// 支持Oracleclass OracleConnection : public IDBConnection&#123;&#125;;class OracleConnectionFactory &#123; public: virtual OracleConnectionFactory* CreateDBConnection()=0; virtual ~OracleConnectionFactory()&#123;&#125;&#125;;class OracleCommand : public IDBCommand&#123;&#125;;class OracleCommandFactory &#123; public: virtual OracleCommandFactory* CreateDBCommand()=0; virtual ~OracleCommandFactory()&#123;&#125;&#125;;class OracleDataReader : public IDataReader&#123;&#125;class OracleDataReaderFactory &#123; public: virtual OracleDataReaderFactory* CreateDBReader()=0; virtual ~OracleDataReaderFactory()&#123;&#125;&#125;;class EmployeeDAO&#123; IDBConnectionFactory* dbConnectionFactory; IDBCommandFactory* dbCommandFactory; IDBReaderFactory* dbReaderFactory; // 以上三个对象必须是同系列的，由以下三个具有关联性 public: vector&lt;EmployeeDAO&gt; GetEmployees()&#123; IDBConnection* connection = dbConnectionFactory-&gt;CreateDBConnection(); connection -&gt; ConnectionString = &quot;...&quot;; IDBCommand* command = dbCommandFactory -&gt; CreateDBCommand(); command -&gt; CommandText = &quot;...&quot;; command -&gt; SetConnection(connection); // 关联性 IDBDataReader* reader = command -&gt; ExecuteReader(); // 关联性 while(reader-&gt;Read())&#123;&#125; &#125;&#125;;// ------------------// 使用抽象工厂进行改善// ------------------// 三个工厂类具有相关性，可以将三个工厂放在一个类中，改善该问题class IDBConnection&#123; // 虚基类&#125;;class IDBCommand&#123;&#125;;class IDataReader&#123;&#125;;class IDBFactory &#123; public: virtual IDBConnection* CreateDBConnection()=0; virtual IDBCommand* CreateDBCommand()=0; virtual IDataReader* CreateDBReader()=0; virtual ~IDBFactory()&#123;&#125;&#125;;// 支持Sql Serverclass SqlConnection : public IDBConnection&#123;&#125;;class SqlCommand : public IDBCommand&#123;&#125;;class SqlDataReader : public IDataReader&#123;&#125;class SqlDBFactory : public IDBFactory&#123; public: virtual IDBConnection* CreateDBConnection()=0; virtual IDBCommand* CreateDBCommand()=0; virtual IDataReader* CreateDBReader()=0; virtual ~SqlDBFactory()&#123;&#125;&#125;;// 支持Oracleclass OracleConnection : public IDBConnection&#123;&#125;;class OracleCommand : public IDBCommand&#123;&#125;;class OracleDataReader : public IDataReader&#123;&#125;class OracleDBFactory : public IDBFactory&#123; public: virtual IDBConnection* CreateDBConnection()=0; virtual IDBCommand* CreateDBCommand()=0; virtual IDataReader* CreateDBReader()=0; virtual ~OracleDBFactory()&#123;&#125;&#125;;class EmployeeDAO&#123; IDBFactory* dbFactory; public: vector&lt;EmployeeDAO&gt; GetEmployees()&#123; IDBConnection* connection = dbFactory -&gt; CreateDBConnection(); connection -&gt; ConnectionString = &quot;...&quot;; IDBCommand* command = dbFactory -&gt; CreateDBCommand(); command -&gt; CommandText = &quot;...&quot;; command -&gt; SetConnection(connection); // 关联性 IDBDataReader* reader = command -&gt; ExecuteReader(); // 关联性 while(reader-&gt;Read())&#123;&#125; &#125;&#125;; 模式定义 提供一个接口，让该接口负责创建一系列“相关或相互依赖的对象”，无需指定它们具体的类 要点总结 如果没有应对多系列对象构建的需求变化，则没有必要使用抽象工厂模式，这时候使用简单的工厂完全可以 系列对象指的是某一特定条件下对象之间有相互依赖、或作用的关系。不同系列的对象之间不能相互依赖 抽象工厂模式主要在于应对新系列的需求变化。其缺点在于难以应对新对象的需求变化 5.3 原型模式 动机：在软件系统中，经常面临着某些结构复杂的对象的创建工作；由于需求的变化，这些对象经常面临着剧烈的变化，但是它们却拥有比较稳定一致的接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// ISplitterFactory.cpp// 抽象类// 将之前的两个类合并class ISplitter&#123; public: virtual ISplitter* clone() =0; //通过克隆自己创建 virtual void split()=0; virtual ~ISplitter()&#123;&#125;&#125;// MainForm.cppclass MainForm ： public Form&#123; ISplitter* prototype; //原型对象 public: MainForm(ISplitter* prototype)&#123; this -&gt; prototype = prototype; &#125; void Button1_Click()&#123; ISplitter* splitter = prototype-&gt;clone(); //克隆原型 splitter -&gt; split(); &#125;&#125;;// FileSplitter.cpp// 具体类class BinarySplitter : public ISplitter&#123; // .... public: virtual ISplitter* clone()&#123; return new BinarySplitter(*this); // 拷贝构造函数 &#125;&#125;;class TxtSplitter : public ISplitter&#123; // .... public: virtual ISplitter* CreateSplitter()&#123; return new TxtSplitter(*this); &#125;&#125;class PictureSplitter : public ISplitter&#123; // .... public: virtual ISplitter* CreateSplitter()&#123; return new PictureSplitter(*this); &#125;&#125;class VideoSplitter : public ISplitter&#123; public: virtual ISplitter* CreateSplitter()&#123; return new VideoSplitter(*this); &#125;&#125; 模式定义：使用原型实例指定创建对象的种类，然后通过==拷贝（深克隆）==这些原型来创建新的对象 若创建对象使用工厂方法较为简单，则使用工厂方法，若创建时需要保留对象的某些特性，则使用原型模式利用拷贝创建对象 要点总结（不常用） 原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，同时要求这些易变类拥有稳定的接口 原型模式对于如何创建易变类的实体对象采用原型克隆的方法来做，使得可以非常灵活地动态创建拥有某些稳定接口的新对象——所需工作仅仅使注册一个新类的对象(即原型)，然后在任何需要的地方Clone（C++中利用拷贝构造函数） 原型模式中的Clone方法可以利用某些框架中的序列化来实现深拷贝 5.4 构建器 动机 在软件系统中，有时候面临着一个复杂对象的创建工作，其通常由各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定（注意与模板方法对比） 提供一种封闭机制来隔离出复杂对象的各个部分的变化，从而保持系统中的稳定构建算法不随着需求改变而改变 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134class House&#123; public: // C++中构造函数调用虚函数，为静态绑定，不是动态绑定，不会调用子类的虚函数版本 // 子类的构造函数先调用父类的构造函数 // 若父类的构造函数可以调用子类的虚函数，则子类构造函数还没有调用（子类没有生成）就开始调用其函数，违背对象的生成规则 void Init()&#123; this -&gt; BuildPart1(); for(int i = 0; i&lt; 4; i++) this -&gt; BuildPart2(); bool flag = this-&gt;BuildPart3(); if(flag)&#123; this -&gt; BuildPart4(); &#125; this -&gt; BuildPart5(); &#125; virtual ~House()&#123;&#125; protected: virtual void BuildPart1()=0; virtual void BuildPart2()=0; virtual void BuildPart3()=0; virtual void BuildPart4()=0; virtual void BuildPart5()=0;&#125;class StoneHouse : public House&#123; protected: virtual void BuildPart1()&#123; // ... &#125; virtual void BuildPart2()&#123; // ... &#125; virtual void BuildPart3()&#123; // ... &#125; virtual void BuildPart4()&#123; // ... &#125; virtual void BuildPart5()&#123; // ... &#125;&#125;// 使用时int main()&#123; House* pHouse = new StoneHouse(); pHouse -&gt; Init(); // 完成构建&#125;// ------------------------------------// 优化空间：对象过于复杂时，对对象进行拆分// ------------------------------------class House&#123; // .....&#125;class HouseBuilder&#123; public: House* GetResult()&#123; return pHouse; &#125; virtual ~House()&#123;&#125; protected: House* pHouse; virtual void BuildPart1()=0; virtual void BuildPart2()=0; virtual void BuildPart3()=0; virtual void BuildPart4()=0; virtual void BuildPart5()=0;&#125;class StoneHouse : public House&#123;&#125;class StoneHouseBuilder : public HouseBuilder&#123; protected: virtual void BuildPart1()&#123; // ... &#125; virtual void BuildPart2()&#123; // ... &#125; virtual void BuildPart3()&#123; // ... &#125; virtual void BuildPart4()&#123; // ... &#125; virtual void BuildPart5()&#123; // ... &#125;&#125;class HouseDirector&#123; public: HouseBuilder* pHouseBuilder; HouseDirector(HouseBuilder* pHouseBuilder)&#123; this -&gt; pHouseBuilder = pHouseBuilder; &#125; House* Construct()&#123; pHouseBuilder -&gt; BuildPart1(); for(int i = 0; i&lt; 4; i++) pHouseBuilder -&gt; BuildPart2(); bool flag = pHouseBuilder-&gt;BuildPart3(); if(flag)&#123; pHouseBuilder -&gt; BuildPart4(); &#125; pHouseBuilder -&gt; BuildPart5(); return pHouseBuilder -&gt; GetResult(); &#125;&#125;// 使用时int main()&#123; HouseBuilder* pHouseBuilder = new StoneHouseBuilder(); HouseDirector* pHouseDirector = new HouseDirector(pHouseBuilder); pHouseDirector -&gt; Construct();&#125; 模式定义：将一个复杂对象的构造与其表示相分离，使用相同的构建过程（稳定）可以创建不同的表示（变化） Director和Builder为稳定的，而ConcreteBuilder为变化的 要点总结 构建器主要用于分步骤构建一个复杂的对象。在这其中分步骤是一个稳定的算法，而复杂对象的各个部分则经常变化 变化点在哪里，封装哪里——构建器模式主要在于应对复杂对象各个部分的频繁需求变动。其缺点在于难以应对“分步骤构建算法”的需求变动 在构建器模式中，要注意不同语言中构造器内调用虚函数的差别 6 对象性能模式 对象性能模式 面向对象很好地解决了抽象的问题，但是必不可免地要付出一定的代价。对于通常情况，面向对象的成本大都可以忽略不计。但是某些情况，面向对象所带来的成本必须谨慎处理 包含：单件模式，享元模式 6.1 单件模式 动机 在软件系统中，经常有一些特殊的类，必须保证它们在系统中只存在一个实例，才能确保它们的逻辑正确性、以及良好的效率 需要绕过常规的构造器，提供一种机制来保证一个类只有一个实例 是类设计者的责任，不是使用者的责任 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Singleton&#123; private: // 设置为私有，外部不能构造该对象 Singleton(); Singleton(const Singleton&amp; other); public: static Singleton* getInstance(); static Singleton* m_instance;&#125;;Singleton* Singleton::m_instance = nullptr;// 线程非安全版本// 单线程中OK，在多线程中Singleton* Singleton::getInstance()&#123; if(m_instance == nullptr)&#123; m_instance = new Singleton(); &#125; return m_instance;&#125;// 线程安全版本，但锁的代价过高Singleton* Singleton::getInstance()&#123; Lock lock; // 对一下4行进行加锁，执行完之后释放锁 if(m_instance == nullptr)&#123; m_instance = new Singleton(); &#125; return m_instance;&#125;// 双检查锁，但由于内存读写reorder不安全Singleton* Singleton::getInstance()&#123; if(m_instance == nullptr)&#123; Lock lock; if(m_instance == nullptr)&#123; // 为了防止在上锁之前两个线程抢占加锁，需要进行二次判断 m_instance = new Singleton(); // reorder不安全：该行拆分为3个步骤，首先分配内存，接着调用构造器，最后将内存指针给m_instance // 真正在CPU层次，3个步骤很有可能被reorder，分配内存后直接将内存指针给m_instance,最后调用构造器 &#125; &#125; return m_instance;&#125;// C++11版本之后的跨平台实现（volatile）std::atomic&lt;Singleton*&gt; Singleton::m_instance; // 原子对象std::mutex Singleton::m_mutex;Singleton* Singleton::getInstance() &#123; Singleton* tmp = m_instance.load(std::memory_order_relaxed); std::atomic_thread_fence(std::memory_order_acquire);//获取内存fence if (tmp == nullptr) &#123; std::lock_guard&lt;std::mutex&gt; lock(m_mutex); tmp = m_instance.load(std::memory_order_relaxed); if (tmp == nullptr) &#123; tmp = new Singleton; std::atomic_thread_fence(std::memory_order_release);//释放内存fence m_instance.store(tmp, std::memory_order_relaxed); &#125; &#125; return tmp;&#125; 模式定义：保证一个类仅有一个实例，并提供一个该实例的全局访问点 要点总结 单件模式中的实例构造器可以设置为protected以允许子类派生 单件模式一般不要支持拷贝构造函数和Clone接口，因为这有可能导致多个实例，与单件模式的初衷违背 如何实现多线程环境下安全的单件模式？注意对双检查锁的正确实现 6.2 享元模式 动机 在软件系统采用纯粹对象方法的问题在于大量细粒度的对象会很快充斥在系统中，从而带来很高的运行时代价——主要指内存需求方面的代价 享元模式避免大量细粒度对象问题的同时，让外部客户程序仍然能够透明地使用面向对象的方式进行操作 模式定义 运用共享技术有效地支持大量细粒度的对象 123456789101112131415161718192021222324252627282930313233343536// 特点：对象创建之后状态不可以更改class Font&#123; private: // unique object key string key; // object state // ... public: Font(const string&amp; key)&#123; // ... &#125;&#125;;class FontFactory&#123; private: map&lt;string, Font*&gt; fontPool; public: Font* GetFont(const string&amp; key)&#123; map&lt;string, Font*&gt;::Iterator item = fontPool.fing(key); if(item != fontPool,end())&#123; return fontPool[key]; // 共享的方式 &#125;else&#123; Font* font = new Font(key); fontPool[key] = font; return font; &#125; &#125; void clear()&#123; // ... &#125;&#125;; 要点总结 面向对象很好地解决了抽象性问题，但是作为一个运行在机器中的程序尸体，需要考虑对象的代价问题。享元模式主要解决了面向对象的代价问题，一般不触及面向对象的抽象性问题 享元模式采用了对象共享的做法来降低系统中的对象个数。从而降低细粒度对象给系统带来的内存压力。在具体实现方面，要注意对象状态的处理 对象的数量太大从而导致对象内存开销加大——需要仔细根据具体应用情况进行评估，不能凭空臆断 对象数量足够大时可以使用该模式 7 接口隔离模式 接口隔离模式 在组件构建过程中，某些接口之间直接的依赖常常会带来很多问题、甚至根本无法实现。采用添加一层==间接（稳定）==接口，来隔离本来互相紧密关联的接口是一种常见的解决方案 包括：门面模式、代理模式、适配器、中介器 7.1 门面模式 动机 方案中存在组件的客户和组件中各种复杂的子系统有了过多的耦合，随着外部客户程序和各子系统的演化，过多的耦合面临很多变化的挑战 简化外部客户程序和系统间的交互接口，将外部客户程序的演化和内部子系统的变化之间的依赖相互解耦 模式定义 为子系统中的一组接口提供一个一致（稳定）的界面，门面模式定义了一个高层接口，该接口使子系统更加容易使用（复用） 要点总结 从客户程序的角度来看，门面模式简化了整个组件系统的接口，对于组件内部与外部客户程序来说，达到了解耦的效果——内部子系统的任何变化不会影响到门面接口的变化 门面模式更加注重从架构的层次来看整个系统，而不是单个类的层次。门面模式很多时候更是一种架构设计模式 门面模式并非一个集装箱，可以任意地放进任何多个对象。门面模式中组件的内部应该是“相互耦合关系比较大的一系列组件”，而不是一个简单的功能集合 7.2 代理模式 动机 在面向对象系统中，有些对象由于某种原因（比如对象创建的开销很大，或某些操作系统需要安全控制，或需要进程外的访问等），直接访问会给使用者、或系统结构带来很多麻烦 代理模式在不失去透明操作对象的同时来管理/控制这些对象特有的复杂性 增加一层间接层是软件开发中常见的解决方式 模式定义 为其他对象提供一种代理以控制（隔离，使用接口）对这个对象的访问 Subject为稳定不变的，RealSubject为变化的，使用Proxy的realSubject指针间接访问RealSubject 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// client.cppclass ISubject&#123; pubilc: virtual void process();&#125;;class RealSubject : public ISubject&#123; public: virtual void process()&#123; // ... &#125;&#125;;class ClientApp&#123; ISubject* subject; public: ClientApp()&#123; subject = new RealSubject(); // 通过各种方式生成，但该操作不合适（由于性能原因或各种原因） &#125; void DoTask()&#123; // ... subject -&gt; process(); // ... &#125;&#125;// -----------// 使用代理模式// -----------class ISubject&#123; pubilc: virtual void process();&#125;;// Proxy的设计class SubjectProxy : public ISubject&#123; // RealSubject realSubject; public: virtual void process()&#123; // 对RealSubject的简介访问 // ... &#125;&#125;;class ClientApp&#123; ISubject* subject; public: ClientApp()&#123; subject = new SubjectProxy(); &#125; void DoTask()&#123; // ... subject -&gt; process(); // ... &#125;&#125; 要点总结 增加一层间接层是软件系统中对许多复杂问题的一种常见解决方法。在面向对象系统中，直接使用某些对象会带来很多问题，作为间接层的proxy对象便是解决这一问题的常用手段 具体代理模式的实现方法、实现粒度相差很大，有可能对单个对象做细粒度的控制，如copy-on-write技术，有些可能对组件模块提供抽象代理层，在架构层次对对象做proxy proxy并不一定要求接口完整的一致性，只要能够间接控制，有时候损及一些透明性是可以接受的 7.3 适配器 动机 在软件系统中，由于应用环境的变化，常常需要将一些现存的对象放在新的环境中应用，但是新环境要求的接口是这些现存对象所不满足的 使用适配器应对迁移变化，既能利用现有对象的良好实现，同时又能满足新的应用环境所要求的接口 模式定义 将一个类的接口转换成客户希望的另一个接口。适配器模式使得原来由于接口不兼容而不能一起工作的那些类可以一起工作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 目标接口（新接口）class ITarget&#123; public: virtual void process()=0;&#125;;// 遗留接口（老接口）class IAdaptee&#123; public: virtual void foo(int data) = 0; virtual int bar() = 0;&#125;;// 遗留类型class OldClass : public IAdaptee&#123; // ...&#125;;// 对象适配器：通过组合对象来实现class Adapter : public ITarget&#123; //继承 protected: IAdaptee* pAdaptee; // 组合了一个对象 public: Adapter(IAdaptee* pAdaptee)&#123; this-&gt;pAdaptee = pAdaptee; &#125; virtual void process()&#123; // 伪码表示 int data = pAdaptee -&gt; bar(); pAdaptee -&gt; foo(data); &#125;&#125;// 类适配器class Adapter : public ITarget, protected IAdaptee&#123; // 多继承 // 继承纯虚接口，需要自己实现内部函数，没有意义 // 常见方法是继承实体类&#125;class Adapter : public ITarget, protected OldClass&#123; // 多继承 // 继承OldClass将父类定死了，没有灵活性&#125;int main()&#123; IAdaptee* pAdaptee = new OldClass(); // 使用旧的遗留类与适配器可以作为新的类型使用 ITarget* pTarget = new Adapter(pAdaptee); pTarget -&gt; process();&#125; 要点总结 适配器模式主要应用于希望复用一些现存的类，但是接口又与复用环境要求不一致的情况，在遗留代码复用、类库迁移等方面非常有用 GOF23定义了两种适配器模式的实现结构：对象适配器和类适配器，但类适配器采用多继承的实现方式，一般不推荐使用。对象适配器采用对象组合的方式，更符合松耦合精神 适配器模式可以实现的非常灵活，不必拘泥于GOF23中定义的两种结构。例如，完全可以将适配器模式中的现存对象作为新的接口方法参数来达到适配的目的 7.4 中介器 动机 在软件构建过程中，经常会出现多个对象互相关联交互的情况，对象之间常常会维持一种复杂的引用关系，如果遇到一些需求的更改，这种直接的引用关系将面临不断的变化 这种情况下，使用中介者模式来管理对象间的关联关系，表面相互交互对象之间的紧耦合引用关系，从而更好地抵御变化 模式定义 用一个中介对象来封装==（封装变化）一系列对象的交互。中介者使各对象不需要显式的相互引用（编译时依赖-&gt;运行时依赖）==，从而使其耦合松散（管理变化），而且可以独立地改变它们之间的交互 要点总结 将多个对象间复杂的关联关系解耦，中介器模式将多个对象间的控制逻辑进行集中管理，变“多个对象互相关联”为“多个对象和一个中介者关联”，简化了系统的维护，抵御了可能的变化 随着控制逻辑的复杂化，中介器具体对象的实现可能相当复杂。这时候可能对中介对象进行分解处理 门面模式是解耦系统间（单向）的对象关联关系；中介器模式是解耦系统内各个对象之间（双向）的关联关系 8 状态变化模式 状态变化模式 在组件构建过程中，某些对象的状态经常面临变化，如何对这些变化进行有效的管理？同时又维持高层模式的稳定？“状态变化”模式为这一问题提供了一种解决方案 典型模式：状态模式、备忘录 8.1 状态模式 动机 在软件构建过程中，某些对象的状态如果改变，其行为也会随之而发生变化，比如文档处于只读状态，其支持的行为和读写状态支持的行为就可能完全不同 状态模式在运行时根据对象的状态来透明地改变对象的行为，而不会为对象操作和状态转化之间引入紧耦合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114enum NetworkState&#123; Network_Open, Network_Close, Network_Connect,&#125;;class NetworkProcessor&#123; NetworkState state; public: void Operation1()&#123; if(state == Network_Open)&#123; // ********* state = Network_Close; &#125;else if(state == Network_Close)&#123; // ......... state = Network_Connect; &#125;else if(state == Network_Connect)&#123; // $$$$$$$$$ state = Network_Open; &#125; &#125; public void Operation2()&#123; if(state == Network_Open)&#123; // ********* state = Network_Connect; &#125;else if(state == Network_Close)&#123; // ......... state = Network_Open; &#125;else if(state == Network_Connect)&#123; // $$$$$$$$$ state = Network_Close; &#125; &#125; public void Operation3()&#123; &#125;&#125;;// ----------// 使用状态模式// ----------class NetworkState&#123; public: NetworkState* pNext; virtual void Operation1()=0; virtual void Operation2()=0; virtual void Operation3()=0; virtual ~NetworkState()&#123;&#125;&#125;;class OpenState : public NetworkState&#123; // 注意使用单体模式 static NetworkState* m_instance; public: static NetworkState* getInstance()&#123; if(m_instance == nullptr)&#123; m_instance = new OpenState(); &#125; &#125; void Operation1()&#123; // ************ pNext = CloseState::getInstance(); &#125; void Operation2()&#123; // ............ pNext = ConnectState::getInstance(); &#125; void Operation3()&#123; // $$$$$$$$$$$$ pNext = OpenState::getInstance(); &#125;&#125;class CloseState : public NetworkState&#123; // ...&#125;class ConnectState : public NetworkState&#123; // ...&#125;// 当添加一个新的状态时，只需要关注该新添加的状态的代码// 为扩展的方法class NetworkProcessor&#123; NetworkState* pState; public: NetworkProcessor(NetworkState* pState)&#123; this -&gt; pState = pState; &#125; void Operation1()&#123; // ... pState -&gt; Operation1(); pState = pState -&gt; pNext; // ... &#125; void Operation2()&#123; // ... pState -&gt; Operation2(); pState = pState -&gt; pNext; // ... &#125; void Operation3()&#123; // ... pState -&gt; Operation3(); pState = pState -&gt; pNext; // ... &#125;&#125; 模式定义 允许一个对象在其内部状态改变时改变它的行为。从而使对象看起来似乎修改了其行为 要点总结 状态模式将所有与一个特定状态相关的行为都放入一个State的子类对象中，在对象状态切换时，切换相应的对象；但同时维持State的接口，实现了具体操作与状态转换之间的解耦 为不同的状态引入不同的对象使得状态转换变得更加明确，而且可以保证不会出现状态不一致的情况，因为转换时原子性的——即要么彻底转换过来，要么不转换 如果State对象没有实例变量，那么各个上下文可以共享同一个State对象，从而节省对象开销 8.2 备忘录 动机 在软件构建过程中，某些对象的状态在转换过程中，可能由于某种需要，要求程序能够回溯到对象之前处于某个点时的状态。如果使用一些公有接口来让其他对象得到对象的状态，便会暴露对象的细节实现 备忘录实现对象状态的良好保存与恢复，同时不会因此破坏对象本身的封装性 123456789101112131415161718192021222324252627282930313233class Memento&#123; string state; public: Memento(const string &amp; s) : state(s) &#123;&#125; string getState() const &#123;return state;&#125; void setState(const string &amp; s) &#123;state = s;&#125;&#125;;class Originator&#123; string state; // ... public: Originator()&#123;&#125; Memento createMomento()&#123; Memento m(state); return m; &#125; void setMomento(const Memento &amp; m)&#123; state = m.getState(); &#125;&#125;;int main()&#123; Originator orginator; //捕获对象状态，存储到备忘录 Memento mem = orginator.createMomento(); //... 改变orginator状态 //从备忘录中恢复 orginator.setMomento(mem);&#125; 模式定义 在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可以将该对象恢复到原先保存的状态 要点总结 备忘录存储原发器（Originator）对象的内部状态，在需要时恢复原发器状态 备忘录模式的核心是信息隐藏，即Originator需要向外隐藏信息，保持其封装性。但同时有需要将状态保持到外界(Memento) 可以采用效率较高、又容易正确实现的序列化方案来实现备忘录模式 9 数据结构模式 数据结构模式 常常有一些组件在内部具有特定的数据结构，如果让客户程序依赖这些特定的数据结构，将极大地破坏组件的复用。需要特定数据结构封装在内部，在外部提供统一的接口，来实现与特定数据结构无关的访问 典型模式：组合器、迭代器、职责链 9.1 组合器 动机 在软件在某些情况下，客户代码过多地依赖于对象容器复杂的内部实现结构，对象容器内部实现代码（而非抽象接口）的变化将引起客户代码的频繁变化，带来代码的维护性、扩展性等弊端 组合器将客户代码与复杂的对象容器结构解耦，让对象容器自己实现自身的复杂结构，从而使客户代码就像处理简单对象一样处理复杂的对象容器 模式定义 将对象组合成树形结构以表示部分-整体的层次结构。组合其使得用户对单个对象和组合对象的使用具有一致性（稳定） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;#include &lt;list&gt;#include &lt;string&gt;#include &lt;algorithm&gt;using namespace std;class Component&#123; public: virtual void process() = 0; virtual ~Component()&#123;&#125;&#125;;//树节点class Composite : public Component&#123; string name; list&lt;Component*&gt; elements; public: Composite(const string &amp; s) : name(s) &#123;&#125; void add(Component* element) &#123; elements.push_back(element); &#125; void remove(Component* element)&#123; elements.remove(element); &#125; void process()&#123; //1. process current node //2. process leaf nodes for (auto &amp;e : elements) e-&gt;process(); //多态调用 &#125;&#125;;//叶子节点class Leaf : public Component&#123; string name; public: Leaf(string s) : name(s) &#123;&#125; void process()&#123; //process current node &#125;&#125;;void Invoke(Component &amp; c)&#123; //... c.process(); //...&#125;int main()&#123; Composite root(&quot;root&quot;); Composite treeNode1(&quot;treeNode1&quot;); Composite treeNode2(&quot;treeNode2&quot;); Composite treeNode3(&quot;treeNode3&quot;); Composite treeNode4(&quot;treeNode4&quot;); Leaf leat1(&quot;left1&quot;); Leaf leat2(&quot;left2&quot;); root.add(&amp;treeNode1); treeNode1.add(&amp;treeNode2); treeNode2.add(&amp;leaf1); root.add(&amp;treeNode3); treeNode3.add(&amp;treeNode4); treeNode4.add(&amp;leaf2); process(root); process(leaf2); process(treeNode3);&#125; 要点总结 组合器模式采用树形结构来实现普遍存在的对象容器，从而将一对多的关系转换成一对一的关系，使得客户代码可以一致地（复用）处理对象和对象容器，无需关心处理的是单个的对象，还是组合的对象容器 将客户代码与复杂的对象容器结构解耦是组合器的核心思想，解耦之后，客户代码将与纯粹的抽象接口——而非对象容器的内部实现结构——发生依赖，从而更能应对变化 组合器模式在具体实现中，可以让父对象中的子对象反向追溯；如果父对象有频繁的遍历需求，可以使用缓存技术来改善效率 9.2 迭代器 动机 在软件构建过程中，集合对象内部结构常常变化各异。但对于这些集合对象，希望在不暴露其内部结构的同时，可以让外部客户代码透明地访问其中包含的元素；同时这种透明遍历也为同一种算法在多种集合对象上进行操作提供了可能 使用面向对象技术将这种遍历机制抽象为“迭代器对象”为“应对变化中的集合对象”提供了一种优雅的方式 模式定义 提供一种方法顺序访问一个聚合对象中的各种元素，而==又不暴露（稳定）==该对象内部的表示 GOF中以面向对象（多态机制）的方式实现迭代器 在STL的大背景下，该方法已经过时（泛型编程中的迭代器），迭代器使用模板（也是一种多态）实现编译时多态，性能较高，且泛型编程可以使接口的扩展性更高，且成本较低 虚函数为运行时多态（性能有损失） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253template&lt;typename T&gt;class Iterator&#123; public: virtual void first() = 0; virtual void next() = 0; virtual bool isDone() const = 0; virtual T&amp; current() = 0;&#125;;template&lt;typename T&gt;class MyCollection&#123; public: Iterator&lt;T&gt; GetIterator()&#123; //... &#125; &#125;;template&lt;typename T&gt;class CollectionIterator : public Iterator&lt;T&gt;&#123; MyCollection&lt;T&gt; mc; public: CollectionIterator(const MyCollection&lt;T&gt; &amp; c): mc(c)&#123; &#125; void first() override &#123; // ... &#125; void next() override &#123; // ... &#125; bool isDone() const override&#123; // ... &#125; T&amp; current() override&#123; // ... &#125;&#125;;void MyAlgorithm()&#123; MyCollection&lt;int&gt; mc; Iterator&lt;int&gt; iter= mc.GetIterator(); for (iter.first(); !iter.isDone(); iter.next())&#123; cout &lt;&lt; iter.current() &lt;&lt; endl; &#125;&#125;// 虚函数的调用具有性能成本，需要根据虚函数表进行查找 要点总结 迭代抽象：访问一个聚合对象的内容而无需暴露它内部表示 迭代多态：为遍历不同的集合结构提供一个统一的接口，从而支持同样的算法在不同的集合结构上进行操作 迭代器的健壮性考虑：遍历的同时改变迭代器所在的集合结构会导致问题 9.3 职责链 动机 在软件构建过程中，一个请求可能被多个对象处理，但是每个请求在运行时只能有一个接受者，如果显式指定，将必不可少地带来请求发送者与接受者地紧耦合 模式定义 使多个对象都有机会处理请求，从而避免请求地发送者和接收者之间地耦合关系。将这些对象 连成一条链(链表)，并沿着这条链传递请求，直到有一个对象处理它为止 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;enum class RequestType&#123; REQ_HANDLER1, REQ_HANDLER2, REQ_HANDLER3&#125;;class Reqest&#123; string description; RequestType reqType; public: Reqest(const string &amp; desc, RequestType type) : description(desc), reqType(type) &#123;&#125; RequestType getReqType() const &#123; return reqType; &#125; const string&amp; getDescription() const &#123; return description; &#125;&#125;;class ChainHandler&#123; ChainHandler *nextChain; void sendReqestToNextHandler(const Reqest &amp; req)&#123; if (nextChain != nullptr) nextChain-&gt;handle(req); &#125; protected: virtual bool canHandleRequest(const Reqest &amp; req) = 0; virtual void processRequest(const Reqest &amp; req) = 0; public: ChainHandler() &#123; nextChain = nullptr; &#125; void setNextChain(ChainHandler *next) &#123; nextChain = next; &#125; void handle(const Reqest &amp; req)&#123; if (canHandleRequest(req)) processRequest(req); else sendReqestToNextHandler(req); &#125;&#125;;class Handler1 : public ChainHandler&#123; protected: bool canHandleRequest(const Reqest &amp; req) override&#123; return req.getReqType() == RequestType::REQ_HANDLER1; &#125; void processRequest(const Reqest &amp; req) override&#123; cout &lt;&lt; &quot;Handler1 is handle reqest: &quot; &lt;&lt; req.getDescription() &lt;&lt; endl; &#125;&#125;;class Handler2 : public ChainHandler&#123; protected: bool canHandleRequest(const Reqest &amp; req) override&#123; return req.getReqType() == RequestType::REQ_HANDLER2; &#125; void processRequest(const Reqest &amp; req) override&#123; cout &lt;&lt; &quot;Handler2 is handle reqest: &quot; &lt;&lt; req.getDescription() &lt;&lt; endl; &#125;&#125;;class Handler3 : public ChainHandler&#123; protected: bool canHandleRequest(const Reqest &amp; req) override&#123; return req.getReqType() == RequestType::REQ_HANDLER3; &#125; void processRequest(const Reqest &amp; req) override&#123; cout &lt;&lt; &quot;Handler3 is handle reqest: &quot; &lt;&lt; req.getDescription() &lt;&lt; endl; &#125;&#125;;int main()&#123; Handler1 h1; Handler2 h2; Handler3 h3; h1.setNextChain(&amp;h2); h2.setNextChain(&amp;h3); Reqest req(&quot;process task ... &quot;, RequestType::REQ_HANDLER3); h1.handle(req); return 0;&#125; 要点总结 职责链模式地应用场景在于“一个请求可能有多个接收者，但是最后真正地接收者只有一个”，这时候请求发送者与接收者地耦合有可能出现“变化脆弱”地症状，职责链地目的就是将二者解耦，从而更好地应对变化 应用了职责链模式后，对象的职责分派将更具灵活性，可以在运行时动态添加/修改请求地处理职责 如果请求传递到职责链地末尾仍得不到处理，应该有一个合理地缺省机制，这是每一个接受对象地责任，而不是发出请求地对象的责任 10 行为变化模式 行为变化模式 在组件的构建过程中，组件行为的变化经常导致组件本身剧烈的变化。“行为变化”模式将组件的行为和组件本身进行解耦，从而支持组件行为的变化，实现两者之间的松耦合 典型模式：命令模式，访问器模式 10.1 命令模式 动机 在软件构建过程中，行为请求者与行为实现者通常呈现一种紧耦合。但在某些场合——比如需要对行为进行记录，撤销/重，事务等处理，这种无法抵御变化的紧耦合是不合适的 模式定义 将请求（行为）封装为一个对象，从而使得可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可撤销的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;class Command&#123; public: virtual void execute() = 0;&#125;;class ConcreteCommand1 : public Command&#123; string arg; public: ConcreteCommand1(const string &amp; a) : arg(a) &#123;&#125; void execute() override&#123; cout&lt;&lt; &quot;#1 process...&quot;&lt;&lt;arg&lt;&lt;endl; &#125;&#125;;class ConcreteCommand2 : public Command&#123; string arg; public: ConcreteCommand2(const string &amp; a) : arg(a) &#123;&#125; void execute() override&#123; cout&lt;&lt; &quot;#2 process...&quot;&lt;&lt;arg&lt;&lt;endl; &#125;&#125;; class MacroCommand : public Command&#123; vector&lt;Command*&gt; commands; public: void addCommand(Command *c)&#123; commands.push_back(c); &#125; void execute() override&#123; for (auto &amp;c : commands) c-&gt;execute(); &#125;&#125;;int main()&#123; ConcreteCommand1 command1(receiver, &quot;Arg ###&quot;); ConcreteCommand2 command2(receiver, &quot;Arg $$$&quot;); MacroCommand macro; macro.addCommand(&amp;command1); macro.addCommand(&amp;command2); macro.execute();&#125; 要点总结 命令模式的根本目的在于将行为请求者与行为实现者解耦，在面向对象语言中，常见的实现手段是讲行为抽象为对象 实现命令接口的具体命令对象ConcreteCommand有时候根据需要可能会保存一些额外的状态信息。通过使用Composite模式，可以将多个命令封装成一个复合命令MacroCommand 命令模式与C++中函数对象有些类似。但两者定义行为接口的规范有所区别： 命令模式以面向对象中的接口-实现来定义行为接口规范，更严格，但有性能损失 C++函数对象以函数签名来定义行为接口规范，更灵活，性能更高，并且使用模板，为编译时多态，运行效率更高 10.2 访问器模式 动机 在软件构建过程中，由于需求的改变，某些类层次结构中常常需要增加新的行为（方法），如果直接在基类中做更改，将会给子类带来繁重的变更负担，甚至破坏原有设计 访问器模式在不更改类层次结构的前提下，在运行时根据需要透明地为类层次结构上的各个类动态添加新的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// 使用访问器模式之前// 完成开发后，添加新需求，需要对基类进行修改，违反开放封闭原则#include &lt;iostream&gt;using namespace std;class Visitor;class Element&#123; public: virtual void Func1()=0; virtual void Func2(int data)=0; // 添加的新方法 virtual ~Element()&#123;&#125;&#125;;class ElementA : public Element&#123; public: void Func1() override&#123; // ... &#125; void Func2(int data) override&#123; // 变更 // ... &#125;&#125;;class ElementB : public Element&#123; public: void Func1() override&#123; // ... &#125; void Func2(int data) override&#123; //变更 // ... &#125;&#125;;// -----------// 使用访问器模式// -----------#include &lt;iostream&gt;using namespace std;class Visitor;class Element&#123; public: virtual void accept(Visitor&amp; visitor) = 0; //第一次多态辨析 virtual ~Element()&#123;&#125;&#125;;class ElementA : public Element&#123; public: void accept(Visitor &amp;visitor) override &#123; visitor.visitElementA(*this); &#125;&#125;;class ElementB : public Element&#123; public: void accept(Visitor &amp;visitor) override &#123; visitor.visitElementB(*this); //第二次多态辨析 &#125;&#125;;class Visitor&#123; public: virtual void visitElementA(ElementA&amp; element) = 0; virtual void visitElementB(ElementB&amp; element) = 0; virtual ~Visitor()&#123;&#125;&#125;;//==================================// 添加新的需求//扩展1class Visitor1 : public Visitor&#123; public: void visitElementA(ElementA&amp; element) override&#123; cout &lt;&lt; &quot;Visitor1 is processing ElementA&quot; &lt;&lt; endl; &#125; void visitElementB(ElementB&amp; element) override&#123; cout &lt;&lt; &quot;Visitor1 is processing ElementB&quot; &lt;&lt; endl; &#125;&#125;; //扩展2class Visitor2 : public Visitor&#123; public: void visitElementA(ElementA&amp; element) override&#123; cout &lt;&lt; &quot;Visitor2 is processing ElementA&quot; &lt;&lt; endl; &#125; void visitElementB(ElementB&amp; element) override&#123; cout &lt;&lt; &quot;Visitor2 is processing ElementB&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; Visitor2 visitor; ElementB elementB; elementB.accept(visitor);// double dispatch（二次多态辨析） ElementA elementA; elementA.accept(visitor); return 0;&#125; 模式定义 表示一个作用于某对象结构中的各元素的操作。使得可以在不改变（稳定）各元素的类的前提下定义（扩展）作用于这些元素的新操作（变化） Visitor,Element要求稳定,并且要求ConcreteElementA和ConcreteElementB稳定 缺点：当新增一个ConcreteElement时，visitor也需要跟着变化，此时会违反开闭原则 要点总结 访问器模式通过所谓双重分发来实现在不更改（不添加新的操作-编译时）Element类层次结构的前提下，在运行时透明地为类层次结构上的各个类添加新的操作（支持变化） 所谓双重分发即访问器模式中间包括了两个多态分发（注意其中的多态机制）：第一个为accept方法的多态辨析；第二个为visitElementX方法的多态辨析 访问器模式的最大缺点在于扩展类层次结构（增添新的Element子类），会导致Visitor类的改变。因此Visitor模式适用于Element类层次结构稳定，而其中的操作却经常面临频繁改动 11 领域规则模式 领域规则模式 在特定领域中，某些变化虽然频繁，但是可以抽象为某种规则。这时候，结合特定领域，将问题抽象为语法规则，从而给出在该领域下的一般性解决方案 典型模式：解析器模式 11.1 解析器模式 动机 在软件构建过程中，如果某一特定领域的问题比较复杂，类似的结构不断重复出现，如果使用普通的编程方式来实现将面临非常频繁的变化 解析器模式将特定领域的问题表达为某种语法规则下的句子，然后构建一个解释器来解释这样的句子，从而达到解决问题的目的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#include &lt;iostream&gt;#include &lt;map&gt;#include &lt;stack&gt;using namespace std;class Expression &#123; public: virtual int interpreter(map&lt;char, int&gt; var)=0; virtual ~Expression()&#123;&#125;&#125;;//变量表达式class VarExpression: public Expression &#123; char key; public: VarExpression(const char&amp; key)&#123; this-&gt;key = key; &#125; int interpreter(map&lt;char, int&gt; var) override &#123; return var[key]; &#125;&#125;;//符号表达式class SymbolExpression : public Expression &#123; // 运算符左右两个参数 protected: Expression* left; Expression* right; public: SymbolExpression( Expression* left, Expression* right): left(left),right(right)&#123;&#125;&#125;;//加法运算class AddExpression : public SymbolExpression &#123; public: AddExpression(Expression* left, Expression* right): SymbolExpression(left,right)&#123;&#125; int interpreter(map&lt;char, int&gt; var) override&#123; return left-&gt;interpreter(var) + right-&gt;interpreter(var); &#125;&#125;;//减法运算class SubExpression : public SymbolExpression &#123; public: SubExpression(Expression* left, Expression* right): SymbolExpression(left,right)&#123;&#125; int interpreter(map&lt;char, int&gt; var) override &#123; return left-&gt;interpreter(var) - right-&gt;interpreter(var); &#125;&#125;;Expression* analyse(string expStr) &#123; stack&lt;Expression*&gt; expStack; Expression* left = nullptr; Expression* right = nullptr; for(int i=0; i&lt;expStr.size(); i++)&#123; switch(expStr[i])&#123; case &#x27;+&#x27;: // 加法运算 left = expStack.top(); right = new VarExpression(expStr[++i]); expStack.push(new AddExpression(left, right)); break; case &#x27;-&#x27;: // 减法运算 left = expStack.top(); right = new VarExpression(expStr[++i]); expStack.push(new SubExpression(left, right)); break; default: // 变量表达式 expStack.push(new VarExpression(expStr[i])); &#125; &#125; Expression* expression = expStack.top(); return expression;&#125;void release(Expression* expression)&#123; //释放表达式树的节点内存...&#125;int main(int argc, const char * argv[]) &#123; string expStr = &quot;a+b-c+d-e&quot;; map&lt;char, int&gt; var; var.insert(make_pair(&#x27;a&#x27;,5)); var.insert(make_pair(&#x27;b&#x27;,2)); var.insert(make_pair(&#x27;c&#x27;,1)); var.insert(make_pair(&#x27;d&#x27;,6)); var.insert(make_pair(&#x27;e&#x27;,10)); Expression* expression= analyse(expStr); int result=expression-&gt;interpreter(var); cout&lt;&lt;result&lt;&lt;endl; release(expression); return 0;&#125; 要点总结 解析器模式的应用场合时解析器模式应用中的难点，只有满足业务规则频繁变化，且类似的结构不断重复出现，并且容易抽象为语法规则的问题才使用解析器模式 使用解析器模式来表示文法规则，从而可以使用面向对象技巧来方便地扩展文法 解析器模式比较适合简单的文法表示，对于复杂的文法表示，解析器模式会产生比较大的类层次结构，需要求助于语法分析生成器这样的标准工具 12 总结 12345678910111213141516171819202122// ----------// C++对象模型// ----------class A:B&#123; // ...&#125;// 该方式为继承方式，B放在A的前面class A&#123; B b; // ...&#125;// 该方式为组合方式，但是仍为B在A的前面// 组合的B为对象，会导致紧耦合class A&#123; B* pb; // ...&#125;// 该方式为组合方式，但是是A中含有B的指针// 组合的为B的指针，指向多态对象，带来松耦合，多态性，带来便利// C++中的许多模式都为该模式 什么时候不用模式 代码可读性很差 需求理解很浅 变化没有显现 不是系统的关键依赖点 项目没有复用价值 项目想要发布 经验之谈 不要为模式而模式 关注抽象类&amp;接口 理清变化点和稳定点 审视依赖关系 要有Framework和Application的区隔思维 良好的设计是演化的结果","categories":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/categories/Basic/"}],"tags":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/tags/Basic/"}]},{"title":"C++标准11-14","slug":"计算机基础知识/C++标准11-14","date":"2022-06-10T02:09:56.000Z","updated":"2023-04-09T13:40:12.455Z","comments":true,"path":"2022/06/10/计算机基础知识/C++标准11-14/","link":"","permalink":"http://jay1060950003.github.io/2022/06/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/C++%E6%A0%87%E5%87%8611-14/","excerpt":"引言 侯捷老师C++标准11-14学习笔记","text":"引言 侯捷老师C++标准11-14学习笔记 1 演进,环境与资源 C++1.0为C++98 C++2.0为C++11 C++2.0新特性包括语言和标准库两个层面(标准库以header files形式呈现) C++标准库的header files不带副档名(.h) 新式C header files不带副名称 旧式C header files(带有副名称.h)仍可用 123456789101112131415161718192021222324252627#include&lt;type_traits&gt;#include&lt;unordered_set&gt;#include&lt;forward_list&gt;#include&lt;array&gt;#include&lt;tuple&gt;#include&lt;regex&gt;#include&lt;thread&gt;using namespace std;// 第一步，确认支持C++11// 如果C++版本支持C++11则__cplusplus为201103L#define __cplusplus 201103L// 如果C++版本不支持C++11则__cplusplus为199711L#define __cplusplus 199711L// 使用程序打印出C++的版本#include&quot;stdafx.h&quot;#include&lt;iostream&gt;using namespace std;int main()&#123; cout&lt;&lt;__cplusplus&lt;&lt;endl; return 0;&#125;// 需要设置编译器属性来支持C++14 2 variadic Templates(数量不定的模板参数) 12345678910111213141516171819202122232425262728// 为处理最后的空参数的情况，添加该函数，否则会报错void print()&#123; // 空函数&#125;// 版本二template &lt;typename T, typename... Types&gt;void print(const T&amp; firstArg, const Types&amp;... args)&#123; const &lt;&lt; firstArg &lt;&lt; endl; print(args...); // 帮助实现递归&#125;// ...表示接受可变数量的参数// ...为所谓的pack(包)// 用于模板参数则为模板参数包；// 用于函数参数类型则为函数参数类型包；// 用于函数参数则为函数参数包// 用于知道args参数有多少个sizeof...(args);// 第三个版本template&lt;typename... Types&gt;void print(const Types&amp;... args)&#123; /* ... */&#125;// 该版本可以与版本二并存// 版本二更加特化，版本三更加特化 12345678910111213141516171819202122232425262728293031323334353637383940// 更加方便地完成函数调用class CustomerHash&#123; public: std::size_t operator()(const Customer&amp; c) const&#123; return hash_val(c.fname, c.lname, c.no); &#125;&#125;// hash_val的版本一template&lt;typename... Types&gt;inline size_t hash_val(const Types... args)&#123; size_t seed = 0; hash_val(seed, args...); return seed;&#125;// hash_val的版本二template&lt;typename T, typename... Types&gt;inline void hash_val(size_t&amp; seed, const T&amp; val, const Types... args)&#123; hash_combine(seed, val); hash_val(seed, args...);&#125;// hash_val的版本三，可作为终止递归的函数template&lt;typename T&gt;inline void hash_val(size_t&amp; seed, const T&amp; val)&#123; hash_combine(seed, val);&#125;// hash_combine函数#include&lt;functional&gt;template&lt;typename T&gt;inline void hash_combine(size_t&amp; seed, const T&amp; val)&#123; seed ^= std::hash&lt;T&gt;()(val) + 0x9e3779b9 + (seed&lt;&lt;6) + (seed&gt;&gt;2);&#125;// hash_val不能调用版本二(第一个参数不符合)，版本三(参数不符合)，只能调用版本一// 随后调用版本二// 递归调用版本二// 最后调用版本三终止递归调用 1234567891011121314151617181920template&lt;typename... Values&gt; class tuple;template&lt;&gt; class tuple&lt;&gt;&#123;&#125;;template&lt;typename Head, typename... Tail&gt;class tuple&lt;Head, Tail...&gt; :private tuple&lt;Tail...&gt; //私有继承一包参数&#123; typedef tuple&lt;Tail...&gt; inherited; public: tuple()&#123;&#125; tuple(Head v, Tail... vtail) :m_head(v), inherited(vtail...)&#123;&#125; typename Head::type head &#123;return&#125; inherited&amp; tail &#123; return *this;&#125; protected: Head m_head; //第一个参数定义为一个变量&#125;// 例:tuple&lt;int, float, string&gt; t(41, 6.3, &quot;nico&quot;); tuple可以放任意数量的任意类型的元组 3 模板表达式的空格, nullptr与std::nullptr_t, auto 3.1 模板表达式的空格 在之前版本的C++98中，模板中模板参数为一个模板时，两个&gt;&gt;之间必须包含一个空格 vector&lt;list&lt;int&gt; &gt; 在C++2.0中，空格可以省略 vector&lt;list&lt;int&gt;&gt; 3.2 nullptr与std::nullptr_t C++11使用nullptr代替NULL或者0给指针赋值为空指针 nullptr的类型为std::nullptr_t, 定义在cstddef中 123456void f(int);void f(void*);f(0); //调用上面的函数f(NULL); //可调用上面的函数，也可以调用下面的函数,编译器不知道该调用哪一个f(nullptr); //调用下面的函数 3.3 auto 使用auto自动推断变量类型 编译器可推断变量类型 建议auto用于类型名太长或类型名过于复杂的情况 123456789101112131415161718192021222324auto i = 42;double f();auto d = f(); //推断d为double类型vector&lt;string&gt; v;auto pos = v.begin(); //vector&lt;string&gt;::iteratorauto L = [](int x) -&gt; bool&#123; //Lambda表达式的类型推断 ...,&#125;// L为一个对象list&lt;string&gt; c;...list&lt;string&gt;::iterator ite;ite = find(c.begin(), c.end(), target);// 可简化为list&lt;string&gt; c;...auto ite = find(c.begin(), c.end(), target);// 在标准库中的使用示例inline auto operator-(const reverse_iterator&lt;_Iterator&gt;&amp; __x, const reverse_iterator&lt;_Iterator&gt;&amp; __y,) -&gt; decltype(__y.base() - __x.base()) 4 一致性的初始化 初始化可能发生在(),{}或者=赋值符号中 C++11引入一致性的初始化：任何初始化可以使用大括号{}进行 编译器看到{t1,t1,…}便做出一个initializer_list&lt;T&gt;，initializer_list&lt;T&gt;关联到一个array&lt;T,n&gt;(n为个数) 调用函数有参数为initializer_list&lt;T&gt;的版本，则调用该版本，否则将该array内的元素分解依次传给函数 调用函数(构造函数)时，该array内的元素可被编译器分解依次传给函数 若函数参数是initializer_list&lt;T&gt;，调用者却不能给数个T参数然后以为它们会被自动转为一个initializer_list&lt;T&gt;传入 123456// 使用示例int values[]&#123;1,2,3&#125;;vector&lt;int&gt; v &#123;2,3,4,5,6&#125;;vector&lt;string&gt; cities &#123;&quot;Berlin&quot;,&quot;New York&quot;,&quot;Cairo&quot;&#125;;// C++标准库中的复数complex&lt;double&gt; c&#123;4.0,3.0&#125; 5 initializer_list&lt;T&gt; {}可以被用来设定初值 {}不允许窄化转换，不允许向低位数转换 但是在开发平台上只是提出警告 传给initializer_list的必须为initializer_list或者为{…}的形式 C++11提供std::initializer_list&lt;&gt;模板 123456789101112131415161718192021222324252627282930313233343536373839404142434445// &#123;&#125;可以被用来设定初值int i; // 初值未定义int j&#123;&#125;; // 初值为0int* p; // 初值未定义int* q&#123;&#125;; // 初值为nullptrint x1(5.3);int x2 = 5.3;int x3&#123;5.0&#125;; // 不允许窄化转换int x4 = &#123;5.3&#125;; // 不允许窄化转换char c1&#123;7&#125;;char c2&#123;99999&#125;; // 不允许窄化转换std::vector&lt;int&gt; v1&#123;1, 2, 3, 4&#125;;std::vector&lt;int&gt; v1&#123;1, 2.3, 3, 4&#125;; // 不允许窄化转换void print(std::initializer_list&lt;int&gt; vals)&#123; for(auto p = vals.begin(); p!= vals.end(); ++p) std::cout&lt;&lt;*p&lt;&lt;&quot;\\n&quot;;&#125;print(12,3,5,7,11,13,17);// 传给initializer_list的必须为initializer_list或者为&#123;...&#125;的形式class P&#123; public: // 版本1 P(int a, int b)&#123; cout&lt;&lt;&quot;P(int, int), a=&quot; &lt;&lt; a &lt;&lt; &quot;, b=&quot; &lt;&lt; b &lt;&lt; endl; &#125; // 版本2 P(initializer_list&lt;int&gt; initlist)&#123; cout&lt;&lt;&quot;P(initializer_list&lt;int&gt;), values=&quot;; for(auto i : initlist) cout &lt;&lt; i &lt;&lt; &#x27; &#x27;; cout &lt;&lt; endl; &#125;&#125;P p(77 ,5); // 调用版本1P q&#123;77 ,5&#125;; // 调用版本2P r&#123;77 ,5, 42&#125;; // 调用版本2P s = &#123;77 ,5, 42&#125;; // 调用版本2// 如果没有版本2只有版本1，不影响p,q和s的调用，当为q,s时会将q的&#123;&#125;拆解为两个参数后调用版本1，r为非法的，因为r有3个参数// complex&lt;T&gt;没有版本2，故只能一个一个分解使用版本1 123456789101112131415161718192021222324252627282930// initializer_list的源代码template&lt;class E&gt; class initializer_list&#123; public: typedef _E value_type; typedef const _E&amp; reference; typedef const _E&amp; const_reference; typedef size_t size_type; typedef const _E* iterator; typedef const _E* const_iterator; private: iterator _M_array; size_type _M_len; // the complier can call a private constructor constexpr initializer_list(const_iterator __a, size_type __l) : _M_array(__a),__M_len(__l)&#123;&#125; public: constexpr initializer_list() noexcept : _M_array(0), _M_len(0) &#123;&#125; constexpr size_type size() const noexcept &#123;return _M_len;&#125; constexpr const_iterator begin() const noexcept &#123;return _M_array;&#125; constexpr const_iterator end() const noexcept &#123;return begin() - end();&#125; &#125; array就是C++中数组的另一种形式 可以用到标准库中的begin(),end()等接口 array提供迭代器，故可以被其他算法接受 1234567891011121314151617181920212223// array// TR1版本template&lt;typename _Tp, std::size_t _Nm&gt; struct array&#123; typedef _Tp value_type; typedef _Tp* pointer; typedef value_type* iterator; // support for zerp_sized arrays mandatory value_type _M_instance[ _Nm ? _Nm : 1]; iterator begin() &#123;return iterator(&amp;_M_instance[0]);&#125; iterator end() &#123;return iterator(&amp;_M_instance[_Nm]);&#125; ... &#125;array&lt;int, 10&gt; myArray;auto ite = myArray.begin();itr+=3;cout&lt;&lt;*ite; initializer_list对象只是指向背后的array而不是包含array 详见源代码中的构造函数 拷贝initializer_list时为浅拷贝，是指针拷贝(指针指向的东西相同，而不是值拷贝) 使用initializer_list可以对算法进行扩充，可以传进任意数量的参数 6 explicit参数 explicit参数会使函数不自动进行隐式转换，只有明确调用构造函数时进行转换 只有一个实参的非explicit构造函数可以进行隐式转换 C++11之后，explicit支持两个及以上实参的构造函数声明为explicit，该构造函数不进行隐式转换 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// explicit用在一个参数的构造函数上struct Complex&#123; int real,imag; // 该形式为单一实参，第二个参数有默认实参 Complex(int re, int im=0):real(re),imag(im)&#123;&#125; Complex operator+(const Complex&amp; x)&#123; return Complex((real + x.real), (imag + x.image);) &#125;&#125;Complex c1(12,5);Complex c2 = c1+5; //会将5转换为Complexstruct Complex&#123; int real,imag; explicit Complex(int re, int im=0):real(re),imag(im)&#123;&#125; Complex operator+(const Complex&amp; x)&#123; return Complex((real + x.real), (imag + x.image);) &#125;&#125;Complex c1(12,5);Complex c2 = c1+5; // 由于explicit，不会进行转换// -----// 小测试// -----class P&#123; public: // 版本1 P(int a, int b)&#123; cout&lt;&lt;&quot;P(int, int), a=&quot; &lt;&lt; a &lt;&lt; &quot;, b=&quot; &lt;&lt; b &lt;&lt; endl; &#125; // 版本2 P(initializer_list&lt;int&gt; initlist)&#123; cout&lt;&lt;&quot;P(initializer_list&lt;int&gt;), values=&quot;; for(auto i : initlist) cout &lt;&lt; i &lt;&lt; &#x27; &#x27;; cout &lt;&lt; endl; &#125; // 版本3 explicit P(int a, int b, int c)&#123; cout&lt;&lt;&quot;P(int, int), a=&quot; &lt;&lt; a &lt;&lt; &quot;, b=&quot; &lt;&lt; b &lt;&lt; endl; &#125;&#125;;void fp(const P&amp;)&#123;&#125;;P p1 (77,5);P p2 &#123;77,5&#125;;P p3 &#123;77,5,42&#125;;P p4 = &#123;77,5&#125;;// P p5 = &#123;77,5,42&#125;;// 错误原因:版本3声明为explicit，故不能隐式转换后拷贝给p4P p6 (77,5,42);fp(&#123;42,11&#125;);// fp(&#123;42,11,3&#125;); //错误fp(P&#123;42,11&#125;);fp(P&#123;42,11,3&#125;); 7 范围for循环 范围for循环拿出元素时，若需要进行转换，则在其构造函数中不能声明为explicit（不能进行隐式转换） 1234567891011121314151617181920212223242526272829303132333435for(decl:coll)&#123; statement&#125;// 例子for(int i:&#123;2,3,4,5,6,7,13,17,19&#125;) cout &lt;&lt; i &lt;&lt; endl;vector&lt;double&gt; vec;...for(auto elem : vec)&#123; cout &lt;&lt; elem &lt;&lt; endl;&#125;for(auto&amp; elem : vec)&#123; elem *= 3;&#125;for(decl:coll)&#123; statement&#125;// 编译器行为代码化for(auto _pos = coll.begin(),_end=coll.end();_pos!=_end;++_pos)&#123; decl = *_pos; statement&#125;for(const auto&amp; elem :coll)&#123; cout &lt;&lt; elem &lt;&lt; endl;&#125;// 编译器行为代码化for(auto _pos = coll.begin(),_end=coll.end();_pos!=_end;++_pos)&#123; const auto&amp; elem = *_pos; cout &lt;&lt; elem &lt;&lt; endl;&#125; 8 =default，=delete 如果自定义了构造函数，则编译器不会合成默认构造函数 强制加上=default，可以重新获取默认构造函数 对于big-five(C++2.0之后)之外的函数使用=default会报错，因为没有默认版本 =delete可以使用在任何函数上 =0只可以使用在virtual函数上 123456789101112131415161718192021222324252627282930313233class Zoo&#123; public: Zoo(int i1, int i2) : d1(i1),d2(i2)&#123;&#125; //构造函数 Zoo(const Zoo&amp;) = delete; //拷贝构造函数copy Zoo(Zoo&amp;&amp;) = default; //右值引用move Zoo&amp; operator=(const Zoo&amp;) =default; //拷贝赋值函数copy Zoo&amp; operator=(const Zoo&amp;&amp;) =delete; //右值赋值函数move virtual ~Zoo()&#123;&#125; private: int d1,d2;&#125;class Foo&#123; public: Foo(int i) : _i(i) &#123;&#125; Foo() = default; //可以与构造函数并存 Foo(const Foo&amp; x) : _i(x._i) &#123;&#125; // !Foo(const Foo&amp; x) =default; // 拷贝构造函数不可以重载 // !Foo(const Foo&amp; x) =delete; Foo&amp; operator=(const Foo&amp; x) &#123;_i = x._i;return *this;&#125; // !Foo&amp; operator=(const Foo&amp; x) =default; // !Foo&amp; operator=(const Foo&amp; x) =delete; // !void func1() = default; //一般函数没有默认版本 // ！ ~Foo() = delete; //会造成无析构函数 ~Foo() = default; private: int _i;&#125; 声明一个空类，该类并不是空的，编译器会为其声明一个拷贝构造函数、拷贝赋值函数和析构函数(big-three)。若没有声明任何构造函数，编译器会声明一个默认构造函数 该函数都是pubic和inline的 这些函数只有使用时才会被编译器合成 默认构造函数和析构函数是为了给编译器一个地方存放藏身幕后的代码 子类的构造函数调用父类的构造函数 一个类只要含有指针成员，则该类需要自己定义big-three；若不含有绝大多数不需要自定义 1234567891011121314151617181920212223242526// NoCopy and Private-Copystruct NoCopy&#123; NoCopy() = default; NoCopy(const NoCopy&amp;) = delete; NoCopy&amp; operator=(const NoCopy&amp;) = delete; ~NoCopy() = default; // other members&#125;struct NoDtor&#123; NoDtor() = default; ~NoDtor() = delete;&#125;NoDtor nd; //errorNoDtor *p = new NoDtor();delete p; //errorclass PrivateCopy&#123; private: PrivateCopy(const PrivateCopy&amp;); PrivateCopy&amp; operator=(const PrivateCopy&amp;); public: PrivateCopy() = default; ~PrivateCopy();&#125;// 这个类不能被一般的代码调用，但可以被友元friend或成员member复制 =delete告诉编译器不要定义它，必须出现在声明式 用于析构函数时后果自负 将拷贝构造函数和拷贝赋值函数声明为private时，只能被友元或成员复制 这种类用于被继承，性质为不能被复制 boost社群:为C++标准库的先前版本 boost::noncopyable实现了上述的PrivateCopy类 9 模板化名(template typedef) 不能使用化名对模板进行特化 特化时还需要使用模板本身 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576template &lt;typename T&gt;using Vec = std::vector&lt;T,MyAlloc&lt;T&gt;&gt;; //Vec为=后面的别名// 使用Vec&lt;int&gt; coll;// 等效于std::vector&lt;int,MyAlloc&lt;int&gt;&gt; coll;// ---------------------------// 使用#define无法达到相同的效果#define Vec&lt;T&gt; template&lt;typename T&gt; std::vector&lt;T,MyAlloc&lt;T&gt;&gt;Vec&lt;int&gt; coll;// 等效于template&lt;typename int&gt; std::vector&lt;int,MyAlloc&lt;int&gt;&gt; coll;// 使用typedef亦 无法达到相同的效果typedef std::vector&lt;int, MyAlloc&lt;int&gt;&gt; vec; //不是想要的结果// ---------------------------// 使用模板可以更好的实现代码复用void test_moveable(Container cntr, T elem)&#123; Container&lt;T&gt; c; for(long i = 0; i&lt;SIZE;++i) c.insert(c.end(),T()); output_static_data(T()); Container&lt;T&gt; c1(c); Container&lt;T&gt; c2(std::move(c)); c1.swap(c2);&#125;test_moveable(list,MyString()); //list写法错误需要尖括号test_moveable(list,MyStrNoMove()); //list写法错误需要尖括号// 天方夜谭，调用函数传递的参数为Object，但拿参数的type做文章// Container is not a templatetemplate&lt;typename Container, typename T&gt;void test_moveable(Container cntr, T elem)&#123; Container&lt;T&gt; c; for(long i = 0; i&lt;SIZE;++i) c.insert(c.end(),T()); output_static_data(T()); Container&lt;T&gt; c1(c); Container&lt;T&gt; c2(std::move(c)); c1.swap(c2);&#125;test_moveable(list(),MyString()); //list()为建立一个临时对象，但写法错误需要尖括号test_moveable(list(),MyStrNoMove()); //list()为建立一个临时对象，但写法错误需要尖括号// typename后面加小括号为创建一个临时对象// 最终解决方案// 容器都包含iterator迭代器，通过iterator_traits获得value_type,即为每个元素的类型template&lt;typename Container&gt;void test_moveable(Container c)&#123; typedef typename iterator_traits&lt;typename Container::iterator&gt;::value_type Valtype; for(long i = 0; i&lt;SIZE ;++i) c.insert(c.end(),Valtype()); output_static_data(*(c.begin())); Container c1(c); Container c2(std::move(c)); c1.swap(c2);&#125;test_moveable(list&lt;MyString&gt;());test_moveable(list&lt;MyStrString&gt;());// 另向思考:在没有iterator和traits的情况下// template语法能够在模板接受一个template参数Container时，当Container本身又是个class template，能去除Container的template参数 // 例如一个vector&lt;string&gt;，能够取出其元素类型string// 使用模板模板参数template template parameter 10 模板模板参数template template parameter 在推导模板模板参数时，不会通过模板实参推导模板化名 模板模板参数的使用需要配合模板化名 123456789101112131415161718192021222324252627282930// 单独模板编译通过template&lt;typename T, template&lt;class&gt; class Container&gt;class XCls&#123; private: Container&lt;T&gt; c; public: XCls()&#123; for(long i = 0; i&lt;SIZE;++i) c.insert(c.end(),T()); output_static_data(T()); Container&lt;T&gt; c1(c); Container&lt;T&gt; c2(std::move(c)); c1.swap(c); &#125;&#125;;// 相当于template&lt;typename T, template&lt;class T&gt; class Container&gt;// 添加参数后，编译不通过XCls&lt;MyString, vector&gt; c1;// 由于在推导模板模板参数时，不会通过模板实参推导模板化名// 解决方法，传递模板化名// 不能再function body之内声明template&lt;typename T&gt;using Vec=vector&lt;T,allocator&lt;T&gt;&gt;;XCls&lt;Mystring, Vec&gt; c1; 11 类型别名、noexcept、override、final 11.1 类型别名 类型别名(Type Alias)类似于typedef，两者之间没有任何差别 标准库中&lt;string&gt;和&lt;string_fwd.h&gt;中都typedef basic_string&lt;char&gt; string; 12345678910111213141516171819// -----------// 类型别名(Type Alias)// typedef void (*func)(int, int);using func = void(*)(int, int);// the name &#x27;func&#x27; now denotes a pointer to functionvoid example(int, int)&#123;&#125;func fn = example;// type Alias can introuce a member typedef name template&lt;typename T&gt;struct Container&#123; using value_type = T;&#125;// Alias templatetemplate&lt;class CharT&gt; using mystring = std::basic_string&lt;CharT,std::char_traits&lt;CharT&gt;&gt;;mystring&lt;char&gt; str; using的用途 using引用命名空间或命名空间中的成员 using namespace std using std::count using声明类成员 using _Base::_M_allocate; using用来声明类型别名或模板别名 11.2 noexcept noexcept保证函数不抛出异常 可跟上小括号表明条件 ==如果异常没有被处理，程序将调用std::terminate()，其中调用std::abort()终止程序 必须通知C++移动构造函数和析构函数不抛出异常，然后当vector成长时移动构造函数将被调用 若移动构造函数不是noexcept的就无法使用它，因为不能保证异常能被正确的处理 函数只要有move function，必须保证函数不会抛出异常且声明noexcept 成长容器(会发生内存重新分配)只有两种：vector和deque 12345678910111213141516171819202122void foo() noexcept()// 相当于void foo() noexcept(true)void swap(Type&amp; x, Type&amp; y) noexcept(noexcept(x.swap(y)))&#123; x.swap(y);&#125;// 通知C++移动构造函数和析构函数不抛出异常class MyString&#123; private: char* _data; size_t _len; ... public: MyString(MyString&amp;&amp; str) noexcept : _data(str,_data),_len(str,_len)&#123;...&#125; MyString&amp; operator=(MyString&amp;&amp; str) noexcept &#123;...return *this;&#125; ...&#125; 11.3 override 123456789101112131415struct Base&#123; virtual void vfunc(float)&#123;&#125;&#125;;struct Derived1 : Base&#123; virtual void vfunc(int)&#123;&#125; // 创建了一个新的函数&#125;// 使用override可以使编译器进行侦错struct Derived2 : Base&#123; virtual void vfunc(int) override&#123;&#125; // 错误:并没有override virtual void vfunc(float) override&#123;&#125; // 正确&#125; 11.4 final 被final关键字修饰的类不能继承，为继承体系中的最后一个版本 被final关键字修饰的虚函数不能重写 1234567891011121314struct Base1 final&#123;&#125;;// final类不能被继承struct Derived1 : Base1&#123;&#125;;struct Base2&#123; virtual void f() final;&#125;// final虚函数不能被重写struct Derived2&#123; void f() // 错误&#125;; 12 decltype 使用decltype可以使编译器找出表达式的类型 然而存在的typeof的实现并不完整，故C++11导入了decltype 在C++11之前，使用typeof可以得到对象的类型，但不能使用其创建对象，只能做打印输出等操作；而decltype完善了该操作 decltype的用处 用于定义一个表达式类型的 用于声明返回类型 用于元编程(模板中的各种操作)或传递lambda表达式的类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// decltype使用范例map&lt;string, float&gt; coll;decltype(coll) :: value_type elem;// 用来声明返回类型template&lt;typename T1, typename T2&gt;decltype(x+y) add(T1 x, T2 y);// 在C++11之后，返回类型可以声明在函数参数列表之后template&lt;typename T1, typename T2&gt;auto add(T1 x, T2 y) -&gt; decltype(x+y);// lambda表达式[...](...)mutable throwSpec -&gt; retType&#123;...&#125;// ---------// 第二种用法，用于元编程template&lt;typename T&gt;void test18_decltype(T obj)&#123; map&lt;string, float&gt;::value_type elem1; // 当手上有type，可以取其inner typedef map&lt;string, float&gt; coll; decltype(coll)::value_type elem2; // 面对obj取其class type的inner typedef // 因为如今可以使用decltype // 有了decltype可以这样 typedef typename decltype(obj)::iterator iType; typedef typename T::iterator iType; decltype(obj) anotherObj(obj);&#125;// 传递，编译失败test18_decltype(complex&lt;int&gt;()); // 编译失败// complex没有迭代器// --------------------------// 第三种用法，用于lambda表达式auto cmp = [](const Person&amp; p1, const Person&amp; p2)&#123; return p1.lastname()&lt;p2.lastname() || (p1.lastname() == p2.lastname() &amp;&amp; p1.firstname()&lt;p2.firstname()); &#125;;...std::set&lt;Person, decltype(cmp)&gt; coll(cmp);// 在lambda表达式中，常常只有object，没有type，可以使用decltype 13 lambda表达式 C++11允许使用lambda定义inline函数，可以被用来一个参数或一个本地对象 lambda改变了C++标准库的使用方式 lambda为一个函数定义，可以被定义在表达式内部作为一个内联函数使用 lambda的类型为一个匿名的函数对象，每个Lambda表达式是独一无二的 声明一个这种类型的对象，需要用模板或者auto关键字 如果需要Lambda表达式的类型，使用decltype，比如需要传递Lambda表达式作为散列准则或排序准则，分类准则 decltype的第三种用途跳转至decltype关键字 Lambda没有默认的构造函数，没有赋值操作 所以需要一个排序准则时，一个定义函数对象的类会更加明显 函数对象是对于自定义STL算法和其函数是一种重要的方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// lambda表达式[...](...)mutable throwSpec -&gt; retType&#123;...&#125;// []为导入器，为取用外部的变量，可传值或传引用，加上&amp;为传引用 // [=,&amp;y]表明接受外界所有的变量(不常用，不易被理解)// ()为参数；* 为可选选项，若下面三个都不写则()可不写// * mutable表示[]中的变量可被改写// * throwSpec为抛出的异常// * retType为返回类型// &#123;&#125;中可以声明静态变量，可以声明变量，可以指定返回变量[]&#123; std::cout &lt;&lt; &quot;hello lambda&quot; &lt;&lt; std::endl;&#125;() //加上()表示直接调用// 或者auto I = []&#123; std::cout &lt;&lt; &quot;hello lambda&quot; &lt;&lt; std::endl;&#125;;...I(); //调用lambda表达式// ----// 例子int id = 0;auto f = [id]() mutable &#123; std::cout &lt;&lt; &quot;id: &quot; &lt;&lt; id &lt;&lt; std::endl; ++id; // 不写mutable则id不可以++&#125;id = 42;f(); //0f(); //1f(); //2std::cout &lt;&lt; id &lt;&lt; std::endl; //42// 该例子中id传递为id=0时的id，并不是外部id=42// 版本2int id = 0;auto f = [&amp;id](int param)&#123; std::cout &lt;&lt; &quot;id: &quot; &lt;&lt; id &lt;&lt; std::endl; ++id;++param; //OK // 不写mutable则id不可以++&#125;id = 42;f(7); //id 42;param 7f(7); //id 43;param 8f(7); //id 44;param 9std::cout &lt;&lt; id &lt;&lt; std::endl; //42// 版本3int id = 0;auto f = [id]()&#123; std::cout &lt;&lt; &quot;id: &quot; &lt;&lt; id &lt;&lt; std::endl; ++id; // !报错:不写mutable则id不可以++&#125;// ----// 例子int tobefound = 5;auto lambda1 = [tobefound](int val) &#123;return val == tobefound;&#125;;// --------------------------// decltype的第三种用法，用于lambda表达式auto cmp = [](const Person&amp; p1, const Person&amp; p2)&#123; return p1.lastname()&lt;p2.lastname() || (p1.lastname() == p2.lastname() &amp;&amp; p1.firstname()&lt;p2.firstname()); &#125;;...std::set&lt;Person, decltype(cmp)&gt; coll(cmp);// --------------------// 例子(自定义标准库算法)vector&lt;int&gt; vi &#123;5,28,50,83,70,590,245,59,24&#125;;int x = 30;int y = 100;vi.erase(remove_if(vi.begin(), vi.end(), [x,y](int n) &#123;return x&lt;n &amp;&amp; n&lt;y;&#125; ), vi.end() );for(auto i:vi) cout &lt;&lt; i&lt;&lt; &#x27; &#x27;;cout &lt;&lt; endl; 14 可变模板(Variadic Templates) 谈的是template，包括function template和class template 变化的是模板参数 参数个数：利用参数个数的逐一递减，实现递归函数调用 参数类型：利用参数个数的逐一递减导致参数类型也逐一递减的特性，实现递归继承或递归组合，以class template完成 参数类型相同但个数不限可以使用initializer_list&lt;T&gt;，不必要使用可变模板 递归调用处理的都是参数，使用函数模板 递归继承处理的都是类型，使用类模板 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188void func()&#123;/* ... */&#125;template&lt;typename T, typename... Type&gt;void func(const T&amp; firstArg, const Type&amp;... args)&#123; func(args...);&#125;// 注意...的位置// ---// 例1void printX()&#123;&#125;// 1template&lt;typename T, typename... Types&gt;void printX(const T&amp; firstArg, const Type&amp;...args)&#123; cout &lt;&lt; firstArg &lt;&lt; endl; // 使用sizeof...(args)知道args参数有几个 printX(args...);&#125;// 3template&lt;typename... Type&gt;void printX(const Type&amp;... args)&#123;/* ...*/&#125;print(7.5, &quot;hello&quot;,bitset&lt;16&gt;(377),42);// 1和3可以并存不产生歧义，1更加特化，3更加泛化，3一般永远不会被调用// ---// 例2// 使用variadic templates重写printf()int* pi = new int;printf(&quot;%d %s %p %f\\n&quot;, 15, &quot;this is Ace&quot;, pi, 3.1415926);template&lt;typename T, typename... Args&gt;void printf(const char* s, T value, Args... args)&#123; while(*s)&#123; if(*s==&#x27;%&#x27; &amp;&amp; *(++s)!=&#x27;%&#x27;)&#123; std::cout &lt;&lt; value; printf(++s, args...); return; &#125; std::cout &lt;&lt; *s++; &#125; throw std::logic_error(&quot;extra argments provided to print&quot;);&#125;// 最后一个没有其他参数的版本void printf(const char* s)&#123; while(*s)&#123; if(*s==&#x27;%&#x27; &amp;&amp; *(++s)!=&#x27;%&#x27;) throw std::runtime_error(&quot;invalid format string: missing argment&quot;); std::cout &lt;&lt; *s++; &#125;&#125;// ---// 例3// 使用initializer_list实现类型相同个数不同的参数传递// ---// 例4// 使用variadic template实现maximumint maximum(int n)&#123; return n;&#125;template&lt;typename... Args&gt;int maximum(int n, Args... args)&#123; return std::max(n, maximum(args...));&#125;// ---// 例5// 以易于一般的方式处理first元素和last元素(头尾元素)cout &lt;&lt; make_tuple(7.5,string(&quot;hello&quot;),bitset&lt;16&gt;(377),42)// 想要输出[7.5,hello,000000010111001,42]// 需要指导处理的元素的index，使用sizeof...()获得元素个数，以get&lt;index&gt;(t)取出元素并将其index++// 首先操作符&lt;&lt;重载// output operator for tupletemplate&lt;typename... Args&gt;ostream&amp; operator&lt;&lt;(ostream&amp; os, const tuple&lt;Args...&gt;&amp; t)&#123; os&lt;&lt;&quot;[&quot;; PRINT_TUPLE&lt;0,sizeof...(Args),Args...&gt;::print(os,t); return os &lt;&lt; &quot;]&quot;;&#125;template&lt;int IDX, int MAX, typename... Args&gt;struct PRINT_TUPLE&#123; static void print(ostream&amp; os, const tuple&lt;Args...&gt;&amp; t)&#123; os &lt;&lt; get&lt;IDX&gt;(t) &lt;&lt; (IDX+1==MAX?&quot;&quot;:&quot;,&quot;); PRINT_TUPLE&lt;IDX,MAX,Args...&gt;::print(os,t); &#125;&#125;template&lt;int MAX, typename... Args&gt;struct PRINT_TUPLE&lt;IDX,MAX,Args...&gt;&#123; static void print (std::ostream&amp; os, const tuple&lt;Args...&gt;&amp; t)&#123; &#125;;&#125;// ---// 例6// 用于递归继承template&lt;typename... Values&gt; class tuple;template&lt;&gt; class tuple()&#123; &#125;;template&lt;typename Head, typename... Tail&gt;class tuple&lt;Head,Tail...&gt;: private tuple&lt;Tail...&gt;&#123; typedef tuple&lt;Tail...&gt; inherited; public: tuple()&#123;&#125; tuple(Head v, Tail... vtail) : m_head(v), inherited(vtail...) &#123; /*这里是initialization_list*/ &#125; typename Head::type head() &#123;return m_head;&#125; // 获得Head的类型使用Head::type并加上typename inherited&amp; tail() &#123;return *this;&#125; // tail()转型为inherited返回 protected: Head m_head;&#125;tuple&lt;int, float, string&gt; t(41, 6.3, &quot;nico&quot;);// 该程序在typename Head::type head() &#123;return m_head;&#125;行报错，原因在于int等类型的::type处报错// 考虑使用decltype()实现template&lt;typename... Values&gt; class tuple;template&lt;&gt; class tuple()&#123; &#125;;template&lt;typename Head, typename... Tail&gt;class tuple&lt;Head,Tail...&gt;: private tuple&lt;Tail...&gt;&#123; typedef tuple&lt;Tail...&gt; inherited; protected: Head m_head; // 若没有移动上去，编译器不认识m_head public: tuple()&#123;&#125; tuple(Head v, Tail... vtail) : m_head(v), inherited(vtail...) &#123; /*这里是initialization_list*/ &#125; auto head() -&gt; decltype(m_head) &#123;return m_head;&#125; inherited&amp; tail() &#123;return *this;&#125; // tail()转型为inherited返回&#125;// 该类型返回的类型就是Headtemplate&lt;typename... Values&gt; class tuple;template&lt;&gt; class tuple()&#123; &#125;;template&lt;typename Head, typename... Tail&gt;class tuple&lt;Head,Tail...&gt;: private tuple&lt;Tail...&gt;&#123; typedef tuple&lt;Tail...&gt; inherited; public: tuple()&#123;&#125; tuple(Head v, Tail... vtail) : m_head(v), inherited(vtail...) &#123; /*这里是initialization_list*/ &#125; Head head()&#123;return m_head;&#125; inherited&amp; tail() &#123;return *this;&#125; // tail()转型为inherited返回 protected: Head m_head;&#125;// ---// 例7// 递归组合// 将不同的东西组合成一个typetemplate&lt;typename... Values&gt; class tup;template&lt;&gt; class tup&lt;&gt; &#123;&#125;;template&lt;typename Head, typename... Tail&gt;class tup&lt;Head, Tail...&gt;&#123; typedef tup&lt;Tail...&gt; composited; protected: composited m_tail; Head m_head; public: tup()&#123;&#125; tup(Head v, Tail... vtail) : m_tail(vtail...), m_head(v)&#123;&#125; Head head() &#123;return m_head;&#125; composited&amp; tail() &#123;return m_tail;&#125;&#125; 15 标准库源代码分布 visual C++中源代码分布在…\\include和…\\include\\cliext 16 右值引用和move语义 右值引用帮助解决没有必要的拷贝操作，并保证高效率 当=右边是一个右值，左边的接收端可以偷(move)右值的资源而不需要重新分配资源 左值：变量，可以出现在operator=左侧者 右值：只能出现在operator=右侧者，不可以出现在=左侧 临时对象为右值，临时对象没有名称故不能进行赋值为右值 函数返回的为右值，不可以对右值取地址 1234567891011121314151617181920212223242526// 以int试验int a = 9;int b = 4;a = b;b = a;a = a+b;a+b = 42; // a+b为右值，故报错// 以string试验string s1(&quot;Hello&quot;);string s2(&quot;World&quot;);s1+s2 = s2; // 编译通过string() = &quot;World&quot; // 可以对临时对象赋值// 以complex试验complex&lt;int&gt; c1(3,8),c2(1,0);c1+c2 = complex&lt;int&gt;(4,9); // 编译通过complex&lt;int&gt;() = complex&lt;int&gt;(4,9); // 可以对临时对象赋值// 右值只能出现在operator=右侧int foo()&#123;return 5;&#125;...int x = foo(); // okint *p = &amp;foo(); // !错误，不可对右值取地址 移动构造函数只需要浅拷贝指针，不需要重新分配内存空间 为了安全需要打断原来的指针，将原来的指针设置为nullptr 被移动之后的原对象不能使用，可以使用临时对象(右值) 若为左值，在确定左值不再使用的前提下，可以将左值转换为右值从而使用移动构造函数(std::move) 17 完美的转交 1234567891011121314151617181920212223242526// 不完美的转交：右值属性被抛弃void process(int&amp; i)&#123; cout &lt;&lt; &quot;provess(int&amp; i):&quot; &lt;&lt; i &lt;&lt; endl;&#125;void process(int&amp;&amp; i)&#123; cout &lt;&lt; &quot;provess(int&amp;&amp; i):&quot; &lt;&lt; i &lt;&lt; endl;&#125;int a = 0;process(a); //provess(int&amp; i):0provess(1); //provess(int&amp;&amp; i):1process(move(a)); //provess(int&amp; i):0void forward(int&amp;&amp; i)&#123; cout &lt;&lt; &quot;forward(int&amp;&amp; i):&quot; &lt;&lt; i &lt;&lt; endl; process(i);&#125;forward(2); //forward(int&amp;&amp; i): 0, provess(int&amp; i):2// 右值经forward()函数传给另一个函数变成了左值// 原因是在传递过程中变成了另一个name objectforward(move(a));// 右值经forward()函数传给另一个函数变成了左值// ! forward(a); // 左值不能转换为一个右值 完美的转交：完美转交让一个单一的接受n个任意参数的函数模板，并透明地将参数转发给另一个任意函数。参数的性质(可修改的，Const，左值或右值)在这个转发过程中被保留 使用std::forward&lt;&gt;()保留参数的性质 123456// 完美的转交template&lt;typename T1, typename T2&gt;void functionA(T1&amp;&amp; t1, T2&amp;&amp; t2)&#123; functionB(std::forward&lt;T1&gt;(t1), std::forward&lt;T2&gt;(t2));&#125; 18 写一个Move-aware类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109class MyString&#123; public: static size_t Dctor; static size_t Ctor; static size_t CCtor; static size_t CAsgn; static size_t MCtor; static size_t MAsgn; static size_t Dtor; private: char* _data; size_t _len; void _init_data(const char *s)&#123; _data = new char[_len+1]; memcpy(_data, s, _len); _data[_len] = &#x27;\\0&#x27;; &#125; public: MyString() : _data(NULL), _len(0) &#123;++Dctor;&#125; // constructor MyString(const char* p) : _len(strlen(p))&#123; ++Ctor; _init_data(p); &#125; // copy constructor MyString(const MyString&amp; str) : _len(str)&#123; ++CCtor; _inti_data(str._data); &#125; // move constructor,with noexcept MyString(MyString&amp;&amp; str) noexcept : _data(str.data), _len(str._len)&#123; ++MCtor; str._len = 0; str._data = NULL; //重要 &#125; // copy assignment MyString&amp; operator=(const MyString&amp; str)&#123; ++CAsgn; if(this != &amp;str)&#123; if(_data) delete _data; _len = str._len; _init_data(str._data); &#125;else&#123; &#125; return *this; &#125; // move assignment MyString&amp; operator=(MyString&amp;&amp; str) noexcept&#123; ++MAsgn; // 自我赋值检查 if(this != &amp;str)&#123; if(_data) delete _data; _len = str._len; _data = str._data; //move str._len = 0; str._data = NULL; //重要 &#125; return *this; &#125; // dtor virtual ~MyString()&#123; ++Dctor; if(_data)&#123; delete _data; &#125; &#125; bool operator&lt;(const MyString&amp; rhs) const&#123; //为了set return string(this-&gt;data)&lt;string(rhs); // 借用现成是事实std::string能够比较大小 &#125; bool operator==(const MyString&amp; rhs) const&#123; //为了set return string(this-&gt;_data)==string(rhs._data); // string能够判断相等与否 &#125; char* get() const &#123;return _data;&#125;&#125;;size_t MyString::Dctor = 0;size_t MyString::Ctor = 0;size_t MyString::CCtor = 0;size_t MyString::CAsgn = 0;size_t MyString::MCtor = 0;size_t MyString::MAsgn = 0;size_t MyString::Dtor = 0;namespace std&#123; // 必须放在std内 template&lt;&gt; struct hash&lt;MyString&gt;&#123; //为了unordered containers size_t operator()(const MyString&amp; str)&#123; return hash&lt;string&gt;() (str) // 借用现成的hash&lt;string&gt; &#125; &#125;&#125; 19 对容器的效能测试 在vector中，为什么实际构造的次数大于添加元素的个数 因为vector会成长，当vector不够时会成长导致搬移次数或拷贝次数增加 在list、deque、multiset和unordered_multiset中，构造函数调用的次数和添加元素的个数相同 且在deque、multiset和unordered_multiset中性能差别不大 是否具有move的函数对于vector影响较大 123456789101112131415161718192021222324252627282930313233343536#include&lt;typeinfo&gt;template&lt;typename T&gt;void output_static_data(const T&amp; myStr)&#123; cout &lt;&lt; &quot;CCtor=&quot; &lt;&lt; T::CCtor &lt;&lt; &quot;MCtor=&quot; &lt;&lt; T::MCtor &lt;&lt; &quot;CAsgn=&quot; &lt;&lt; T::CAsgn &lt;&lt; &quot;MAsgn=&quot; &lt;&lt; T::MAsgn &lt;&lt; &quot;Dtor=&quot; &lt;&lt; T::Dtor &lt;&lt; &quot;Ctor=&quot; &lt;&lt; T::Ctor &lt;&lt; &quot;DCtor=&quot; &lt;&lt; T::DCtor &lt;&lt; endl;&#125;template&lt;typename M, typename NM&gt;void test_moveable(M c1, NM c2, long&amp; value)&#123; char buf[10]; // 测试moveable typedef typename iterator_traits&lt;typename M::iterator&gt;::value_type V1type; clock_t timeStart = clock(); for(long i = 0; i&lt; value; ++i)&#123; snprintf(buf, 10, &quot;%d&quot;, rand()); auto ite = c1.end(); c1.insert(ite, V1type(buf)); &#125; cout &lt;&lt; &quot;construction, milli-seconds:&quot; &lt;&lt; (clock()-timeStart); cout &lt;&lt; &quot;size()=&quot; &lt;&lt; c1.size() &lt;&lt; endl; output_static_data(*(c1.begin())); M cl1(c1); M Cl2(std::move(c1)); cl1.swap(cl2); // 测试none-test_moveable ...&#125; 20 容器-结构与分类 Sequence Container Array Vector Deque List Forward-List Associative Container Set/Multiset Map/Multimap Unordered Container Unordered Set/Multiset Unordered Map/Multimap 21 容器hashtable 在hashtable中，若元素的个数大于篮子的个数，则打断重新建立篮子(rehashing)，篮子的个数为对应的最大素数 元素落在哪个篮子的计算方法(取余数)：MOD(元素/篮子个数) 元素为对象，为hash function计算出的hash code 22 hash function 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 使用内置的hash functionvoid* pi = (void*)(new int(100)); cout &lt;&lt; hash&lt;int&gt;()(123) &lt;&lt; endl; cout &lt;&lt; hash&lt;long&gt;()(123L) &lt;&lt; endl; cout &lt;&lt; hash&lt;string&gt;()(string(&quot;Ace&quot;)) &lt;&lt; endl; cout &lt;&lt; hash&lt;const char*&gt;()(&quot;Ace&quot;) &lt;&lt; endl; cout &lt;&lt; hash&lt;char&gt;()(&#x27;A&#x27;) &lt;&lt; endl; cout &lt;&lt; hash&lt;float&gt;()(3.1415926) &lt;&lt; endl; cout &lt;&lt; hash&lt;double&gt;()(3.1415926) &lt;&lt; endl; cout &lt;&lt; hash&lt;void*&gt;()(pi) &lt;&lt; endl;// G2.9// 泛化template&lt;class Key&gt; struct hash() &#123;&#125;;// 特化// __STL_TEMPLATE_NULL等效于template&lt;&gt;__STL_TEMPLATE_NULL struct hash&lt;char&gt;&#123; size_t operator() (char x) const &#123;return x;&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;short&gt;&#123; size_t operator() (short x) const &#123;return x;&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;unsigned short&gt;&#123; size_t operator() (unsigned short x) const &#123;return x;&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;int&gt;&#123; size_t operator() (int x) const &#123;return x;&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;unsigned int&gt;&#123; size_t operator() (unsigned int x) const &#123;return x;&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;long&gt;&#123; size_t operator() (long x) const &#123;return x;&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;unsigned long&gt;&#123; size_t operator() (unsigned long x) const &#123;return x;&#125;&#125;;// G4.9中提供stringinline size_t __stl_hash_string(const char* s)&#123; unsigned long h = 0; for(; *s; ++s) h = 5*h + *s; return size_t(h);&#125;__STL_TEMPLATE_NULL struct hash&lt;char*&gt;&#123; size_t operator() (char* s) const &#123;return __stl_hash_string(s);&#125;&#125;;__STL_TEMPLATE_NULL struct hash&lt;const char*&gt;&#123; size_t operator() (const char* s) const &#123;return __stl_hash_string(s);&#125;&#125;;// G4.9// function_hash.h中实现hash_function// 字符串string的hash_function在basic_string.h文件中实现 23 tuple tuple的大小为其中空间最大的元素的空间与元素个数的乘积(每个元素的空间为元素中占用空间最大的元素的占用空间) meta programing(元编程)：对类型进行编程 123456// 得到tuple的大小typedef tuple&lt;int, float, string&gt; TupleType;cout &lt;&lt; tuple_size&lt;TupleType&gt;::value &lt;&lt; endl; //3// 使用tuple_elementtuple_element&lt;1,TupleType&gt;::type f1 = 1.0;","categories":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/tags/C/"}]},{"title":"杂项知识记录","slug":"杂项知识记录","date":"2022-05-07T08:19:50.000Z","updated":"2023-05-07T08:22:40.835Z","comments":true,"path":"2022/05/07/杂项知识记录/","link":"","permalink":"http://jay1060950003.github.io/2022/05/07/%E6%9D%82%E9%A1%B9%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/","excerpt":"","text":"深度学习 TensorRT介绍 TensorRT采用C++开发, 能使深度学习模型在GPU上进行低延迟、高吞吐量的部署 Pytorch的支持需要先转换成中间模型ONNX格式 工作流程 首先输入一个训练好的 FP32 模型文件, 并通过 parser 等方式输入到 TensorRT 中做解析, 解析完成后 engin 会进行计算图优化 得到优化好的 engine 可以序列化到内存(buffer)或文件(file), 读的时候需要反序列化, 将其变成 engine以供使用 在执行的时候创建 context, 主要是分配预先的资源, engine 加 context 就可以做推理(Inference) 优化原理 算子融合（网络层合并） concat 层的消除; 对于 channel 维度的 concat 层, TensorRT 通过非拷贝方式将层输出定向到正确的内存地址来消除 concat 层, 从而减少内存访存次数 Kernel 可以根据不同 batch size 大小和问题的复杂度, 去自动选择最合适的算法；TensorRT 预先写了很多 GPU 实现, 有一个自动选择的过程; 其问题包括：怎么调用 CUDA 核心、怎么分配、每个 block 里面分配多少个线程、每个 grid 里面有多少个 block FP32-&gt;FP16,INT8,INT4：低精度量化, 模型体积更小、内存占用和延迟更低等 不同的硬件如 P4 卡还是 V100 卡甚至是嵌入式设备的卡, TensorRT 都会做对应的优化, 得到优化后的 engine 卷积网络的压缩方法 来源旷世学术分享-张祥雨：高效轻量级深度模型的研究和实践 低秩近似 原理: 将权值矩阵表示为若干个低秩矩阵的组合, 其中每个低秩矩阵可以分解为小规模矩阵的乘积, 当秩取值很小时,能大幅降低总体的存储和计算开销 方法: 使用结构化矩阵进行低秩分解 奇异值分解(SVD分解) 剪枝与稀疏约束 方法1：对不重要的神经元进行剪枝随后微调网络 方法2：对低于某个阈值的权重连接全部剪枝随后微调网络 方法3：利用稀疏约束对网络进行剪枝(思路是在网络的优化目标中加入权重的稀疏正则项, 使得训练时网络的部分权重趋向于 0 , 而这些 0 值就是剪枝的对象) 参数量化 浮点转定点, 加快运算速率同时减少内存和存储空间的占用保证模型精度损失在可接受的范围内 二值化网络 知识蒸馏 先训练好一个 teacher 网络, 然后将 teacher 的网络的输出结果 qqq 作为 student 网络的目标, 训练 student 网络, 使得 student 网络的结果 ppp 接近 qqq, 因此, student 网络的损失函数为 L=CE(y,p)+αCE(q,p)L = CE(y,p)+\\alpha CE(q,p)L=CE(y,p)+αCE(q,p), yyy 是真实标签的 onehot 编码, qqq 是 teacher 网络的输出结果, ppp 是 student 网络的输出结果 使用softmax-T(软标签计算公式)解决teacher网络输出的softmax结果q置信度较高的问题(无法将teacher网络学到的数据的相似信息传达给student网络, 因为概率接近0) softmax-T: qi=zi/T∑jzj/Tq_{i} = \\frac{z_{i}/T}{\\sum_{j}z_{j}/T}qi​=∑j​zj​/Tzi​/T​ T 的取值会影响最终的结果, 一般而言, 较大的 T 能够获得较高的准确度, T(蒸馏温度参数)属于知识蒸馏模型训练超参数的一种. T 是一个可调节的超参数、T 值越大、概率分布越软（论文中的描述）, 曲线便越平滑 浅层网络 设计浅层网络MobilenetV2、ShuffleNetv2等作为backbone YOLOv4论文中的相关工作 Bag of freebies(Tricks) 不改变模型大小, 主要针对输入和loss做的优化工作 数据增强(data augmentation): 提升输入图像的可变性, 使模型在不同环境中会有更高的鲁棒性 逐像素调节： 光度失真: 调节亮度、对比度、色调、饱和度噪声 几何失真：随机缩放、裁剪、翻转、旋转 模拟对象遮挡 随机擦除(random-erase)和Cutout方法：随机选择图像中的矩形区域, 并填充零的随机或互补值 捉迷藏(hide-and-seek)和网格遮罩(grid-mask)：随机或均匀地选择图像中的多个矩形区域, 并将它们替换为所有的 zeros(类似Dropout等在feature层面的操作) 多个图像一起执行数据增强 Mixup方法：使用两个图像以不同的系数比值相乘后叠加, 然后使用这些叠加的比值来调整标签 CutMix方法：将裁切后的图像覆盖到其他图像的矩形区域, 并根据混合区域的大小调整标签 style transfer GAN方法用于数据扩充、减少 CNN 所学习的纹理偏差 针对解决数据集中予以分布可能存在偏差的问题(semantic distribution in the dataset may have bias) 类别不平衡(imbalance between different classes) 两阶段对象模型： 困难负样本挖掘(hard negative example mining)或在线困难样本挖掘(online hard example mining (OHEM)) 一阶段检测器(密集检测架构(prediction architecture)): Focal Loss决绝类别不平衡 很难用one-hot hard representation表达不同类别之间的关联程度, 但执行标记时通常使用这种方法 标签平滑(label smoothing)[Rethinking the inception architecture for computer vision] 知识蒸馏设置标签细化网络[Label refinement network for coarse-to-fine semantic segmentation] 针对边界框(BBox)回归的目标函数 传统目标检测器使用均方根误差MSE对中心点坐标以及高度和宽度直接执行回归, 或对基于锚的方法估计相应的偏移量, 没有考虑对象本身的完整性 IOU损失是尺度不变的表示, 所以可以解决传统方法计算 {x,y,w,h}\\lbrace x, y, w, h \\rbrace{x,y,w,h} 的 L1L1L1 或 L2L2L2 损失时, 损失会随着尺度增加的问题 GIoU损失除了覆盖区域外还包括对象的形状和方向, 分母为同时包含了预测框和真实框的最小框的面积 DIoU损失还考虑了对象中心的距离 CIoU损失同时考虑了重叠区域, 中心点之间的距离和纵横比, 在 BBox 回归问题上可以实现更好的收敛速度和准确性. Bag of sepcials(即插即用模块+后处理方法) 仅增加少量推理成本但可以显著提高目标检测器准确性的插件模块或后处理方法 一般而言, 插件模块用于增强模型中的某些属性, 例如扩大感受野, 引入注意力机制或增强特征集成能力等, 而后处理是用于筛选模型预测结果的方法 增大感受野模块 常用模块: SPP, ASPP和RFB SPP 起源于空间金字塔匹配（SPM）,SPM 的原始方法是将特征图分割为几个d×dd\\times dd×d个相等的块, 其中ddd可以为 {1,2,3,..}\\lbrace 1,2,3, .. \\rbrace{1,2,3,..}, 从而形成空间金字塔. SPP将SPM集成到CNN中, 并使用最大池化操作. 原始的SPP模块是输出一维特征向量, 在FCN网络中不可行 引入注意力机制 目标检测中常用的注意力模块为channel-wise注意力和point-wise注意力, 代表模型为SE和SAM 特征融合或特征集成 早期的实践是使用 skip connection 或 hyper-column 将低层物理特征集成到高层语义特征 由于诸如 FPN 的多尺度预测方法已变得流行, 因此提出了许多集成了不同特征金字塔的轻量级模块. 这种模块包括 SFAM, ASFF和 BiFPN. SFAM 的主要思想是使用 SE 模块在多尺度级联特征图上执行通道级级别的加权 对于 ASFF, 它使用softmax 作为逐点级别权重, 然后添加不同比例的特征图 在BiFPN 中, 提出了多输入加权残差连接以执行按比例的级别重新加权, 然后添加不同比例的特征图 激活函数 良好的激活函数可以使梯度在反向传播算法中得以更有效的传播, 同时不会引入过多的额外计算成本 ReLU 激活函数, 实质上解决了传统的tanh 和 sigmoid 激活函数中经常遇到的梯度消失问题 LReLU 和 PReLU 的主要目的是解决当输出小于零时 ReLU 的梯度为零的问题 ReLU6 和 Hard-Swish 是专门为量化网络设计的 SELU 激活函数来对神经网络进行自归一化 后处理 最开始常用 NMS 来剔除重复检测的 BBox, 但是 NMS 会不考虑上下文信息（可能会把一些相邻检测框框给过滤掉）, Soft NMS, 为相邻检测框设置一个衰减函数而非彻底将其分数置为零 DIoU NMS 则是在 soft NMS 的基础上将中心距离的信息添加到 BBox 筛选过程中 值得一提的是, 因为上述后处理方法都没有直接涉及捕获的图像特征, 因此在后续的 anchor-free 方法中不再需要 NMS 后处理","categories":[{"name":"Misc","slug":"Misc","permalink":"http://jay1060950003.github.io/categories/Misc/"}],"tags":[{"name":"Misc","slug":"Misc","permalink":"http://jay1060950003.github.io/tags/Misc/"}]},{"title":"操作系统","slug":"计算机基础知识/操作系统","date":"2022-05-05T07:53:37.000Z","updated":"2023-05-06T16:12:59.036Z","comments":true,"path":"2022/05/05/计算机基础知识/操作系统/","link":"","permalink":"http://jay1060950003.github.io/2022/05/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"引言 《极客时间操作系统45讲》学习笔记","text":"引言 《极客时间操作系统45讲》学习笔记 1 从hello到另一个hello 1.1 程序的运行过程:从代码到机器运行 程序编译过程 1234567891011// HelloWorld.c#include &lt;studio.h&gt;int main()&#123; printf(&quot;hello world!&quot;); return 0;&#125;// 编译gcc HelloWorld.c -o HelloWorld// 运行./HelloWorld 使用命令编译:gcc HelloWorld.c -o HelloWorld gcc只是完成编译工作的驱动程序,根据编译流程分别调用预处理程序,编译程序,汇编程序,链接程序来完成具体工作 手动控制编译流程 gcc -E HelloWorld.c -o HelloWorld.i预处理,加入头文件,替换宏 gcc -S HelloWorld.i -o HelloWorld.s编译,包含预处理,将C转换成汇编程序 gcc -c HelloWorld.s -o HelloWorld.o汇编,包含预处理和编译,将汇编程序转换成可链接的二进制程序 gcc HelloWorld.o -o HelloWorld…链接,包含以上所有操作,将可链接的二进制程序和其他库链接形成可执行的程序文件 程序装载执行 冯诺依曼体系计算机结构 输入设备 存储器 运算器 控制器 输出设备 更形象地将HelloWorld程序装入原型计算机 使用gcc -Og -S HelloWorld可得到汇编代码 使用objdump -d HelloWorld,得到/lesson01/HelloWorld.dump,其中含有库代码 1.2 实现一个最简单的内核 PC机的引导流程 PC上电后,执行BIOS固件程序,负责检测和初始化CPU,内存及主板平台,然后加载引导设备的第一个扇区数据,到0x7c00地址开始的内存空间,再跳转到0x7c00处执行指令 Hello OS引导汇编代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586MBT_HDR_FLAGS EQU 0x00010003MBT_HDR_MAGIC EQU 0x1BADB002 ;多引导协议头魔数MBT_HDR2_MAGIC EQU 0xe85250d6 ;第二版多引导协议头魔数global _start ;导出_start符号extern main ;导入外部的main函数符号[section .start.text] ;定义.start.text代码节[bits 32] ;汇编成32位代码_start:jmp _entryALIGN 8mbt_hdr:dd MBT_HDR_MAGICdd MBT_HDR_FLAGSdd -(MBT_HDR_MAGIC+MBT_HDR_FLAGS)dd mbt_hdrdd _startdd 0dd 0dd _entry;以上是GRUB所需要的头ALIGN 8mbt2_hdr:DD MBT_HDR2_MAGICDD 0DD mbt2_hdr_end - mbt2_hdrDD -(MBT_HDR2_MAGIC + 0 + (mbt2_hdr_end - mbt2_hdr))DW 2, 0DD 24DD mbt2_hdrDD _startDD 0DD 0DW 3, 0DD 12DD _entryDD 0DW 0, 0DD 8mbt2_hdr_end:;以上是GRUB2所需要的头;包含两个头是为了同时兼容GRUB、GRUB2ALIGN 8_entry:;关中断cli;关不可屏蔽中断in al, 0x70or al, 0x80out 0x70,al;重新加载GDTlgdt [GDT_PTR]jmp dword 0x8 :_32bits_mode_32bits_mode:;下面初始化C语言可能会用到的寄存器mov ax, 0x10mov ds, axmov ss, axmov es, axmov fs, axmov gs, axxor eax,eaxxor ebx,ebxxor ecx,ecxxor edx,edxxor edi,edixor esi,esixor ebp,ebpxor esp,esp;初始化栈,C语言需要栈才能工作mov esp,0x9000;调用C语言函数maincall main;让CPU停止执行指令halt_step:haltjmp halt_stepGDT_START:knull_dsc: dq 0kcode_dsc: dq 0x00cf9e000000ffffkdata_dsc: dq 0x00cf92000000ffffk16cd_dsc: dq 0x00009e000000ffffk16da_dsc: dq 0x000092000000ffffGDT_END:GDT_PTR:GDTLEN dw GDT_END-GDT_START-1GDTBASE dd GDT_START 代码分为4个部分 1-40行:汇编定义GRUB多引导协议头 44-52行:关闭中断,设定CPU的工作模式 54-73行:初始化CPU寄存器和C语言的运行环境 78-87行,GDT_START开始的,是CPU工作模式需要的数据 Hello OS的主函数 12345#include &quot;vgastr.h&quot;void main()&#123; printf(&quot;Hello OS!&quot;); return;&#125; 需要自己实现printf函数(在vgastr.h中) 控制计算机屏幕 显卡支持VESA标准 该标准具有两种工作模式:字符模式和图形模式 显卡为了兼容这种标准,需要提供VGABIOS固件程序 字符模式的工作细节 将屏幕分成24行,每行80个字节,将24*80个位置映射到以0xb8000地址开始的内存中,每两个字节对应一个字符,其中一个字节是字符的ASCII码,另一个字节为字符的颜色值 C语言是UTF8编码,对ASCII编码兼容,英文字符的ASCII编码和UTF8编码相等 12345678910111213void _strwrite(char* string)&#123; char* p_strdst = (char*)(0xb8000); while(*string)&#123; *p_strdst = *string++; p_strdst +=2; &#125; return;&#125;void printf(char* fmt,...)&#123; _strwrite(fmt); return;&#125; 编译和安装Hello OS 编译使用四条命令完成 跳转至命令 make工具 使用make工具程序,读取makefile文件,该文件写好了构建软件的程序,根据规则自动化构建程序 makefile文件的规则 首先由一个或者多个构建目标称为target 目标后面紧跟着用于构建该目标所需要的文件,目标下面是构建该目标所需要的命令及参数 第一次构建目标后,下一次执行make时,会根据该目标所依赖的文件是否更新决定是否编译该目标 若依赖文件没有更新,则不构建目标 123456789CC = gcc #定义一个宏CC 等于gccCFLAGS = -c #定义一个宏 CFLAGS 等于-cOBJS_FILE = file.c file1.c file2.c file3.c file4.c #定义一个宏.PHONY : all everything #定义两个伪目标all、everythingall:everything #伪目标all依赖于伪目标everythingeverything :$( OBJS_FILE) #伪目标everything依赖于OBJS_FILE,而OBJS_FILE是宏会被#替换成file.c file1.c file2.c file3.c file4.c%.o : %.c$(CC) $(CFLAGS) -o $@ $&lt; 代码解释 make规定#后面为注释 makefile定义宏 字符串后面跟一个=或:= 引用宏时使用$(宏名),宏最终会在宏出现的地方替换成相应的字符串 .PHONY表示定义伪目标 伪目标不代表一个真正的文件名,在执行 make 时可以指定这个目标来执行其所在规则定义的命令.但是伪目标可以依赖于另一个伪目标或者文件 编译 安装Hello OS 得到Hello OS.bin,在计算机启动时加载该文件,该过程称为安装 GRUB在启动时加载一个grub.cfg的文本文件,根据其中的内容执行相应的操作,其中包含启动项 将启动代码插入到/boot/grub/grub.cfg文件中,然后将Hello OS.bin复制到/boot/目录下,最终可启动Hello OS 1234567menuentry &#x27;HelloOS&#x27; &#123;insmod part_msdos #GRUB加载分区模块识别分区insmod ext2 #GRUB加载ext文件系统模块识别ext文件系统set root=&#x27;hd0,msdos4&#x27; #注意boot目录挂载的分区,这是我机器上的情况multiboot2 /boot/HelloOS.bin #GRUB以multiboot2协议加载HelloOS.binboot #GRUB启动HelloOS.bin&#125; 2 设计 2.1 内核结构与设计 内核是计算机资源的管理者 计算机资源分为硬件资源和软件资源 硬件资源包括,总线,CPU,内存,硬盘,网卡,显卡和各种IO 软件资源表示为计算机中的各种形式的数据 内核作为硬件资源和软件资源的管理者,内部组成在逻辑上大致为 管理CPU,由于CPU是执行程序的,而内核把运行时的程序抽象成进程,为进程管理 管理内存,分配释放内存 管理磁盘,合理组织文件形成文件系统 管理显卡,负责显示信息 管理网卡,完成网络通信,在内核中形成网络协议栈(网络组件) 管理各种IO设备 驱动程序:内核管理和控制硬件编写的对应与不同计算机的代码 宏内核结构 宏内核把管理进程的代码,管理内存的代码,管理各种IO设备的代码,文件系统的代码,图形系统代码以及其他功能模块的代码经过编译,最后链接在一起,形成一个大的可执行程序 该程序向用户应用软件提供一些接口(系统API函数) 该大程序在系统的特权模式下运行,该模式称为宏内核模式 宏内核提供内存分配功能的服务过程 应用程序调用内存分配的API函数 处理器切换到特权模式,开始运行内核代码 内核里的内存管理代码按照特定的算法,分配一块内存 把分配的内存块的首地址,返回给内存分配的API函数 内存分配的API函数返回,处理器开始运行用户模式下的应用程序,应用程序得到内存的首地址,使用这块内存 优点:性能极高,但目前没有人使用 缺点:没有模块化,没有扩展性,没有移植性,高度耦合,一旦一个组件有漏洞,内核的所有组件都可能出现问题 微内核结构 微内核架构内核功能尽可能少,只有进度调度,处理中断,内存空间映射,进程间通信等功能(不完成实际的功能) 实际的进程管理,内存管理,设备管理,文件管理等服务功能做成服务进程(实现宏内核提供的功能) 微内核定义了良好的进程间通信的机制：消息机制 应用程序请求相关服务,就向微内核发送一条与此服务对应的消息,微内核再将消息转发给相关的服务进程,服务进程完成相应的服务 服务进程的编程模式就是循环处理来自其他进程的消息,完成相关的服务功能 微内核提供内存分配功能的服务过程 应用程序发送内存分配的消息 处理器切换到特权模式,开始运行内核代码 微内核代码让当前进程停止运行,并根据消息包中的数据,确定消息发送给谁,分配内存的消息发送给内存管理进程 内存管理服务进程收到消息,分配一块内存 内存管理服务进程通过消息的形式返回分配内存块的地址给内核,等待下一条消息 微内核把包含内存地址的消息返回给发送内存分配消息的应用程序 处理器开始运行用户模式下的应用程序 优点:系统结构清晰利于协作开发,移植性好,代码量少,伸缩性好,扩展性好 缺点:性能较差 分离硬件的相关性 windows内核的HAL层,Linux内核的arch层是系统内核的一个分层 分层的目的和好处:屏蔽底层细节,使上层开发更加简单 分层的基本方法是增加一个抽象层,从而使得抽象层的上下两层地理发展 软件抽象层,分离硬件的相关性,将操作硬件和处理硬件功能差异的代码抽离,对外提供相应的接口,方便上层开发 进程调度模块(例子) 进程,操作系统为实现多任务而提出的能让每个进程在CPU上运行一小段时间,实现多任务同时运行的家乡 进程调度:从众多进程中选择一个将要运行的进程,轮转算法,优先级算法 进程切换:停止当前进程,运行新的进程,主要动作是保存当前进程上机器上下文,装载新进程的机器上下文 对于ARM硬件或x86硬件,进程切换相关的代码因为硬件平台的机器上下文不同而不同,故将进程切换放在一个独立的层中实现(硬件平台相关层),不同硬件平台只需要修改硬件相关层的代码即可,提高移植性 分离硬件相关性,将所有硬件平台相关的代码抽离放在独立硬件相关层中实现定义相关调用接口,在此层之上开发内核的其他代码,移植性增强 混合内核结构 分为3个层:内核接口层,内核功能层,内核硬件层 内核接口层,定义了一系列的接口 内核功能层,主要完成各种实际功能的各种模块 进程管理：主要是实现进程的创建、销毁、调度进程,设计几套数据结构用于表示进程和组织进程,实现进程调度算法 内存管理:在内核功能层中只有内存池管理,分两种内存池：页面内存池和任意大小的内存池 中断管理:中断回调函数安插到相关的数据结构中,发生中断就调用该函数 设备管理:用数据结构表示驱动程序模块、驱动程序本身、驱动程序创建的设备,最后把它们组织在一起,还要实现创建设备、销毁设备、访问设备的代码,这些代码最终会调用设备驱动程序,达到操作设备的目的 内核硬件层,具体硬件平台相关的代码 区别 操作系统内核没有任何设备驱动程序,甚至没有文件系统和网络组件,内核所实现的功能很少.吸取了微内核的优势,内核小出问题的可能性就少,扩展性就越强 同时,把文件系统、网络组件、其它功能组件作为虚拟设备交由设备管理,比如需要文件系统时就写一个文件系统虚拟设备的驱动,完成文件系统的功能,需要网络时就开发一个网络虚拟设备的驱动,完成网络功能 驱动一旦被装载,就是内核的一部分了,并不是像微内核一样作为服务进程运行.吸取了宏内核的优势,代码高度耦合,性能强劲 2.2 业界成熟的内核架构 Linux,全称GNU/Linux,支持类UNIX,POSIX标准接口,也支持多用户,多进程,多线程可以在多CPU的机器上运行 基本思想是,一起都是文件,每个文件都有确定的用途,包括用户数据,命令,配置参数,硬件设备等对于操作系统内核而言都被视为各种类型的文件 Linux系统的五大重要组件 系统 进程 内存 储存 网络 Darwin-XNU内核 苹果公司在2000年开发的开放源代码的操作系统 Darwin具有两个内核层:Mach层与BSD层 两套内核的原因: 单纯的Mach内核出现性能瓶颈,为了兼容之前Mach开发的应用和设备驱动,保留了Mach内核,同时加入了BSD内核 Mach内核提供十分简单的进程,县城,IPC通信,虚拟内存设备驱动相关的功能服务 BSD内核提供强大的安全特性,完善的网络服务,各种文件系统的支持,同时对Mach的进程,线程,IPC,虚拟内核组件进行细化,扩展延伸 使用Darwin系统的服务,应用会同感用户层的框架和库来请求Darwin系统的服务,调用Darwin系统的API 在调用Darwin系统API时,传入一个API号,索引Mach陷入中断服务表中的函数,若API号小于0,则请求的是Mach内核的服务,若大于0表示请求的是BSD内核的服务,提供了一套完整的POSIX接口 组件Linkern库,提供底层的操作函数,同时支持C++运行环境 IOKit依赖此库,管理所有的设备驱动和内核功能扩展模块,驱动程序可以使用C++开发驱动 Windows NT内核 NT内核在设计上清晰明了,各组件之间界限耦合程度很低 在HAL层上定义一个小内核,小内核之下是硬件抽象层HAL HAL存在,不同的硬件平台只要提供对应的HAL就可以移植系统 小内核之上是各种内核组件,为内核执行体,其互相独立,只对外提供相应的接口,其执行体要通过内核模式可调用接口和其他执行体通信完成相应的功能服务 所有的设备驱动和文件系统都有IO管理器统一管理,驱动程序堆叠形成IO驱动栈,功能请求封装成IO包 属于微内核结构,但从权限角度看为宏内核,属于混合内核 3 硬件 3.1 执行程序的三种模式 CPU的工作模式 按x86_CPU功能升级迭代的顺序,工作模式分为实模式,保护模式,长模式 123456789int main()&#123; int* addr = (int*)0; cli(); //关中断 while(1)&#123; *addr = 0; addr++; &#125; return 0;&#125; 从一段死循环的代码说起 上述代码关闭CPU中断,进入死循环,最后从内存0地址开始写入0 锁住CPU,清空内存 在实模式下,代码可正常运行 计算机资源太少,单道程序运行,没有操作系统的概念 3.1.1 实模式 实模式 实地址模式,运行真实的指令,对指令的动作不做区分,直接执行指令的真实功能;发往内存的地址是真实的,对任何地址不加限制 实模式寄存器,表中的每个寄存器都是16位的 寄存器 描述 AX,BX,CX,DX,DI,SI,BP 通用寄存器,可以存放数据,地址,参与运算 IP 程序指针寄存器,始终指向下一条指针的地址 SP 栈指针寄存器 CS,DS,ES,SS 段寄存器,里面存放一个内存段的基地址 FLAGS CPU标志寄存器,里面存放CPU执行运算指令产生的状态位 实模式下访问内存 需要把数据装载进寄存器中才能操作,还要有获取指令的动作,都要访问内存 分段内存管理模型:所有的内存地址都是由段寄存器左移4位,再加上一个通用寄存器中的值或者常数形式形成地址,然后由这个地址去访问内存 代码段是由CS和IP确定的,而栈段是由SS和SP确定的 实模式中断 中断即中止执行当前程序,转而跳转到另一个特定的地址上,运行特定的代码 在实模式下,实现过程是先保存CS和IP寄存器,然后装载新的CS和IP寄存器 中断分为:硬件中断和软件中断 硬件中断是中断控制器给CPU发送电子信号,CPU对中断信号作出应答,随后中断控制器将中断号发给CPU 软件中断是CPU执行INT指令,该指令跟随软中断号 为了实现中断,需要在内存中存放一个中断向量表,该表的地址和长度由CPU的特定寄存器IDTR指向 实模式下,表中的一个条目由代码段地址和段内偏移组成 利用中断号,CPU根据IDTR寄存器中的信息,计算出中断向量的条目,装载CS,IP寄存器,最终响应中断 3.1.2 保护模式 CPU保护模式,将CPU寄存器和运算单元扩展成32位,解决了寻址问题,并且解决了实模式下,CPU对任何指令不加区分执行,对访问内存不加限制的问题 保护模式寄存器 增加了控制寄存器和段寄存器,扩展通用寄存器的位宽,所有的通用寄存器都是32位寄存器 寄存器 描述 EAX,EBX,ECX,EDX,EDI,ESI,EBP 32位通用寄存器,可以存放数据,地址,参与运算 EIP 32位程序指针寄存器,始终指向下一条指针的地址 ESP 栈寄存器 CS,DS,ES,SS,FS,GS 16位段寄存器,里面存放一个内存段的描述符索引 EFLAGS 32位CPU标志寄存器,里面存放CPU执行运算指令产生的状态位 CR0,CR1,CR2,CR3 32位CPU控制寄存器,控制CPU的功能控制特性 保护模式特权级 为了区分指令和资源可以被访问,CPU实现了特权级 特权级分为4级,R0~R3,每个特权级执行指令的数量不同 R0可以执行所有指令 R1,R2,R3依次递减,只能执行上一次指令数量的自己 内存的访问是靠段描述符和特权级相互配合实现 保护模式段描述符 内存目前位分段模型,要对内存进行保护即对段进行保护 由于CPU扩展导致32位段基地址和段内偏移,16位段寄存器放不下,将描述段的信息封装成特定格式的段描述符放在内存中 段描述符由64位8字节数据,包含了段基地址,段长度,段权限,段类型,段是否可读写,可执行等信息 多个段描述符在内存中形成全局段描述符表,该表的基地址和长度由CPU和GDTR寄存器指示 段寄存器不存放段基地址,存放具体段描述符的索引,访问一个内存地址时,段寄存器中索引首先会结合GDTR寄存器找到内存中的段描述符,再根据其中段信息判断是否能访问成功 保护模式段选择子 CS,DS,ES,SS,FS,GS段寄存器,由影子寄存器,段描述符索引,描述符表索引,权限级别组成 影子寄存器靠硬件操作,对系统程序员不可见,高性能(64位8字节) CS和SS中RPL组成CPL(当前权限级别),常常是RPL=CPL CPL表示发起访问者以什么权限访问目标段,当CPL大于目标段DPL时,CPU禁止访问 保护模式平坦模型 分段模型存在很多缺陷,现代使用分页模型 X86CPU不能直接使用分页模型,需要在分段的前提下根据决定是否开启分页 保护模式的平坦模型,使分段成为虚设 CPU 32位的寄存器最多只能产生4GB大小的地址,而一段长度只能是4GB,所以把所有段的基地址设为0,段的长度设为0xFFFFF,段长度的粒度设为4KB,这样所有段都指向同一个字节大小的地址空间 123456789101112131415161718GDT_START:knull_dsc: dq 0;第一个段描述符CPU硬件规定必须为0kcode_dsc: dq 0x00cf9e000000ffff;段基地址=0,段长度=0xfffff;G=1,D/B=1,L=0,AVL=0;P=1,DPL=0,S=1;T=1,C=1,R=1,A=0kdata_dsc: dq 0x00cf92000000ffff;段基地址=0,段长度=0xfffff;G=1,D/B=1,L=0,AVL=0;P=1,DPL=0,S=1;T=0,C=0,R=1,A=0GDT_END:GDT_PTR:GDTLEN dw GDT_END-GDT_START-1GDTBASE dd GDT_START 段长度需要和G位配合,若G位为1,则段长度等于0xfffff个4KB 上面段描述符的DPL=0,说明需要最高权限即CPL=0才能访问 保护模式中断 保护模式下的中断要权限检查,特权级切换,需要扩展中断向量表的信息,即每个中断用一个中断门描述符表示 保护模式要实现中断,在内存中有中断向量表,由IDTR寄存器指示,只不过中断向量表中的条目变成了中断门描述符 产生中断后,CPU会检查中断号是否大于最后一个中断门描述符,x86CPU支持256个中断源,然后检查描述符类型,是否为系统描述符,是不是存在于内存中 检查中断门描述符中的段选择子指向的段描述符 最后,权限检查,若CPL小于等于中断门的DPL并且CPL大于等于中断门中的段选择子,就指向段描述符的DPL CPL等于中断门中的DPL,则为同级权限不进行栈切换,若进行栈切换,还需要从TSS中加载具体权限的SS,ESP 做完检查之后,CPU才会加载中断门描述符中目标代码段选择子到CS寄存器中,把目标代码段偏移加载道EIP寄存器中 切换到保护模式 x86CPU在第一次加电和每次reset后,都会自动进入实模式,要想进入保护模式,就需要切换到保护模式 第一步,准备全局段描述符表 第二步,加载设置GDTR寄存器,使之指向全局段描述符表 第三步,设置CR0寄存器,开启保护模式 第四步,进行长跳转,加载CS段寄存器,即段选择子 长跳转的原因 因为无法直接或间接mov一个数据到CS寄存器中,因为刚刚开启保护模式,CS的影子寄存器还是实模式下的指,故需要告诉CPU加载新的段信息 CPU发现CR0寄存器第0位的值是1,就会按GDTR的指示找到全局描述符表,然后根据索引指8,将新的段描述符信息加载到CS影子寄存器 到此为止CPU进入保护模式,可以处理32位 3.1.3 长模式 长模式,完成64位的数据运算,也能寻址64位的地址空间 长模式寄存器 相比于保护模式,增加了一些通用寄存器,并扩宽通用寄存器的位宽 寄存器 描述 RAX,RBX,RCX,RDX,RDI,RSI,RBP,R8~R15 64位通用寄存器,可以存放数据,地址,参与运算 RIP 64位程序指针寄存器,始终指向下一条指针的地址 RSP 栈寄存器 CS,DS,ES,SS,FS,GS 16位段寄存器,里面存放一个内存段的描述符索引 RFLAGS 64位CPU标志寄存器,里面存放CPU执行运算指令产生的状态位 CR0,CR1,CR2,CR3 CR0为32位CPU控制寄存器,控制CPU的功能控制特性,其他的都是64位寄存器 长模式段描述符 长模式下,CPU不再对段基址和段长度进行检查,支队DPL进行相关检查 当描述符中L=1,D/B=0时,就是64位代码段,DPL还是0～3特权级,多个段描述在内存中形成一个全局段描述符表,同样由CPU的GDTR寄存器指向 长模式中断 长模式支持64位内存寻址,中断门描述符进行了修改和扩展 长模式下中断门描述符的格式变化 为支持64位寻址中断门描述符在原有基础上增加8字节,用于存放目标段偏移的高32位值 其次,目标代码段选择子对应的代码段描述符必须是64位的代码段 其中的IST是64位TSS中的IST指针(不使用该特性,不做详细介绍) 长模式的中断门描述符表,表中的条目为16字节,最多支持256个中断源 切换到长模式 第一步,准备长模式全局段描述符表 第二步,准备长模式下MMU(内存管理单元)页表(为了开启分页模式,切换到长模式必须要开启分页) 长模式下不对段基址和段长度进行检查,在长模式下内存地址空间的保护交给MMU,MMU依赖页表对地址进行转换,页表有特定的格式存放在内存中,其地址由CPU的CR3寄存器指向 第三步,加载GDTR寄存器,使之指向全局段描述表 第四步,开启长模式,同时开启保护模式和分页模式 在实现长模式时定义了MSR寄存器,需要用专用的指令 rdmsr、wrmsr 进行读写,IA32_EFER 寄存器的地址为0xC0000080,它的第8位决定了是否开启长模式 第五步,进行跳转,加载CS寄存器,刷新其影子寄存器 3.2 程序中的地址如何转换 虚拟地址和物理地址的关系和转换机制 采用虚拟地址的方法可以解决多程序并发的处理场景 虚拟地址 虚拟地址是逻辑上存在的一个数据值 虚拟地址是链接器产生的,在开发软件经过编译步骤后,需要链接成可执行文件才可以运行 链接器的主要工作就是把多个代码模块组装在一起,解决模块之间的引用,即处理程序代码间的地址引用,形成程序运行的静态内存空间视图 物理地址 物理地址在逻辑上也是一个数据,不过数据被地址译码器等电子器件变成电子信号,放在地址总线上 地址总线电子信号的各种组合可以选择到内存的储存单元 但地址总线上的信号,也可以选择到别的设备的储存单元 虚拟地址到物理地址的转换 转换机制相当于函数p=f(v),输入虚拟地址v,输出物理地址p 采用软硬件结合的方式实现,即MMU(内存管理单元) MMU可以接收软件给出的地址对应关系数据,进行地址转换 32位地址空间下,4GB虚拟地址的地址关系转换表把整个32位物理地址空间用完,显然不行,采用把虚拟地址空间和物理地址空间都分成同等大小的块,称为页,按照虚拟页和物理页进行转换(分页模型) 页的大小可以设置为4KB,2MB,4MB,1GB 一个虚拟页对应一个物理页,由于页大小一经配置就是固定的,所以只要存放虚拟页地址对应的物理页地址 MMU MMU即内存管理单元,是用硬件电路逻辑实现的一个地址转换器件,负责接受虚拟地址和地址关系转换表,以及输出物理地址 使用保护模式的平坦模式,绕过了分段模式 地址产生过程 程序代码中的虚拟地址,经过CPU的分段机制产生了线性地址,平坦模式和长模式下线性地址和虚拟地址相等 不开启MMU,在保护模式下可以关闭MMU,线性地址就是物理地址 长模式下的分段弱化了地址空间的隔离,故必须开启MMU MMU页表 页表(地址关系转换表),描述了虚拟地址到物理地址的转换关系 页表不存放虚拟地址和物理地址的对应关系,只存放物理页面的地址,MMU以虚拟地址为索引去查表返回物理页面地址 页表是分级的,分为三个部分:一个顶级页目录,多个中级页目录,最后才是页表 第一个位段索引顶级目录中的一个项,该项指向一个中级页目录,然后用第二个位段去索引中级页目录中的一个项,该项指向一个页目录,再用第三个位段去索引页目录中的项,该项指向一个物理页地址,最后用第四个位段作为该物理页的偏移去访问物理内存 保护模式下的分页——4KB页 保护模式下只有32位地址空间,32位虚拟地址经过分段机制后得到线性地址,使用平坦模式,所以线性地址和虚拟地址相同 保护模式下分页大小通常为4KB或4MB,分页大小的不同会导致虚拟地址位段的分隔和页目录的层级不同,但虚拟页和物理页的大小始终是等同的 CR3是CPU中的一个32位寄存器,MMU根据该寄存器找到页目录 保护模式下的分页——4MB 32位虚拟地址被分为两个位段:页表索引,页内偏移 只有一级页目录,其中包含1024个条目,其中一个条目指向一个物理页,每个物理页4MB CR3还是32位寄存器,但不再指向顶级页目录,指向一个4KB大小的页表,该页表要4KB地址对齐,其中包含1024个页表项 4MB大小的页面下,页表项还是4字节32位,但只需要用高10位来保存物理页面的基地址就可以,但每个物理页面都是4MB,故低22位始终为0(为了兼容4MB页表低8位和4KB页表项,但第七位变成了PS位,且必须位1,PAT位移动到了12位) 长模式下的分页 开启了长模式就必须开启分页模式,长模式扩宽了CPU的位宽,使得CPU能使用64位的超大内存地址空间,故长模式下的虚拟地址必须等于线性地址且为64位 长模式下的分页大小有4KB和2MB大小的页 长模式下的分页——4KB页 该分页方式下,64位虚拟地址被分为6个位段,分别是保留位段,顶级页目录索引,页目录指针索引,页目录索引,页表索引,页内偏移,顶级页目录,页目录指针,页目录,页表各占有4KB大小,其中含有512个条目,每个条目8字节64位大小 CR3是64位CPU寄存器,指向一个顶级页目录,里面的顶级页目项指向页目录指针 虚拟地址48到63这6位是根据第47位来决定的,47位为1,就为0,否则为0 x86CPU并没有实现全64位的地址总线,而是只实现了48位,但是CPU的寄存器却是64位的 长模式下4KB分页下,由一个顶级目录,二级中间层目录和一层页表组成了64位地址翻译过程 顶级页目录项指向页目录指针页,页目录指针项指向页目录页,页目录项指向页表页,页表项指向一个4KB大小的物理页,各级页目录项中和页表项中仍然存在各种属性位 XD位,可以控制代码页面是否能够运行 长模式下的分页——2MB页 64位虚拟地址被分为5个位段：保留位段,顶级页目录索引,页目录指针索引,页目录索引,页内偏移,顶级页目录,页目录指针 2MB分页下是页目录项直接指向了2MB大小的物理页面,放弃了页表项,然后把虚拟地址的低21位作为页内偏移,21位正好索引2MB大小的地址空间 开启MMU 使CPU进入保护模式或长模式(前提) 准备好页表数据,这包含顶级页目录,中间层页目录,页表 把顶级页目录的物理内存地址赋值给CR3寄存器 设置CPU的CR0的PE位为1,这样就开启了MMU MMU地址转换失败执行的操作 MMU停止转换地址 MMU把转换失败的虚拟地址写入CPU的CR2寄存器 MMU触发CPU的14号中断,使CPU停止执行当前指令 CPU开始执行14号中断的处理代码,代码会检查原因,处理好页表数据返回 CPU中断返回继续执行MMU地址转换失败时的指令 3.3 Cache与内存:程序放在哪儿 Cache是解决内存瓶颈的神来之笔 123456789101112//九九乘法表#include &lt;studio.h&gt;int main()&#123; int i,j; for(i=1;i&lt;=9;i++)&#123; for(j=1;j&lt;=i;j++)&#123; printf(&quot;%d*%d=%2d &quot;,i,j,i*j); &#125; printf(&quot;\\n&quot;); &#125; return 0;&#125; 从经典代码看局部性原理 程序局部性原理,CPU在大多数时间在执行相同的指令或者与此相邻的指令 内存 内存为DRAM,即动态随机存储器 内存储存颗粒芯片中的存储单元是由电容和相关原件组成的,电容存储电荷的多少代表数字信号0和1 由于电容存在漏电现象,会导致电荷不同,故DRAM需要周期性刷新以保持电荷状态 控制内存刷新和内存读写的是内存控制器,其集中在北桥芯片,现集成在CPU芯片中 CPU到内存的性能瓶颈 CPU和内存条的数据吞吐量天差地别,且多核心CPU同时访问内存会导致总线争用问题,数据吞吐量会进一步下降 内存是决定系统整体性能的关键 Cache CPU大多数时间在访问相同或者与之相邻的地址,那么立马就可以想到用一块小而快的储存器放在CPU和内存之间,可以利用程序的局部性原理来缓解CPU和内存之间的性能瓶颈,小而快的储存器就是Cache,即高速缓存 Cache中存放了内存中的一部分数据,CPU在访问内存时要先访问Cache,若Cache中有需要的数据就直接从Cache中取出,若没有则需要从内存中读取数据,并同时把这块数据放入Cache中;但由于程序的局部性原理,在一段时间内,CPU总能从Cache中读取到自己想要的数据 Cache可目前主要集中在X86CPU内部,主要由高速的静态储存器,地址转换模块和Cache行替换模块组成 Cache把高速静态储存器和内存分成大小相同的行(Cahce和内存交换数据的最小单位),一行大小通常为32字节或64字节 Cache的逻辑工作流程 CPU发出的地址由Cache的地址转换模块分为3段：组号,行号,行内偏移 Cache会根据组号,行号查找高速静态储存器中对应的行 若没有新行,就进入行替换逻辑,即找出一个Cache行写回内存,腾出空间,替换行有相关算法(替换算法为了让替换的代价最小化) Cache带来的问题,数据一致性问题 三级Cache,第一级Cache是指令和数据分开的,第二级Cache是独立于CPU核心的,第三级Cache是所有CPU核心共享的 一致性问题的三个方面 一个CPU核心中的指令Cache和数据Cache的一致性问题 多个CPU核心各自的2级Cache的一致性问题 CPU的3级Cache与设备内存之间的一致性问题 典型的多核心Cache数据同步协议有MESI和MOESI Cache的MESI协议 MESI协议定义了4种基本状态:M(修改),E(独占),S(共享),I(无效) M修改:当前Cache的内容有效,数据已经被修改而且与内存中的数据不一致,数据只有在当前Cache里存在 E独占:当前Cache中的内容有效,数据与内存中的数据一致,数据只在当前Cache里存在 S共享:当前Cache中的内容有效,Cache中的数据与内存中的数据一致,数据在多个CPU核心的Cache里面存在 I无效:当前Cache无效 Cache硬件会监控所有CPU上Cache的操作,根据相应的操作使得Cache里的数据行在状态之间切换 Cache虽提升了系统性能,但带来了很多问题,问题硬件自动完成,对软件而言透明的,但在程序设计时需要规避这些问题,否则会导致程序运行的效能大大下降 开启Cache x86CPU上默认是关闭Cache的,需要在初始化时将其开启 需要将CR0寄存器中CD,NW位同时清0即可 CD=1表示Cache关闭 NW=2时CPU不维护内存数据一致 CD=0,NW=0的组合是开启Cache的正确方法 123456// 开启Cache的汇编代码mov eax, cr0;开启Cachebtr eax,29;CR0.NW=0btr eax,30;CR0.CD=0mov cr0, eax 获取内存视图 关键是获取哪些物理地址空间是可以读写的内存,获取内存有多大没用 物理地址空间是由北桥芯片控制管理的,在x86平台上利用BIOS提供的实模式下中断服务(int指令后跟着一个常数的形式) 由于PC机上电后由BIOS执行硬件初始化,中断向量表是由BIOS设置的,故执行中断自然执行BIOS服务 12345678910111213141516171819202122232425262728// 中断服务是int 15h// 但在执行int 15h之前需要对特定寄存器设置一些值_getmemmap:xor ebx,ebx ;ebx设为0mov edi,E80MAP_ADR ;edi设为存放输出结果的1MB内的物理内存地址loop:mov eax,0e820h ;eax必须为0e820hmov ecx,20 ;输出结果数据项的大小为20字节：8字节内存基地址,8字节内存长度,4字节内存类型mov edx,0534d4150h ;edx必须为0534d4150hint 15h ;执行中断jc error ;如果flags寄存器的C位置1,则表示出错add edi,20;更新下一次输出结果的地址cmp ebx,0 ;如ebx为0,则表示循环迭代结束jne loop ;还有结果项,继续迭代reterror:;出错处理// 在迭代中执行中断,每次中断都输出一个20字节大小的数据项,最终形成一个该数据项的数组#define RAM_USABLE 1 //可用内存#define RAM_RESERV 2 //保留内存不可使用#define RAM_ACPIREC 3 //ACPI表相关的#define RAM_ACPINVS 4 //ACPI NVS空间#define RAM_AREACON 5 //包含坏内存typedef struct s_e820&#123; u64_t saddr; /* 内存开始地址 */ u64_t lsize; /* 内存大小 */ u32_t type; /* 内存类型 */&#125;e820map_t; 系统地认识了硬件模型 4 基本法:同步原语 4.1 锁:并发操作中,解决数据同步的四种方法 几种常见的锁:原子变量,关中断,信号量,自旋锁 4.1.1 方法1:原子操作 拿下单体变量 将a++变成原子操作,原子时不可分隔的,即a++操作不可分隔,要么不执行,要么一口气执行完 编译器不能自动生成原子操作,在x86平台支持很多原子指令,只需要应用指令即可 现代C语言支持嵌入汇编代码,可以在C语言中按照特定的方式嵌入汇编代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445//定义一个原子类型typedef struct s_ATOMIC&#123;volatile s32_t a_count; //在变量前加上volatile,是为了禁止编译器优化,使其每次都从&#125;atomic_t;//原子读static inline s32_t atomic_read(const atomic_t *v)&#123;//x86平台取地址处是原子return (*(volatile u32_t*)&amp;(v)-&gt;a_count);&#125;//原子写static inline void atomic_write(atomic_t *v, int i)&#123;//x86平台把一个值写入一个地址处也是原子的v-&gt;a_count = i;&#125;//原子加上一个整数static inline void atomic_add(int i, atomic_t *v)&#123;__asm__ __volatile__(&quot;lock;&quot; &quot;addl %1,%0&quot;: &quot;+m&quot; (v-&gt;a_count): &quot;ir&quot; (i));&#125;//原子减去一个整数static inline void atomic_sub(int i, atomic_t *v)&#123;__asm__ __volatile__(&quot;lock;&quot; &quot;subl %1,%0&quot;: &quot;+m&quot; (v-&gt;a_count): &quot;ir&quot; (i));&#125;//原子加1static inline void atomic_inc(atomic_t *v)&#123;__asm__ __volatile__(&quot;lock;&quot; &quot;incl %0&quot;: &quot;+m&quot; (v-&gt;a_count));&#125;//原子减1static inline void atomic_dec(atomic_t *v)&#123;__asm__ __volatile__(&quot;lock;&quot; &quot;decl %0&quot;: &quot;+m&quot; (v-&gt;a_count));&#125;// 加上lock前缀的指令都是原子操作// lock前缀表示锁定总线 GCC支持嵌入汇编代码的模板:规定了汇编代码嵌入的形式和嵌入汇编代码需要由几部分构成 代码模板从_asm__开始,紧跟着_volatile,然后是跟着一对括号,最后以分号结束 括号内的4部分 汇编代码部分,实际嵌入的汇编代码 输出列表部分,让GCC能够处理C语言左值表达式与汇编代码的结合 输入列表部分,让GCC能够处理C语言表达式,变量,常量,让它们能够输入到汇编代码中去 损坏列表部分,告诉GCC汇编代码用到了哪些寄存器,以便GCC在汇编代码运算前,生成保存的代码,在生成的汇编代码运行后恢复寄存器的代码 _asm_ _volatile_(代码部分:输出部分列表:输入部分列表:损坏部分列表); 12345678// 利用原子操作atomic_t a = &#123;0&#125;;void interrupt_handle()&#123; atomic_inc(&amp;a);&#125;void thread_func()&#123; atomic_inc(&amp;a);&#125; 4.1.2 方法2:中断控制 搞定复杂变量 原子操作只适用于单体变量 x86CPU上关闭,开启中断有专门的指令,即cli,sti指令 主要对CPU的eflags寄存器的IF位(第9位)进行清除和设置,CPU通过该位来相应中断信号 两条指令只能Ring0权限才能执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//关闭中断void hal_cli()&#123; __asm__ __volatile__(&quot;cli&quot;: : :&quot;memory&quot;);&#125;//开启中断void hal_sti()&#123; __asm__ __volatile__(&quot;sti&quot;: : :&quot;memory&quot;);&#125;//使用场景void foo()&#123; hal_cli(); //操作数据…… hal_sti();&#125;void bar()&#123; hal_cli(); //操作数据…… hal_sti();&#125;// hal_cli,hal_sti无法嵌套使用void foo()&#123; hal_cli(); //操作数据第一步…… hal_sti();&#125;void bar()&#123; hal_cli(); foo(); //操作数据第二步…… hal_sti();&#125;// bar函数在关中断的情况下调用foo函数,foo函数中先关掉中断,处理好数据然后开启中断,回到bar函数中,bar函数以为中断是关闭的,接着处理数据,以为不会被中断抢占// 修改:在关闭中断函数中先保存 eflags 寄存器,然后执行 cli 指令,在开启中断函数中直接恢复之前保存的 eflags 寄存器就行了typedef u32_t cpuflg_t;static inline void hal_save_flags_cli(cpuflg_t* flags)&#123; __asm__ __volatile__( &quot;pushfl \\t\\n&quot; //把eflags寄存器压入当前栈顶 &quot;cli \\t\\n&quot; //关闭中断 &quot;popl %0 \\t\\n&quot;//把当前栈顶弹出到flags为地址的内存中 : &quot;=m&quot;(*flags) : : &quot;memory&quot; );&#125;static inline void hal_restore_flags_sti(cpuflg_t* flags)&#123; __asm__ __volatile__( &quot;pushl %0 \\t\\n&quot;//把flags为地址处的值寄存器压入当前栈顶 &quot;popfl \\t\\n&quot; //把当前栈顶弹出到flags寄存器中 : : &quot;m&quot;(*flags) : &quot;memory&quot; );&#125;// pushfl指令把eflags寄存器压入当前栈顶,popfl把当前栈顶的数据弹出到eflags寄存器中// hal_restore_flags_sti() 函数的执行,是否开启中断完全取决于上一次 eflags 寄存器中的值,并且 popfl 指令只会影响 eflags 寄存器中的 IF 位 4.1.3 方法3:自旋锁,协调多核心CPU 多核心CPU系统中存在多条代码执行流,控制中断只能控制本地CPU的中断,无法控制其他CPU核心的中断 自旋锁的原理 首先读取锁变量,判断其值是否已经加锁 如果未加锁则执行加锁,然后返回表示加锁成功 如果已经加锁,就要返回第一步继续执行后续步骤,因而得名自旋锁 要想正确执行,需要保证读取锁变量和判断并加锁的原子操作是原子执行的 否则,CPU0在读取锁变量之后,CPU1读取锁变量判断未加锁执行加锁,然后CPU0也判断未加锁执行加锁,发现两个CPU都加锁成功,因此算法出错 需要硬件解决方案,X86CPU提供原子交换指令xchg可以让寄存器里的一个值跟内存空间中的一个值交换 使用自旋锁时需要注意中断 要写的自旋锁函数必须适应这样的中断环境,也就是说,它需要在处理中断的过程中也能使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 实现自旋锁//自旋锁结构typedef struct&#123; volatile u32_t lock;//volatile可以防止编译器优化,保证其它代码始终从内存加载lock变&#125; spinlock_t;//锁初始化函数static inline void x86_spin_lock_init(spinlock_t * lock)&#123; lock-&gt;lock = 0;//锁值初始化为0是未加锁状态&#125;//加锁函数static inline void x86_spin_lock(spinlock_t * lock)&#123; __asm__ __volatile__ ( &quot;1: \\n&quot; &quot;lock; xchg %0, %1 \\n&quot;//把值为1的寄存器和lock内存中的值进行交换 &quot;cmpl $0, %0 \\n&quot; //用0和交换回来的值进行比较 &quot;jnz 2f \\n&quot; //不等于0则跳转后面2标号处运行 &quot;jmp 3f \\n&quot; //若等于0则跳转后面3标号处返回 &quot;2: \\n&quot; &quot;cmpl $0, %1 \\n&quot;//用0和lock内存中的值进行比较 &quot;jne 2b \\n&quot;//若不等于0则跳转到前面2标号处运行继续比较 &quot;jmp 1b \\n&quot;//若等于0则跳转到前面1标号处运行,交换并加锁 &quot;3: \\n&quot; : : &quot;r&quot;(1), &quot;m&quot;(*lock));&#125;//解锁函数static inline void x86_spin_unlock(spinlock_t * lock)&#123; __asm__ __volatile__( &quot;movl $0, %0\\n&quot;//解锁把lock内存中的值设为0就行 : : &quot;m&quot;(*lock));&#125;// 实现了关中断下获取自旋锁,以及恢复中断状态释放自旋锁static inline void x86_spin_lock_disable_irq(spinlock_t * lock,cpuflg_t* flags&#123; __asm__ __volatile__( &quot;pushfq \\n\\t&quot; &quot;cli \\n\\t&quot; &quot;popq %0 \\n\\t&quot; &quot;1: \\n\\t&quot; &quot;lock; xchg %1, %2 \\n\\t&quot; &quot;cmpl $0,%1 \\n\\t&quot; &quot;jnz 2f \\n\\t&quot; &quot;jmp 3f \\n&quot; &quot;2: \\n\\t&quot; &quot;cmpl $0,%2 \\n\\t&quot; &quot;jne 2b \\n\\t&quot; &quot;jmp 1b \\n\\t&quot; &quot;3: \\n&quot; :&quot;=m&quot;(*flags) : &quot;r&quot;(1), &quot;m&quot;(*lock));&#125;static inline void x86_spin_unlock_enabled_irq(spinlock_t* lock,cpuflg_t* flag&#123; __asm__ __volatile__( &quot;movl $0, %0\\n\\t&quot; &quot;pushq %1 \\n\\t&quot; &quot;popfq \\n\\t&quot; : : &quot;m&quot;(*lock), &quot;m&quot;(*flags));&#125; 4.1.4 方法4:信号量 CPU时间管理大师 原子操作和自旋锁不适合长时间等待的操作,因为很多资源有一定的时间性,使用自旋锁访问这种资源对CPU时间是巨大的浪费 使用信号量解决等待,互斥,唤醒(即重新激活等待的代码执行流)问题 需要一种全新的数据结构来解决这些问题,该数据结构至少需要一个变量来表示互斥,比如大于 0 则代码执行流可以继续运行,等于 0 则让代码执行流进入等待状态.还需要一个等待链,用于保存等待的代码执行流 1234567891011121314151617181920212223// 数据结构的实现代码#define SEM_FLG_MUTEX 0#define SEM_FLG_MULTI 1#define SEM_MUTEX_ONE_LOCK 1#define SEM_MULTI_LOCK 0//等待链数据结构,用于挂载等待代码执行流（线程）的结构,里面有用于挂载代码执行流的链表和计数器typedef struct s_KWLST&#123; spinlock_t wl_lock; uint_t wl_tdnr; list_h_t wl_list;&#125;kwlst_t;//信号量数据结构typedef struct s_SEM&#123; spinlock_t sem_lock;//维护sem_t自身数据的自旋锁 uint_t sem_flg;//信号量相关的标志 sint_t sem_count;//信号量计数值 kwlst_t sem_waitlst;//用于挂载等待代码执行流（线程）结构&#125;sem_t;// 注意信号量在使用之前需要先进行初始化// 这里假定信号量数据结构中的 sem_count 初始化为 1,sem_waitlst 等待链初始化为空 使用信号量的步骤 第一步,获取信号量 首先对用于保护信号量自身的自旋锁sem_lock进行加锁 对信号值sem_count执行“减1”操作,并检查其值是否小于0 检查sem_count如果小于0,进程进入等待状态并将其挂入sem_waitlst中,然后调度其它进程运行;否则表示获取信号量成功,最后需要对自旋锁sem_lock进行解锁 第二步,代码执行流开始执行相关操作 第三步,释放信号量 首先对用于保护信号量自身的自旋锁sem_lock进行加锁 对信号值sem_count执行“加1”操作,并检查其值是否大于0 上步中检查sem_count值如果大于0,就执行唤醒sem_waitlst中进程的操作,并且需要调度进程时就执行进程调度操作,不管sem_count是否大于0(通常会大于0)都标记信号量释放成功.最后对自旋锁sem_lock进行解锁 12345678910111213141516171819202122232425262728293031323334353637// 信号量的两个操作,down, up//获取信号量void krlsem_down(sem_t* sem)&#123; cpuflg_t cpufg; start_step: krlspinlock_cli(&amp;sem-&gt;sem_lock,&amp;cpufg); if(sem-&gt;sem_count&lt;1) &#123; //如果信号量值小于1,则让代码执行流（线程）睡眠 krlwlst_wait(&amp;sem-&gt;sem_waitlst); krlspinunlock_sti(&amp;sem-&gt;sem_lock,&amp;cpufg); krlschedul();//切换代码执行流,下次恢复执行时依然从下一行开始执行,所以要goto开始 goto start_step; &#125; sem-&gt;sem_count--;//信号量值减1,表示成功获取信号量 krlspinunlock_sti(&amp;sem-&gt;sem_lock,&amp;cpufg); return;&#125;//释放信号量void krlsem_up(sem_t* sem)&#123; cpuflg_t cpufg; krlspinlock_cli(&amp;sem-&gt;sem_lock,&amp;cpufg); sem-&gt;sem_count++;//释放信号量 if(sem-&gt;sem_count&lt;1) &#123; //如果小于1,则说数据结构出错了,挂起系统 krlspinunlock_sti(&amp;sem-&gt;sem_lock,&amp;cpufg); hal_sysdie(&quot;sem up err&quot;);&#125; //唤醒该信号量上所有等待的代码执行流（线程） krlwlst_allup(&amp;sem-&gt;sem_waitlst); krlspinunlock_sti(&amp;sem-&gt;sem_lock,&amp;cpufg); krlsched_set_schedflgs(); return;&#125; 4.2 Linux的自旋锁和信号量如何实现 4.2.1 Linux的原子变量 在文件描述符中,需要包含一个简单的计数器,表示有多少个应用程序打开了文件 在文件系统的open函数中将计数器变量加1;close函数中将计数器变量减1 多个进程同时打开或关闭文件,会导致计数器变量容易出现错误 使用原子类型变量atomic_t Linux的实现采用了X86CPU的原子指令 LOCK_PREFIX为一个宏,根据需要展开成&quot;lock&quot;或空串 单核心CPU是不需要lock前缀的,只要在多核心CPU下才需要加上lock前缀 __READ_ONCE,__WRITE_ONCE两个宏,是对代码封装并利用GCC特性对代码进行检查,显现错误在编译阶段 volatile int* 是为了提醒编译器,是对内存地址读写,不要有优化动作,每次都必须强制写入内存或从内存读取 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 原子类型变量atomic_ttypedef struct &#123; int counter;&#125; atomic_t;//常用的32位的原子变量类型#ifdef CONFIG_64BITtypedef struct &#123; s64 counter;&#125; atomic64_t;//64位的原子变量类型#endif// Linux提供的基本的接口函数//原子读取变量中的值static __always_inline int arch_atomic_read(const atomic_t *v)&#123; return __READ_ONCE((v)-&gt;counter);&#125;//原子写入一个具体的值static __always_inline void arch_atomic_set(atomic_t *v, int i)&#123; __WRITE_ONCE(v-&gt;counter, i);&#125;//原子加上一个具体的值static __always_inline void arch_atomic_add(int i, atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;addl %1,%0&quot; : &quot;+m&quot; (v-&gt;counter) : &quot;ir&quot; (i) : &quot;memory&quot;);&#125;//原子减去一个具体的值static __always_inline void arch_atomic_sub(int i, atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;subl %1,%0&quot; : &quot;+m&quot; (v-&gt;counter) : &quot;ir&quot; (i) : &quot;memory&quot;);&#125;//原子加1static __always_inline void arch_atomic_inc(atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;incl %0&quot; : &quot;+m&quot; (v-&gt;counter) :: &quot;memory&quot;);&#125;//原子减1static __always_inline void arch_atomic_dec(atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;decl %0&quot; : &quot;+m&quot; (v-&gt;counter) :: &quot;memory&quot;);&#125;// __READ_ONCE,__WRITE_ONCE两个宏#define __READ_ONCE(x) \\ (*(const volatile __unqual_scalar_typeof(x) *)&amp;(x))#define __WRITE_ONCE(x, val) \\ do &#123;*(volatile typeof(x) *)&amp;(x) = (val);&#125; while (0)//__unqual_scalar_typeof表示声明一个非限定的标量类型,非标量类型保持不变.即返回x//如果 x 是int类型则返回“int”#define __READ_ONCE(x) \\ (*(const volatile int *)&amp;(x))#define __WRITE_ONCE(x, val) \\ do &#123;*(volatile int *)&amp;(x) = (val);&#125; while (0) 4.2.2 Linux控制中断 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// Linux控制CPU响应中断的函数//实际保存eflags寄存器extern __always_inline unsigned long native_save_fl(void)&#123; unsigned long flags; asm volatile(&quot;# __raw_save_flags\\n\\t&quot; &quot;pushf ; pop %0&quot;:&quot;=rm&quot;(flags)::&quot;memory&quot;); return flags;&#125;//实际恢复eflags寄存器extern inline void native_restore_fl(unsigned long flags)&#123; asm volatile(&quot;push %0 ; popf&quot;::&quot;g&quot;(flags):&quot;memory&quot;,&quot;cc&quot;);&#125;//实际关中断static __always_inline void native_irq_disable(void)&#123; asm volatile(&quot;cli&quot;:::&quot;memory&quot;);&#125;//实际开启中断static __always_inline void native_irq_enable(void)&#123; asm volatile(&quot;sti&quot;:::&quot;memory&quot;);&#125;//arch层关中断static __always_inline void arch_local_irq_disable(void)&#123; native_irq_disable();&#125;//arch层开启中断static __always_inline void arch_local_irq_enable(void)&#123; native_irq_enable();&#125;//arch层保存eflags寄存器static __always_inline unsigned long arch_local_save_flags(void)&#123; return native_save_fl();&#125;//arch层恢复eflags寄存器static __always_inline void arch_local_irq_restore(unsigned long flags)&#123; native_restore_fl(flags);&#125;//实际保存eflags寄存器并关中断static __always_inline unsigned long arch_local_irq_save(void)&#123; unsigned long flags = arch_local_save_flags(); arch_local_irq_disable(); return flags;&#125;//raw层关闭开启中断宏#define raw_local_irq_disable() arch_local_irq_disable()#define raw_local_irq_enable() arch_local_irq_enable()//raw层保存恢复eflags寄存器宏#define raw_local_irq_save(flags) \\do &#123; \\ typecheck(unsigned long, flags); \\ flags = arch_local_irq_save(); \\&#125; while (0)#define raw_local_irq_restore(flags) \\do &#123; \\ typecheck(unsigned long, flags); \\arch_local_irq_restore(flags); \\&#125; while (0)#define raw_local_save_flags(flags) \\do &#123; \\typecheck(unsigned long, flags); \\flags = arch_local_save_flags(); \\&#125; while (0)//通用层接口宏#define local_irq_enable() \\do &#123; \\ raw_local_irq_enable(); \\&#125; while (0)#define local_irq_disable() \\do &#123; \\ raw_local_irq_disable(); \\&#125; while (0)#define local_irq_save(flags) \\do &#123; \\ raw_local_irq_save(flags); \\&#125; while (0)#define local_irq_restore(flags) \\do &#123; \\ raw_local_irq_restore(flags); \\&#125; while (0) Linux通过定义的方式对一些底层函数进行包装 编译Linux代码时,编译器对宏进行展开 4.2.3 Linux自旋锁 Linux需要自旋锁来对系统中的共享资源进行保护,同一时刻,获取了锁的进程才能使用共享资源 自旋锁不会引起加锁进程睡眠,如果自旋锁已经被别的进程持有,加锁进程需要一直循环,查看是否该自旋锁的持有者已经释放锁 Linux有多种自旋锁,重点介绍原始自旋锁和排队自旋锁 Linux原始自旋锁 Linux原始自旋锁本质上用一个整数表示,值1表示锁未被占用,值0或负数表示未被占用 当某个CPU核心执行进程请求加锁时,若锁是未加锁状态,则加锁,然后操作共享资源,最后释放锁 若锁已被加锁,则进程不会转入睡眠状态,而是循环等待该锁,一旦锁被释放,则第一个感知此信息的进程获得锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Linux底层的自旋锁数据结构typedef struct&#123; volatile unsigned long lock; //真正的锁值变量 // Linux原始自旋锁数据结构封装一个unsigned long类型变量&#125;spinlock_t;// 自旋锁接口#define spin_unlock_string \\ &quot;movb $1,%0&quot; \\ //写入1表示解锁 :&quot;=m&quot; (lock-&gt;lock) : : &quot;memory&quot;#define spin_lock_string \\ &quot;\\n1:\\t&quot; \\ &quot;lock ; decb %0\\n\\t&quot; \\ //原子减1 &quot;js 2f\\n&quot; \\ //当结果小于0则跳转到标号2处,表示加锁失败 &quot;.section .text.lock,\\&quot;ax\\&quot;\\n&quot; \\ //重新定义一个代码段,这是优化技术,避免后面的代码 &quot;2:\\t&quot; \\ &quot;cmpb $0,%0\\n\\t&quot; \\ //和0比较 &quot;rep;nop\\n\\t&quot; \\ //空指令 &quot;jle 2b\\n\\t&quot; \\ //小于或等于0跳转到标号2 &quot;jmp 1b\\n&quot; \\ //跳转到标号1 &quot;.previous&quot;//获取自旋锁static inline void spin_lock(spinlock_t*lock)&#123; __asm__ __volatile__( spin_lock_string :&quot;=m&quot;(lock-&gt;lock)::&quot;memory&quot; );&#125;//释放自旋锁static inline void spin_unlock(spinlock_t*lock)&#123; __asm__ __volatile__( spin_unlock_string );&#125;// spin_lock_string、spin_unlock_string 两个宏,定义了获取、释放自旋锁的汇编指令// spin_unlock_string 只是简单将锁值变量设置成 1,表示释放自旋锁// spin_lock_string 中并没有像Cosmos一样使用xchg指令,而是使用了decb指令,这条指令也能原子地执行减1操作// 开始锁值变量为 1 时,执行 decb 指令就变成了 0,0 就表示加锁成功// 如果小于 0,则表示有其它进程已经加锁了,就会导致循环比较 Linux排队自旋锁 在多个进程获取自旋锁时,必须等待,该获取次序依赖哪个CPU核心能最先访问内存,哪个CPU核心可以访问内存是由总线仲裁协议决定的 为了解决排队公平性问题,开发了排队自旋锁,通过保存进程申请获得锁的先后次序,就能公平地调度进程 slock域被分成两部分:锁持有者和未来锁申请者 只有next域与owner域相等时,才表示自旋锁处于未使用的状态 在排队自旋锁初始化时,slock被置为0,即next和owner被置为0,Linux进程执行申请自旋锁时,原子地将next域加0,并将原值返回作为自己的序号 如果返回的序号等于申请时的owner值,说明自旋锁处于未使用的状态,则进程直接获得锁;否则,该进程循环检查owner域是否等于自己持有的序号,一旦相等,则表明锁轮到自己获取 进程释放自旋锁时,原子地将owner域加1即可,下一个进程将会从循环状态中退出.进程将严格地按照申请顺序依次获取排队自旋锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//RAW层的自旋锁数据结构typedef struct raw_spinlock&#123; unsigned int slock;//真正的锁值变量&#125;raw_spinlock_t;//最上层的自旋锁数据结构typedef struct spinlock&#123; struct raw_spinlock rlock;&#125;spinlock_t;//Linux没有这样的结构,这只是为了描述方便typedef struct raw_spinlock&#123; union &#123; unsigned int slock;//真正的锁值变量 u16 owner; u16 next; &#125;&#125;raw_spinlock_t;static inline void __raw_spin_lock(raw_spinlock_t*lock)&#123; int inc = 0x00010000; int tmp; __asm__ __volatile__( &quot;lock ; xaddl %0, %1\\n&quot; //将inc和slock交换,然后 inc=inc+slock //相当于原子读取next和owner并对next+1 &quot;movzwl %w0, %2\\n\\t&quot;//将inc的低16位做0扩展后送tmp tmp=(u16)inc &quot;shrl $16, %0\\n\\t&quot; //将inc右移16位 inc=inc&gt;&gt;16 &quot;1:\\t&quot; &quot;cmpl %0, %2\\n\\t&quot; //比较inc和tmp,即比较next和owner &quot;je 2f\\n\\t&quot; //相等则跳转到标号2处返回 &quot;rep ; nop\\n\\t&quot; //空指令 &quot;movzwl %1, %2\\n\\t&quot; //将slock的低16位做0扩展后送tmp 即tmp=owner &quot;jmp 1b\\n&quot; //跳转到标号1处继续比较 &quot;2:&quot; :&quot;+Q&quot;(inc),&quot;+m&quot;(lock-&gt;slock),&quot;=r&quot;(tmp) ::&quot;memory&quot;,&quot;cc&quot; );&#125;#define UNLOCK_LOCK_PREFIX LOCK_PREFIXstatic inline void __raw_spin_unlock(raw_spinlock_t*lock)&#123; __asm__ __volatile__( UNLOCK_LOCK_PREFIX&quot;incw %0&quot;//将slock的低16位加1 即owner+1 :&quot;+m&quot;(lock-&gt;slock) ::&quot;memory&quot;,&quot;cc&quot;);&#125;// Linux为了避免差异性,在spinlock_t结构体中包含了raw_spinlock_t,而在raw_spinlock_t结构体中并没使用next和owner字段,而是在代码中直接操作slock的高16位和低16位来实现的// 当一个进程发现另一个进程已经拥有自己所请求地自旋锁时,就自愿放弃,转而做其他的工作,不循环等待浪费时间// Linux提供的自旋锁接口static inline int __raw_spin_trylock(raw_spinlock_t*lock)&#123; int tmp; int new; asm volatile( &quot;movl %2,%0\\n\\t&quot;//tmp=slock &quot;movl %0,%1\\n\\t&quot;//new=tmp &quot;roll $16, %0\\n\\t&quot;//tmp循环左移16位,即next和owner交换了 &quot;cmpl %0,%1\\n\\t&quot;//比较tmp和new即（owner、next）？=（next、owner） &quot;jne 1f\\n\\t&quot; //不等则跳转到标号1处 &quot;addl $0x00010000, %1\\n\\t&quot;//相当于next+1 &quot;lock ; cmpxchgl %1,%2\\n\\t&quot;//new和slock交换比较 &quot;1:&quot; &quot;sete %b1\\n\\t&quot; //new = eflags.ZF位,ZF取决于前面的判断是否相等 &quot;movzbl %b1,%0\\n\\t&quot; //tmp = new :&quot;=&amp;a&quot;(tmp),&quot;=Q&quot;(new),&quot;+m&quot;(lock-&gt;slock) ::&quot;memory&quot;,&quot;cc&quot;); return tmp;&#125;// _spin_trylock 返回1表示尝试加锁成功,可以安全的地问共享资源了// 返回值为 0 则表示尝试加锁失败,不能操作共享资源,应该等一段时间,再次尝试加锁int __lockfunc _spin_trylock(spinlock_t*lock)&#123; preempt_disable(); if(_raw_spin_trylock(lock))&#123; spin_acquire(&amp;lock-&gt;dep_map,0,1,_RET_IP_); return 1; &#125; preempt_enable(); return 0;&#125;// _cond_lock 只用代码静态检查工作#define spin_trylock(lock) __cond_lock(lock, _spin_trylock(lock)) Linux信号量 Linux信号量被用来保护共享资源,能保证资源在一个时刻只有一个进程使用,是单值信号量,也可以用来作为资源计数器,为多值信号量 信号量的值为正时,所申请的进程可以锁定使用它 若为0表示被其他进程占用,申请的进程要进入睡眠队列中,等待被唤醒 信号量的最大优势:既可以使申请失败的进程睡眠,还可以作为资源计数器使用 在Linux源代码的kernel/printk.c中,使用宏DEFINE_SEMAPHORE声明了一个单值信号量console_sem,也可以说是互斥锁,用于保护console驱动列表console_drivers以及同步对整个console驱动的访问 其中定义了宏down_console_sem()来获得信号量console_sem 定义了宏up_console_sem()来释放信号量console_sem console_lock 和 console_unlock 函数是用于互斥访问 console 驱动的,核心操作就是调用前面定义两个宏 代码描述了信号量的工作原理,详见代码 一个进程进入了__down 函数中,设置了一个不可中断的等待状态,然后执行了schedule_timeout函数.这个执行了进程的调度器,就直接调度到别的进程运行了 这时,这个进程就不会返回了,直到下一次它被up函数唤醒.执行了wake_up_process函数以后,重新调度它就会回到schedule_timeout函数下一行代码,沿着调用路经返回,最后从__down函数中出来,即进程睡醒 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// Linux实习信号量的数据结构struct semaphore&#123; raw_spinlock_t lock;//保护信号量自身的自旋锁 unsigned int count;//信号量值 struct list_head wait_list;//挂载睡眠等待进程的链表&#125;;// Linux信号量接口函数#define down_console_sem() do &#123; \\ down(&amp;console_sem);\\&#125; while (0)static void __up_console_sem(unsigned long ip) &#123; up(&amp;console_sem);&#125;#define up_console_sem() __up_console_sem(_RET_IP_)//加锁consolevoid console_lock(void)&#123; might_sleep(); down_console_sem();//获取信号量console_sem if (console_suspended) return; console_locked = 1; console_may_schedule = 1;&#125;//解锁consolevoid console_unlock(void)&#123; static char ext_text[CONSOLE_EXT_LOG_MAX]; static char text[LOG_LINE_MAX + PREFIX_MAX]; //……删除了很多代码 up_console_sem();//释放信号量console_sem raw_spin_lock(&amp;logbuf_lock); //……删除了很多代码&#125;// down_console_sem() 和 up_console_sem() 宏的核心主要是调用了信号量的接口函数 down、up 函数,完成获取、释放信号量的核心操作static inline int __sched __down_common(struct semaphore *sem, long state,long&#123;struct semaphore_waiter waiter;//把waiter加入sem-&gt;wait_list的头部list_add_tail(&amp;waiter.list, &amp;sem-&gt;wait_list);waiter.task = current;//current表示当前进程,即调用该函数的进程waiter.up = false;for (;;) &#123;if (signal_pending_state(state, current))goto interrupted;if (unlikely(timeout &lt;= 0))goto timed_out;__set_current_state(state);//设置当前进程的状态,进程睡眠,即先前__down函数中raw_spin_unlock_irq(&amp;sem-&gt;lock);//释放在down函数中加的锁timeout = schedule_timeout(timeout);//真正进入睡眠raw_spin_lock_irq(&amp;sem-&gt;lock);//进程下次运行会回到这里,所以要加锁if (waiter.up)return 0;&#125;timed_out:list_del(&amp;waiter.list);return -ETIME;interrupted:list_del(&amp;waiter.list);return -EINTR;//为了简单起见处理进程信号（signal）和超时的逻辑代码我已经删除&#125;//进入睡眠等待static noinline void __sched __down(struct semaphore *sem)&#123;__down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);&#125;//获取信号量void down(struct semaphore *sem)&#123;unsigned long flags;//对信号量本身加锁并关中断,必须另一段代码也在操作该信号量raw_spin_lock_irqsave(&amp;sem-&gt;lock, flags);if (likely(sem-&gt;count &gt; 0))sem-&gt;count--;//如果信号量值大于0,则对其减1else__down(sem);//否则让当前进程进入睡眠raw_spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);&#125;//实际唤醒进程static noinline void __sched __up(struct semaphore *sem)&#123;struct semaphore_waiter *waiter = list_first_entry(&amp;sem-&gt;wait_list, struct//获取信号量等待链表中的第一个数据结构semaphore_waiter,它里面保存着睡眠进程的指针list_del(&amp;waiter-&gt;list);waiter-&gt;up = true;wake_up_process(waiter-&gt;task);//唤醒进程重新加入调度队列&#125;//释放信号量void up(struct semaphore *sem)&#123;unsigned long flags;//对信号量本身加锁并关中断,必须另一段代码也在操作该信号量raw_spin_lock_irqsave(&amp;sem-&gt;lock, flags);if (likely(list_empty(&amp;sem-&gt;wait_list)))sem-&gt;count++;//如果信号量等待链表中为空,则对信号量值加1else__up(sem);//否则执行唤醒进程相关的操作raw_spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);&#125; Linux读写锁 在操作系统中,读取共享数据时,加锁会大大浪费时间,降低进程的运行效率,可共享访问解决;在写时,加锁解锁,大量进程等待,降低系统性能 读写锁(共享-独占),当读写锁用读取模式加锁时,以共享模式上锁,写入修改模式加锁时,以独占模式上锁(互斥) 非常适用于读取数据的频率远大于修改数据的频率的场景, 读写锁读取时不能写入,写入时不能读取,而且读取和写入竞争锁时,写会优先得到锁 步骤 当共享数据没有锁的时候,读取的加锁操作和写入的加锁操作都可以满足 当共享数据有读锁的时候,所有的读取加锁操作都可以满足,写入的加锁操作不能满足,读写是互斥的 当共享数据有写锁的时候,所有的读取的加锁操作都不能满足,所有的写入的加锁操作也不能满足,读与写之间是互斥的,写与写之间也是互斥的 Linux中读写锁本质上时自旋锁的变种 Linux读写锁的原理本质上时基于计数器,初始值为0x01000000 获取读锁时对其减1,结果不小于0表示读锁成功,获取写锁时直接减去0x01000000 **减初值的原因:**只有当锁值为初始值时,减去初始值结果才可以是 0,这是唯一没有进程持有任何锁的情况,这样才能保证获取写锁时是互斥的 读写锁其实是带计数的特殊自旋锁,能同时被多个读取数据的进程占有或一个修改数据的进程占有,但不能同时被读取数据的进程和修改数据的进程占有 获取,释放读写锁的流程 获取读锁时,锁值变量 lock 计数减去 1,判断结果的符号位是否为 1.若结果符号位为0 时,获取读锁成功,即表示 lock 大于 0 获取读锁时,锁值变量 lock 计数减去 1,判断结果的符号位是否为 1.若结果符号位为1 时,获取读锁失败,表示此时读写锁被修改数据的进程占有,此时调用__read_lock_failed 失败处理函数,循环测试 lock+1 的值,直到结果的值大于等于 1 获取写锁时,锁值变量 lock 计数减去 RW_LOCK_BIAS_STR,即 lock-0x01000000,判断结果是否为 0.若结果为 0 时,表示获取写锁成功 获取写锁时,锁值变量 lock 计数减去 RW_LOCK_BIAS_STR,即 lock-0x01000000,判断结果是否为 0.若结果不为 0 时,获取写锁失败,表示此时有读取数据的进程占有读锁或有修改数据的进程占有写锁,此时调用 __write_lock_failed 失败处理函数,循环测试lock+0x01000000,直到结果的值等于 0x01000000 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//读写锁初始化锁值#define RW_LOCK_BIAS 0x01000000//读写锁的底层数据结构typedef struct&#123;unsigned int lock;&#125;arch_rwlock_t;//释放读锁static inline void arch_read_unlock(arch_rwlock_t*rw)&#123;asm volatile(LOCK_PREFIX&quot;incl %0&quot; //原子对lock加1:&quot;+m&quot;(rw-&gt;lock)::&quot;memory&quot;);&#125;//释放写锁static inline void arch_write_unlock(arch_rwlock_t*rw)&#123;asm volatile(LOCK_PREFIX&quot;addl %1, %0&quot;//原子对lock加上RW_LOCK_BIAS:&quot;+m&quot;(rw-&gt;lock):&quot;i&quot;(RW_LOCK_BIAS):&quot;memory&quot;);&#125;//获取写锁失败时调用ENTRY(__write_lock_failed)//(%eax)表示由eax指向的内存空间是调用者传进来的2:LOCK_PREFIX addl $ RW_LOCK_BIAS,(%eax)1:rep;nop//空指令cmpl $RW_LOCK_BIAS,(%eax)//不等于初始值则循环比较,相等则表示有进程释放了写锁jne 1b//执行加写锁LOCK_PREFIX subl $ RW_LOCK_BIAS,(%eax)jnz 2b //不为0则继续测试,为0则表示加写锁成功ret //返回ENDPROC(__write_lock_failed)//获取读锁失败时调用ENTRY(__read_lock_failed)//(%eax)表示由eax指向的内存空间是调用者传进来的2:LOCK_PREFIX incl(%eax)//原子加11: rep; nop//空指令cmpl $1,(%eax) //和1比较 小于0则js 1b //为负则继续循环比较LOCK_PREFIX decl(%eax) //加读锁js 2b //为负则继续加1并比较,否则返回ret //返回ENDPROC(__read_lock_failed)//获取读锁static inline void arch_read_lock(arch_rwlock_t*rw)&#123;asm volatile(LOCK_PREFIX&quot; subl $1,(%0)\\n\\t&quot;//原子对lock减1&quot;jns 1f\\n&quot;//不为小于0则跳转标号1处,表示获取读锁成功&quot;call __read_lock_failed\\n\\t&quot;//调用__read_lock_failed&quot;1:\\n&quot;::LOCK_PTR_REG(rw):&quot;memory&quot;);&#125;//获取写锁static inline void arch_write_lock(arch_rwlock_t*rw)&#123;asm volatile(LOCK_PREFIX&quot;subl %1,(%0)\\n\\t&quot;//原子对lock减去RW_LOCK_BIAS&quot;jz 1f\\n&quot;//为0则跳转标号1处&quot;call __write_lock_failed\\n\\t&quot;//调用__write_lock_failed&quot;1:\\n&quot;::LOCK_PTR_REG(rw),&quot;i&quot;(RW_LOCK_BIAS):&quot;memory&quot;); 5 启动初始化 5.1 建立计算机 把多个文件变成一个文件就需要封装,即把多个文件组装形成一个文件,这个文件称为内核映像文件 内核映像文件包含二级引导器的模块,内核模块,图片和字库文件 GRUB头有4KB大小,GRUB通过一小段代码来识别映像文件,根据映像文件描述符和文件头描述符里的信息,并且还可以解析映像文件中的其他文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//映像文件头描述符typedef struct s_mlosrddsc&#123;u64_t mdc_mgic; //映像文件标识u64_t mdc_sfsum;//未使用u64_t mdc_sfsoff;//未使用u64_t mdc_sfeoff;//未使用u64_t mdc_sfrlsz;//未使用u64_t mdc_ldrbk_s;//映像文件中二级引导器的开始偏移u64_t mdc_ldrbk_e;//映像文件中二级引导器的结束偏移u64_t mdc_ldrbk_rsz;//映像文件中二级引导器的实际大小u64_t mdc_ldrbk_sum;//映像文件中二级引导器的校验和u64_t mdc_fhdbk_s;//映像文件中文件头描述的开始偏移u64_t mdc_fhdbk_e;//映像文件中文件头描述的结束偏移u64_t mdc_fhdbk_rsz;//映像文件中文件头描述的实际大小u64_t mdc_fhdbk_sum;//映像文件中文件头描述的校验和u64_t mdc_filbk_s;//映像文件中文件数据的开始偏移u64_t mdc_filbk_e;//映像文件中文件数据的结束偏移u64_t mdc_filbk_rsz;//映像文件中文件数据的实际大小u64_t mdc_filbk_sum;//映像文件中文件数据的校验和u64_t mdc_ldrcodenr;//映像文件中二级引导器的文件头描述符的索引号u64_t mdc_fhdnr;//映像文件中文件头描述符有多少个u64_t mdc_filnr;//映像文件中文件头有多少个u64_t mdc_endgic;//映像文件结束标识u64_t mdc_rv;//映像文件版本&#125;mlosrddsc_t;#define FHDSC_NMAX 192 //文件名长度//文件头描述符typedef struct s_fhdsc&#123;u64_t fhd_type;//文件类型u64_t fhd_subtype;//文件子类型u64_t fhd_stuts;//文件状态u64_t fhd_id;//文件idu64_t fhd_intsfsoff;//文件在映像文件位置开始偏移u64_t fhd_intsfend;//文件在映像文件的结束偏移u64_t fhd_frealsz;//文件实际大小u64_t fhd_fsum;//文件校验和char fhd_name[FHDSC_NMAX];//文件名&#125;fhdsc_t;// Linux命令行下的打包映像的工具lmoskrlimg -m k -lhf GRUB头文件 -o 映像文件 -f 输入的文件列表-m 表示模式 只能是k内核模式-lhf 表示后面跟上GRUB头文件-o 表示输出的映像文件名-f 表示输入文件列表 使用虚拟机建立虚拟电脑 需要手工生产磁盘,使用dd命令 Linux在文件上建立文件系统 第一步,把虚拟磁盘文件变成Linux下的回环设备,用losetup命令,将hd.img变成Linux的回环设备 第二步,将losetup命令用于设置回环设备.回环设备可以把文件虚拟成Linux块设备,用来模拟整个文件系统,让用户可以将其看作硬盘、光驱或软驱等设备,并且可用mount命令挂载当作目录来使用 第三步,用Linux下的mount命令,将hd.img文件当作块设备,把它挂载到事先建立的hdisk目录下,并在其中建立一个boot mount命令只能识别在纯二进制文件上建立的文件系统,如果使用虚拟机自己生成的磁盘文件,mount无法识别文件系统 安装GRUB 通过GRUB的安装程序,将GRUB安装到指定的虚拟磁盘上 /hdisk/boot/目录下创建了grub目录,表示GRUB安装成功 在/hdisk/boot/grub/目录下建立一个grub.cfg文本文件,GRUB正是通过这个文件内容,查找到操作系统映像文件的 转换虚拟磁盘格式供虚拟机识别 使用专用的转化格式工具 安装虚拟磁盘 生成VDI格式的虚拟磁盘后,使用hd.vdi文件和虚拟机软件联系 配置虚拟磁盘分两步：第一步,配置硬盘控制器,其控制器是intelAHCI;第二步,挂载虚拟硬盘文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Linux下dd命令// 用指定大小的块拷贝一个文件,并在拷贝的同时进行指定的转换dd bs=512 if=/dev/zero of=hd.img count=204800;bs:表示块大小,这里是512字节;if：表示输入文件,/dev/zero就是Linux下专门返回0数据的设备文件,读取它就返回0;of：表示输出文件,即我们的硬盘文件.;count：表示输出多少块sudo losetup /dev/loop0 hd.imgsudo mkfs.ext4 -q /dev/loop0sudo mount -o loop ./hd.img ./hdisk/ ;挂载硬盘文件sudo mkdir ./hdisk/boot/ ;建立boot目录// 安装GRUB第一步挂载虚拟硬盘文件为loop0回环设备sudo losetup /dev/loop0 hd.imgsudo mount -o loop ./hd.img ./hdisk/ ;挂载硬盘文件第二步安装GRUBsudo grub-install --boot-directory=./hdisk/boot/ --force --allow-floppy /dev/l;--boot-directory 指向先前我们在虚拟硬盘中建立的boot目录.;--force --allow-floppy ：指向我们的虚拟硬盘设备文件/dev/loop0// grub.cfgmenuentry &#x27;HelloOS&#x27; &#123;insmod part_msdosinsmod ext2set root=&#x27;hd0,msdos1&#x27; #我们的硬盘只有一个分区所以是&#x27;hd0,msdos1&#x27;multiboot2 /boot/HelloOS.eki #加载boot目录下的HelloOS.eki文件boot #引导启动&#125;set timeout_style=menuif [ &quot;$&#123;timeout&#125;&quot; = 0 ]; thenset timeout=10 #等待10秒钟自动启动fi// 转换虚拟磁盘格式VBoxManage convertfromraw ./hd.img --format VDI ./hd.vdi;convertfromraw 指向原始格式文件;--format VDI 表示转换成虚拟需要的VDI格式// 安装虚拟磁盘#第一步 SATA的硬盘其控制器是intelAHCIVBoxManage storagectl HelloOS --name &quot;SATA&quot; --add sata --controller IntelAhci#第二步VBoxManage closemedium disk ./hd.vdi #删除虚拟硬盘UUID并重新分配#将虚拟硬盘挂到虚拟机的硬盘控制器VBoxManage storageattach HelloOS --storagectl &quot;SATA&quot; --port 1 --device 0 --typ 5.2 建造二级引导器 二级引导器作为操作系统的先驱,需要收集机器信息,确定这个计算机能不能运行操作系统,对CPU,内存,显卡进行初级配置,放置内核相关的文件 二级引导器不执行具体的加载任务,而是解析内核文件,收集机器环境信息 设计机器信息结构 二级引导器收集的信息放在内存1MB的地方,方便传给操作系统 1234567891011121314151617181920212223// 存放信息的数据结构typedef struct s_MACHBSTART&#123;u64_t mb_krlinitstack;//内核栈地址u64_t mb_krlitstacksz;//内核栈大小u64_t mb_imgpadr;//操作系统映像u64_t mb_imgsz;//操作系统映像大小u64_t mb_bfontpadr;//操作系统字体地址u64_t mb_bfontsz;//操作系统字体大小u64_t mb_fvrmphyadr;//机器显存地址u64_t mb_fvrmsz;//机器显存大小u64_t mb_cpumode;//机器CPU工作模式u64_t mb_memsz;//机器内存大小u64_t mb_e820padr;//机器e820数组地址u64_t mb_e820nr;//机器e820数组元素个数u64_t mb_e820sz;//机器e820数组大小//……u64_t mb_pml4padr;//机器页表数据地址u64_t mb_subpageslen;//机器页表个数u64_t mb_kpmapphymemsz;//操作系统映射空间大小//……graph_t mb_ghparm;//图形信息&#125;__attribute__((packed)) machbstart_t; 规划二级引导器 整体划分二级引导器的功能模块 实现GRUB头 GRUB头有两个文件组成 imginithead.asm汇编文件:能让GRUB识别,又能设置C语言运行环境,调用C函数 主要工作是初始化CPU寄存器,加载GDT,切换到CPU的保护模式 inithead.c文件:查找二级引导器的核心文件(initdrkrl.bin),将它放置到特定的内存地址上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155// GRUB1和GRUB2需要的两个头结构MBT_HDR_FLAGS EQU 0x00010003MBT_HDR_MAGIC EQU 0x1BADB002MBT2_MAGIC EQU 0xe85250d6global _startextern inithead_entry[section .text][bits 32]_start:jmp _entryalign 4mbt_hdr:dd MBT_HDR_MAGICdd MBT_HDR_FLAGSdd -(MBT_HDR_MAGIC+MBT_HDR_FLAGS)dd mbt_hdrdd _startdd 0dd 0dd _entryALIGN 8mbhdr:DD 0xE85250D6DD 0DD mhdrend - mbhdrDD -(0xE85250D6 + 0 + (mhdrend - mbhdr))DW 2, 0DD 24DD mbhdrDD _startDD 0DD 0DW 3, 0DD 12DD _entryDD 0DW 0, 0DD 8mhdrend:// 关中断并加载GDT_entry: cli ;关中断 in al, 0x70 or al, 0x80 out 0x70,al ;关掉不可屏蔽中断 lgdt [GDT_PTR] ;加载GDT地址到GDTR寄存器 jmp dword 0x8 :_32bits_mode ;长跳转刷新CS影子寄存器 ;………………;GDT全局段描述符表GDT_START:knull_dsc: dq 0kcode_dsc: dq 0x00cf9e000000ffffkdata_dsc: dq 0x00cf92000000ffffk16cd_dsc: dq 0x00009e000000ffff ;16位代码段描述符k16da_dsc: dq 0x000092000000ffff ;16位数据段描述符GDT_END:GDT_PTR:GDTLEN dw GDT_END-GDT_START-1 ;GDT界限GDTBASE dd GDT_ST// 初始化段寄存器和通用寄存器,栈寄存器// 给调用inithead_entry函数做准备_32bits_mode： mov ax, 0x10 mov ds, ax mov ss, ax mov es, ax mov fs, ax mov gs, ax xor eax,eax xor ebx,ebx xor ecx,ecx xor edx,edx xor edi,edi xor esi,esi xor ebp,ebp xor esp,esp mov esp,0x7c00 ;设置栈顶为0x7c00 call inithead_entry ;调用inithead_entry函数在inithead.c中实现 jmp 0x200000 ;跳转到0x200000地址// inithead.c文件中实现inithead_entry函数#define MDC_ENDGIC 0xaaffaaffaaffaaff#define MDC_RVGIC 0xffaaffaaffaaffaa#define REALDRV_PHYADR 0x1000#define IMGFILE_PHYADR 0x4000000#define IMGKRNL_PHYADR 0x2000000#define LDRFILEADR IMGFILE_PHYADR#define MLOSDSC_OFF (0x1000)#define MRDDSC_ADR (mlosrddsc_t*)(LDRFILEADR+0x1000)void inithead_entry()&#123;write_realintsvefile();write_ldrkrlfile();return;&#125;//写initldrsve.bin文件到特定的内存中void write_realintsvefile()&#123;fhdsc_t *fhdscstart = find_file(&quot;initldrsve.bin&quot;);if (fhdscstart == NULL)&#123;error(&quot;not file initldrsve.bin&quot;);&#125;m2mcopy((void *)((u32_t)(fhdscstart-&gt;fhd_intsfsoff) + LDRFILEADR),(void *)REALDRV_PHYADR, (sint_t)fhdscstart-&gt;fhd_frealsz);return;&#125;//写initldrkrl.bin文件到特定的内存中void write_ldrkrlfile()&#123;fhdsc_t *fhdscstart = find_file(&quot;initldrkrl.bin&quot;);if (fhdscstart == NULL)&#123;error(&quot;not file initldrkrl.bin&quot;);&#125;m2mcopy((void *)((u32_t)(fhdscstart-&gt;fhd_intsfsoff) + LDRFILEADR),(void *)ILDRKRL_PHYADR, (sint_t)fhdscstart-&gt;fhd_frealsz);return;&#125;//在映像文件中查找对应的文件fhdsc_t *find_file(char_t *fname)&#123;mlosrddsc_t *mrddadrs = MRDDSC_ADR;if (mrddadrs-&gt;mdc_endgic != MDC_ENDGIC ||mrddadrs-&gt;mdc_rv != MDC_RVGIC ||mrddadrs-&gt;mdc_fhdnr &lt; 2 ||mrddadrs-&gt;mdc_filnr &lt; 2)&#123;error(&quot;no mrddsc&quot;);&#125;s64_t rethn = -1;fhdsc_t *fhdscstart = (fhdsc_t *)((u32_t)(mrddadrs-&gt;mdc_fhdbk_s) + LDRFILEfor (u64_t i = 0; i &lt; mrddadrs-&gt;mdc_fhdnr; i++)&#123;if (strcmpl(fname, fhdscstart[i].fhd_name) == 0)&#123;rethn = (s64_t)i;goto ok_l;&#125;&#125;rethn = -1;ok_l:if (rethn &lt; 0)&#123;error(&quot;not find file&quot;);&#125;return &amp;fhdscstart[rethn];&#125;// inithead_entry函数// 工作:分别调用write_realintsvefile();write_ldrkrlfile()函数,把映像文件中的initldrsve.bin和initldrkrl.bin文件写入特定的内存地址空间中 // find_file 函数负责扫描映像文件中的文件头描述符,对比其中的文件名,然后返回对应的文件头描述符的地址,这样就可以得到文件在映像文件中的位置和大小了 // m2mcopy函数负责把映像文件复制到具体的内存空间里 进入二级引导器 在GRUB头imghead.asm文件中jmp 0x200000跳转到物理内存0x200000地址处 物理地址,此地址是inithead.c中由write_ldrkrlfile()函数放置的initldrkrl.bin文件,跳转进入了二级引导器的主模块 1234567891011121314151617181920212223242526272829303132333435363738394041// 模块改变,需要汇编代码,建立initldr32.asm文件// 加载GDTR和IDTR寄存器,然后初始化CPU相关寄存器_entry: cli lgdt [GDT_PTR];加载GDT地址到GDTR寄存器 lidt [IDT_PTR];加载IDT地址到IDTR寄存器 jmp dword 0x8 :_32bits_mode;长跳转刷新CS影子寄存器_32bits_mode: mov ax, 0x10 ; 数据段选择子(目的) mov ds, ax mov ss, ax mov es, ax mov fs, ax mov gs, ax xor eax,eax xor ebx,ebx xor ecx,ecx xor edx,edx xor edi,edi xor esi,esi xor ebp,ebp xor esp,esp mov esp,0x90000 ;使得栈底指向了0x90000 call ldrkrl_entry ;调用ldrkrl_entry函数 xor ebx,ebx jmp 0x2000000 ;跳转到0x2000000的内存地址 jmp $GDT_START:knull_dsc: dq 0kcode_dsc: dq 0x00cf9a000000ffff ;a-ekdata_dsc: dq 0x00cf92000000ffffk16cd_dsc: dq 0x00009a000000ffff ;16位代码段描述符k16da_dsc: dq 0x000092000000ffff ;16位数据段描述符GDT_END:GDT_PTR:GDTLEN dw GDT_END-GDT_START-1 ;GDT界限GDTBASE dd GDT_STARTIDT_PTR:IDTLEN dw 0x3ffIDTBAS dd 0 ;这是BIOS中断表的地址和长度// 把 GDT,IDT寄存器重新初始化,最后再去调用二级引导器的主函数 ldrkrl_entry 巧妙调用BIOS中断 获得内存信息以及设置显卡图形模式依赖BIOS提供的中断服务 C语言代码工作在32位保护模式下,BIOS中断工作在16位的实模式 C语言调用BIOS中断需要处理的问题 保存C语言环境的上下文 切换回实模式,调用BIOS中断,把BIOS中断返回的结果保存在内存中 切换回保护模式,重新加载第一步中的数据 将汇编函数写在initldr32.asm中 之前write_realintsvefile()函数的功能与意义 把映像文件中的initldrsve.bin文件写入到特定的内存地址空间中 initldrsve.bin是由上面的realintsve.asm文件编译而成的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970realadr_call_entry: pushad ;保存通用寄存器 push ds push es push fs ;保存4个段寄存器 push gs call save_eip_jmp ;调用save_eip_jmp pop gs pop fs pop es ;恢复4个段寄存器 pop ds popad ;恢复通用寄存器 retsave_eip_jmp: pop esi ;弹出call save_eip_jmp时保存的eip到esi寄存器中, mov [PM32_EIP_OFF],esi ;把eip保存到特定的内存空间中 mov [PM32_ESP_OFF],esp ;把esp保存到特定的内存空间中 jmp dword far [cpmty_mode];长跳转这里表示把cpmty_mode处的第一个4字节装入eip;把0x18：0x1000 装入到 CS：EIP 中cpmty_mode: dd 0x1000 dw 0x18 jmp $// 0x18就是段描述索引指向GDT中的16位代码段描述符// 0x1000 代表段内的偏移地址,必须放一段代码指令// 建立realintsve.asm[bits 16]_start:_16_mode: mov bp,0x20 ;0x20是指向GDT中的16位数据段描述符 mov ds, bp mov es, bp mov ss, bp mov ebp, cr0 and ebp, 0xfffffffe mov cr0, ebp ;CR0.P=0 关闭保护模式 jmp 0:real_entry ;刷新CS影子寄存器,真正进入实模式real_entry: mov bp, cs mov ds, bp mov es, bp mov ss, bp ;重新设置实模式下的段寄存器 都是CS中值,即为0 mov sp, 08000h ;设置栈 mov bp,func_table add bp,ax call [bp] ;调用函数表中的汇编函数,ax是C函数中传递进来的 cli call disable_nmi mov ebp, cr0 or ebp, 1 mov cr0, ebp ;CR0.P=1 开启保护模式 jmp dword 0x8 :_32bits_mode[BITS 32]_32bits_mode: mov bp, 0x10 mov ds, bp mov ss, bp;重新设置保护模式下的段寄存器0x10是32位数据段描述符的索引 mov esi,[PM32_EIP_OFF];加载先前保存的EIP mov esp,[PM32_ESP_OFF];加载先前保存的ESP jmp esi ;eip=esi 回到了realadr_call_entry函数中 func_table: ;函数表 dw _getmmap ;获取内存布局视图的函数 dw _read ;读取硬盘的函数 dw _getvbemode ;获取显卡VBE模式 dw _getvbeonemodeinfo ;获取显卡VBE模式的数据 dw _setvbemode ;设置显卡VBE模式// 首先从_16_mode:标号处进入实模式,然后根据传递进来(由ax寄存器传入)的函数号,到函数表中调用对应的函数,里面的函数执行完成后,再次进入保护模式,加载EIP和ESP寄存器从而回到realadr_call_entry函数中// GDT还是imghead.asm汇编代码文件中的GDT,因为它是由GDTR寄存器指向的 二级引导器主函数 二级引导器主函数使用C来写 代码中的ldrkrl_entry函数在initldr32.asm文件中被调用 从callldrkrl_entry指令开始进入了ldrkrl_entry()函数,在其中调用了**init_bstartparm()**函数 **init_bstartparm()**负责处理开始参数的,位手机机器环境信息的主函数 将处理操作系统运行环境的工作独立出来,交给二级引导器做,大大降低开发操作系统的难度,增加操作系统的通用性 5.3 探查和收集信息 完成具体的二级引导器的工作 检查CPU是否支持64位的工作模式 收集内存布局信息 是否符合操作系统的最低运行要求 设置操作系统需要的MMU页表 设置显卡模式 释放中文字体 检查与收集机器信息 为了使代码清晰,不直接在ldrkrl__entry()中实现,在bstartparm.c文件中实现init_bstartparm() 123456789101112131415//初始化machbstart_t结构体,清0,并设置一个标志void machbstart_t_init(machbstart_t* initp)&#123; memset(initp,0,sizeof(machbstart_t)); initp-&gt;mb_migc=MBS_MIGC; return;&#125;void init_bstartparm()&#123; machbstart_t* mbsp = MBSPADR;//1MB的内存地址 machbstart_t_init(mbsp); return;&#125;// 调用了一个machbstart_t_init()函数// 在1MB内存地址处初始化了一个机器信息结构machbstart_t 检查CPU:init_chkcpu() 要CPUID指令检查CPU是否支持64位长模式,所以需要chk_cpuid,chk_cpu_longmode开实现检查CPU是否支持CPUID指令,以及检查CPU支持64位长模式 最后设置机器信息结构中的mb_cpumode字段为64,mbsp正是传递进来的机器信息machbstart_t 结构体的指针 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//通过改写Eflags寄存器的第21位,观察其位的变化判断是否支持CPUIDint chk_cpuid()&#123; int rets = 0; __asm__ __volatile__( &quot;pushfl \\n\\t&quot; &quot;popl %%eax \\n\\t&quot; &quot;movl %%eax,%%ebx \\n\\t&quot; &quot;xorl $0x0200000,%%eax \\n\\t&quot; &quot;pushl %%eax \\n\\t&quot; &quot;popfl \\n\\t&quot; &quot;pushfl \\n\\t&quot; &quot;popl %%eax \\n\\t&quot; &quot;xorl %%ebx,%%eax \\n\\t&quot; &quot;jz 1f \\n\\t&quot; &quot;movl $1,%0 \\n\\t&quot; &quot;jmp 2f \\n\\t&quot; &quot;1: movl $0,%0 \\n\\t&quot; &quot;2: \\n\\t&quot; : &quot;=c&quot;(rets) : :); return rets;&#125;//检查CPU是否支持长模式int chk_cpu_longmode()&#123; int rets = 0; __asm__ __volatile__( &quot;movl $0x80000000,%%eax \\n\\t&quot; &quot;cpuid \\n\\t&quot; //把eax中放入0x80000000调用CPUID指令 &quot;cmpl $0x80000001,%%eax \\n\\t&quot;//看eax中返回结果 &quot;setnb %%al \\n\\t&quot; //不为0x80000001,则不支持0x80000001号功能 &quot;jb 1f \\n\\t&quot; &quot;movl $0x80000001,%%eax \\n\\t&quot; &quot;cpuid \\n\\t&quot;//把eax中放入0x800000001调用CPUID指令,检查edx中的返回数据 &quot;bt $29,%%edx \\n\\t&quot; //长模式 支持位 是否为1 &quot;setcb %%al \\n\\t&quot; &quot;1: \\n\\t&quot; &quot;movzx %%al,%%eax \\n\\t&quot; : &quot;=a&quot;(rets) : :); return rets;&#125;//检查CPU主函数void init_chkcpu(machbstart_t *mbsp)&#123; if (!chk_cpuid()) &#123; kerror(&quot;Your CPU is not support CPUID sys is die!&quot;); CLI_HALT(); &#125; if (!chk_cpu_longmode()) &#123; kerror(&quot;Your CPU is not support 64bits mode sys is die!&quot;); CLI_HALT(); &#125; mbsp-&gt;mb_cpumode = 0x40;//如果成功则设置机器信息结构的cpu模式为64位 return;&#125;// 检查CPU是否支持CPUID指令和检查CPU是否支持长模式,只要其中一步检查失败,就打印一条相应的提示信息,然后主动死机 获取内存布局 物理内存在物理地址空间中是一段一段的,描述一段内存有一个数据结构 获取内存布局信息就是获取结构体的数组,交给init_mem函数来干 完成获取上述这个结构体数组,并且检查内存 实现init_mem函数中最难写的是mmap函数,只要调用BIOS中断,就能获取e820map结构数组 init_mem函数在调用mmap函数后,就会得到e820map结构数组,其首地址和数组元素个数由retemp,retemnr两个变量分别提供 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#define RAM_USABLE 1 //可用内存#define RAM_RESERV 2 //保留内存不可使用#define RAM_ACPIREC 3 //ACPI表相关的#define RAM_ACPINVS 4 //ACPI NVS空间#define RAM_AREACON 5 //包含坏内存typedef struct s_e820&#123; u64_t saddr; /* 内存开始地址 */ u64_t lsize; /* 内存大小 */ u32_t type; /* 内存类型 */&#125;e820map_t;// 实现init_mem函数#define ETYBAK_ADR 0x2000#define PM32_EIP_OFF (ETYBAK_ADR)#define PM32_ESP_OFF (ETYBAK_ADR+4)#define E80MAP_NR (ETYBAK_ADR+64)//保存e820map_t结构数组元素个数的地址#define E80MAP_ADRADR (ETYBAK_ADR+68) //保存e820map_t结构数组的开始地址void init_mem(machbstart_t *mbsp)&#123; e820map_t *retemp; u32_t retemnr = 0; mmap(&amp;retemp, &amp;retemnr); if (retemnr == 0) &#123; kerror(&quot;no e820map\\n&quot;); &#125; //根据e820map_t结构数据检查内存大小 if (chk_memsize(retemp, retemnr, 0x100000, 0x8000000) == NULL) &#123; kerror(&quot;Your computer is low on memory, the memory cannot be less than &#125; mbsp-&gt;mb_e820padr = (u64_t)((u32_t)(retemp));//把e820map_t结构数组的首地址传给 mbsp-&gt;mb_e820nr = (u64_t)retemnr;//把e820map_t结构数组元素个数传给mbsp-&gt;mb_e82 mbsp-&gt;mb_e820sz = retemnr * (sizeof(e820map_t));//把e820map_t结构数组大小传给 mbsp-&gt;mb_memsz = get_memsize(retemp, retemnr);//根据e820map_t结构数据计算内存大 return;&#125;// mmap函数调用关系// realadr_call_entry 函数,来调用实模式下的_getmmap 函数的,并且在 _getmmap 函数中调用 BIOS 中断的void mmap(e820map_t **retemp, u32_t *retemnr)&#123; realadr_call_entry(RLINTNR(0), 0, 0); *retemnr = *((u32_t *)(E80MAP_NR)); *retemp = (e820map_t *)(*((u32_t *)(E80MAP_ADRADR))); return;&#125;_getmmap: push ds push es push ss mov esi,0 mov dword[E80MAP_NR],esi mov dword[E80MAP_ADRADR],E80MAP_ADR ;e820map结构体开始地址 xor ebx,ebx mov edi,E80MAP_ADRloop: mov eax,0e820h ;获取e820map结构参数 mov ecx,20 ;e820map结构大小 mov edx,0534d4150h ;获取e820map结构参数必须是这个数据 int 15h ;BIOS的15h中断 jc .1 add edi,20 cmp edi,E80MAP_ADR+0x1000 jg .1 inc esi cmp ebx,0 jne loop ;循环获取e820map结构 jmp .2.1: mov esi,0 ;出错处理,e820map结构数组元素个数为0.2: mov dword[E80MAP_NR],esi ;e820map结构数组元素个数 pop ss pop es pop ds ret 初始化内核栈 给即将运行的内核初始化一个栈,就是在机器信息结构machbstart_t中,记录一个栈地址和栈大小,供内核在启动时使用 init_krlinitstack函数非常简单,但其中调用链一个move_krlimg函数负责判断一个地址空间是否和内存中存放的内容有冲突 因为内存中放置了机器信息结构,内存视窗结构数组,二级引导器,内核映像文件,故在处理内存空间时不能和内存中已经存在的冲突,否则就要覆盖数据 0x8f000-(0x8f000+0x1001)是内核栈空间,需要检测它是否和其它空间有冲突 12345678910111213#define IKSTACK_PHYADR (0x90000-0x10)#define IKSTACK_SIZE 0x1000//初始化内核栈void init_krlinitstack(machbstart_t *mbsp)&#123; if (1 &gt; move_krlimg(mbsp, (u64_t)(0x8f000), 0x1001)) &#123; kerror(&quot;iks_moveimg err&quot;); &#125; mbsp-&gt;mb_krlinitstack = IKSTACK_PHYADR;//栈顶地址 mbsp-&gt;mb_krlitstacksz = IKSTACK_SIZE; //栈大小是4KB return;&#125; 放置内核文件与字库文件 内核已经编译成一个独立的二进制程序,和其它文件一起被打包到映像文件中,故必须要从映像中将它解压出来,将其放在特定的物理内存空间中才可以 放置字库文件和放置内核文件的原理一样 内核是代码数据,所以必须要复制到指定的内存空间中 12345678910111213141516171819202122232425262728293031323334353637//放置内核文件void init_krlfile(machbstart_t *mbsp)&#123;//在映像中查找相应的文件,并复制到对应的地址,并返回文件的大小,这里是查找kernel.bin文件 u64_t sz = r_file_to_padr(mbsp, IMGKRNL_PHYADR, &quot;kernel.bin&quot;); if (0 == sz) &#123; kerror(&quot;r_file_to_padr err&quot;); &#125; //放置完成后更新机器信息结构中的数据 mbsp-&gt;mb_krlimgpadr = IMGKRNL_PHYADR; mbsp-&gt;mb_krlsz = sz; //mbsp-&gt;mb_nextwtpadr始终要保持指向下一段空闲内存的首地址 mbsp-&gt;mb_nextwtpadr = P4K_ALIGN(mbsp-&gt;mb_krlimgpadr + mbsp-&gt;mb_krlsz); mbsp-&gt;mb_kalldendpadr = mbsp-&gt;mb_krlimgpadr + mbsp-&gt;mb_krlsz; return;&#125;//放置字库文件void init_defutfont(machbstart_t *mbsp)&#123; u64_t sz = 0; //获取下一段空闲内存空间的首地址 u32_t dfadr = (u32_t)mbsp-&gt;mb_nextwtpadr;//在映像中查找相应的文件,并复制到对应的地址,并返回文件的大小,这里是查找font.fnt文件 sz = r_file_to_padr(mbsp, dfadr, &quot;font.fnt&quot;); if (0 == sz) &#123; kerror(&quot;r_file_to_padr err&quot;); &#125; //放置完成后更新机器信息结构中的数据 mbsp-&gt;mb_bfontpadr = (u64_t)(dfadr); mbsp-&gt;mb_bfontsz = sz; //更新机器信息结构中下一段空闲内存的首地址 mbsp-&gt;mb_nextwtpadr = P4K_ALIGN((u32_t)(dfadr) + sz); mbsp-&gt;mb_kalldendpadr = mbsp-&gt;mb_bfontpadr + mbsp-&gt;mb_bfontsz; return;&#125; 建立MMU页表数据 在二级引导器中建立MMU页表数据,目的就是要在内核加载运行之初开启长模式,MMU需要的页表数据已经准备好了 内核虚拟地址空间从0xffff800000000000开始,所以这个虚拟地址映射到从物理地址 0 开始,大小都是 0x400000000即16GB 虚拟地址空间：0xffff800000000000～0xffff800400000000映射到物理地址空间0～0x400000000 映射的核心逻辑由两重循环控制,外层循环控制页目录指针顶,只有16项,其中每一项都指向一个页目录,每个页目录中有512个物理页地址 内核在启动初期,虚拟地址和物理地址保持相同 123456789101112131415161718192021222324252627282930313233343536373839404142// 使用长模式下2MB分页方式#define KINITPAGE_PHYADR 0x1000000void init_bstartpages(machbstart_t *mbsp)&#123; //顶级页目录 u64_t *p = (u64_t *)(KINITPAGE_PHYADR);//16MB地址处 //页目录指针 u64_t *pdpte = (u64_t *)(KINITPAGE_PHYADR + 0x1000); //页目录 u64_t *pde = (u64_t *)(KINITPAGE_PHYADR + 0x2000); //物理地址从0开始 u64_t adr = 0; if (1 &gt; move_krlimg(mbsp, (u64_t)(KINITPAGE_PHYADR), (0x1000 * 16 + 0x2000 &#123; kerror(&quot;move_krlimg err&quot;); &#125; //将顶级页目录、页目录指针的空间清0 for (uint_t mi = 0; mi &lt; PGENTY_SIZE; mi++) &#123; p[mi] = 0; pdpte[mi] = 0; &#125; //映射 for (uint_t pdei = 0; pdei &lt; 16; pdei++) &#123; pdpte[pdei] = (u64_t)((u32_t)pde | KPDPTE_RW | KPDPTE_P); for (uint_t pdeii = 0; pdeii &lt; PGENTY_SIZE; pdeii++) &#123;//大页KPDE_PS 2MB,可读写KPDE_RW,存在KPDE_P pde[pdeii] = 0 | adr | KPDE_PS | KPDE_RW | KPDE_P; adr += 0x200000; &#125; pde = (u64_t *)((u32_t)pde + 0x1000); &#125; //让顶级页目录中第0项和第((KRNL_VIRTUAL_ADDRESS_START) &gt;&gt; KPML4_SHIFT) &amp; 0x1ff p[((KRNL_VIRTUAL_ADDRESS_START) &gt;&gt; KPML4_SHIFT) &amp; 0x1ff] = (u64_t)((u32_t) p[0] = (u64_t)((u32_t)pdpte | KPML4_RW | KPML4_P); //把页表首地址保存在机器信息结构中 mbsp-&gt;mb_pml4padr = (u64_t)(KINITPAGE_PHYADR); mbsp-&gt;mb_subpageslen = (u64_t)(0x1000 * 16 + 0x2000); mbsp-&gt;mb_kpmapphymemsz = (u64_t)(0x400000000); return;&#125; 设置图形模式 在计算机加电启动时,计算机显卡进入文本模式,文本模式只能显示ASCII字符,不能显示汉字和图形,所以要让显卡切换到图形模式 切换显卡模式依然用BIOS中断 VBE是显卡的一个图形规范标准 定义了显卡的集中图形模式,每个模式包括屏幕分辨率,像素格式与大小,显存大小 调用BIOS 10h中断可以返回这些数据结构 VBE的118h模式,该模式下屏幕分辨率为1024*768,显存大小是16.8MB,现存开始地址为0xe0000000 屏幕分为768行,每行1024个像素点,每个像素点占用显存的32位数据(4字节,红,绿,蓝,透明各占8位) 1234567891011121314151617181920212223242526272829void init_graph(machbstart_t* mbsp)&#123; //初始化图形数据结构 graph_t_init(&amp;mbsp-&gt;mb_ghparm); //获取VBE模式,通过BIOS中断 get_vbemode(mbsp); //获取一个具体VBE模式的信息,通过BIOS中断 get_vbemodeinfo(mbsp); //设置VBE模式,通过BIOS中断 set_vbemodeinfo(); return;&#125;// 每个像素点的数据结构typedef struct s_PIXCL&#123; u8_t cl_b; //蓝 u8_t cl_g; //绿 u8_t cl_r; //红 u8_t cl_a; //透明&#125;__attribute__((packed)) pixcl_t;#define BGRA(r,g,b) ((0|(r&lt;&lt;16)|(g&lt;&lt;8)|b))//通常情况下用pixl_t 和 BGRA宏typedef u32_t pixl_t;// 屏幕像素点和显存位置对应的计算方式u32_t* dispmem = (u32_t*)mbsp-&gt;mb_ghparm.gh_framphyadr;dispmem[x + (y * 1024)] = pix;//x,y是像素的位置 串联 在init_bstartparm函数中将各个工作函数串联 按照事件的先后顺序依次调用完成工作,实现检查,收集机器信息,设置工作环境 123456789101112131415161718192021void init_bstartparm()&#123; machbstart_t *mbsp = MBSPADR; machbstart_t_init(mbsp); //检查CPU init_chkcpu(mbsp); //获取内存布局 init_mem(mbsp); //初始化内核栈 init_krlinitstack(mbsp); //放置内核文件 init_krlfile(mbsp); //放置字库文件 init_defutfont(mbsp); init_meme820(mbsp); //建立MMU页表 init_bstartpages(mbsp); //设置图形模式 init_graph(mbsp); return;&#125; 显示logo logo文件是24位的位图文件 在图格式的文件中,除了文件头的数据就是图形像素点的数据 只不过24位的位图每个像素占用3字节,并且位置是倒排的,依次将位图文件的数据倒排次序写入显存中,就可以显示了 随后的工作 将二级引导器文件和logo文件打包成映像文件,放在虚拟磁盘中 复制文件到虚拟磁盘中,需要先mount,然后复制,最后转换成VDI格式的虚拟硬盘,挂载到虚拟机上启动 进入Cosmos系统 调用C函数之前,需要写汇编代码切换CPU到长模式,初始化CPU寄存器和C语言要用的栈 目前代码执行流在二级引导器中,进入到Cosmos中二级引导器初始化过的东西不能用了 CPU进入长模式,寄存器的位宽发生变化,需要重新初始化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081[section .start.text][BITS 32]_start:climov ax,0x10mov ds,axmov es,axmov ss,axmov fs,axmov gs,axlgdt [eGdtPtr];开启 PAEmov eax, cr4bts eax, 5 ; CR4.PAE = 1mov cr4, eaxmov eax, PML4T_BADR ;加载MMU顶级页目录mov cr3, eax;开启 64bits long-modemov ecx, IA32_EFERrdmsrbts eax, 8 ; IA32_EFER.LME =1wrmsr;开启 PE 和 pagingmov eax, cr0bts eax, 0 ; CR0.PE =1bts eax, 31;开启 CACHEbtr eax,29 ; CR0.NW=0btr eax,30 ; CR0.CD=0 CACHEmov cr0, eax ; IA32_EFER.LMA = 1jmp 08:entry64[BITS 64]entry64:mov ax,0x10mov ds,axmov es,axmov ss,axmov fs,axmov gs,axxor rax,raxxor rbx,rbxxor rbp,rbpxor rcx,rcxxor rdx,rdxxor rdi,rdixor rsi,rsixor r8,r8xor r9,r9xor r10,r10xor r11,r11xor r12,r12xor r13,r13xor r14,r14xor r15,r15mov rbx,MBSP_ADRmov rax,KRLVIRADRmov rcx,[rbx+KINITSTACK_OFF]add rax,rcxxor rcx,rcxxor rbx,rbxmov rsp,raxpush 0push 0x8mov rax,hal_start ;调用内核主函数push raxdw 0xcb48jmp $[section .start.data][BITS 32]x64_GDT:enull_x64_dsc: dq 0ekrnl_c64_dsc: dq 0x0020980000000000 ; 64-bit 内核代码段ekrnl_d64_dsc: dq 0x0000920000000000 ; 64-bit 内核数据段euser_c64_dsc: dq 0x0020f80000000000 ; 64-bit 用户代码段euser_d64_dsc: dq 0x0000f20000000000 ; 64-bit 用户数据段eGdtLen equ $ - enull_x64_dsc ; GDT长度eGdtPtr: dw eGdtLen - 1 ; GDT界限dq ex64 GDT// 最关键的是63～66行,它开始把8和hal_start函数的地址压入栈中//dw 0xcb48是直接写一条指令的机器码0xcb48,这是一条返回指令,会把栈中的数据分别弹出到RIP,CS寄存器,这正是为了调用Cosmos的第一个C函数hal_start 二级引导器总结 二级引导器彻底摆脱了GRUB的控制之后,就开始检查CPU,获取内存布局信息,确认是不是要求的CPU和内存大小,接着初始化内核栈、放置好内核文件和字库文件,建立MMU页表数据和设置好图形模式,为后面运行内核做好准备 当二级引导器完成了上述功能后,就会显示操作系统的logo,标志着二级引导器所有的工作一切正常 进入Cosmos,二级引导器通过跳转到Cosmos的入口,二级引导器结束使命,Cosmos 的入口是一小段汇编代码,主要是开启CPU的长模式,最后调用了Cosmos的第一个C函数hal_start 5.4 第一个C函数:如何实现板级初始化 在hal_start函数中 首先执行板级初始化(hal层(硬件抽象层)初始化),其中执行平台初始化,hal层的内存初始化,中断初始化,最后是内核层的初始化 第一个C函数 初始化函数,在Cosmos/hal/x86下建立hal_start.c文件 该函数第一步是初始化hal层,第二部是初始化内核层 死循环是避免函数返回 1234567// hal_start.cvoid hal_start()&#123; //第一步：初始化hal层 //第二步：初始化内核层 for(;;); return;&#125; hal层初始化 分离硬件,将硬件相关的操作集中在hal层,并向上提供接口,目的是让上层不用关注硬件相关的细节,方便以后的移植和扩展 完成初始化平台,初始化内存,初始化中断的功能函数 12345678// Cosmos/hal/x86/halinit.cvoid init_hal()&#123; //初始化平台 //初始化内存 //初始化中断 return;&#125; 初始化平台 把二级引导器建立的机器信息结构复制到hal层中的一个全局变量中,方便内核中的其他代码使用里面的信息,之后二级引导器建立的数据所占用的内存都会被释放 初始化图形显示驱动,内核在运行过程中输出信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129// Cosmos/hal/x86/halplatform.cvoid machbstart_t_init(machbstart_t *initp)&#123; //清零 memset(initp, 0, sizeof(machbstart_t)); return;&#125;void init_machbstart()&#123; machbstart_t *kmbsp = &amp;kmachbsp; // kmachbsp位结构体变量,类型位machbstart_t,与二级引导器所使用的一样 machbstart_t *smbsp = MBSPADR;//物理地址1MB处 machbstart_t_init(kmbsp); //复制,要把地址转换成虚拟地址 memcopy((void *)phyadr_to_viradr((adr_t)smbsp), (void *)kmbsp, sizeof(mach return;&#125;//平台初始化函数void init_halplaltform()&#123; //复制机器信息结构 init_machbstart(); //初始化图形显示驱动 init_bdvideo(); return;&#125;// hal层的全局变量// Cosmos/hal/x86/halglobal.c//全局变量定义变量放在data段#define HAL_DEFGLOB_VARIABLE(vartype,varname) \\EXTERN __attribute__((section(&quot;.data&quot;))) vartype varnameHAL_DEFGLOB_VARIABLE(machbstart_t,kmachbsp);// Cosmos/hal/x86/bdvideo.c// 添加init_bdvideo函数void init_bdvideo()&#123; dftgraph_t *kghp = &amp;kdftgh; //初始化图形数据结构,里面放有图形模式,分辨率,图形驱动函数指针 init_dftgraph(); //初始bga图形显卡的函数指针 init_bga(); //初始vbe图形显卡的函数指针 init_vbe(); //清空屏幕 为黑色 fill_graph(kghp, BGRA(0, 0, 0)); //显示背景图片 set_charsdxwflush(0, 0); hal_background(); return;&#125;// init_defgraph函数初始化了dftgraph_t结构体类型变量kdftgh// 在halglobal.c文件中定义该变量,结构类型typedef struct s_DFTGRAPH&#123; u64_t gh_mode; //图形模式 u64_t gh_x; //水平像素点 u64_t gh_y; //垂直像素点 u64_t gh_framphyadr; //显存物理地址 u64_t gh_fvrmphyadr; //显存虚拟地址 u64_t gh_fvrmsz; //显存大小 u64_t gh_onepixbits; //一个像素字占用的数据位数 u64_t gh_onepixbyte; u64_t gh_vbemodenr; //vbe模式号 u64_t gh_bank; //显存的bank数 u64_t gh_curdipbnk; //当前bank u64_t gh_nextbnk; //下一个bank u64_t gh_banksz; //bank大小 u64_t gh_fontadr; //字库地址 u64_t gh_fontsz; //字库大小 u64_t gh_fnthight; //字体高度 u64_t gh_nxtcharsx; //下一字符显示的x坐标 u64_t gh_nxtcharsy; //下一字符显示的y坐标 u64_t gh_linesz; //字符行高 pixl_t gh_deffontpx; //默认字体大小 u64_t gh_chardxw; u64_t gh_flush; u64_t gh_framnr; u64_t gh_fshdata; //刷新相关的 dftghops_t gh_opfun; //图形驱动操作函数指针结构体&#125;dftgraph_t;typedef struct s_DFTGHOPS&#123; //读写显存数据 size_t (*dgo_read)(void* ghpdev,void* outp,size_t rdsz); size_t (*dgo_write)(void* ghpdev,void* inp,size_t wesz); sint_t (*dgo_ioctrl)(void* ghpdev,void* outp,uint_t iocode); //刷新 void (*dgo_flush)(void* ghpdev); sint_t (*dgo_set_bank)(void* ghpdev, sint_t bnr); //读写像素 pixl_t (*dgo_readpix)(void* ghpdev,uint_t x,uint_t y); void (*dgo_writepix)(void* ghpdev,pixl_t pix,uint_t x,uint_t y); //直接读写像素 pixl_t (*dgo_dxreadpix)(void* ghpdev,uint_t x,uint_t y); void (*dgo_dxwritepix)(void* ghpdev,pixl_t pix,uint_t x,uint_t y); //设置x,y坐标和偏移 sint_t (*dgo_set_xy)(void* ghpdev,uint_t x,uint_t y); sint_t (*dgo_set_vwh)(void* ghpdev,uint_t vwt,uint_t vhi); sint_t (*dgo_set_xyoffset)(void* ghpdev,uint_t xoff,uint_t yoff); //获取x,y坐标和偏移 sint_t (*dgo_get_xy)(void* ghpdev,uint_t* rx,uint_t* ry); sint_t (*dgo_get_vwh)(void* ghpdev,uint_t* rvwt,uint_t* rvhi); sint_t (*dgo_get_xyoffset)(void* ghpdev,uint_t* rxoff,uint_t* ryoff);&#125;dftghops_t;//刷新显存void flush_videoram(dftgraph_t *kghp)&#123; kghp-&gt;gh_opfun.dgo_flush(kghp); return;&#125;// 把实际的图形驱动函数的地址填入该结构体中// 然后通过这个结构体,可调用相应的函数// 将函数调用起来// halinit.cvoid init_hal()&#123; init_halplaltform(); return;&#125;// hal_start.cvoid hal_start()&#123; init_hal();//初始化hal层,其中会调用初始化平台函数,在那里会调用初始化图形驱动 for(;;); return;&#125; 初始化内存 在Cosmos/hal/x86下建立halmm.c文件,用于初始化内存,位后面的内存管理器作准备 hal层的初始化只要向内存管理器提供内存空间布局信息即可 Cosmos的内存管理器需要保存更多信息,最好是顺序的内存布局信息,可以增加额外的功能属性,同时降低代码的复杂度 以BIOS提供的结构为基础,设计新的数据结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// 新的数据结构保存信息#define PMR_T_OSAPUSERRAM 1#define PMR_T_RESERVRAM 2#define PMR_T_HWUSERRAM 8#define PMR_T_ARACONRAM 0xf#define PMR_T_BUGRAM 0xff#define PMR_F_X86_32 (1&lt;&lt;0)#define PMR_F_X86_64 (1&lt;&lt;1)#define PMR_F_ARM_32 (1&lt;&lt;2)#define PMR_F_ARM_64 (1&lt;&lt;3)#define PMR_F_HAL_MASK 0xfftypedef struct s_PHYMMARGE&#123; spinlock_t pmr_lock;//保护这个结构是自旋锁 u32_t pmr_type; //内存地址空间类型 u32_t pmr_stype; u32_t pmr_dtype; //内存地址空间的子类型,见上面的宏 u32_t pmr_flgs; //结构的标志与状态 u32_t pmr_stus; u64_t pmr_saddr; //内存空间的开始地址 u64_t pmr_lsize; //内存空间的大小 u64_t pmr_end; //内存空间的结束地址 u64_t pmr_rrvmsaddr;//内存保留空间的开始地址 u64_t pmr_rrvmend; //内存保留空间的结束地址 void* pmr_prip; //结构的私有数据指针,以后扩展所用 void* pmr_extp; //结构的扩展数据指针,以后扩展所用&#125;phymmarge_t;// 操作内存u64_t initpmrge_core(e820map_t *e8sp, u64_t e8nr, phymmarge_t *pmargesp)&#123; u64_t retnr = 0; for (u64_t i = 0; i &lt; e8nr; i++) &#123; //根据一个e820map_t结构建立一个phymmarge_t结构 if (init_one_pmrge(&amp;e8sp[i], &amp;pmargesp[i]) == FALSE) &#123; return retnr; &#125; retnr++; &#125; return retnr;&#125;void init_phymmarge()&#123; machbstart_t *mbsp = &amp;kmachbsp; phymmarge_t *pmarge_adr = NULL; u64_t pmrgesz = 0; //根据machbstart_t机器信息结构计算获得phymmarge_t结构的开始地址和大小 ret_phymmarge_adrandsz(mbsp, &amp;pmarge_adr, &amp;pmrgesz); u64_t tmppmrphyadr = mbsp-&gt;mb_nextwtpadr; e820map_t *e8p = (e820map_t *)((adr_t)(mbsp-&gt;mb_e820padr)); //建立phymmarge_t结构 u64_t ipmgnr = initpmrge_core(e8p, mbsp-&gt;mb_e820nr, pmarge_adr); //把phymmarge_t结构的地址大小个数保存machbstart_t机器信息结构中 mbsp-&gt;mb_e820expadr = tmppmrphyadr; mbsp-&gt;mb_e820exnr = ipmgnr; mbsp-&gt;mb_e820exsz = ipmgnr * sizeof(phymmarge_t); mbsp-&gt;mb_nextwtpadr = PAGE_ALIGN(mbsp-&gt;mb_e820expadr + mbsp-&gt;mb_e820exsz); //phymmarge_t结构中地址空间从低到高进行排序,我已经帮你写好了 phymmarge_sort(pmarge_adr, ipmgnr); return;&#125;// 根据e820map_t结构数组建立phymmarge_t结构数组// init_one_pmrge将e820map_t结构中的信息复制到phymmarge_t结构中// 总管函数init_halmm,被init_hal函数调用void init_halmm()&#123; init_phymmarge(); //init_memmgr(); //调用该函数为内存管理器初始化函数 return;&#125; 初始化中断 中断被分为两类 异常,同步的(若不修改程序中的错误,下次运行程序同样会发生异常) 中断,异步的(外部事件而产生的) 由于不确定何种设备何时发出中断信号,所以是异步的 X86CPU上支持256个中断,需要准备256个中断门描述符和256个中断处理程序的入口 中断表为gate_t的数组,由CPU的IDTR寄存器指向,IDTMAX为256 将数据填入中断门描述符中,有了中断门之后,需要中断处理程序 保护CPU寄存器,即中断发生时的程序运行的上下文 调用中断处理程序(可以是修复异常的,可以是设备驱动程序中对设备响应的程序) 恢复CPU寄存器(恢复中断时程序运行的上下文使程序继续运行) 中断处理程序需要用汇编代码编写,以kernel.asm命名 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265// 定义typedef struct s_GATE&#123;u16_t offset_low; /* 偏移 */u16_t selector; /* 段选择子 */u8_t dcount; /* 该字段只在调用门描述符中有效.如果在利用调用门调用子u8_t attr; /* P(1) DPL(2) DT(1) TYPE(4) */u16_t offset_high; /* 偏移的高位段 */u32_t offset_high_h;u32_t offset_resv;&#125;__attribute__((packed)) gate_t;//定义中断表HAL_DEFGLOB_VARIABLE(gate_t,x64_idt)[IDTMAX];// 设置gate_t结构数组中的数据// halsgdidt.c// 将数据填入中断门描述符中void set_idt_desc(u8_t vector, u8_t desc_type, inthandler_t handler, u8_t priv&#123; //vector 向量也是中断号 //desc_type 中断门类型,中断门,陷阱门 //handler 中断处理程序的入口地址 //privilege 中断门的权限级别 gate_t *p_gate = &amp;x64_idt[vector]; u64_t base = (u64_t)handler; p_gate-&gt;offset_low = base &amp; 0xFFFF; p_gate-&gt;selector = SELECTOR_KERNEL_CS; p_gate-&gt;dcount = 0; p_gate-&gt;attr = (u8_t)(desc_type | (privilege &lt;&lt; 5)); p_gate-&gt;offset_high = (u16_t)((base &gt;&gt; 16) &amp; 0xFFFF); p_gate-&gt;offset_high_h = (u32_t)((base &gt;&gt; 32) &amp; 0xffffffff); p_gate-&gt;offset_resv = 0; return;&#125;// 中断处理程序// kernel.asm// 保存中断后的寄存器%macro SAVEALL 0 push rax push rbx push rcx push rdx push rbp push rsi push rdi push r8 push r9 push r10 push r11 push r12 push r13 push r14 push r15 xor r14,r14 mov r14w,ds push r14 mov r14w,es push r14 mov r14w,fs push r14 mov r14w,gs push r14%endmacro//恢复中断后寄存器%macro RESTOREALL 0 pop r14 mov gs,r14w pop r14 mov fs,r14w pop r14 mov es,r14w pop r14 mov ds,r14w pop r15 pop r14 pop r13 pop r12 pop r11 pop r10 pop r9 pop r8 pop rdi pop rsi pop rbp pop rdx pop rcx pop rbx pop rax iretq%endmacro//保存异常下的寄存器%macro SAVEALLFAULT 0 push rax push rbx push rcx push rdx push rbp push rsi push rdi push r8 push r9 push r10 push r11 push r12 push r13 push r14 push r15 xor r14,r14 mov r14w,ds push r14 mov r14w,es push r14 mov r14w,fs push r14 mov r14w,gs push r14%endmacro//恢复异常下寄存器%macro RESTOREALLFAULT 0 pop r14 mov gs,r14w pop r14 mov fs,r14w pop r14 mov es,r14w pop r14 mov ds,r14w pop r15 pop r14 pop r13 pop r12 pop r11 pop r10 pop r9 pop r8 pop rdi pop rsi pop rbp pop rdx pop rcx pop rbx pop rax add rsp,8 iretq%endmacro//没有错误码CPU异常%macro SRFTFAULT 1 push _NOERRO_CODE SAVEALLFAULT mov r14w,0x10 mov ds,r14w mov es,r14w mov fs,r14w mov gs,r14w mov rdi,%1 ;rdi, rsi mov rsi,rsp call hal_fault_allocator RESTOREALLFAULT%endmacro//CPU异常%macro SRFTFAULT_ECODE 1 SAVEALLFAULT mov r14w,0x10 mov ds,r14w mov es,r14w mov fs,r14w mov gs,r14w mov rdi,%1 mov rsi,rsp call hal_fault_allocator RESTOREALLFAULT%endmacro//硬件中断%macro HARWINT 1 SAVEALL mov r14w,0x10 mov ds,r14w mov es,r14w mov fs,r14w mov gs,r14w mov rdi, %1 mov rsi,rsp call hal_intpt_allocator RESTOREALL// kernel.asm中,中断异常的处理程序入口点函数//除法错误异常 比如除0exc_divide_error:SRFTFAULT 0//单步执行异常exc_single_step_exception:SRFTFAULT 1exc_nmi:SRFTFAULT 2//调试断点异常exc_breakpoint_exception:SRFTFAULT 3//溢出异常exc_overflow:SRFTFAULT 4//段不存在异常exc_segment_not_present:SRFTFAULT_ECODE 11//栈异常exc_stack_exception:SRFTFAULT_ECODE 12//通用异常exc_general_protection:SRFTFAULT_ECODE 13//缺页异常exc_page_fault:SRFTFAULT_ECODE 14hxi_exc_general_intpfault:SRFTFAULT 256//硬件1～7号中断hxi_hwint00:HARWINT (INT_VECTOR_IRQ0+0)hxi_hwint01:HARWINT (INT_VECTOR_IRQ0+1)hxi_hwint02:HARWINT (INT_VECTOR_IRQ0+2)hxi_hwint03:HARWINT (INT_VECTOR_IRQ0+3)hxi_hwint04:HARWINT (INT_VECTOR_IRQ0+4)hxi_hwint05:HARWINT (INT_VECTOR_IRQ0+5)hxi_hwint06:HARWINT (INT_VECTOR_IRQ0+6)hxi_hwint07:HARWINT (INT_VECTOR_IRQ0+7)// 在halsgdidt.c文件写出函数设置中断门描述符void init_idt_descriptor()&#123; //一开始把所有中断的处理程序设置为保留的通用处理程序 for (u16_t intindx = 0; intindx &lt;= 255; intindx++) &#123; set_idt_desc((u8_t)intindx, DA_386IGate, hxi_exc_general_intpfault, PRIVILEGE_KRNL); &#125; set_idt_desc(INT_VECTOR_DIVIDE, DA_386IGate, exc_divide_error, PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_DEBUG, DA_386IGate, exc_single_step_exception, PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_NMI, DA_386IGate, exc_nmi, PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_BREAKPOINT, DA_386IGate, exc_breakpoint_exception,PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_OVERFLOW, DA_386IGate, exc_overflow, PRIVILEGE_USE); //篇幅所限,未全部展示 set_idt_desc(INT_VECTOR_PAGE_FAULT, DA_386IGate, exc_page_fault, PRIVILEGE); set_idt_desc(INT_VECTOR_IRQ0 + 0, DA_386IGate, hxi_hwint00, PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_IRQ0 + 1, DA_386IGate, hxi_hwint01, PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_IRQ0 + 2, DA_386IGate, hxi_hwint02, PRIVILEGE_KRNL); set_idt_desc(INT_VECTOR_IRQ0 + 3, DA_386IGate, hxi_hwint03, PRIVILEGE_KRNL); //篇幅所限,未全部展示 return;&#125;// 将所有中断的处理程序设置为保留的通用处理程序,避免未知中断异常发生了CPU无处可去// 然后对已知的中断和异常进一步设置,覆盖之前的通用处理程序// halintput.cvoid init_halintupt()&#123; init_idt_descriptor(); init_intfltdsc(); return;&#125; CPU体系层面的中断初始化完成 在init_halinput函数中还调用init_intfltdsc()函数 init_intfltdsc()函数处理中断 中断异常描述为一个表,在C语言中使结构数组 结构中记录了中断优先级,中断号,中断计数等统计信息 中断可以由线程方式执行,也可以是一个回调函数,该函数的地址放在另一个结构体中 如果内核或者设备驱动程序要安装一个中断处理函数,就要先申请一个intserdsc_t结构体,然后把中断函数的地址写入其中,最后把这个结构挂载到对应的intfltdsc_t结构中的i_serfisrlst链表中 **将中断处理函数放在结构中的原因:**中断控制器最多只能产生几十号中断号,而设备不止几十个,会有多个设备共享一根中断信号线,让设备驱动程序来决定是哪个设备产生的中断,使用结构上所有中断处理函数都依次执行,查看是不是自己的设备产生了中断,如果是就处理,否则略过 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// 中断异常描述typedef struct s_INTFLTDSC&#123; spinlock_t i_lock; u32_t i_flg; u32_t i_stus; uint_t i_prity; //中断优先级 uint_t i_irqnr; //中断号 uint_t i_deep; //中断嵌套深度 u64_t i_indx; //中断计数 list_h_t i_serlist; //也可以使用中断回调函数的方式 uint_t i_sernr; //中断回调函数个数 list_h_t i_serthrdlst; //中断线程链表头 uint_t i_serthrdnr; //中断线程个数 void* i_onethread; //只有一个中断线程时直接用指针 void* i_rbtreeroot; //如果中断线程太多则按优先级组成红黑树 list_h_t i_serfisrlst; uint_t i_serfisrnr; void* i_msgmpool; //可能的中断消息池 void* i_privp; void* i_extp;&#125;intfltdsc_t;// 中断回调函数的地址的结构体typedef drvstus_t (*intflthandle_t)(uint_t ift_nr,void* device,void* sframe); typedef struct s_INTSERDSC&#123; list_h_t s_list; //在中断异常描述符中的链表 list_h_t s_indevlst; //在设备描述描述符中的链表 u32_t s_flg; intfltdsc_t* s_intfltp; //指向中断异常描述符 void* s_device; //指向设备描述符 uint_t s_indx; intflthandle_t s_handle; //中断处理的回调函数指针&#125;intserdsc_t;// halglobal.c文件中定义intfltdsc_t结构//定义intfltdsc_t结构数组大小为256HAL_DEFGLOB_VARIABLE(intfltdsc_t,machintflt)[IDTMAX];// 实现中断,异常分发器函数// 中断处理函数void hal_do_hwint(uint_t intnumb, void *krnlsframp)&#123; intfltdsc_t *ifdscp = NULL; cpuflg_t cpuflg; //根据中断号获取中断异常描述符地址 ifdscp = hal_retn_intfltdsc(intnumb); //对断异常描述符加锁并中断 hal_spinlock_saveflg_cli(&amp;ifdscp-&gt;i_lock, &amp;cpuflg); ifdscp-&gt;i_indx++; ifdscp-&gt;i_deep++; //运行中断处理的回调函数 hal_run_intflthandle(intnumb, krnlsframp); ifdscp-&gt;i_deep--; //解锁并恢复中断状态 hal_spinunlock_restflg_sti(&amp;ifdscp-&gt;i_lock, &amp;cpuflg); return;&#125;//异常分发器void hal_fault_allocator(uint_t faultnumb, void *krnlsframp)&#123; //异常处理回调函数也是放在中断异常描述符中的 hal_do_hwint(faultnumb, krnlsframp); return;&#125;//中断分发器void hal_hwint_allocator(uint_t intnumb, void *krnlsframp)&#123; hal_do_hwint(intnumb, krnlsframp); return;&#125;// 实现hal_run_intflthandle函数,负责调用中断处理的回调函数void hal_run_intflthandle(uint_t ifdnr, void *sframe)&#123; intserdsc_t *isdscp; list_h_t *lst; //根据中断号获取中断异常描述符地址 intfltdsc_t *ifdscp = hal_retn_intfltdsc(ifdnr); //遍历i_serlist链表 list_for_each(lst, &amp;ifdscp-&gt;i_serlist) &#123; //获取i_serlist链表上对象即intserdsc_t结构 isdscp = list_entry(lst, intserdsc_t, s_list); //调用中断处理回调函数 isdscp-&gt;s_handle(ifdnr, isdscp-&gt;s_device, sframe); &#125; return;&#125;// 循环遍历intfltdsc_t结构中,i_serlis 链表上所有挂载的intserdsc_t结构,然后调用intserdsc_t结构中的中断处理的回调函数 初始化中断控制器 CPU端的中断解决之后,设备端的中断交给设备驱动程序,但CPU和设备之间的中断控制器需要解决 中断控制器:多个设备的中断信号线都会连接到中断控制器上,中断控制器可以决定启用或屏蔽哪些设备的中断,决定设备中断之间的优先线 x86上的中断控制器最开始是8259A,然后是IOAPIC,最新的是MSI-X 8259A在任何x86平台上都可以使用,使用了两片8259A芯片,以级联的方式存在,拥有15个中断源 8259A在系统的框架 与CPU连接的是主8259A,下面的是8259A 每个8259A都有两个IO端口,可进行编程 主8259A的端口地址为0x20,0x21 从8259A的端口地址为0xA0,0xA1 ICW用来实现8259A芯片的初始化 OCW用来向8259A发布命令,对其进行控制,在初始化后的任何时候被使用 12345678910111213141516void init_i8259()&#123; //初始化主从8259a out_u8_p(ZIOPT, ICW1); out_u8_p(SIOPT, ICW1); out_u8_p(ZIOPT1, ZICW2); out_u8_p(SIOPT1, SICW2); out_u8_p(ZIOPT1, ZICW3); out_u8_p(SIOPT1, SICW3); out_u8_p(ZIOPT1, ICW4); out_u8_p(SIOPT1, ICW4); //屏蔽全部中断源 out_u8_p(ZIOPT1, 0xff); out_u8_p(SIOPT1, 0xff); return;&#125; 在init_halintupt函数的最后调用int_i8259函数 在初始化中断控制器后屏蔽所有的中断源,Cosmos在初始化阶段还不能处理中断 内存管理器的初始化之后介绍 进入内核层:编写内核初始化 由于内核层从hal层进入,必须在hal_start()函数中调用 123456789101112131415161718// 内核初始化函数// init_krl()void init_krl()&#123; //禁止函数返回 die(0); return;&#125;// hal_start()函数中调用init_krl()void hal_start()&#123; //初始化Cosmos的hal层 init_hal(); //初始化Cosmos的内核层 init_krl(); return;&#125; 5.5 Linux初始化:GRUB与vmlinuz的结构 Linux的启动的整体流程 Linux在GRUB是怎样启动及vmlinuz是如何产生和运转的 从setup.bin文件的_start函数入手,研究Linux初始化流程 全局流程 在机器加电后,BIOS会进行自检,然后由BIOS加载引导设备中引导扇区.在安装有Linux操作系统的情况下,在引导扇区里,通常是安装的GRUB的一小段程序(安装windows的情况不同).最后,GRUB会加载Linux的内核映像vmlinuz 引导设备通常是机器中的硬盘;BIOS会自动读取保存在CMOS中的引导设备信息 从BIOS到GRUB CPU被设计成只能运行内存中的程序,没有办法直接运行储存在硬盘或U盘中的操作系统程序 想要运行硬盘或U盘中的程序,就必须先加载到内存(RAM)中运行 BIOS启动,在设计CPU时硬性地规定在加点瞬间强制将CS寄存器的值设置为0xF000,IP寄存器的值设置为0xFFF0 CS:IP指向了0xFFF0物理地址,该物理地址连接了主板上的一小块ROM芯片(只读芯片),BIOS程序固化在该芯片中,此时BIOS程序开始启动 BIOS一开始会初始化CPU,接着检查并初始化内存,然后将自己的一部分复制到内存,最后跳转到内存中运行,BIOS的下一步就是枚举本地设备进行初始化,并进行相关的检查,检查硬件是否损坏,这期间BIOS会调用其他设备上的固件程序 当设备初始化和检查步骤之后,BIOS会在内存中建立中断表和中断服务程序 建立中断表和中断服务程序:BIOS从内存地址开始用1KB的内存空间构建中断表,在紧接着中断表的位置,用256KB的内存空间构建BIOS数据区,并在0x0e05b的地址加载8KB大小的与中断表对应的中断服务程序 中断表中有256个条目,每个条目占用4个字节,其中两个字节时CS寄存器的值,两个字节时IP寄存器的值;每个条目都指向一个具体的中断服务程序 为了启动外部存储器中的程序,BIOS会搜索可引导设备 Linux通常是从硬盘中启动的.硬盘上的第1个扇区(每个扇区512字节空间),被称为MBR(主启动记录),其中包含有基本的GRUB启动程序和分区表,安装GRUB时会自动写入到这个扇区,当MBR被BIOS装载到0x7c00地址开始的内存空间中后,BIOS就会将控制权转交给了MBR(其实是交给了GRUB) GRUB是如何启动的 BIOS只会加载硬盘上的第1个扇区,该扇区仅有512字节,其中有64字节的分区表加2字节的启动标志,剩余空间无法装得下GRUB通用引导器 GRUB的加载分成多个步骤,同时GRUB分成多个文件,其中两个重要的文件boot.img和core.img boot.img被GRUB的安装程序写入到硬盘的MBR中,同时在boot.img文件中的一个位置写入core.img文件占用的第一个扇区的扇区号 core.img是由GRUB安装程序根据安装时环境信息,用其它GRUB的模块文件动态生成的 如果从硬盘启动core.img中的第一个扇区的内容就是diskboot.img文件 diskboot.img文件的作用是读取core.img中剩余的部分到内存中 由于此时diskboot.img文件不识别文件系统,所以将core.img文件的全部位置都用文件块列表的方式保存到diskboot.img文件中,确保diskboot.img文件找到core.img文件的剩余内容,最后将控制权交给kernel.img文件 因为此时core.img文件中嵌入了足够多的功能模块,所以可以保证GRUB识别出硬盘分区上文件系统,能够访问/boot/grub目录,并且可以加载相关的配置文件和功能模块,来实现相关的功能 GRUB2大量使用了动态加载功能模块,使得core.img文件的体积变得足够小,而GRUB的core.img文件一旦开始工作,就可以加载Linux系统的vmlinuz内核文件 详解vmlinuz文件结构 在/boot目录下由vmlinuz文件,该文件是由Linux编译生成bzlmage文件复制而来的 一致把Linux源码解压到一个Linux目录中,切换代码目录执行make ARCH=x86_64,再执行make install,就会产生vmlinuz文件 生成 bzImage 文件需要三个依赖文件：setup.bin,vmlinux.bin,linux/arch/x86/boot/tools目录下的 build setup.bin是由objcopy命令根据setup.elf生成的 setup.bin文件由/arch/x86/boot/目录下一系列对应的程序源代码文件编译链接产生,其中的head.S文件和main.c文件格外重要 vmlinux.bin vmlinux.bin文件依赖于linux/arch/x86/boot/compressed/目录下的vmlinux目标,是由 objcopy 工具通过vmlinux目标生成. vmlinux目标没有任何修饰前缀和依赖的目标,这说明它就是最顶层目录下的一个 vmlinux 文件 linux/arch/x86/boot/compressed目录下的vmlinux是由该目录下的head_32.o或者head_64.o、cpuflags.o,error.o,kernel.o,misc.o,string.o,cmdline.o,early_serial_console.o等文件以及 piggy.o链接而成的 piggy.o是由piggy.S汇编代码生成而来,而piggy.S是编译Linux内核时由mkpiggy工作(HOST OS下的应用程序)动态创建的 piggy.S的第一个依赖文件vmlinux.bin.$(suffix-y)中的suffix-y,表示内核压缩方式对应的后缀 piggy.S 中还定义了解压vmlinux.bin.gz 时需要的各种信息,包括压缩内核映像的长度、解压后的长度等信息 vmlinux文件时如何创建的 vmlinux文件就是编译整个Linux内核源代码文件生成的,Linux的代码分布在各个代码目录下,这些目录之下又存在目录,Linux的kbuild(内核编译)系统,会递归进入到每个目录,由该目录下的Makefile决定要编译哪些文件 在编译完具体文件之后,就会在该目录下,把已经编译了的文件链接成一个该目录下的built-in.o文件,这个built-in.o文件也会与上层目录的built-in.o文件链接在一起 层层目录返回到顶层目录,所有的built-in.o文件会链接生成一个vmlinux文件,该文件会通过前面的方法转换成vmlinux.bin文件.但是注意vmlinux.bin文件依然是ELF格式的文件 最后,工具软件会压缩成vmlinux.bin.gz文件,以gzip方式压缩 piggy.S的信息和vmlinux.bin.gz文件,它们一起生成了piggy.o文件,然后piggy.o文件和(vmlinux−objs−y)(vmlinux-objs-y)(vmlinux−objs−y)(efi-obj-y)中的目标文件一起链接生成,最终生成了linux/arch/x86/boot/compressed 目录下的vmlinux 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#linux/arch/x86/boot/Makefileinstall: sh $(srctree)/$(src)/install.sh $(KERNELRELEASE) $(obj)/bzImage \\# bzlmage文件再Makefile中的生成规则#linux/arch/x86/boot/Makefile$(obj)/bzImage: $(obj)/setup.bin $(obj)/vmlinux.bin $(obj)/tools/build FORCE#setup.bin是由objcopy命令根据setup.elf生成的#这些目标文件正是由/arch/x86/boot/目录下对应的程序源代码文件编译产生setup-y += a20.o bioscall.o cmdline.o copy.o cpu.o cpuflags.o cpucheck.osetup-y += early_serial_console.o edd.o header.o main.o memory.osetup-y += pm.o pmjump.o printf.o regs.o string.o tty.o video.osetup-y += video-mode.o version.o#……SETUP_OBJS = $(addprefix $(obj)/,$(setup-y))#……LDFLAGS_setup.elf := -m elf_i386 -T$(obj)/setup.elf: $(src)/setup.ld $(SETUP#……OBJCOPYFLAGS_setup.bin := -O binary$(obj)/setup.bin: $(obj)/setup.elf FORCE# vmlinux.bin#linux/arch/x86/boot/MakefileOBJCOPYFLAGS_vmlinux.bin := -O binary -R .note -R .comment -S$(obj)/vmlinux.bin# makefile文件#linux/arch/x86/boot/compressed/Makefile#……#这些目标文件正是由/arch/x86/boot/compressed/目录下对应的程序源代码文件编译产生$(BITS)取vmlinux-objs-y := $(obj)/vmlinux.lds $(obj)/kernel_info.o $(obj)/head_$(BITS).vmlinux-objs-$(CONFIG_EARLY_PRINTK) += $(obj)/early_serial_console.ovmlinux-objs-$(CONFIG_RANDOMIZE_BASE) += $(obj)/kaslr.oifdef CONFIG_X86_64vmlinux-objs-y += $(obj)/ident_map_64.ovmlinux-objs-y += $(obj)/idt_64.o $(obj)/idt_handlers_64.o vmlinux-objs-y +vmlinux-objs-y += $(obj)/pgtable_64.ovmlinux-objs-$(CONFIG_AMD_MEM_ENCRYPT) += $(obj)/sev-es.oendif#……$(obj)/vmlinux: $(vmlinux-objs-y) $(efi-obj-y) FORCE$(call if_changed,ld)#linux/arch/x86/boot/compressed/Makefile#……vmlinux.bin.all-y := $(obj)/vmlinux.binvmlinux.bin.all-$(CONFIG_X86_NEED_RELOCS) += $(obj)/vmlinux.relocs$(obj)/vmlinux.bin.gz: $(vmlinux.bin.all-y) FORCE$(call if_changed,gzip)$(obj)/vmlinux.bin.bz2: $(vmlinux.bin.all-y) FORCE$(call if_changed,bzip2)$(obj)/vmlinux.bin.lzma: $(vmlinux.bin.all-y) FORCE$(call if_changed,lzma)$(obj)/vmlinux.bin.xz: $(vmlinux.bin.all-y) FORCE$(call if_changed,xzkern)$(obj)/vmlinux.bin.lzo: $(vmlinux.bin.all-y) FORCE$(call if_changed,lzo)$(obj)/vmlinux.bin.lz4: $(vmlinux.bin.all-y) FORCE$(call if_changed,lz4)$(obj)/vmlinux.bin.zst: $(vmlinux.bin.all-y) FORCE$(call if_changed,zstd22)suffix-$(CONFIG_KERNEL_GZIP) := gzsuffix-$(CONFIG_KERNEL_BZIP2) := bz2suffix-$(CONFIG_KERNEL_LZMA) := lzmasuffix-$(CONFIG_KERNEL_XZ) := xzsuffix-$(CONFIG_KERNEL_LZO) := lzosuffix-$(CONFIG_KERNEL_LZ4) := lz4suffix-$(CONFIG_KERNEL_ZSTD) := zst#linux/arch/x86/boot/compressed/Makefile#……OBJCOPYFLAGS_vmlinux.bin := -R .comment -S$(obj)/vmlinux.bin: vmlinux FORCE$(call if_changed,objcopy)# arch/x86/boot/compressed目录下的vmlinux.bin,它是由objcopy工具通过vmlinux目标生成# 而vmlinux目标没有任何修饰前缀和依赖的目标,这说明它就是最顶层目录下的一个vmlinux文件 5.6 Linux初始化:从_start到第一个进程 如何解压内核,Linux内核第一个C函数,然后建立Linux的第一个用户进程 解压后内核初始化 从setup.bin文件的入口_start开始,了解启动信息结构,然后由16位main函数切换CPU到保护模式,然后跳入vmlinux.bin文件中的startup_32函数重新加载段描述符 64位系统,进入startup_64函数,切换到CPU长模式,最后调用extract_kernel函数解压linux内核,并进入内核的startup_64函数,Linux内核开始运行 为何从_start开始 vmlinux.bin是由linux/arch/x86/boot/compressed目录下的一些目标文件,以及piggy.S包含的一个vmlinux.bin.gz的压缩文件一起生成的 vmlinux.bin.gz是由编译的Linux内核所生成的elf格式的vmlinux文件,去掉了文件的符号信息和重定位信息后,压缩得到的 CPU无法识别压缩文件中的指令直接运行的,必须先进行解压后,然后解析elf格式的vmlinux吻技安,去掉了文件的符号信息和重定位信息后,压缩得到的 _start是setup.bin文件的入口,在head.S文件中定义 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#linux/arch/x86/boot/head.S.code16.section &quot;.bstext&quot;, &quot;ax&quot;.global bootsect_startbootsect_start:ljmp $BOOTSEG, $start2start2:#……#这里的512字段bootsector对于硬盘启动是用不到的#…….globl _start_start:.byte 0xeb # short (2-byte) jump.byte start_of_setup-1f #这指令是用.byte定义出来的,跳转start_of_setup-1f#……#这里是一个庞大的数据结构,没展示出来#……start_of_setup:movw %ds, %axmovw %ax, %es #ds = escld #主要指定si、di寄存器的自增方向,即si++ di++movw %ss, %dxcmpw %ax, %dx # ds 是否等于 ssmovw %sp, %dxje 2f# 如果ss为空则建立新栈movw $_end, %dxtestb $CAN_USE_HEAP, loadflagsjz 1fmovw heap_end_ptr, %dx1: addw $STACK_SIZE, %dxjnc 2fxorw %dx, %dx2:andw $~3, %dxjnz 3fmovw $0xfffc, %dx3: movw %ax, %ssmovzwl %dx, %espsti # 栈已经初始化好,开中断pushw %dspushw $6flretw # cs=ds ip=6：跳转到标号6处6:cmpl $0x5a5aaa55, setup_sig #检查setup标记jne setup_badmovw $__bss_start, %dimovw $_end+3, %cxxorl %eax, %eaxsubw %di, %cxshrw $2, %cxrep; stosl #清空setup程序的bss段calll main #调用C语言main函数 setup_header结构 硬盘中MBR是由GRUB写入的boot.img,这里的linux/arch/x86/boot/head.S中的bootsector对于硬盘启动无用 GRUB将vmlinux的setup.bin部分读到内存地址0x90000处,然后跳转到0x90200开始执行,恰好跳过了前面512字节的bootsector,从_start开始 123456789101112131415161718192021// linux/arch/x86/include/uapi/asm/bootparam.hstruct setup_header &#123; __u8 setup_sects; //setup大小 __u16 root_flags; //根标志 __u32 syssize; //系统文件大小 __u16 ram_size; //内存大小 __u16 vid_mode; __u16 root_dev; //根设备号 __u16 boot_flag; //引导标志 //…… __u32 realmode_swtch; //切换回实模式的函数地址 __u16 start_sys_seg; __u16 kernel_version; //内核版本 __u8 type_of_loader; //引导器类型 我们这里是GRUB __u8 loadflags; //加载内核的标志 __u16 setup_move_size; //移动setup的大小 __u32 code32_start; //将要跳转到32位模式下的地址 __u32 ramdisk_image; //初始化内存盘映像地址,里面有内核驱动模块 __u32 ramdisk_size; //初始化内存盘映像大小 //……&#125; __attribute__((packed)); 16位main函数 C编译器编译的代码,是在32位保护模式下的或者64位长模式的,很少编译成16位实模式下,其实setup.bin大部分代码是在16位实模式下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// main函数// linux/arch/x86/boot/main.c//定义boot_params变量struct boot_params boot_params __attribute__((aligned(16)));char *HEAP = _end;char *heap_end = _end;//……void main(void)&#123; //把先前setup_header结构复制到boot_params结构中的hdr变量中,在linux/arch/x86/inc copy_boot_params(); //初始化早期引导所用的console console_init(); //初始化堆 init_heap(); //检查CPU是否支持运行Linux if (validate_cpu()) &#123; puts(&quot;Unable to boot - please use a kernel appropriate &quot; &quot; die(); &#125; //告诉BIOS我们打算在什么CPU模式下运行它 set_bios_mode(); //查看物理内存空间布局 detect_memory(); //初始化键盘 keyboard_init(); //查询Intel的(IST)信息. query_ist(); /*查询APM BIOS电源管理信息.*/ #if defined(CONFIG_APM) || defined(CONFIG_APM_MODULE) query_apm_bios(); #endif //查询EDD BIOS扩展数据区域的信息 #if defined(CONFIG_EDD) || defined(CONFIG_EDD_MODULE) query_edd(); #endif //设置显卡的图形模式 set_video(); //进入CPU保护模式,不会返回了 go_to_protected_mode();&#125;//linux/arch/x86/boot/pm.cvoid go_to_protected_mode(void)&#123; //安装切换实模式的函数 realmode_switch_hook(); //开启a20地址线,是为了能访问1MB以上的内存空间 if (enable_a20()) &#123; puts(&quot;A20 gate not responding, unable to boot...\\n&quot;); die(); &#125; //重置协处理器,早期x86上的浮点运算单元是以协处理器的方式存在的 reset_coprocessor(); //屏蔽8259所示的中断源 mask_all_interrupts(); //安装中断描述符表和全局描述符表, setup_idt(); setup_gdt(); //保护模式下长跳转到boot_params.hdr.code32_start protected_mode_jump(boot_params.hdr.code32_start, (u32)&amp;boo&#125;// protected_mode_jump是汇编函数,在linux/arch/x86/boot/pmjump.S文件中// 该代码逻辑和保护模式一样,只是多了处理参数的逻辑,即跳转到boot_params.hrd.code32_start中的地址// 地址在在linux/arch/x86/boot/head.S文件中设为0x100000code32_start:long 0x100000// GRUB会把vmlinuz中的vmlinux.bin部分,放在1MB开始的内存空间中// 通过跳转,正式进入vmlinux.bin中 startup_32函数 startup_32中需要重新加载段描述符,之后计算vmlinux.bin文件的编译生成的地址和实际加载地址的偏移,然后重新设置内核栈,检测CPU是否支持长模式,接着再次计算vmlinux.bin加载地址的偏移,来去顶对其中vmlinux.bin.gz解压缩的地址 CPU支持长模式,就设置64位的全局描述表,开启CPU的PAE物理地址扩展特性 设置最初的MMU页表,最后开启分页并进入长模式,跳转到startup_64 1234567891011121314151617181920212223242526272829303132333435363738394041 .code32SYM_FUNC_START(startup_32) cld cli leal (BP_scratch+4)(%esi), %esp call 1f1: popl %ebpsubl $ rva(1b), %ebp #重新加载全局段描述符表leal rva(gdt)(%ebp), %eaxmovl %eax, 2(%eax)lgdt (%eax) #……篇幅所限未全部展示代码 #重新设置栈leal rva(boot_stack_end)(%ebp), %esp #检测CPU是否支持长模式call verify_cputestl %eax, %eaxjnz .Lno_longmode #……计算偏移的代码略过 #开启PAE movl %cr4, %eaxorl $X86_CR4_PAE, %eaxmovl %eax, %cr4 #……建立MMU页表的代码略过 #开启长模式 movl $MSR_EFER, %ecxrdmsrbtsl $_EFER_LME, %eax #获取startup_64的地址 leal rva(startup_64)(%ebp), %eax #……篇幅所限未全部展示代码 #内核代码段描述符索和startup_64的地址引压入栈 pushl $__KERNEL_CSpushl %eax #开启分页和保护模式movl $(X86_CR0_PG | X86_CR0_PE), %eaxmovl %eax, %cr0 #弹出刚刚栈中压入的内核代码段描述符和startup_64的地址到CS和RIP中,实现跳转,真正进入长 lretSYM_FUNC_END(startup_32） startup_64函数 开启CPU长模式,从startup_64开开真正进入64位的时代 startup_64函数同样也是再linux/arch/x86/boot/compressed/head64.S文件中定义 startup_64函数中,初始化长模式下数据段寄存器,确定最终解压缩地址,然后拷贝压缩vmlinuxbin到该地址,跳转到decompress_kernel地址处,开始解压vmlinux.bin.gz 最后跳转extract_kernel函数就是解压内核的函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657.code64.org 0x200SYM_CODE_START(startup_64)cldcli#初始化长模式下数据段寄存器xorl %eax, %eaxmovl %eax, %dsmovl %eax, %esmovl %eax, %ssmovl %eax, %fsmovl %eax, %gs#……重新确定内核映像加载地址的代码略过#重新初始化64位长模式下的栈leaq rva(boot_stack_end)(%rbx), %rsp#……建立最新5级MMU页表的代码略过#确定最终解压缩地址,然后拷贝压缩vmlinux.bin到该地址pushq %rsileaq (_bss-8)(%rip), %rsileaq rva(_bss-8)(%rbx), %rdimovl $(_bss - startup_32), %ecxshrl $3, %ecxstdrep movsqcldpopq %rsi#跳转到重定位的Lrelocated处leaq rva(.Lrelocated)(%rbx), %raxjmp *%raxSYM_CODE_END(startup_64).textSYM_FUNC_START_LOCAL_NOALIGN(.Lrelocated)#清理程序文件中需要的BSS段xorl %eax, %eaxleaq _bss(%rip), %rdileaq _ebss(%rip), %rcxsubq %rdi, %rcxshrq $3, %rcxrep stosq#……省略无关代码pushq %rsimovq %rsi, %rdileaq boot_heap(%rip), %rsi#准备参数：被解压数据的开始地址leaq input_data(%rip), %rdx#准备参数：被解压数据的长度movl input_len(%rip), %ecx#准备参数：解压数据后的开始地址movq %rbp, %r8#准备参数：解压数据后的长度movl output_len(%rip), %r9d#调用解压函数解压vmlinux.bin.gz,返回入口地址call extract_kernelpopq %rsi#跳转到内核入口地址jmp *%raxSYM FUNC END(.Lrelocated) extract_kernel函数 从startup_32函数到startup_64函数,其间经过了保护模式,长模式,最终到达了extract_kernel函数,extract_kernel函数根据piggy.o中的信息从vmlinux.bin.gz解压出vmlinux vmlinux正是编译出Linux内核elf格式的文件,只不过它被去掉了符号信息,extract_kernel函数不仅仅是解压,还需要解析elf格式 extract_kernel函数调用__decompress 函数,对vmlinux.bin.gz使用特定的解压算法进行解压 __decompress函数解压出来的是vmlinux文件是elf格式的,所以还要调用parse_elf函数进一步解析elf格式,把vmlinux中的指令段,数据段,BSS 段,根据elf中信息和要求放入特定的内存空间,返回指令段的入口地址 123456789101112131415161718192021// extract_kernel函数是在linux/arch/x86/boot/compressed/misc.c文件中定义asmlinkage __visible void *extract_kernel(void *rmode, memptr heap,unsigned char *input_data,unsigned long input_len,unsigned char *output,unsigned long output_len)&#123;const unsigned long kernel_total_size = VO__end - VO__text;unsigned long virt_addr = LOAD_PHYSICAL_ADDR;unsigned long needed_size;//省略了无关性代码debug_putstr(&quot;\\nDecompressing Linux... &quot;);//调用具体的解压缩算法解压__decompress(input_data, input_len, NULL, NULL, output, output_len,//解压出的vmlinux是elf格式,所以要解析出里面的指令数据段和常规数据段//返回vmlinux的入口点即Linux内核程序的开始地址parse_elf(output);handle_relocations(output, output_len, virt_addr); debug_putstr(&quot;done.\\return output;&#125; Linux内核的startup_64 此时的startup_64函数不是之前的startup_64函数,也不参与前面的链接工作 对于SMP系统加电之后,总线仲裁机制会选出多个CPU中的一个CPU,称为BSP,也叫第一个启动的CPU,负责让BSP CPU先启动,其他CPU则等待BSP CPU的唤醒 对于第一个启动的CPU,会跳转secondary_startup_64函数中1标号处,对于其他唤醒的CPU则会直接执行seondary_startup_64函数,在该函数一切准备就绪之后,最后调用x86_64_start_kernel函数 123456789101112131415161718192021222324252627282930313233343536373839404142#linux/arch/x86/kernel/head_64.S.code64SYM_CODE_START_NOALIGN(startup_64)#切换栈leaq (__end_init_task - SIZEOF_PTREGS)(%rip), %rsp#跳转到.Lon_kernel_cs:pushq $__KERNEL_CSleaq .Lon_kernel_cs(%rip), %raxpushq %raxlretq.Lon_kernel_cs:#对于第一个CPU,则会跳转secondary_startup_64函数中1标号处jmp 1fSYM_CODE_END(startup_64)# secondary_startup_64函数SYM_CODE_START(secondary_startup_64)#省略了大量无关性代码1:movl $(X86_CR4_PAE | X86_CR4_PGE), %ecx#ifdef CONFIG_X86_5LEVELtestl $1, __pgtable_l5_enabled(%rip)jz 1forl $X86_CR4_LA57, %ecx1:#endif#省略了大量无关性代码.Ljump_to_C_code:pushq $.Lafter_lretxorl %ebp, %ebp#获取x86_64_start_kernel函数地址赋给raxmovq initial_code(%rip), %raxpushq $__KERNEL_CS#将x86_64_start_kernel函数地址压入栈中pushq %rax#弹出__KERNEL_CS 和x86_64_start_kernel函数地址到CS：RIP完成调用lretq.Lafter_lret:SYM_CODE_END(secondary_startup_64)#保存了x86_64_start_kernel函数地址SYM_DATA(initial_code, .quad x86_64_start_kernel) Linux内核的第一个C函数 调用的x86_64_start_kernel函数是使用C编写的,其为Linux内核的第一个C函数 在linux/arch/x86/kernel/head64.c文件中定义 x86_64_start_kernel函数处理了页表(处理Linux内核虚拟地址空间),然后复制引导信息(struct boot_params结构体),最后调用x86_64_start_reservations函数(处理平台固件相关的东西,调用start_kernel函数) 12345678910111213141516171819asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)&#123; //重新设置早期页表 reset_early_page_tables(); //清理BSS段 clear_bss(); //清理之前的顶层页目录 clear_page(init_top_pgt); //复制引导信息 copy_bootdata(__va(real_mode_data)); //加载BSP CPU的微码 load_ucode_bsp(); //让顶层页目录指向重新设置早期页表 init_top_pgt[511] = early_top_pgt[511]; x86_64_start_reservations(real_mode_data);&#125;void __init x86_64_start_reservations(char *real_mode_data)&#123; //略过无关的代码 start_kernel();&#125; start_kernel函数 该函数调用大量的Linux内核功能的初始化函数,定义在/linux/init/main.c文件中 Linux内核所有功能的初始化函数都是在start_kernel函数中调用,一旦函数执行完成,Linux内核就具备向应用程序提供一系列功能服务的能力 关注arch_call_rest_init函数,为包装函数,其中直接调用rest_init函数 rest_init函数为建立两个Linux内核线程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// start_kernel定义在/linux/init/main.cvoid start_kernel(void)&#123; char *command_line; char *after_dashes; //CPU组早期初始化 cgroup_init_early(); //关中断 local_irq_disable(); //ARCH层初始化 setup_arch(&amp;command_line); //日志初始化 setup_log_buf(0); sort_main_extable(); //陷阱门初始化 trap_init(); //内存初始化 mm_init(); ftrace_init(); //调度器初始化 sched_init(); //工作队列初始化 workqueue_init_early(); //RCU锁初始化 rcu_init(); //IRQ 中断请求初始化 early_irq_init(); init_IRQ(); tick_init(); rcu_init_nohz(); //定时器初始化 init_timers(); hrtimers_init(); //软中断初始化 softirq_init(); timekeeping_init(); mem_encrypt_init(); //每个cpu页面集初始化 setup_per_cpu_pageset(); //fork初始化建立进程的 fork_init(); proc_caches_init(); uts_ns_init(); //内核缓冲区初始化 buffer_init(); key_init(); //安全相关的初始化 security_init(); //VFS数据结构内存池初始化 vfs_caches_init(); //页缓存初始化 pagecache_init(); //进程信号初始化 signals_init(); //运行第一个进程 arch_call_rest_init();&#125;// 包装函数void __init __weak arch_call_rest_init(void)&#123; rest_init();&#125;// 精简后的rest_init函数noinline void __ref rest_init(void)&#123; struct task_struct *tsk; int pid; //建立kernel_init线程 pid = kernel_thread(kernel_init, NULL, CLONE_FS); //建立khreadd线程 pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);&#125; Linux的第一个用户进程 可建立第一个用户进程时,代表Linux内核的初始流程已经基本完成 Linux内核的第一个用户态进程是在kernel_init线程建立的,kernel_init线程执行的就是kernel_init函数 1234567891011121314151617181920static int __ref kernel_init(void *unused)&#123; int ret; if (ramdisk_execute_command) &#123; ret = run_init_process(ramdisk_execute_command); if (!ret) return 0; pr_err(&quot;Failed to execute %s (error %d)\\n&quot;,ramdisk_execute_command, r &#125; if (execute_command) &#123; ret = run_init_process(execute_command); if (!ret) return 0; panic(&quot;Requested init %s failed (error %d).&quot;, execute_co &#125; if (!try_to_run_init_process(&quot;/sbin/init&quot;) || !try_to_r return 0; panic(&quot;No working init found. Try passing init= option to kernel. &quot;&#125;// ramdisk_execute_command和execute_command都是内核启动时传递的参数,可以在GRUB启动选项中设置 重点 GRUB加载vmlinuz文件后,会把控制权交给vmlinuz文件的setup.bin的部分中_start,它会设置好栈,清空bss,设置好setup_header结构,调用16位main切换到保护模式,最后跳转到1MB处的vmlinux.bin文件中 从vmlinux.bin文件中startup32、startup64函数开始建立新的全局段描述符表和 MMU页表,切换到长模式下解压vmlinux.bin.gz.释放出vmlinux文件之后,由解析elf格式的函数进行解析,释放vmlinux中的代码段和数据段到指定的内存.然后调用其中的startup_64函数,在这个函数的最后调用Linux内核的第一个C函数 Linux内核第一个C函数重新设置MMU页表,随后便调用了最有名的start_kernel函数,start_kernel函数中调用了大多数Linux内核功能性初始化函数,在最后调用rest_init函数建立了两个内核线程,在其中的kernel_init线程建立了第一个用户态进程 6 内存 6.1 如何划分与组织内存 首先解决内存的划分方式与内存页的表示,组织问题,设计好数据结构;然后在内存中建立数据结构对应的实例变量,搞定内存页的初始化问题;最后依赖前面建立的数据结构实现内存页面管理算法 分段还是分页 第一点,从表示方式和状态角度考虑 段的长度大小不一,用什么数据结构表示一个段,如何确定一个段已经分配或空闲 页的大小固定,只需用位图能表示页的分配与释放 第二点,从内存碎片的利用看 段的长度大小不一,容易产生内存碎片 页的大小固定,分配的最小单位是页,可通过修改页表的方式让连续的虚拟页面映射到非连续的物理页面 第三点,从内存和硬盘的数据交换效率考虑 内存不足时,操作系统把内存中的一部分数据写回硬盘来释放内存,涉及到内存和硬盘交换数据 使用页交换数据时,页大小固定,系统性能稳定 段最大的问题是使虚拟内存地址空间难以实施 使用4KB作为页大小(正好对应x86CPU下长模式下MMU4KB的分页方式),选择分页模式管理内存 如何表示一个页 使用分页模型来管理内存,首先把物理内存空间分为4KB大小页,表示从地址x开始到x+0xFFF一段的物理内存空间,x必须是0x1000对其的,这一段x+0xFFF的内存空间称为内存页 真实的物理内存地址空间不是连续的,中间可能有空洞的,可能是显存或外设的寄存器 真正的物理内存空间布局信息来源于e820msp_t结构数组,已经转换成phymmarge_t结构数组,由kmachbsp-&gt;mb_e820expadr指向 表示页 用位图或者整型变量数组,用其中一个位代表一个页,位值为0时表示页空闲,值为1时表示页已分配;用整型数组中一个元素表示一个页,用具体数组元素的数值代表页的状态 分配,释放内存页的算法:扫描位图或扫描数组 该内存管理器是最简单的,但最低效 仅仅保存了内存页的空闲和已分配的信息 页还需要页的状态,地址,页的分配计数,页的类型,页的链表信息,使用C语言结构体封装 msadsc_t结构实则很小,表示一个页面,物理内存页有多少就需要多少个msadsc_t结构 因为页面地址总是按4kb对齐,所以phyadrflgs_t的低12位可以另作它用 msadsc_t结构里的链表,可以方便它挂入到其他数据结构中 除了分配计数,msadflgs_t结构中的其他部分都是用来描述msadsc_t结构本身信息的 123456789101112131415161718192021222324252627282930313233// /Cosmos/include/halinc/msadsc_t.h//内存空间地址描述符标志typedef struct s_MSADFLGS&#123; u32_t mf_olkty:2; //挂入链表的类型 u32_t mf_lstty:1; //是否挂入链表 u32_t mf_mocty:2; //分配类型,被谁占用了,内核还是应用或者空闲 u32_t mf_marty:3; //属于哪个区 u32_t mf_uindx:24; //分配计数&#125;__attribute__((packed)) msadflgs_t;//物理地址和标志typedef struct s_PHYADRFLGS&#123; u64_t paf_alloc:1; //分配位 u64_t paf_shared:1; //共享位 u64_t paf_swap:1; //交换位 u64_t paf_cache:1; //缓存位 u64_t paf_kmap:1; //映射位 u64_t paf_lock:1; //锁定位 u64_t paf_dirty:1; //脏位 u64_t paf_busy:1; //忙位 u64_t paf_rv2:4; //保留位 u64_t paf_padrs:52; //页物理地址位&#125;__attribute__((packed)) phyadrflgs_t;//内存空间地址描述符typedef struct s_MSADSC&#123; list_h_t md_list; //链表 spinlock_t md_lock; //保护自身的自旋锁 msadflgs_t md_indxflgs; //内存空间地址描述符标志 phyadrflgs_t md_phyadrs; //物理地址和标志 void* md_odlink; //相邻且相同大小msadsc的指针&#125;__attribute__((packed)) msadsc_t; 内存区 将多个页面分成几个内存区,方便对内存更加合理地管理,进一步做精细化的控制 内存区为逻辑上的概念,并不是硬件上必须的;但没有内存也绝对不行 将物理内存分为三个区:硬件区,内核区,应用区 硬件区,占物理内存低端区域0~32MB,虚拟地址主要依赖于CPU中的MMU,但很多外部硬件能直接和内存交换数据,并且只能访问低于24MB的物理内存,只需规定硬件区分配内存页就可分配内存页给硬件设备 内核区,内核运行在虚拟地址空间需要一段物理内存空间和内核的虚拟地址空间线性映射 应用区,给应用用户态程序使用,应用程序使用虚拟地址空间按需分配物理内存 如果访问到没有与物理内存页建立映射关系的虚拟内存页,CPU产生缺页异常,最终会由操作系统分配一个物理内存页,并建立好映射关系 分配单个页面,把离散的单页,或者内核自身需要建好页表才可以访问的页面,统统收归到用户区 使用结构体表示内存区,但并不能高效的分配内存,因为没有把内存区数据结构和内存页面数据结构关联,分配内存需要遍历扫描msadsc_t结构数组,需要组织内存页以关联起来提高分配效率 组织内存页 组织内存页就是祖师msadsc_t结构,而msassc_t结构中拥有链表,组织msassc_t结构正是通过另一个数据结构中的链表,将msassc_t结构串联在其中 但需要扫描链表,和之前没有区别 定义挂在msadsc_t结构的数据结构,其中需要锁,状态,msadsc_t结构数量,挂载msassc_t结构的链表,和一些统计数据 定义了bafhlst_t数据结构,需要将多个bafhlst_t数据结构组成结构数组,并放在更高的内存分割合并数据结构memdivmer_t中 内存的两个标准操作为什么要用分割和合并:取意于内存分配释放算法,对算法而言分配内存就是分割内存,释放内存就是合并内存 若memdivmer_t结构中dm_mdmlielst数组只是一个数组,没有意义 要通过dm_mdmlielst数组,来划分物理内存地址不连续的msadsc_t结构 dm_mdmlielst数组中第0个元素挂载单个msadsc_t结构,其物理内存地址可能对应于0x1000,0x3000,0x5000 dm_mdmlielst数组中第1个元素挂载两个连续的msadsc_t结构,物理内存地址可能对应于0x80000x9FFF,0xA0000xBFFF dm_mdmlielst数组中第2个元素挂载4个连续的msadsc_t结构,物理内存地址可能对应于0x100000~0x103FFF,0x104000～0x107FFF 依次类推,dm_mdmlielst数组挂载连续msadsc_t结构的数量等于用1左移其数组下标,如数组下标为3,那结果就是8(1&lt;&lt;3)个连续的msadsc_t结构 并不在意其中第一个msadsc_t结构对应的内存物理地址从哪里开始,但是第一个msadsc_t结构与最后一个 msadsc_t结构,它们之间的内存物理地址是连续的 123456789101112131415161718192021222324typedef struct s_BAFHLST&#123; spinlock_t af_lock; //保护自身结构的自旋锁 u32_t af_stus; //状态 uint_t af_oder; //页面数的位移量 uint_t af_oderpnr; //oder对应的页面数比如 oder为2那就是1&lt;&lt;2=4 uint_t af_fobjnr; //多少个空闲msadsc_t结构,即空闲页面 uint_t af_mobjnr; //此结构的msadsc_t结构总数,即此结构总页面 uint_t af_alcindx; //此结构的分配计数 uint_t af_freindx; //此结构的释放计数 list_h_t af_frelst; //挂载此结构的空闲msadsc_t结构 list_h_t af_alclst; //挂载此结构已经分配的msadsc_t结构&#125;bafhlst_t;#define MDIVMER_ARR_LMAX 52typedef struct s_MEMDIVMER&#123; spinlock_t dm_lock; //保护自身结构的自旋锁 u32_t dm_stus; //状态 uint_t dm_divnr; //内存分配次数 uint_t dm_mernr; //内存合并次数 bafhlst_t dm_mdmlielst[MDIVMER_ARR_LMAX];//bafhlst_t结构数组 bafhlst_t dm_onemsalst; //单个的bafhlst_t结构&#125;memdivmer_t; 每个内存区memarea_t结构中包含一个内存分割合并memdivmer_t结构 在memdivmer_t结构中又包含dm_mdmlielst数组 在dm_mdmlielst数组中挂载了多个msadsc_t结构 6.2 如何实现内存页的分配与释放 内存管理相关的数据结构已定义好了,但没有在内存中建立对应的实例变量,在代码的实际操作中必须建立对应的实例变量 初始化 在hal层初始化中,初始化了从二级引导器中获取的内存布局信息e820map_t数组,并转换成了phymmarge_t结构数组,并对它做了排序 但Cosmos物理内存管理器剩下的部分还没有完成初始化 Cosmos的物理内存管理器,依然放在Cosmos的hal层 物理内存和硬件平台相关,在cosmos/hal/x86目录下建立memmgrinit.c文件,在文件中写入Cosmos物理内存管理器初始化的init_memmgr函数,并在init_halmm函数中调用 init_memmgr函数需要完成内存页结构msadsc_t和内存区结构memarea_t的初始化 123456789101112131415//cosmos/hal/x86/halmm.c中//hal层的内存初始化函数void init_halmm()&#123; init_phymmarge(); init_memmgr(); return;&#125;//Cosmos物理内存管理器初始化void init_memmgr()&#123; //初始化内存页结构msadsc_t //初始化内存区结构memarea_t return;&#125; 内存页结构初始化 初始化msadsc_t结构对应的变量,一个msadsc_t结构体变量代表一个物理内存页,而物理内存由多个页组成,最终形成msadsc_t结构体数组 只需要找一个内存地址,作为msadsc_t结构体数组,然后扫描phymmarge_t结构体数组中的信息,只要类型是可用内存,就建立一个msadsc_t结构体,并将其中的开始地址作为第一个页面地址 接着要给开始地址加上0x1000,如此循环,直到其结束地址 当phymmarge_t结构体的地址区间,它对所有msadsc_t结构体都建立完成之后,就开始下一个phymmarge_t结构体.依次类推,最后就能建好所有可用物理内存页面对应的msadsc_t结构体 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// cosmos/hal.x86/msadsc.cvoid write_one_msadsc(msadsc_t *msap, u64_t phyadr)&#123; //对msadsc_t结构做基本的初始化,比如链表、锁、标志位 msadsc_t_init(msap); //这是把一个64位的变量地址转换成phyadrflgs_t*类型方便取得其中的地址位段 phyadrflgs_t *tmp = (phyadrflgs_t *)(&amp;phyadr); //把页的物理地址写入到msadsc_t结构中 msap-&gt;md_phyadrs.paf_padrs = tmp-&gt;paf_padrs; return;&#125;u64_t init_msadsc_core(machbstart_t *mbsp, msadsc_t *msavstart, u64_t msanr)&#123; //获取phymmarge_t结构数组开始地址 phymmarge_t *pmagep = (phymmarge_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_e820 u64_t mdindx = 0; //扫描phymmarge_t结构数组 for (u64_t i = 0; i &lt; mbsp-&gt;mb_e820exnr; i++) &#123; //判断phymmarge_t结构的类型是不是可用内存 if (PMR_T_OSAPUSERRAM == pmagep[i].pmr_type) &#123; //遍历phymmarge_t结构的地址区间 for (u64_t start = pmagep[i].pmr_saddr; start &lt; pmagep[i].pmr_end; &#123; //每次加上4KB-1比较是否小于等于phymmarge_t结构的结束地址 if ((start + 4096 - 1) &lt;= pmagep[i].pmr_end) &#123; //与当前地址为参数写入第mdindx个msadsc结构 write_one_msadsc(&amp;msavstart[mdindx], start); mdindx++; &#125; &#125; &#125; &#125; return mdindx;&#125;void init_msadsc()&#123; u64_t coremdnr = 0, msadscnr = 0; msadsc_t *msadscvp = NULL; machbstart_t *mbsp = &amp;kmachbsp; //计算msadsc_t结构数组的开始地址和数组元素个数 if (ret_msadsc_vadrandsz(mbsp, &amp;msadscvp, &amp;msadscnr) == FALSE) &#123; system_error(&quot;init_msadsc ret_msadsc_vadrandsz err\\n&quot;); &#125; //开始真正初始化msadsc_t结构数组 coremdnr = init_msadsc_core(mbsp, msadscvp, msadscnr); if (coremdnr != msadscnr) &#123; system_error(&quot;init_msadsc init_msadsc_core err\\n&quot;); &#125; //将msadsc_t结构数组的开始的物理地址写入kmachbsp结构中 mbsp-&gt;mb_memmappadr = viradr_to_phyadr((adr_t)msadscvp); //将msadsc_t结构数组的元素个数写入kmachbsp结构中 mbsp-&gt;mb_memmapnr = coremdnr; //将msadsc_t结构数组的大小写入kmachbsp结构中 mbsp-&gt;mb_memmapsz = coremdnr * sizeof(msadsc_t); //计算下一个空闲内存的开始地址 mbsp-&gt;mb_nextwtpadr = PAGE_ALIGN(mbsp-&gt;mb_memmappadr + mbsp-&gt;mb_memmapsz); return;&#125;// ret_msadsc_vadrandsz函数也是遍历phymmarge_t结构数组,计算出有多大的可用内存空间,可以分成多少个页面,需要多少个msadsc_t结构 内存区结构初始化 将物理空间在逻辑上分为硬件区,内核区,用户区; 要求在内存中建立三个memarea_t结构体的实例变量,需要在内存中找到空闲空间,存放着三个结构体,该结构体是顶层结构,不依赖其他数据结构,只是对其本身进行初始化就好,但其包含了其他数据结构,在初始化时,要对其中的数据结构进行初始化 在init_memarea_core函数的开始,调用memarea_t_init函数,对MEMAREA_MAX个memarea_t结构进行了基本的初始化.然后,在memarea_t_init函数中又调用memdivmer_t_init函数,而在memdivmer_t_init函数中又调用了bafhlst_t_init函数,这保证了那些被包含的数据结构得到了初始化;最后,给三个区分别设置了类型和地址空间 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// cosmos/hal/x86/memarea.cvoid bafhlst_t_init(bafhlst_t *initp, u32_t stus, uint_t oder, uint_t oderpnr)&#123; //初始化bafhlst_t结构体的基本数据 knl_spinlock_init(&amp;initp-&gt;af_lock); initp-&gt;af_stus = stus; initp-&gt;af_oder = oder; initp-&gt;af_oderpnr = oderpnr; initp-&gt;af_fobjnr = 0; initp-&gt;af_mobjnr = 0; initp-&gt;af_alcindx = 0; initp-&gt;af_freindx = 0; list_init(&amp;initp-&gt;af_frelst); list_init(&amp;initp-&gt;af_alclst); list_init(&amp;initp-&gt;af_ovelst); return;&#125;void memdivmer_t_init(memdivmer_t *initp)&#123; //初始化medivmer_t结构体的基本数据 knl_spinlock_init(&amp;initp-&gt;dm_lock); initp-&gt;dm_stus = 0; initp-&gt;dm_divnr = 0; initp-&gt;dm_mernr = 0; //循环初始化memdivmer_t结构体中dm_mdmlielst数组中的每个bafhlst_t结构的基本数据 for (uint_t li = 0; li &lt; MDIVMER_ARR_LMAX; li++) &#123; bafhlst_t_init(&amp;initp-&gt;dm_mdmlielst[li], BAFH_STUS_DIVM, li, (1UL &lt;&lt; l &#125; bafhlst_t_init(&amp;initp-&gt;dm_onemsalst, BAFH_STUS_ONEM, 0, 1UL); return;&#125;void memarea_t_init(memarea_t *initp)&#123; //初始化memarea_t结构体的基本数据 list_init(&amp;initp-&gt;ma_list); knl_spinlock_init(&amp;initp-&gt;ma_lock); initp-&gt;ma_stus = 0; initp-&gt;ma_flgs = 0; initp-&gt;ma_type = MA_TYPE_INIT; initp-&gt;ma_maxpages = 0; initp-&gt;ma_allocpages = 0; initp-&gt;ma_freepages = 0; initp-&gt;ma_resvpages = 0; initp-&gt;ma_horizline = 0; initp-&gt;ma_logicstart = 0; initp-&gt;ma_logicend = 0; initp-&gt;ma_logicsz = 0; //初始化memarea_t结构体中的memdivmer_t结构体 memdivmer_t_init(&amp;initp-&gt;ma_mdmdata); initp-&gt;ma_privp = NULL; return;&#125;bool_t init_memarea_core(machbstart_t *mbsp)&#123; //获取memarea_t结构开始地址 u64_t phymarea = mbsp-&gt;mb_nextwtpadr; //检查内存空间够不够放下MEMAREA_MAX个memarea_t结构实例变量 if (initchkadr_is_ok(mbsp, phymarea, (sizeof(memarea_t) * MEMAREA_MAX)) != &#123; return FALSE; &#125; memarea_t *virmarea = (memarea_t *)phyadr_to_viradr((adr_t)phymarea); for (uint_t mai = 0; mai &lt; MEMAREA_MAX; mai++) &#123; //循环初始化每个memarea_t结构实例变量 memarea_t_init(&amp;virmarea[mai]); &#125; //设置硬件区的类型和空间大小 virmarea[0].ma_type = MA_TYPE_HWAD; virmarea[0].ma_logicstart = MA_HWAD_LSTART; virmarea[0].ma_logicend = MA_HWAD_LEND; virmarea[0].ma_logicsz = MA_HWAD_LSZ; //设置内核区的类型和空间大小 virmarea[1].ma_type = MA_TYPE_KRNL; virmarea[1].ma_logicstart = MA_KRNL_LSTART; virmarea[1].ma_logicend = MA_KRNL_LEND; virmarea[1].ma_logicsz = MA_KRNL_LSZ; //设置应用区的类型和空间大小 virmarea[2].ma_type = MA_TYPE_PROC; virmarea[2].ma_logicstart = MA_PROC_LSTART; virmarea[2].ma_logicend = MA_PROC_LEND; virmarea[2].ma_logicsz = MA_PROC_LSZ; //将memarea_t结构的开始的物理地址写入kmachbsp结构中 mbsp-&gt;mb_memznpadr = phymarea; //将memarea_t结构的个数写入kmachbsp结构中 mbsp-&gt;mb_memznnr = MEMAREA_MAX; //将所有memarea_t结构的大小写入kmachbsp结构中 mbsp-&gt;mb_memznsz = sizeof(memarea_t) * MEMAREA_MAX; //计算下一个空闲内存的开始地址 mbsp-&gt;mb_nextwtpadr = PAGE_ALIGN(phymarea + sizeof(memarea_t) * MEMAREA_MA return TRUE;&#125;//初始化内存区void init_memarea()&#123; //真正初始化内存区 if (init_memarea_core(&amp;kmachbsp) == FALSE) &#123; system_error(&quot;init_memarea_core fail&quot;); &#125; return;&#125; 处理初始内存占用问题 初始化了内存页和内存区对应的数据结构,已经可以组织好内存页面 目前内存中已经有很多数据,有内核本身的执行文件,有字体文件,有MMU页表,有打包的内核映像文件,还有刚建立的内存页和内存区的数据结构;但建立内存页结构msadsc_t,所有的都是空闲状态,而每一个都表示一个实际的物理内存页 假定在这种情况下,对调用内存分配接口进行内存分配,按既定的分配算法查找空闲的msadsc_t结构,它一定会找到内核占用的内存页所对应的msadsc_t结构,并把这个内存分配出去,然后得到这个页面的程序对其进行改写,这样内核数据就会被覆盖,(不允许该情况发生) 故将这些已经占用的内存页面所对应的msadsc_t结构标记出来,标记成已分配,这样内存分配算法就不会找到它们 解决方法:只要找出被占用内存的起始地址和结束地址,然后从起始地址开始查找对应的msadsc_t结构,再把它标记为已分配,最后直到查找到结束地址为止 实现三个函数:由init_search_krloccupymm函数入口,search_krloccupymsadsc_core函数驱动,由 search_segment_occupymsadsc函数完成实际的工作 由于初始化阶段各种数据占用的开始,结束地址和大小,该信息都保存在machbstart_t类型的kmachbsp变量中,所以函数machbstart_t类型的指针为参数 phymmarge_t,msadsc_t,memarea_t这些结构的实例变量和MMU页表所占用的内存空间已经涵盖在了内核自身占用的内存空间 处理初始内存占用问题问题已完美解决,只要在初始化内存呢页结构和内存区结构之后调用init_search_krloccupymm函数即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// 在msadsc.c实现该方案//搜索一段内存地址空间所对应的msadsc_t结构u64_t search_segment_occupymsadsc(msadsc_t *msastart, u64_t msanr, u64_t ocpys&#123; u64_t mphyadr = 0, fsmsnr = 0; msadsc_t *fstatmp = NULL; for (u64_t mnr = 0; mnr &lt; msanr; mnr++) &#123; if ((msastart[mnr].md_phyadrs.paf_padrs &lt;&lt; PSHRSIZE) == ocpystat) &#123; //找出开始地址对应的第一个msadsc_t结构,就跳转到step1 fstatmp = &amp;msastart[mnr]; goto step1; &#125; &#125; step1: fsmsnr = 0; if (NULL == fstatmp) &#123; return 0; &#125; for (u64_t tmpadr = ocpystat; tmpadr &lt; ocpyend; tmpadr += PAGESIZE, fsmsnr &#123; //从开始地址对应的第一个msadsc_t结构开始设置,直到结束地址对应的最后一个masdsc_t结 mphyadr = fstatmp[fsmsnr].md_phyadrs.paf_padrs &lt;&lt; PSHRSIZE; if (mphyadr != tmpadr) &#123; return 0; &#125; if (MF_MOCTY_FREE != fstatmp[fsmsnr].md_indxflgs.mf_mocty || 0 != fstatmp[fsmsnr].md_indxflgs.mf_uindx || PAF_NO_ALLOC != fstatmp[fsmsnr].md_phyadrs.paf_alloc) &#123; return 0; &#125; //设置msadsc_t结构为已经分配,已经分配给内核 fstatmp[fsmsnr].md_indxflgs.mf_mocty = MF_MOCTY_KRNL; fstatmp[fsmsnr].md_indxflgs.mf_uindx++; fstatmp[fsmsnr].md_phyadrs.paf_alloc = PAF_ALLOC; &#125; //进行一些数据的正确性检查 u64_t ocpysz = ocpyend - ocpystat; if ((ocpysz &amp; 0xfff) != 0) &#123; if (((ocpysz &gt;&gt; PSHRSIZE) + 1) != fsmsnr) &#123; return 0; &#125; return fsmsnr; &#125; if ((ocpysz &gt;&gt; PSHRSIZE) != fsmsnr) &#123; return 0; &#125; return fsmsnr;&#125;bool_t search_krloccupymsadsc_core(machbstart_t *mbsp)&#123; u64_t retschmnr = 0; msadsc_t *msadstat = (msadsc_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_memmappa u64_t msanr = mbsp-&gt;mb_memmapnr; //搜索BIOS中断表占用的内存页所对应msadsc_t结构 retschmnr = search_segment_occupymsadsc(msadstat, msanr, 0, 0x1000); if (0 == retschmnr) &#123; return FALSE; &#125; //搜索内核栈占用的内存页所对应msadsc_t结构 retschmnr = search_segment_occupymsadsc(msadstat, msanr, mbsp-&gt;mb_krlinits if (0 == retschmnr) &#123; return FALSE; &#125; //搜索内核占用的内存页所对应msadsc_t结构 retschmnr = search_segment_occupymsadsc(msadstat, msanr, mbsp-&gt;mb_krlimgpa if (0 == retschmnr) &#123; return FALSE; &#125; //搜索内核映像文件占用的内存页所对应msadsc_t结构 retschmnr = search_segment_occupymsadsc(msadstat, msanr, mbsp-&gt;mb_imgpadr, if (0 == retschmnr) &#123; return FALSE; &#125; return TRUE;&#125;//初始化搜索内核占用的内存页面void init_search_krloccupymm(machbstart_t *mbsp)&#123; //实际初始化搜索内核占用的内存页面 if (search_krloccupymsadsc_core(mbsp) == FALSE) &#123; system_error(&quot;search_krloccupymsadsc_core fail\\n&quot;); &#125; return;&#125; 合并内存页到内存区 让msadsc_t结构挂载到内存区对应的数组中,才能提高内存管理器的分配速度 整体流程分为两步 确定内存页属于哪个区,即标定一系列msadsc_t结构是属于哪个memarea_t结构的 遍历每个memarea_t结构,遍历过程中根据特定的memarea_t结构,然后扫描整个msadsc_t结构数组,最后依次对比msadsc_t的物理地址看msadsc_t是否落在memarea_t结构的地址区间中 如果是,就把memarea_t结构的类型值写入msadsc_t结构中,这样就一个一个打上了标签,遍历memarea_t结构结束之后,每个msadsc_t结构就只归属于某一个memarea_t结构 把特定的内存页合并,然后挂载到特定的内存区下的memdivmer_t结构中的dm_mdmlielst数组中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// memarea.c文件中写几个函数实现第一步//给msadsc_t结构打上标签uint_t merlove_setallmarflgs_onmemarea(memarea_t *mareap, msadsc_t *mstat, uin&#123; u32_t muindx = 0; msadflgs_t *mdfp = NULL; //获取内存区类型 switch (mareap-&gt;ma_type)&#123; case MA_TYPE_HWAD: muindx = MF_MARTY_HWD &lt;&lt; 5;//硬件区标签 mdfp = (msadflgs_t *)(&amp;muindx); break; case MA_TYPE_KRNL: muindx = MF_MARTY_KRL &lt;&lt; 5;//内核区标签 mdfp = (msadflgs_t *)(&amp;muindx); break; case MA_TYPE_PROC: muindx = MF_MARTY_PRC &lt;&lt; 5;//应用区标签 mdfp = (msadflgs_t *)(&amp;muindx); break; &#125; u64_t phyadr = 0; uint_t retnr = 0; //扫描所有的msadsc_t结构 for (uint_t mix = 0; mix &lt; msanr; mix++) &#123; if (MF_MARTY_INIT == mstat[mix].md_indxflgs.mf_marty) &#123; //获取msadsc_t结构对应的地址 phyadr = mstat[mix].md_phyadrs.paf_padrs &lt;&lt; PSHRSIZE; //和内存区的地址区间比较 if (phyadr &gt;= mareap-&gt;ma_logicstart &amp;&amp; ((phyadr + PAGESIZE) - 1) &lt; &#123; //设置msadsc_t结构的标签 mstat[mix].md_indxflgs.mf_marty = mdfp-&gt;mf_marty; retnr++; &#125; &#125; &#125; return retnr;&#125;bool_t merlove_mem_core(machbstart_t *mbsp)&#123; //获取msadsc_t结构的首地址 msadsc_t *mstatp = (msadsc_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_memmappadr //获取msadsc_t结构的个数 uint_t msanr = (uint_t)mbsp-&gt;mb_memmapnr, maxp = 0; //获取memarea_t结构的首地址 memarea_t *marea = (memarea_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_memznpadr uint_t sretf = ~0UL, tretf = ~0UL; //遍历每个memarea_t结构 for (uint_t mi = 0; mi &lt; (uint_t)mbsp-&gt;mb_memznnr; mi++) &#123; //针对其中一个memarea_t结构给msadsc_t结构打上标签 sretf = merlove_setallmarflgs_onmemarea(&amp;marea[mi], mstatp, msanr); if ((~0UL) == sretf) &#123; return FALSE; &#125; &#125; //遍历每个memarea_t结构 for (uint_t maidx = 0; maidx &lt; (uint_t)mbsp-&gt;mb_memznnr; maidx++) &#123; //针对其中一个memarea_t结构对msadsc_t结构进行合并 if (merlove_mem_onmemarea(&amp;marea[maidx], mstatp, msanr) == FALSE) &#123; return FALSE; &#125; maxp += marea[maidx].ma_maxpages; &#125; return TRUE;&#125;//初始化页面合并void init_merlove_mem()&#123; if (merlove_mem_core(&amp;kmachbsp) == FALSE) &#123; system_error(&quot;merlove_mem_core fail\\n&quot;); &#125; return;&#125; 上述代码从init_merlove_mem函数开始,其调用的merlove_mem_core函数真正执行工作 merlove_mem_core函数有两个遍历内存区,第一次遍历是为了完成第一步,确定内存页属于哪个区 当确定内存页属于哪个区之后,到了第二遍遍历memarea_t结构,合并其中的msadsc_t结构,并把它们挂载到其中的memdivmer_t结构中的dm_mdmlielst数组中 该操作较为复杂,第一要保证其中所有的msadsc_t结构挂载到dm_mdmlielst数组中合适的bafhlst_t结构中;第二要保证多个msadsc_t结构有最大的连续性 遍历每个内存区,然后针对其中每一个内存区进行msadsc_t结构的合并操作,完成这个操作的是 merlove_mem_onmemarea merlove_mem_onmemarea的整体分为两步 第一步,通过merlove_scan_continumsadsc函数,返回最多且地址连续的msadsc_t结构体的开始、结束地址、一共多少个msadsc_t结构体,下一轮开始的msadsc_t结构体的索引号 第二步,根据第一步获取的信息调用merlove_continumsadsc_mareabafh函数,把第一步返回那一组连续的 msadsc_t结构体,挂载到合适的m_mdmlielst数组中的bafhlst_t结构中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114// 实现merlove_mem_onmemarea函数bool_t continumsadsc_add_bafhlst(memarea_t *mareap, bafhlst_t *bafhp, msadsc_t&#123; fstat-&gt;md_indxflgs.mf_olkty = MF_OLKTY_ODER; //开始的msadsc_t结构指向最后的msadsc_t结构 fstat-&gt;md_odlink = fend; fend-&gt;md_indxflgs.mf_olkty = MF_OLKTY_BAFH; //最后的msadsc_t结构指向它属于的bafhlst_t结构 fend-&gt;md_odlink = bafhp; //把多个地址连续的msadsc_t结构的的开始的那个msadsc_t结构挂载到bafhlst_t结构的af_fre list_add(&amp;fstat-&gt;md_list, &amp;bafhp-&gt;af_frelst); //更新bafhlst_t的统计数据 bafhp-&gt;af_fobjnr++; bafhp-&gt;af_mobjnr++; //更新内存区的统计数据 mareap-&gt;ma_maxpages += fmnr; mareap-&gt;ma_freepages += fmnr; mareap-&gt;ma_allmsadscnr += fmnr; return TRUE;&#125;bool_t continumsadsc_mareabafh_core(memarea_t *mareap, msadsc_t **rfstat, msad&#123; uint_t retval = *rfmnr, tmpmnr = 0; msadsc_t *mstat = *rfstat, *mend = *rfend; //根据地址连续的msadsc_t结构的数量查找合适bafhlst_t结构 bafhlst_t *bafhp = find_continumsa_inbafhlst(mareap, retval); //判断bafhlst_t结构状态和类型对不对 if ((BAFH_STUS_DIVP == bafhp-&gt;af_stus || BAFH_STUS_DIVM == bafhp-&gt;af_stus) &#123; //看地址连续的msadsc_t结构的数量是不是正好是bafhp-&gt;af_oderpnr tmpmnr = retval - bafhp-&gt;af_oderpnr; //根据地址连续的msadsc_t结构挂载到bafhlst_t结构中 if (continumsadsc_add_bafhlst(mareap, bafhp, mstat, &amp;mstat[bafhp-&gt;af_o &#123; return FALSE; &#125; //如果地址连续的msadsc_t结构的数量正好是bafhp-&gt;af_oderpnr则完成,否则返回再次进 if (tmpmnr == 0) &#123; *rfmnr = tmpmnr; *rfend = NULL; return TRUE; &#125; //挂载bafhp-&gt;af_oderpnr地址连续的msadsc_t结构到bafhlst_t中 *rfstat = &amp;mstat[bafhp-&gt;af_oderpnr]; //还剩多少个地址连续的msadsc_t结构 *rfmnr = tmpmnr; return TRUE; &#125; return FALSE;&#125;bool_t merlove_continumsadsc_mareabafh(memarea_t *mareap, msadsc_t *mstat, msa&#123; uint_t mnridx = mnr; msadsc_t *fstat = mstat, *fend = mend; //如果mnridx &gt; 0并且NULL != fend就循环调用continumsadsc_mareabafh_core函数,而m for (; (mnridx &gt; 0 &amp;&amp; NULL != fend);) &#123; //为一段地址连续的msadsc_t结构寻找合适m_mdmlielst数组中的bafhlst_t结构 continumsadsc_mareabafh_core(mareap, &amp;fstat, &amp;fend, &amp;mnridx) &#125; return TRUE;&#125;bool_t merlove_scan_continumsadsc(memarea_t *mareap, msadsc_t *fmstat, uint_tmsadsc_t **retmsastatp, msadsc_t **re&#123; u32_t muindx = 0; msadflgs_t *mdfp = NULL; msadsc_t *msastat = fmstat; uint_t retfindmnr = 0; bool_t rets = FALSE; uint_t tmidx = *fntmsanr; //从外层函数的fntmnr变量开始遍历所有msadsc_t结构 for (; tmidx &lt; fmsanr; tmidx++) &#123; //一个msadsc_t结构是否属于这个内存区,是否空闲 if (msastat[tmidx].md_indxflgs.mf_marty == mdfp-&gt;mf_marty &amp;&amp; 0 == msastat[tmidx].md_indxflgs.mf_uindx &amp;&amp; MF_MOCTY_FREE == msastat[tmidx].md_indxflgs.mf_mocty &amp;&amp; PAF_NO_ALLOC == msastat[tmidx].md_phyadrs.paf_alloc) &#123; //返回从这个msadsc_t结构开始到下一个非空闲、地址非连续的msadsc_t结构对应的msadsc rets = scan_len_msadsc(&amp;msastat[tmidx], mdfp, fmsanr, &amp;retfindmnr) //下一轮开始的msadsc_t结构索引 *fntmsanr = tmidx + retfindmnr + 1; //当前地址连续msadsc_t结构的开始地址 *retmsastatp = &amp;msastat[tmidx]; //当前地址连续msadsc_t结构的结束地址 *retmsaendp = &amp;msastat[tmidx + retfindmnr]; //当前有多少个地址连续msadsc_t结构 *retfmnr = retfindmnr + 1; return TRUE; &#125; &#125; return FALSE;&#125;bool_t merlove_mem_onmemarea(memarea_t *mareap, msadsc_t *mstat, uint_t msanr)&#123; msadsc_t *retstatmsap = NULL, *retendmsap = NULL, *fntmsap = mstat; uint_t retfindmnr = 0; uint_t fntmnr = 0; bool_t retscan = FALSE; for (; fntmnr &lt; msanr;) &#123; //获取最多且地址连续的msadsc_t结构体的开始、结束地址、一共多少个msadsc_t结构体,下 retscan = merlove_scan_continumsadsc(mareap, fntmsap, &amp;fntmnr, msanr, if (NULL != retstatmsap &amp;&amp; NULL != retendmsap) &#123; //把一组连续的msadsc_t结构体挂载到合适的m_mdmlielst数组中的bafhlst_t结构中 merlove_continumsadsc_mareabafh(mareap, retstatmsap, retendmsap, retfi &#125; &#125; return TRUE;&#125; 初始化汇总 在先前的init_memmgr函数中调用上述函数 init_msadsc、init_memarea函数是可以交换次序的,俩互不影响,但必须最先开始调用,而后面的函数要依赖它们生成的数据结构 但是init_search_krloccupymm函数必须要在init_merlove_mem函数之前被调用,因为init_merlove_mem 函数在合并页面时,必须先知道哪些页面被占用了 **init_memmgrob函数:**phymmarge_t结构体的地址和数量、msadsc_t结构体的地址和数据、memarea_t结构体的地址和数量都保存在了kmachbsp变量中,这个变量其实不是用来管理内存的,而且它里面放的是物理地址;但内核使用的是虚拟地址,需要一个专用的数据结构进行转换用于内存管理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283void init_memmgr()&#123; //初始化内存页结构 init_msadsc(); //初始化内存区结构 init_memarea(); //处理内存占用 init_search_krloccupymm(&amp;kmachbsp); //合并内存页到内存区中 init_merlove_mem(); init_memmgrob(); return;&#125;//cosmos/include/halinc/halglobal.cHAL_DEFGLOB_VARIABLE(memmgrob_t,memmgrob);typedef struct s_MEMMGROB&#123; list_h_t mo_list; spinlock_t mo_lock; //保护自身自旋锁 uint_t mo_stus; //状态 uint_t mo_flgs; //标志 u64_t mo_memsz; //内存大小 u64_t mo_maxpages; //内存最大页面数 u64_t mo_freepages; //内存最大空闲页面数 u64_t mo_alocpages; //内存最大分配页面数 u64_t mo_resvpages; //内存保留页面数 u64_t mo_horizline; //内存分配水位线 phymmarge_t* mo_pmagestat; //内存空间布局结构指针 u64_t mo_pmagenr; msadsc_t* mo_msadscstat; //内存页面结构指针 u64_t mo_msanr; memarea_t* mo_mareastat; //内存区结构指针 u64_t mo_mareanr;&#125;memmgrob_t;//cosmos/hal/x86/memmgrinit.cvoid memmgrob_t_init(memmgrob_t *initp)&#123; list_init(&amp;initp-&gt;mo_list); knl_spinlock_init(&amp;initp-&gt;mo_lock); initp-&gt;mo_stus = 0; initp-&gt;mo_flgs = 0; initp-&gt;mo_memsz = 0; initp-&gt;mo_maxpages = 0; initp-&gt;mo_freepages = 0; initp-&gt;mo_alocpages = 0; initp-&gt;mo_resvpages = 0; initp-&gt;mo_horizline = 0; initp-&gt;mo_pmagestat = NULL; initp-&gt;mo_pmagenr = 0; initp-&gt;mo_msadscstat = NULL; initp-&gt;mo_msanr = 0; initp-&gt;mo_mareastat = NULL; initp-&gt;mo_mareanr = 0; return;&#125;void init_memmgrob()&#123; machbstart_t *mbsp = &amp;kmachbsp; memmgrob_t *mobp = &amp;memmgrob; memmgrob_t_init(mobp); mobp-&gt;mo_pmagestat = (phymmarge_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_e820e mobp-&gt;mo_pmagenr = mbsp-&gt;mb_e820exnr; mobp-&gt;mo_msadscstat = (msadsc_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_memmapp mobp-&gt;mo_msanr = mbsp-&gt;mb_memmapnr; mobp-&gt;mo_mareastat = (memarea_t *)phyadr_to_viradr((adr_t)mbsp-&gt;mb_memznpa mobp-&gt;mo_mareanr = mbsp-&gt;mb_memznnr; mobp-&gt;mo_memsz = mbsp-&gt;mb_memmapnr &lt;&lt; PSHRSIZE; mobp-&gt;mo_maxpages = mbsp-&gt;mb_memmapnr; uint_t aidx = 0; for (uint_t i = 0; i &lt; mobp-&gt;mo_msanr; i++) &#123; if (1 == mobp-&gt;mo_msadscstat[i].md_indxflgs.mf_uindx &amp;&amp; MF_MOCTY_KRNL == mobp-&gt;mo_msadscstat[i].md_indxflgs.mf_mocty &amp;&amp; PAF_ALLOC == mobp-&gt;mo_msadscstat[i].md_phyadrs.paf_alloc) &#123; aidx++; &#125; &#125; mobp-&gt;mo_alocpages = aidx; mobp-&gt;mo_freepages = mobp-&gt;mo_maxpages - mobp-&gt;mo_alocpages; return;&#125; 本节重点 首先,从初始化msadsc_t结构开始,在内存中建立msadsc_t结构的实例变量,每个物理内存页面一个msadsc_t结构的实例变量 然后初始化memarea_t结构,在msadsc_t结构的实例变量之后,每个内存区一个memarea_t结构实例变量 接着标记哪些msadsc_t结构对应的物理内存被内核占用了,这些被标记msadsc_t结构是不能纳入内存管理结构中去的 最后,把所有的空闲msadsc_t结构按最大地址连续的形式组织起来,挂载到memarea_t结构下的memdivmer_t结构中,对应的dm_mdmlielst数组中 6.3 如何实现内存页的分配与释放 内存页的分配 实现一次只分配一个页面:需要写一段循环代码,在其中遍历出一个空闲的msadsc_t结构,然后就可以返回 内存管理器为内核,驱动,还有应用提供服务,对请求内存页面的多少,内存页面是否连续,内存页面所处的物理地址都有要求,问题变得复杂,从内存分配的接口函数入手解决问题 内存管理代码的结构 接口函数(返回msadsc_t接口指针)调用框架函数,框架函数调用核心函数 不直接返回物理地址的原因：物理内存管理器是最底层的内存管理器,上层代码中可能需要页面相关的信息,所以直接返回页面对应msadsc_t结构的指针 还有一个参数用于返回实际分配的页面数(retrealpnr) 在实现接口函数时,onmpgs_retn_bafhlst 函数返回的两个bafhlst_t结构指针 若是相等的,在 mm_reldpgsdivmsa_bafhl 函数中只要取出bafhlst_t结构中对应的msadsc_t结构返回 不相等时需要分隔连续的 msadsc_t 结构了,通过 mm_reldpgsdivmsa_bafhl 函数来处理这个问题 算法执行步骤 根据一个页面的请求返回 m_mdmlielst 数组中的第 0 个 bafhlst_t 结构 如果第 0 个 bafhlst_t 结构中有 msadsc_t 结构就直接返回,若没有 msadsc_t 结构, 就会继续查找 m_mdmlielst 数组中的第 1 个 bafhlst_t 结构 如果第 1 个 bafhlst_t 结构中也没有 msadsc_t 结构,就会继续查找 m_mdmlielst 数组 中的第 2 个 bafhlst_t 结构 如果第 2 个 bafhlst_t 结构中有 msadsc_t 结构,记住第 2 个 bafhlst_t 结构中对应是 4 个连续的 msadsc_t 结构.这时让这 4 个连续的 msadsc_t 结构从第 2 个 bafhlst_t 结构 中脱离 把这 4 个连续的 msadsc_t 结构,对半分割成 2 个双 msadsc_t 结构,把其中一个双 msadsc_t 结构挂载到第 1 个 bafhlst_t 结构中 把剩下一个双 msadsc_t 结构,继续对半分割成两个单 msadsc_t 结构,把其中一个单 msadsc_t 结构挂载到第 0 个 bafhlst_t 结构中,剩下一个单 msadsc_t 结构返回给请求 者,完成内存分配 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208// 内存分配接口函数// cosmos/hal/x86/memdivmer.c//内存分配页面框架函数msadsc_t *mm_divpages_fmwk(memmgrob_t *mmobjp, uint_t pages, uint_t *retrelpnr&#123; //返回mrtype对应的内存区结构的指针 memarea_t *marea = onmrtype_retn_marea(mmobjp, mrtype); if (NULL == marea) &#123; *retrelpnr = 0; return NULL; &#125; uint_t retpnr = 0; //内存分配的核心函数 msadsc_t *retmsa = mm_divpages_core(marea, pages, &amp;retpnr, flgs); if (NULL == retmsa) &#123; *retrelpnr = 0; return NULL; &#125; *retrelpnr = retpnr; return retmsa;&#125;//内存分配页面接口//mmobjp-&gt;内存管理数据结构指针//pages-&gt;请求分配的内存页面数//retrealpnr-&gt;存放实际分配内存页面数的指针//mrtype-&gt;请求的分配内存页面的内存区类型//flgs-&gt;请求分配的内存页面的标志位msadsc_t *mm_division_pages(memmgrob_t *mmobjp, uint_t pages, uint_t *retrealp&#123; if (NULL == mmobjp || NULL == retrealpnr || 0 == mrtype) &#123; return NULL; &#125; uint_t retpnr = 0; msadsc_t *retmsa = mm_divpages_fmwk(mmobjp, pages, &amp;retpnr, mrtype, flgs); if (NULL == retmsa) &#123; *retrealpnr = 0; return NULL; &#125; *retrealpnr = retpnr; return retmsa;&#125;// 内存分配的核心函数bool_t onmpgs_retn_bafhlst(memarea_t *malckp, uint_t pages, bafhlst_t **retrel&#123; //获取bafhlst_t结构数组的开始地址 bafhlst_t *bafhstat = malckp-&gt;ma_mdmdata.dm_mdmlielst; //根据分配页面数计算出分配页面在dm_mdmlielst数组中下标 sint_t dividx = retn_divoder(pages); //从第dividx个数组元素开始搜索 for (sint_t idx = dividx; idx &lt; MDIVMER_ARR_LMAX; idx++) &#123; //如果第idx个数组元素对应的一次可分配连续的页面数大于等于请求的页面数,且其中的可分配对象 if (bafhstat[idx].af_oderpnr &gt;= pages &amp;&amp; 0 &lt; bafhstat[idx].af_fobjnr) &#123; //返回请求分配的bafhlst_t结构指针 *retrelbafh = &amp;bafhstat[dividx]; //返回实际分配的bafhlst_t结构指针 *retdivbafh = &amp;bafhstat[idx]; return TRUE; &#125; &#125; *retrelbafh = NULL; *retdivbafh = NULL; return FALSE;&#125;msadsc_t *mm_reldivpages_onmarea(memarea_t *malckp, uint_t pages, uint_t *retr&#123; bafhlst_t *retrelbhl = NULL, *retdivbhl = NULL; //根据页面数在内存区的m_mdmlielst数组中找出其中请求分配页面的bafhlst_t结构（retrelb bool_t rets = onmpgs_retn_bafhlst(malckp, pages, &amp;retrelbhl, &amp;retdivbhl); if (FALSE == rets) &#123; *retrelpnr = 0; return NULL; &#125; uint_t retpnr = 0; //实际在bafhlst_t结构中分配页面 msadsc_t *retmsa = mm_reldpgsdivmsa_bafhl(malckp, pages, &amp;retpnr, retrelbh if (NULL == retmsa) &#123; *retrelpnr = 0; return NULL; &#125; *retrelpnr = retpnr; return retmsa;&#125;msadsc_t *mm_divpages_core(memarea_t *mareap, uint_t pages, uint_t *retrealpnr&#123; uint_t retpnr = 0; msadsc_t *retmsa = NULL; cpuflg_t cpuflg; //内存区加锁 knl_spinlock_cli(&amp;mareap-&gt;ma_lock, &amp;cpuflg); if (DMF_RELDIV == flgs) &#123; //分配内存 retmsa = mm_reldivpages_onmarea(mareap, pages, &amp;retpnr); goto ret_step; &#125; retmsa = NULL; retpnr = 0; ret_step: //内存区锁 knl_spinunlock_sti(&amp;mareap-&gt;ma_lock, &amp;cpuflg); *retrealpnr = retpnr; return retmsa;&#125;// onmpgs_retn_bafhlst 函数返回的两个bafhlst_t结构指针// 若是相等的,在 mm_reldpgsdivmsa_bafhl 函数中只要取出bafhlst_t结构中对应的msadsc_t结构返回就好了// 不相等时需要分隔连续的 msadsc_t 结构了,通过 mm_reldpgsdivmsa_bafhl 函数来处理这个问题bool_t mrdmb_add_msa_bafh(bafhlst_t *bafhp, msadsc_t *msastat, msadsc_t *msaen&#123; //把一段连续的msadsc_t结构加入到它所对应的bafhlst_t结构中 msastat-&gt;md_indxflgs.mf_olkty = MF_OLKTY_ODER; msastat-&gt;md_odlink = msaend; msaend-&gt;md_indxflgs.mf_olkty = MF_OLKTY_BAFH; msaend-&gt;md_odlink = bafhp; list_add(&amp;msastat-&gt;md_list, &amp;bafhp-&gt;af_frelst); bafhp-&gt;af_mobjnr++; bafhp-&gt;af_fobjnr++; return TRUE;&#125;msadsc_t *mm_divpages_opmsadsc(msadsc_t *msastat, uint_t mnr)&#123; //单个msadsc_t结构的情况 if (mend == msastat) &#123;//增加msadsc_t结构中分配计数,分配标志位设置为1 msastat-&gt;md_indxflgs.mf_uindx++; msastat-&gt;md_phyadrs.paf_alloc = PAF_ALLOC; msastat-&gt;md_indxflgs.mf_olkty = MF_OLKTY_ODER; msastat-&gt;md_odlink = mend; return msastat; &#125; msastat-&gt;md_indxflgs.mf_uindx++; msastat-&gt;md_phyadrs.paf_alloc = PAF_ALLOC; //多个msadsc_t结构的情况下,末端msadsc_t结构也设置已分配状态 mend-&gt;md_indxflgs.mf_uindx++; mend-&gt;md_phyadrs.paf_alloc = PAF_ALLOC; msastat-&gt;md_indxflgs.mf_olkty = MF_OLKTY_ODER; msastat-&gt;md_odlink = mend; return msastat;&#125;bool_t mm_retnmsaob_onbafhlst(bafhlst_t *bafhp, msadsc_t **retmstat, msadsc_t&#123; //取出一个msadsc_t结构 msadsc_t *tmp = list_entry(bafhp-&gt;af_frelst.next, msadsc_t, md_list); //从链表中删除 list_del(&amp;tmp-&gt;md_list); //减少bafhlst_t结构中的msadsc_t计数 bafhp-&gt;af_mobjnr--; bafhp-&gt;af_fobjnr--; //增加分配计数 bafhp-&gt;af_freindx++; //返回msadsc_t结构 *retmstat = tmp; //返回当前msadsc_t结构连续的那个结尾的msadsc_t结构 *retmend = (msadsc_t *)tmp-&gt;md_odlink; if (MF_OLKTY_BAFH == tmp-&gt;md_indxflgs.mf_olkty) &#123;//如果只单个msadsc_t结构,那就是它本身 *retmend = tmp; &#125; return TRUE;&#125;msadsc_t *mm_reldpgsdivmsa_bafhl(memarea_t *malckp, uint_t pages, uint_t *retr&#123; msadsc_t *retmsa = NULL; bool_t rets = FALSE; msadsc_t *retmstat = NULL, *retmend = NULL; //处理相等的情况 if (relbfl == divbfl) &#123; //从bafhlst_t结构中获取msadsc_t结构的开始与结束地址 rets = mm_retnmsaob_onbafhlst(relbfl, &amp;retmstat, &amp;retmend); //设置msadsc_t结构的相关信息表示已经删除 retmsa = mm_divpages_opmsadsc(retmstat, relbfl-&gt;af_oderpnr); //返回实际的分配页数 *retrelpnr = relbfl-&gt;af_oderpnr; return retmsa; &#125; //处理不等的情况 //从bafhlst_t结构中获取msadsc_t结构的开始与结束地址 rets = mm_retnmsaob_onbafhlst(divbfl, &amp;retmstat, &amp;retmend); uint_t divnr = divbfl-&gt;af_oderpnr; //从高bafhlst_t数组元素中向下遍历 for (bafhlst_t *tmpbfl = divbfl - 1; tmpbfl &gt;= relbfl; tmpbfl--) &#123; //开始分割连续的msadsc_t结构,把剩下的一段连续的msadsc_t结构加入到对应该bafhlst if (mrdmb_add_msa_bafh(tmpbfl, &amp;retmstat[tmpbfl-&gt;af_oderpnr], (msadsc_ &#123; system_error(&quot;mrdmb_add_msa_bafh fail\\n&quot;); &#125; retmstat-&gt;md_odlink = &amp;retmstat[tmpbfl-&gt;af_oderpnr - 1]; divnr -= tmpbfl-&gt;af_oderpnr; &#125; retmsa = mm_divpages_opmsadsc(retmstat, divnr); if (NULL == retmsa) &#123; *retrelpnr = 0; return NULL; &#125; *retrelpnr = relbfl-&gt;af_oderpnr; return retmsa;&#125; 内存页的释放 内存释放页面的代码结构:接口函数调用框架函数,框架函数调用核心函数,函数返回值为bool类型表示内存页面释放操作成功与否 框架函数中内存区是由msadsc_t结构中获取的,因为之前该结构中保留了所在内存区的类型,故可以查到并返回内存区 在经过 mm_merpages_opmsadsc 函数操作之后并没有将 msadsc_t 结构加入到对应的 bafhlst_t 结构中,利用 mm_merpages_onbafhlst 函数完成 释放算法的核心逻辑:最核心的是要对空闲页面进行合并,合并成更大的连续的内存页面 算法演绎 释放一个页面,会返回 m_mdmlielst 数组中的第 0 个 bafhlst_t 结构 设置这个页面对应的 msadsc_t 结构的相关信息,表示已经执行了释放操作 开始查看第 0 个 bafhlst_t 结构中有没有空闲的 msadsc_t,并且它和要释放的 msadsc_t 对应的物理地址是连续的.没有则把这个释放的 msadsc_t 挂载第 0 个 bafhlst_t 结构中,算法结束,否则进入下一步 把第 0 个 bafhlst_t 结构中的 msadsc_t 结构拿出来与释放的 msadsc_t 结构,合并成 2 个连续且更大的 msadsc_t 继续查看第 1 个 bafhlst_t 结构中有没有空闲的 msadsc_t,而且这个空闲 msadsc_t 要 和上一步合并的 2 个 msadsc_t 对应的物理地址是连续的.没有则把这个合并的 2 个 msadsc_t 挂载第 1 个 bafhlst_t 结构中,算法结束,否则进入下一步 把第 1 个 bafhlst_t 结构中的 2 个连续的 msadsc_t 结构,还有合并的 2 个地址连续的 msadsc_t 结构拿出来,合并成 4 个连续且更大的 msadsc_t 结构 继续查看第 2 个 bafhlst_t 结构,有没有空闲的 msadsc_t 结构,并且它要和上一步合 并的 4 个 msadsc_t 结构对应的物理地址是连续的.没有则把这个合并的 4 个 msadsc_t 挂载第 2 个 bafhlst_t 结构中,算法结束 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161//释放内存页面核心bool_t mm_merpages_core(memarea_t *marea, msadsc_t *freemsa, uint_t freepgs)&#123; bool_t rets = FALSE; cpuflg_t cpuflg; //内存区加锁 knl_spinlock_cli(&amp;marea-&gt;ma_lock, &amp;cpuflg); //针对一个内存区进行操作 rets = mm_merpages_onmarea(marea, freemsa, freepgs); //内存区解锁 knl_spinunlock_sti(&amp;marea-&gt;ma_lock, &amp;cpuflg); return rets;&#125;//释放内存页面框架函数bool_t mm_merpages_fmwk(memmgrob_t *mmobjp, msadsc_t *freemsa, uint_t freepgs)&#123; //获取要释放msadsc_t结构所在的内存区 memarea_t *marea = onfrmsa_retn_marea(mmobjp, freemsa, freepgs); if (NULL == marea) &#123; return FALSE; &#125; //释放内存页面的核心函数 bool_t rets = mm_merpages_core(marea, freemsa, freepgs); if (FALSE == rets) &#123; return FALSE; &#125; return rets;&#125;//释放内存页面接口//mmobjp-&gt;内存管理数据结构指针//freemsa-&gt;释放内存页面对应的首个msadsc_t结构指针//freepgs-&gt;请求释放的内存页面数bool_t mm_merge_pages(memmgrob_t *mmobjp, msadsc_t *freemsa, uint_t freepgs)&#123; if (NULL == mmobjp || NULL == freemsa || 1 &gt; freepgs) &#123; return FALSE; &#125; //调用释放内存页面的框架函数 bool_t rets = mm_merpages_fmwk(mmobjp, freemsa, freepgs); if (FALSE == rets) &#123; return FALSE; &#125; return rets;&#125;// 实现 mm_merpages_core 函数中,调用 mm_merge_pages_onmarea 函数sint_t mm_merpages_opmsadsc(bafhlst_t *bafh, msadsc_t *freemsa, uint_t freepgs&#123; msadsc_t *fmend = (msadsc_t *)freemsa-&gt;md_odlink; //处理只有一个单页的情况 if (freemsa == fmend) &#123; //页面的分配计数减1 freemsa-&gt;md_indxflgs.mf_uindx--; if (0 &lt; freemsa-&gt;md_indxflgs.mf_uindx) &#123;//如果依然大于0说明它是共享页面 直接返回1指示不需要进行下一步操作 return 1; &#125; //设置页未分配的标志 freemsa-&gt;md_phyadrs.paf_alloc = PAF_NO_ALLOC; freemsa-&gt;md_indxflgs.mf_olkty = MF_OLKTY_BAFH; freemsa-&gt;md_odlink = bafh;//指向所属的bafhlst_t结构 //返回2指示需要进行下一步操作 return 2; &#125; //多个页面的超始页面和结束页面都要减一 freemsa-&gt;md_indxflgs.mf_uindx--; fmend-&gt;md_indxflgs.mf_uindx--; //如果依然大于0说明它是共享页面 直接返回1指示不需要进行下一步操作 if (0 &lt; freemsa-&gt;md_indxflgs.mf_uindx) &#123; return 1; &#125; //设置起始、结束页页未分配的标志 freemsa-&gt;md_phyadrs.paf_alloc = PAF_NO_ALLOC; fmend-&gt;md_phyadrs.paf_alloc = PAF_NO_ALLOC; freemsa-&gt;md_indxflgs.mf_olkty = MF_OLKTY_ODER; //起始页面指向结束页面 freemsa-&gt;md_odlink = fmend; fmend-&gt;md_indxflgs.mf_olkty = MF_OLKTY_BAFH; //结束页面指向所属的bafhlst_t结构 fmend-&gt;md_odlink = bafh; //返回2指示需要进行下一步操作 return 2;&#125;bool_t onfpgs_retn_bafhlst(memarea_t *malckp, uint_t freepgs, bafhlst_t **retr&#123; //获取bafhlst_t结构数组的开始地址 bafhlst_t *bafhstat = malckp-&gt;ma_mdmdata.dm_mdmlielst; //根据分配页面数计算出分配页面在dm_mdmlielst数组中下标 sint_t dividx = retn_divoder(freepgs); //返回请求释放的bafhlst_t结构指针 *retrelbf = &amp;bafhstat[dividx]; //返回最大释放的bafhlst_t结构指针 *retmerbf = &amp;bafhstat[MDIVMER_ARR_LMAX - 1]; return TRUE;&#125;bool_t mm_merpages_onmarea(memarea_t *malckp, msadsc_t *freemsa, uint_t freepg&#123; bafhlst_t *prcbf = NULL; sint_t pocs = 0; bafhlst_t *retrelbf = NULL, *retmerbf = NULL; bool_t rets = FALSE; //根据freepgs返回请求释放的和最大释放的bafhlst_t结构指针 rets = onfpgs_retn_bafhlst(malckp, freepgs, &amp;retrelbf, &amp;retmerbf); //设置msadsc_t结构的信息,完成释放,返回1表示不需要下一步合并操作,返回2表示要进行合并操 sint_t mopms = mm_merpages_opmsadsc(retrelbf, freemsa, freepgs); if (2 == mopms) &#123; //把msadsc_t结构进行合并然后加入对应bafhlst_t结构 return mm_merpages_onbafhlst(freemsa, freepgs, retrelbf, retmerbf); &#125; if (1 == mopms) &#123; return TRUE; &#125; return FALSE;&#125;// 在经过 mm_merpages_opmsadsc 函数操作之后并没有将 msadsc_t 结构加入到对应的 bafhlst_t 结构中,利用 mm_merpages_onbafhlst 函数完成bool_t mpobf_add_msadsc(bafhlst_t *bafhp, msadsc_t *freemstat, msadsc_t *freem&#123; freemstat-&gt;md_indxflgs.mf_olkty = MF_OLKTY_ODER; //设置起始页面指向结束页 freemstat-&gt;md_odlink = freemend; freemend-&gt;md_indxflgs.mf_olkty = MF_OLKTY_BAFH; //结束页面指向所属的bafhlst_t结构 freemend-&gt;md_odlink = bafhp; //把起始页面挂载到所属的bafhlst_t结构中 list_add(&amp;freemstat-&gt;md_list, &amp;bafhp-&gt;af_frelst); //增加bafhlst_t结构的空闲页面对象和总的页面对象的计数 bafhp-&gt;af_fobjnr++; bafhp-&gt;af_mobjnr++; return TRUE;&#125;bool_t mm_merpages_onbafhlst(msadsc_t *freemsa, uint_t freepgs, bafhlst_t *rel&#123; sint_t rets = 0; msadsc_t *mnxs = freemsa, *mnxe = &amp;freemsa[freepgs - 1]; bafhlst_t *tmpbf = relbf; //从实际要开始遍历,直到最高的那个bafhlst_t结构 for (; tmpbf &lt; merbf; tmpbf++) &#123; //查看最大地址连续、且空闲msadsc_t结构,如释放的是第0个msadsc_t结构我们就去查找第 rets = mm_find_cmsa2blk(tmpbf, &amp;mnxs, &amp;mnxe); if (1 == rets) &#123; break; &#125; &#125; //把合并的msadsc_t结构（从mnxs到mnxe）加入到对应的bafhlst_t结构中 if (mpobf_add_msadsc(tmpbf, mnxs, mnxe) == FALSE) &#123; return FALSE; &#125; return TRUE;&#125; 6.4 如何管理内存对象 物理内存页面管理器一次分配至少一个页面,而对内存分页事一个页面4KB,即4096字节 对于小于一个页面的内存分配请求无能为力,故需要实现小于一个页面的内存请求分配 malloc的启发 12345678910111213141516171819202122// 分配一块15字节大小的内存空间// 然后把字符串复制到分配的内存空间中// 最后用字符串的形式打印那个块内存,并释放该内存空间#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;int main() &#123; char *str; // 内存分配 存放15个char字符类型 str = (char *) malloc(15); if (str == NULL) &#123; printf(&quot;mem alloc err\\n&quot;); return -1; &#125; // 把hello world字符串复制到str开始的内存地址空间中 strcpy(str, &quot;hello world&quot;); // 打印hello world字符串和它的地址 printf(&quot;String = %s, Address = %u\\n&quot;, str, str); // 释放分配的内存 free(str); return(0);&#125; 对页进行细分 从内存角度看,页最小是以字节为单位的;但从MMU角度看,内存是以页为单位的;故Cosmos的物理内存分配器以页为单位 细分页:从MMU角度页不能细分,但从软件逻辑层面页可以细分 结合历史经验和硬件特性,可以把一个页面或连续的多个页面分成32字节,64字节,128字节,256字节,512字节,1024字节,2048字节,4096字节(一个页),该小块内存称为内存对象 把一个或多个内存页面分配出来,作为一个内存对象的容器,在这个容器中容纳相同的内存对象,即同等大小的内存块 内存对象容器 内存容器要占用内存页面,需要内存对象计数信息、内存对象大小信息,还要能扩展容量 设计了四个数据结构：kmsob_t 用于表示内存对象容器,kmbext_t 用于表示内存对象容器的扩展内存,msomdc_t 和 msclst_t 用于管理内存对象容器占用的物理内存页面 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 内存对象数据结构typedef struct s_FREOBJH&#123; list_h_t oh_list; //链表 uint_t oh_stus; //对象状态 void* oh_stat; //对象的开始地址&#125;freobjh_t;//管理内存对象容器占用的内存页面所对应的msadsc_t结构typedef struct s_MSCLST&#123; uint_t ml_msanr; //多少个msadsc_t uint_t ml_ompnr; //一个msadsc_t对应的连续的物理内存页面数 list_h_t ml_list; //挂载msadsc_t的链表&#125;msclst_t;//管理内存对象容器占用的内存typedef struct s_MSOMDC&#123; //msclst_t结构数组mc_lst[0]=1个连续页面的msadsc_t // mc_lst[1]=2个连续页面的msadsc_t // mc_lst[2]=4个连续页面的msadsc_t // mc_lst[3]=8个连续页面的msadsc_t // mc_lst[4]=16个连续页面的msadsc_t msclst_t mc_lst[MSCLST_MAX]; uint_t mc_msanr; //总共多个msadsc_t结构 list_h_t mc_list; //内存对象容器第一个占用msadsc_t list_h_t mc_kmobinlst; //内存对象容器第一个占用msadsc_t对应的连续的物理内存页面数 uint_t mc_kmobinpnr;&#125;msomdc_t;//管理内存对象容器扩展容量typedef struct s_KMBEXT&#123; list_h_t mt_list; //链表 adr_t mt_vstat; //内存对象容器扩展容量开始地址 adr_t mt_vend; //内存对象容器扩展容量结束地址 kmsob_t* mt_kmsb; //指向内存对象容器结构 uint_t mt_mobjnr; //内存对象容器扩展容量的内存中有多少对象&#125;kmbext_t;//内存对象容器typedef struct s_KMSOB&#123; list_h_t so_list; //链表 spinlock_t so_lock; //保护结构自身的自旋锁 uint_t so_stus; //状态与标志 uint_t so_flgs; adr_t so_vstat; //内存对象容器的开始地址 adr_t so_vend; //内存对象容器的结束地址 size_t so_objsz; //内存对象大小 size_t so_objrelsz; //内存对象实际大小 uint_t so_mobjnr; //内存对象容器中总共的对象个数 uint_t so_fobjnr; //内存对象容器中空闲的对象个数 list_h_t so_frelst; //内存对象容器中空闲的对象链表头 list_h_t so_alclst; //内存对象容器中分配的对象链表头 list_h_t so_mextlst; //内存对象容器扩展kmbext_t结构链表头 uint_t so_mextnr; //内存对象容器扩展kmbext_t结构个数 msomdc_t so_mc; //内存对象容器占用内存页面管理结构 void* so_privp; //本结构私有数据指针 void* so_extdp; //本结构扩展数据指针&#125;kmsob_t; 初始化 kmsob_t,kmbext_t,freobjh_t结构的实例变量是建立内存对象容器时创建并初始化的,该过程伴随着分配内存对象而进行,故内存对象管理器的初始化很简单 管理 kmsob_t 结构的数据结构,用于挂载不同大小的内存容器 init_kmsob函数调用 kmsobmgrhed_t_init 函数,在其中循环初始化 koblst_t 结构体数组 kmsobmgrhed_t 结构的实例变量放在 memmgrob_t结构中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// 在 cosmos/hal/x86/kmsob.c文件实现kmsob_t数据结构并初始化#define KOBLST_MAX (64)//挂载kmsob_t结构typedef struct s_KOBLST&#123; list_h_t ol_emplst; //挂载kmsob_t结构的链表 kmsob_t* ol_cahe; //最近一次查找的kmsob_t结构 uint_t ol_emnr; //挂载kmsob_t结构的数量 size_t ol_sz; //kmsob_t结构中内存对象的大小&#125;koblst_t;//管理kmsob_t结构的数据结构typedef struct s_KMSOBMGRHED&#123; spinlock_t ks_lock; //保护自身的自旋锁 list_h_t ks_tclst; //链表 uint_t ks_tcnr; uint_t ks_msobnr; //总共多少个kmsob_t结构 kmsob_t* ks_msobche; //最近分配内存对象的kmsob_t结构 koblst_t ks_msoblst[KOBLST_MAX]; //koblst_t结构数组&#125;kmsobmgrhed_t;//初始化koblst_t结构体void koblst_t_init(koblst_t *initp, size_t koblsz)&#123; list_init(&amp;initp-&gt;ol_emplst); initp-&gt;ol_cahe = NULL; initp-&gt;ol_emnr = 0; initp-&gt;ol_sz = koblsz; return;&#125;//初始化kmsobmgrhed_t结构体void kmsobmgrhed_t_init(kmsobmgrhed_t *initp)&#123; size_t koblsz = 32; knl_spinlock_init(&amp;initp-&gt;ks_lock); list_init(&amp;initp-&gt;ks_tclst); initp-&gt;ks_tcnr = 0; initp-&gt;ks_msobnr = 0; initp-&gt;ks_msobche = NULL; for (uint_t i = 0; i &lt; KOBLST_MAX; i++) &#123; koblst_t_init(&amp;initp-&gt;ks_msoblst[i], koblsz); koblsz += 32;//这里并不是按照开始的图形分类的而是每次增加32字节,所以是32,64,96 &#125; return;&#125;//初始化kmsobvoid init_kmsob()&#123; kmsobmgrhed_t_init(&amp;memmgrob.mo_kmsobmgr); return;&#125;// 实现 memmgrob_t//cosmos/include/halinc/halglobal.cHAL_DEFGLOB_VARIABLE(memmgrob_t,memmgrob);typedef struct s_MEMMGROB&#123; list_h_t mo_list; spinlock_t mo_lock; uint_t mo_stus; uint_t mo_flgs; //略去很多字段 //管理kmsob_t结构的数据结构 kmsobmgrhed_t mo_kmsobmgr; void* mo_privp; void* mo_extp;&#125;memmgrob_t;//cosmos/hal/x86/memmgrinit.cvoid init_memmgr()&#123; //初始化内存页结构 init_msadsc(); //初始化内存区结构 init_memarea(); //处理内存占用 init_search_krloccupymm(&amp;kmachbsp); //合并内存页到内存区中 init_memmgrob(); //初始化kmsob init_kmsob(); return;&#125; 分配内存对象 初始化了 kmsobmgrhed_t 结构,但没有初始化任何 kmsob_t 结构(存放内存对象的容器) 如何查找,建立 kmsob_t结构,然后再 kmsob_t结构中建立 freobjh_t 结构,最后在内存对象容器的容量不足时扩展容器的内存 分配内存对象的接口 只有一个内存对象大小的参数,然后返回内存对象的首地址 该接口函数的实现较为简单:只是对分配内存对象的大小进行检查,然后调用分配内存对象的核心函数,围绕之前的数据结构进行操作 查找内存对象容器 内存对象容器数据结构 kmsob_t 挂载在 kmsobmgrhed_t 数据结构中的 ks_msoblst 数组中,需要遍历 ks_msoblst 数组 编写 onmsz_retn_koblst 函数,返回 ks_msoblst 数组元素的指针,表示根据内存对象的大小找到挂载 kmsob_t 结构对应的 koblst_t 结构 通过 onmsz_retn_koblst 函数根据内存对象大小查找并返回 ks_msoblst 数组元素的指针,该数组元素中就挂载着相应的内存对象容器,然后由onkoblst_retn_newkmsob 函数查询其中的内存对象容器并返回 建立内存对象容器 第一次分配内存对象时,调用 onkoblst_retn_newkmsob 函数肯定会返回一个NULL,需要在这时建立一个 kmsob_t结构,即建立内存对象容器 _create_kmsob 函数根据分配内存对象大小,建立 kmsob_t 结构的内存对象容器,并完成一些初始化工作 首先,函数会找物理内存页面管理器申请一块连续内存页面 然后,在其中的开始部分建立 kmsob_t 结构的实例变量,又在 kmsob_t 结构的后面建立 freobjh_t 结构数组,并把每个 freobjh_t 结构挂载到 kmsob_t 结构体中的 so_frelst 中 最后再把 kmsob_t 结构,挂载到 kmsobmgrhed_t 结构对应的 koblst_t 结构中去 扩容内存对象容器 分配另一块连续的内存空间,作为空闲的内存对象,并把这块内存空间加内存对象容器中统一管理 分配内存对象 核心操作是 kmsob_new_opkmsob 函数从空闲内存对象链表头中取出第一个内存对象,返回它的首地址 高效,无论内存对象容器中的内存对象有多少,kmsob_new_opkmsob 函数的操作始终是固定的,而如此高效的算法得益于先进的数据结构设计 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327// 在kmsob.c中实现该分配内存对象的接口函数//分配内存对象的核心函数void *kmsob_new_core(size_t msz)&#123; //获取kmsobmgrhed_t结构的地址 kmsobmgrhed_t *kmobmgrp = &amp;memmgrob.mo_kmsobmgr; void *retptr = NULL; koblst_t *koblp = NULL; kmsob_t *kmsp = NULL; cpuflg_t cpuflg; //对kmsobmgrhed_t结构加锁 knl_spinlock_cli(&amp;kmobmgrp-&gt;ks_lock, &amp;cpuflg); koblp = onmsz_retn_koblst(kmobmgrp, msz); if (NULL == koblp) &#123; retptr = NULL; goto ret_step; &#125; kmsp = onkoblst_retn_newkmsob(koblp, msz); if (NULL == kmsp) &#123; kmsp = _create_kmsob(kmobmgrp, koblp, koblp-&gt;ol_sz); if (NULL == kmsp) &#123; retptr = NULL; goto ret_step; &#125; &#125; retptr = kmsob_new_onkmsob(kmsp, msz); if (NULL == retptr) &#123; retptr = NULL; goto ret_step; &#125; //更新kmsobmgrhed_t结构的信息 kmsob_updata_cache(kmobmgrp, koblp, kmsp, KUC_NEWFLG); ret_step: //解锁kmsobmgrhed_t结构 knl_spinunlock_sti(&amp;kmobmgrp-&gt;ks_lock, &amp;cpuflg); return retptr;&#125;//内存对象分配接口void *kmsob_new(size_t msz)&#123; //对于小于1 或者 大于2048字节的大小不支持 直接返回NULL表示失败 if (1 &gt; msz || 2048 &lt; msz) &#123; return NULL; &#125; //调用核心函数 return kmsob_new_core(msz);&#125;// --------------------// 查找内存对象容器// --------------------//看看内存对象容器是不是合乎要求kmsob_t *scan_newkmsob_isok(kmsob_t *kmsp, size_t msz)&#123; //只要内存对象大小小于等于内存对象容器的对象大小就行 if (msz &lt;= kmsp-&gt;so_objsz) &#123; return kmsp; &#125; return NULL;&#125;koblst_t *onmsz_retn_koblst(kmsobmgrhed_t *kmmgrhlokp, size_t msz)&#123; //遍历ks_msoblst数组 for (uint_t kli = 0; kli &lt; KOBLST_MAX; kli++) &#123; //只要大小合适就返回 if (kmmgrhlokp-&gt;ks_msoblst[kli].ol_sz &gt;= msz) &#123; return &amp;kmmgrhlokp-&gt;ks_msoblst[kli]; &#125; &#125; return NULL;&#125;kmsob_t *onkoblst_retn_newkmsob(koblst_t *koblp, size_t msz)&#123; kmsob_t *kmsp = NULL, *tkmsp = NULL; list_h_t *tmplst = NULL; //先看看上次分配所用到的koblst_t是不是正好是这次需要的 kmsp = scan_newkmsob_isok(koblp-&gt;ol_cahe, msz); if (NULL != kmsp) &#123; return kmsp; &#125; //如果koblst_t中挂载的kmsob_t大于0 if (0 &lt; koblp-&gt;ol_emnr) &#123; //开始遍历koblst_t中挂载的kmsob_t list_for_each(tmplst, &amp;koblp-&gt;ol_emplst) &#123; tkmsp = list_entry(tmplst, kmsob_t, so_list); //检查当前kmsob_t是否合乎要求 kmsp = scan_newkmsob_isok(tkmsp, msz); if (NULL != kmsp) &#123; return kmsp; &#125; &#125; &#125; return NULL;&#125;// ---------------// 建立内存对象容器// ---------------//初始化内存对象数据结构void freobjh_t_init(freobjh_t *initp, uint_t stus, void *stat)&#123; list_init(&amp;initp-&gt;oh_list); initp-&gt;oh_stus = stus; initp-&gt;oh_stat = stat; return;&#125;//初始化内存对象容器数据结构void kmsob_t_init(kmsob_t *initp)&#123; list_init(&amp;initp-&gt;so_list); knl_spinlock_init(&amp;initp-&gt;so_lock); initp-&gt;so_stus = 0; initp-&gt;so_flgs = 0; initp-&gt;so_vstat = NULL; initp-&gt;so_vend = NULL; initp-&gt;so_objsz = 0; initp-&gt;so_objrelsz = 0; initp-&gt;so_mobjnr = 0; initp-&gt;so_fobjnr = 0; list_init(&amp;initp-&gt;so_frelst); list_init(&amp;initp-&gt;so_alclst); list_init(&amp;initp-&gt;so_mextlst); initp-&gt;so_mextnr = 0; msomdc_t_init(&amp;initp-&gt;so_mc); initp-&gt;so_privp = NULL; initp-&gt;so_extdp = NULL; return;&#125;//把内存对象容器数据结构,挂载到对应的koblst_t结构中去bool_t kmsob_add_koblst(koblst_t *koblp, kmsob_t *kmsp)&#123; list_add(&amp;kmsp-&gt;so_list, &amp;koblp-&gt;ol_emplst); koblp-&gt;ol_emnr++; return TRUE;&#125;//初始化内存对象容器kmsob_t *_create_init_kmsob(kmsob_t *kmsp, size_t objsz, adr_t cvadrs, adr_t c&#123; //初始化kmsob结构体 kmsob_t_init(kmsp); //设置内存对象容器的开始、结束地址,内存对象大小 kmsp-&gt;so_vstat = cvadrs; kmsp-&gt;so_vend = cvadre; kmsp-&gt;so_objsz = objsz; //把物理内存页面对应的msadsc_t结构加入到kmsob_t中的so_mc.mc_kmobinlst链表上 list_add(&amp;msa-&gt;md_list, &amp;kmsp-&gt;so_mc.mc_kmobinlst); kmsp-&gt;so_mc.mc_kmobinpnr = (uint_t)relpnr; //设置内存对象的开始地址为kmsob_t结构之后,结束地址为内存对象容器的结束地址 freobjh_t *fohstat = (freobjh_t *)(kmsp + 1), *fohend = (freobjh_t *)cvadr uint_t ap = (uint_t)((uint_t)fohstat); freobjh_t *tmpfoh = (freobjh_t *)((uint_t)ap); for (; tmpfoh &lt; fohend;) &#123;//相当在kmsob_t结构体之后建立一个freobjh_t结构体数组 if ((ap + (uint_t)kmsp-&gt;so_objsz) &lt;= (uint_t)cvadre) &#123;//初始化每个freobjh_t结构体 freobjh_t_init(tmpfoh, 0, (void *)tmpfoh); //把每个freobjh_t结构体加入到kmsob_t结构体中的so_frelst中 list_add(&amp;tmpfoh-&gt;oh_list, &amp;kmsp-&gt;so_frelst); kmsp-&gt;so_mobjnr++; kmsp-&gt;so_fobjnr++; &#125; ap += (uint_t)kmsp-&gt;so_objsz; tmpfoh = (freobjh_t *)((uint_t)ap); &#125; return kmsp;&#125;//建立一个内存对象容器kmsob_t *_create_kmsob(kmsobmgrhed_t *kmmgrlokp, koblst_t *koblp, size_t objsz&#123; kmsob_t *kmsp = NULL; msadsc_t *msa = NULL; uint_t relpnr = 0; uint_t pages = 1; if (128 &lt; objsz) &#123; pages = 2; &#125; if (512 &lt; objsz) &#123; pages = 4; &#125; //为内存对象容器分配物理内存空间,这是我们之前实现的物理内存页面管理器 msa = mm_division_pages(&amp;memmgrob, pages, &amp;relpnr, MA_TYPE_KRNL, DMF_RELDI if (NULL == msa) &#123; return NULL; &#125; u64_t phyadr = msa-&gt;md_phyadrs.paf_padrs &lt;&lt; PSHRSIZE; u64_t phyade = phyadr + (relpnr &lt;&lt; PSHRSIZE) - 1; //计算它们的虚拟地址 adr_t vadrs = phyadr_to_viradr((adr_t)phyadr); adr_t vadre = phyadr_to_viradr((adr_t)phyade); //初始化kmsob_t并建立内存对象 kmsp = _create_init_kmsob((kmsob_t *)vadrs, koblp-&gt;ol_sz, vadrs, vadre, ms //把kmsob_t结构,挂载到对应的koblst_t结构中去 if (kmsob_add_koblst(koblp, kmsp) == FALSE) &#123; system_error(&quot; _create_kmsob kmsob_add_koblst FALSE\\n&quot;); &#125; //增加计数 kmmgrlokp-&gt;ks_msobnr++; return kmsp;&#125;// --------------// 扩容内存对象容器// --------------//初始化kmbext_t结构void kmbext_t_init(kmbext_t *initp, adr_t vstat, adr_t vend, kmsob_t *kmsp)&#123; list_init(&amp;initp-&gt;mt_list); initp-&gt;mt_vstat = vstat; initp-&gt;mt_vend = vend; initp-&gt;mt_kmsb = kmsp; initp-&gt;mt_mobjnr = 0; return;&#125;//扩展内存页面bool_t kmsob_extn_pages(kmsob_t *kmsp)&#123; msadsc_t *msa = NULL; uint_t relpnr = 0; uint_t pages = 1; if (128 &lt; kmsp-&gt;so_objsz) &#123; pages = 2; &#125; if (512 &lt; kmsp-&gt;so_objsz) &#123; pages = 4; &#125; //找物理内存页面管理器分配2或者4个连续的页面 msa = mm_division_pages(&amp;memmgrob, pages, &amp;relpnr, MA_TYPE_KRNL, DMF_RELDI if (NULL == msa) &#123; return FALSE; &#125; u64_t phyadr = msa-&gt;md_phyadrs.paf_padrs &lt;&lt; PSHRSIZE; u64_t phyade = phyadr + (relpnr &lt;&lt; PSHRSIZE) - 1; adr_t vadrs = phyadr_to_viradr((adr_t)phyadr); adr_t vadre = phyadr_to_viradr((adr_t)phyade); //求出物理内存页面数对应在kmsob_t的so_mc.mc_lst数组中下标 sint_t mscidx = retn_mscidx(relpnr); //把物理内存页面对应的msadsc_t结构加入到kmsob_t的so_mc.mc_lst数组中 list_add(&amp;msa-&gt;md_list, &amp;kmsp-&gt;so_mc.mc_lst[mscidx].ml_list); kmsp-&gt;so_mc.mc_lst[mscidx].ml_msanr++; kmbext_t *bextp = (kmbext_t *)vadrs; //初始化kmbext_t数据结构 kmbext_t_init(bextp, vadrs, vadre, kmsp); //设置内存对象的开始地址为kmbext_t结构之后,结束地址为扩展内存页面的结束地址 freobjh_t *fohstat = (freobjh_t *)(bextp + 1), *fohend = (freobjh_t *)vadr uint_t ap = (uint_t)((uint_t)fohstat); freobjh_t *tmpfoh = (freobjh_t *)((uint_t)ap); for (; tmpfoh &lt; fohend;) &#123; if ((ap + (uint_t)kmsp-&gt;so_objsz) &lt;= (uint_t)vadre) &#123;//在扩展的内存空间中建立内存对象 freobjh_t_init(tmpfoh, 0, (void *)tmpfoh); list_add(&amp;tmpfoh-&gt;oh_list, &amp;kmsp-&gt;so_frelst); kmsp-&gt;so_mobjnr++; kmsp-&gt;so_fobjnr++; bextp-&gt;mt_mobjnr++; &#125; ap += (uint_t)kmsp-&gt;so_objsz; tmpfoh = (freobjh_t *)((uint_t)ap); &#125; list_add(&amp;bextp-&gt;mt_list, &amp;kmsp-&gt;so_mextlst); kmsp-&gt;so_mextnr++; return TRUE;&#125;// ------------// 分配内存对象// ------------//判断内存对象容器中有没有内存对象uint_t scan_kmob_objnr(kmsob_t *kmsp)&#123; if (0 &lt; kmsp-&gt;so_fobjnr) &#123; return kmsp-&gt;so_fobjnr; &#125; return 0;&#125;//实际分配内存对象void *kmsob_new_opkmsob(kmsob_t *kmsp, size_t msz)&#123; //获取kmsob_t中的so_frelst链表头的第一个空闲内存对象 freobjh_t *fobh = list_entry(kmsp-&gt;so_frelst.next, freobjh_t, oh_list); //从链表中脱链 list_del(&amp;fobh-&gt;oh_list); //kmsob_t中的空闲对象计数减一 kmsp-&gt;so_fobjnr--; //返回内存对象首地址 return (void *)(fobh);&#125;void *kmsob_new_onkmsob(kmsob_t *kmsp, size_t msz)&#123; void *retptr = NULL; cpuflg_t cpuflg; knl_spinlock_cli(&amp;kmsp-&gt;so_lock, &amp;cpuflg); //如果内存对象容器中没有空闲的内存对象了就需要扩展内存对象容器的内存了 if (scan_kmsob_objnr(kmsp) &lt; 1) &#123;//扩展内存对象容器的内存 if (kmsob_extn_pages(kmsp) == FALSE) &#123; retptr = NULL; goto ret_step; &#125; &#125; //实际分配内存对象 retptr = kmsob_new_opkmsob(kmsp, msz); ret_step: knl_spinunlock_sti(&amp;kmsp-&gt;so_lock, &amp;cpuflg); return retptr;&#125; 释放内存对象 释放内存对象就是把内存对象归还给它所属的内容对象容器,其逻辑就是释放内存对象的地址和大小,找到对应的内存对象容器,然后把该内存对象假如到对应内存对象容器的空闲链表上,最后看是否要释放内存对象容器占用的物理内存页面 释放内存对象的接口 在 kmsob.c中实现释放内存对象的接口函数 等到 kmsob_delete 函数检查参数通过后,调用释放内存对象的核心函数 kmsob_delete_core kmsob_delete_core 函数中,一开始根据释放内存对象大小,找到挂载其kmsob_t 结构的 koblst_t 结构,接着进行一系列的操作 查找内存对象容器 查找将要释放的内存对象所属的内存对象容器,释放时的查找和分配时的查找不一样,需要检查释放的内存对象是否属于该内存对象容器 搜索对应 koblst_t 结构中的每个 kmsob_t 结构体,随后进行检查,检查了 kmsob_t 结构的自身内存区域和扩展内存区域.即比较释放内存对象的地址是不是落在它们的内存区间中,其大小是否合乎要求 释放内存对象 找到释放内存对象的 kmsob_t 结构就可以释放内存对象,将这块内存空间还给内存对象容器 kmsob_delete_onkmsob 函数调用kmsob_del_opkmsob 函数,其核心机制就是把要释放内存对象的空间,重新初始化,变成一个freobjh_t结构的实例变量,最后将这个freobjh_t结构加入到 kmsob_t 结构中空闲链表中,就实现了内存对象的释放 销毁内存对象容器 频繁请求不同大小的内存对象,空的内存对象容器会越来越多,会占用大量内存,所以必须要把空的内存对象容器销毁 首先会检查一下内存对象容器是不是空闲的,如果空闲,就调用销毁内存对象容器的核心函数destroy_kmsob_core 在 _destroy_kmsob_core 函数中 首先要释放内存对象容器的扩展空间所占用的物理内存页面 最后才可以释放内存对象容器自身占用物理内存页面 顺序不能颠倒,因为扩展空间的物理内存页面对应的 msadsc_t 结构就挂载在 kmsob_t 结构的 so_mc.mc_lst 数组中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218// ----------------// 释放内存对象的接口// ----------------bool_t kmsob_delete_core(void *fadrs, size_t fsz)&#123; kmsobmgrhed_t *kmobmgrp = &amp;memmgrob.mo_kmsobmgr; bool_t rets = FALSE; koblst_t *koblp = NULL; kmsob_t *kmsp = NULL; cpuflg_t cpuflg; knl_spinlock_cli(&amp;kmobmgrp-&gt;ks_lock, &amp;cpuflg); //根据释放内存对象的大小在kmsobmgrhed_t中查找并返回koblst_t,在其中挂载着对应的kmsob koblp = onmsz_retn_koblst(kmobmgrp, fsz); if (NULL == koblp) &#123; rets = FALSE; goto ret_step; &#125; kmsp = onkoblst_retn_delkmsob(koblp, fadrs, fsz); if (NULL == kmsp) &#123; rets = FALSE; goto ret_step; &#125; rets = kmsob_delete_onkmsob(kmsp, fadrs, fsz); if (FALSE == rets) &#123; rets = FALSE; goto ret_step; &#125; if (_destroy_kmsob(kmobmgrp, koblp, kmsp) == FALSE) &#123; rets = FALSE; goto ret_step; &#125; rets = TRUE; ret_step: knl_spinunlock_sti(&amp;kmobmgrp-&gt;ks_lock, &amp;cpuflg); return rets;&#125;//释放内存对象接口bool_t kmsob_delete(void *fadrs, size_t fsz)&#123; //对参数进行检查,但是多了对内存对象地址的检查 if (NULL == fadrs || 1 &gt; fsz || 2048 &lt; fsz) &#123; return FALSE; &#125; //调用释放内存对象的核心函数 return kmsob_delete_core(fadrs, fsz);&#125;// ---------------// 查找内存对象容器// ---------------//检查释放的内存对象是不是在kmsob_t结构中kmsob_t *scan_delkmsob_isok(kmsob_t *kmsp, void *fadrs, size_t fsz)&#123;//检查释放内存对象的地址是否落在kmsob_t结构的地址区间 if ((adr_t)fadrs &gt;= (kmsp-&gt;so_vstat + sizeof(kmsob_t)) &amp;&amp; ((adr_t)fadrs + &#123; //检查释放内存对象的大小是否小于等于kmsob_t内存对象容器的对象大小 if (fsz &lt;= kmsp-&gt;so_objsz) &#123; return kmsp; &#125; &#125; if (1 &gt; kmsp-&gt;so_mextnr) &#123;//如果kmsob_t结构没有扩展空间,直接返回 return NULL; &#125; kmbext_t *bexp = NULL; list_h_t *tmplst = NULL; //遍历kmsob_t结构中的每个扩展空间 list_for_each(tmplst, &amp;kmsp-&gt;so_mextlst) &#123; bexp = list_entry(tmplst, kmbext_t, mt_list); //检查释放内存对象的地址是否落在扩展空间的地址区间 if ((adr_t)fadrs &gt;= (bexp-&gt;mt_vstat + sizeof(kmbext_t)) &amp;&amp; ((adr_t)fad &#123;//同样的要检查大小 if (fsz &lt;= kmsp-&gt;so_objsz) &#123; return kmsp; &#125; &#125; &#125; return NULL;&#125;//查找释放内存对象所属的kmsob_t结构kmsob_t *onkoblst_retn_delkmsob(koblst_t *koblp, void *fadrs, size_t fsz)&#123; v *kmsp = NULL, *tkmsp = NULL; list_h_t *tmplst = NULL; //看看上次刚刚操作的kmsob_t结构 kmsp = scan_delkmsob_isok(koblp-&gt;ol_cahe, fadrs, fsz); if (NULL != kmsp) &#123; return kmsp; &#125; if (0 &lt; koblp-&gt;ol_emnr) &#123; //遍历挂载koblp-&gt;ol_emplst链表上的每个kmsob_t结构 list_for_each(tmplst, &amp;koblp-&gt;ol_emplst) &#123; tkmsp = list_entry(tmplst, kmsob_t, so_list); //检查释放的内存对象是不是属于这个kmsob_t结构 kmsp = scan_delkmsob_isok(tkmsp, fadrs, fsz); if (NULL != kmsp) &#123; return kmsp; &#125; &#125; &#125; return NULL;&#125;// -----------// 释放内存对象// -----------bool_t kmsob_del_opkmsob(kmsob_t *kmsp, void *fadrs, size_t fsz)&#123; if ((kmsp-&gt;so_fobjnr + 1) &gt; kmsp-&gt;so_mobjnr) &#123; return FALSE; &#125; //让freobjh_t结构重新指向要释放的内存空间 freobjh_t *obhp = (freobjh_t *)fadrs; //重新初始化块内存空间 freobjh_t_init(obhp, 0, obhp); //加入kmsob_t结构的空闲链表 list_add(&amp;obhp-&gt;oh_list, &amp;kmsp-&gt;so_frelst); //kmsob_t结构的空闲对象计数加一 kmsp-&gt;so_fobjnr++; return TRUE;&#125;//释放内存对象bool_t kmsob_delete_onkmsob(kmsob_t *kmsp, void *fadrs, size_t fsz)&#123; bool_t rets = FALSE; cpuflg_t cpuflg; //对kmsob_t结构加锁 knl_spinlock_cli(&amp;kmsp-&gt;so_lock, &amp;cpuflg); //实际完成内存对象释放 if (kmsob_del_opkmsob(kmsp, fadrs, fsz) == FALSE) &#123; rets = FALSE; goto ret_step; &#125; rets = TRUE; ret_step: //对kmsob_t结构解锁 knl_spinunlock_sti(&amp;kmsp-&gt;so_lock, &amp;cpuflg); return rets;&#125;// ---------------// 销毁内存对象容器// ---------------uint_t scan_freekmsob_isok(kmsob_t *kmsp)&#123; //当内存对象容器的总对象个数等于空闲对象个数时,说明这内存对象容器空闲 if (kmsp-&gt;so_mobjnr == kmsp-&gt;so_fobjnr) &#123; return 2; &#125; return 1;&#125;bool_t _destroy_kmsob_core(kmsobmgrhed_t *kmobmgrp, koblst_t *koblp, kmsob_t *&#123; list_h_t *tmplst = NULL; msadsc_t *msa = NULL; msclst_t *mscp = kmsp-&gt;so_mc.mc_lst; list_del(&amp;kmsp-&gt;so_list); koblp-&gt;ol_emnr--; kmobmgrp-&gt;ks_msobnr--; //释放内存对象容器扩展空间的物理内存页面 //遍历kmsob_t结构中的so_mc.mc_lst数组 for (uint_t j = 0; j &lt; MSCLST_MAX; j++) &#123; if (0 &lt; mscp[j].ml_msanr) &#123;//遍历每个so_mc.mc_lst数组中的msadsc_t结构 list_for_each_head_dell(tmplst, &amp;mscp[j].ml_list) &#123; msa = list_entry(tmplst, msadsc_t, md_list); list_del(&amp;msa-&gt;md_list); //msadsc_t脱链 //释放msadsc_t对应的物理内存页面 if (mm_merge_pages(&amp;memmgrob, msa, (uint_t)mscp[j].ml_ompnr) = &#123; system_error(&quot;_destroy_kmsob_core mm_merge_pages FALSE2\\n&quot; &#125; &#125; &#125; &#125; //释放内存对象容器本身占用的物理内存页面 //遍历每个so_mc.mc_kmobinlst中的msadsc_t结构.它只会遍历一次 list_for_each_head_dell(tmplst, &amp;kmsp-&gt;so_mc.mc_kmobinlst) &#123; msa = list_entry(tmplst, msadsc_t, md_list); list_del(&amp;msa-&gt;md_list); //msadsc_t脱链 //释放msadsc_t对应的物理内存页面 if (mm_merge_pages(&amp;memmgrob, msa, (uint_t)kmsp-&gt;so_mc.mc_kmobinpnr) = &#123; system_error(&quot;_destroy_kmsob_core mm_merge_pages FALSE2\\n&quot;); &#125; &#125; return TRUE;&#125;//```销毁内存对象容器bool_t _destroy_kmsob(kmsobmgrhed_t *kmobmgrp, koblst_t *koblp, kmsob_t *kmsp)&#123; //看看能不能销毁 uint_t screts = scan_freekmsob_isok(kmsp); if (2 == screts) &#123;//调用销毁内存对象容器的核心函数 return _destroy_kmsob_core(kmobmgrp, koblp, kmsp); &#125; return FALSE;&#125; 6.5 如何表示虚拟内存 虚拟地址空间的划分 虚拟地址是逻辑上的一个数值,而虚拟地址空间是一堆数值的集合 通常情况下,32位的处理器0~0xFFFFFFFF的虚拟地址空间,而64位的虚拟地址空间则更大 64位的虚拟地址空间则为0~0xFFFFFFFFFFFFFFFF 需要一定的安排和设计,比如什么虚拟地址段放应用,什么虚拟地址段放内核等 x86CPU如何划分虚拟地址空间 cosmos工作在x86CPU上,x86CPU是如何划分虚拟地址空间 由于x86CPU支持虚拟地址空间时,要么开启保护模式,要么开启长模式 保护模式下是32位的,有0~0xFFFFFFFF个地址,可以使用完整的4GB虚拟地址空间,且没有任何划分 长模式是64位虚拟地址空间有0~0xFFFFFFFFFFFFFFFF个地址,地址空间巨大,将它分为了3段 长模式下,CPU目前只实现了48位地址空间,但寄存器却是64位的,CPU自己用地址数据的第47位的值扩展到最高16位,所以64位地址数据的最高16位,要么全0,要么全1 cosmos如何划分虚拟地址空间 cosmos对x86CPU长模式下虚拟地址空间的使用,在长模式下,整个虚拟地址空间只有两段可以用,0xFFFF8000000000000xFFFFFFFFFFFFFFFF分配给内核(内核空间),00x00007FFFFFFFFFFF给应用(应用空间) 应用程序在链接时,会将各个模块的指令和数据分别放在仪器,栈是在最顶端向下增长,堆是在应用程序数据区的后面,向上增长 内核空间中有线性映射区0xFFFF800000000000～0xFFFF800400000000为在二级引导器中建立的MMU页表映射 如何设计数据结构 需要实现一个功能模块,首先要设计出相应的数据结构,虚拟内存模块也需要设计相应的数据结构 虚拟地址空间 由于虚拟地址空间巨大,且虚拟地址空间是以区为单位的,区内部连续,区之间间隔较大空间且每个区扩大时不会建立新的虚拟地址区间数据结构,而是改变其中的指针(节约了内存空间) 数据结构最重要的是虚拟地址的开始与结束字段,精确描述了一段虚拟地址空间 整个虚拟地址空间如何描述 将许多虚拟地址区间数据结构按顺序连接起来就表示整个虚拟地址空间 进程的内存地址空间 虚拟地址空间作用域应用程序,应用程序在操作系统中用进程表示 进程的完整地址空间:包含虚拟空间信息,进程和虚拟地址到物理地址的映射信息,应用程序文件中的指令区,数据区的开始,结束地址信息 页面盒子 每段虚拟地址空间都会映射到对应的物理页面,每分配一个或一组内存页面都会返回一个 msadsc_t 结构,故还需要设计一个数据结构来挂载 msadsc_t 结构 一般虚拟地址区间和文件对应的数据相关联,常规操作就是把同一个物理内存页面映射到不同的虚拟地址区间,实现一个专用的数据结构,共享操作时就让多个 kmvarsdsc_t 结构指向它 kvmemcbox_t可以独立存在,又和虚拟内存空间有紧密的联系,甚至可以用来管理文件数据占用的物理内存页面 页面盒子的头 kvmemcbox_t独立存在,还需要一个全局的数据结构用于管理所有的 kvmemcbox_t 结构,该结构用于挂载 kvmemcbox_t 结构对其进行计数,还要支持缓存多个空闲的 kvmemcbox_t 结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// 虚拟地址空间数据结构typedef struct KMVARSDSC&#123; spinlock_t kva_lock; //保护自身自旋锁 u32_t kva_maptype; //映射类型 list_h_t kva_list; //链表 u64_t kva_flgs; //相关标志 u64_t kva_limits; void* kva_mcstruct; //指向它的上层结构 adr_t kva_start; //虚拟地址的开始 adr_t kva_end; //虚拟地址的结束 kvmemcbox_t* kva_kvmbox; //管理这个结构映射的物理页面 void* kva_kvmcobj;&#125;kmvarsdsc_t;// -----------------------// 整个虚拟地址空间的数据结构// -----------------------typedef struct s_VIRMEMADRS&#123; spinlock_t vs_lock; //保护自身的自旋锁 u32_t vs_resalin; list_h_t vs_list; //链表,链接虚拟地址区间 uint_t vs_flgs; //标志 uint_t vs_kmvdscnr; //多少个虚拟地址区间 mmadrsdsc_t* vs_mm; //指向它的上层的数据结构 kmvarsdsc_t* vs_startkmvdsc; //开始的虚拟地址区间 kmvarsdsc_t* vs_endkmvdsc; //结束的虚拟地址区间 kmvarsdsc_t* vs_currkmvdsc; //当前的虚拟地址区间 adr_t vs_isalcstart; //能分配的开始虚拟地址 adr_t vs_isalcend; //能分配的结束虚拟地址 void* vs_privte; //私有数据指针 void* vs_ext; //扩展数据指针&#125;virmemadrs_t;// -----------------------// 进程的内存地址空间// -----------------------typedef struct s_MMADRSDSC&#123; spinlock_t msd_lock; //保护自身的自旋锁 list_h_t msd_list; //链表 uint_t msd_flag; //状态和标志 uint_t msd_stus; uint_t msd_scount; //计数,该结构可能被共享 sem_t msd_sem; //信号量 mmudsc_t msd_mmu; //MMU相关的信息 virmemadrs_t msd_virmemadrs; //虚拟地址空间 adr_t msd_stext; //应用的指令区的开始、结束地址 adr_t msd_etext; adr_t msd_sdata; //应用的数据区的开始、结束地址 adr_t msd_edata; adr_t msd_sbss; adr_t msd_ebss; adr_t msd_sbrk; //应用的堆区的开始、结束地址 adr_t msd_ebrk;&#125;mmadrsdsc_t;// ------------// 页面盒子// -------------typedef struct KVMEMCBOX&#123; list_h_t kmb_list; //链表 spinlock_t kmb_lock; //保护自身的自旋锁 refcount_t kmb_cont; //共享的计数器 u64_t kmb_flgs; //状态和标志 u64_t kmb_stus; u64_t kmb_type; //类型 uint_t kmb_msanr; //多少个msadsc_t list_h_t kmb_msalist; //挂载msadsc_t结构的链表 kvmemcboxmgr_t* kmb_mgr; //指向上层结构 void* kmb_filenode; //指向文件节点描述符 void* kmb_pager; //指向分页器 暂时不使用 void* kmb_ext; //自身扩展数据指针&#125;kvmemcbox_t;// ----------// 页面盒子的头// ----------typedef struct KVMEMCBOXMGR&#123; list_h_t kbm_list; //链表 spinlock_t kbm_lock; //保护自身的自旋锁 u64_t kbm_flgs; //标志与状态 u64_t kbm_stus; uint_t kbm_kmbnr; //kvmemcbox_t结构个数 list_h_t kbm_kmbhead; //挂载kvmemcbox_t结构的链表 uint_t kbm_cachenr; //缓存空闲kvmemcbox_t结构的个数 uint_t kbm_cachemax; //最大缓存个数,超过了就要释放 uint_t kbm_cachemin; //最小缓存个数 list_h_t kbm_cachehead; //缓存kvmemcbox_t结构的链表 void* kbm_ext; //扩展数据指针&#125;kvmemcboxmgr_t; 理清数据结构之间的关系(从上往下,从左往右) 首先从进程的虚拟地址空间开始,而进程的虚拟地址是由 kmvarsdsc_t 结构表示的,一个 kmvarsdsc_t 结构就表示一个已经分配出去的虚拟地址空间.一个进程所有的 kmvarsdsc_t 结构,要交给进程的 mmadrsdsc_t 结构中的 virmemadrs_t 结构管理 为了管理虚拟地址空间对应的物理内存页面,建立了 kvmembox_t 结构由 kvmemcboxmgr_t 结构统一管理.在 kvmembox_t 结构中,挂载了物理内存页面对应的 msadsc_t 结构 初始化 虚拟地址空间的分配与释放依赖于进程数据结构下的 mmadrsdsc_t 数据结构,需要产生一个 mmadrsdsc_t 数据结构的实例变量,最后初始化它 init_kvirmemadrs 函数首先调用了 mmadrsdsc_t_init,对申明的变量进行初始化.因为这个变量中有链表、自旋锁、信号量这些数据结构,必须要初始化才能使用 最后调用了 kvma_inituserspace_virmemadrs 函数建立一个虚拟地址区间和一个栈区,栈区位于虚拟地址空间的顶端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// cosmos/kernel/krlglobal.c文件中声明 mmadrsdsc_t数据结构的实例变量KRL_DEFGLOB_VARIABLE(mmadrsdsc_t, initmmadrsdsc);// 初始化这个变量// /cosmos/kernel/krlvadrsmem.cbool_t kvma_inituserspace_virmemadrs(virmemadrs_t *vma)&#123;kmvarsdsc_t *kmvdc = NULL, *stackkmvdc = NULL;//分配一个kmvarsdsc_tkmvdc = new_kmvarsdsc();if (NULL == kmvdc)&#123;return FALSE;&#125;//分配一个栈区的kmvarsdsc_tstackkmvdc = new_kmvarsdsc();if (NULL == stackkmvdc)&#123;del_kmvarsdsc(kmvdc);return FALSE;&#125;//虚拟区间开始地址0x1000kmvdc-&gt;kva_start = USER_VIRTUAL_ADDRESS_START + 0x1000;//虚拟区间结束地址0x5000kmvdc-&gt;kva_end = kmvdc-&gt;kva_start + 0x4000;kmvdc-&gt;kva_mcstruct = vma;//栈虚拟区间开始地址0x1000USER_VIRTUAL_ADDRESS_END - 0x40000000stackkmvdc-&gt;kva_start = PAGE_ALIGN(USER_VIRTUAL_ADDRESS_END - 0x40000000);//栈虚拟区间结束地址0x1000USER_VIRTUAL_ADDRESS_ENDstackkmvdc-&gt;kva_end = USER_VIRTUAL_ADDRESS_END;stackkmvdc-&gt;kva_mcstruct = vma;knl_spinlock(&amp;vma-&gt;vs_lock);vma-&gt;vs_isalcstart = USER_VIRTUAL_ADDRESS_START;vma-&gt;vs_isalcend = USER_VIRTUAL_ADDRESS_END;//设置虚拟地址空间的开始区间为kmvdcvma-&gt;vs_startkmvdsc = kmvdc;//设置虚拟地址空间的开始区间为栈区vma-&gt;vs_endkmvdsc = stackkmvdc;//加入链表list_add_tail(&amp;kmvdc-&gt;kva_list, &amp;vma-&gt;vs_list);list_add_tail(&amp;stackkmvdc-&gt;kva_list, &amp;vma-&gt;vs_list);//计数加2vma-&gt;vs_kmvdscnr += 2;knl_spinunlock(&amp;vma-&gt;vs_lock);return TRUE;&#125;void init_kvirmemadrs()&#123;//初始化mmadrsdsc_t结构非常简单mmadrsdsc_t_init(&amp;initmmadrsdsc);//初始化进程的用户空间kvma_inituserspace_virmemadrs(&amp;initmmadrsdsc.msd_virmemadrs);&#125;// krlinit.c中的int_krl函数中调用void init_krl()&#123;//初始化内核功能层的内存管理init_krlmm();die(0);return;&#125;void init_krlmm()&#123;init_kvirmemadrs();return;&#125; 重点梳理 首先是虚拟地址空间的划分。由于硬件平台的物理特性，虚拟地址空间被分成了两段，Cosmos 也延续了这种划分的形式，顶端的虚拟地址空间为内核占用，底端为应用占用。内核还建立了 16GB 的线性映射区，而应用的虚拟地址空间分成了指令区，数据区，堆区，栈区 然后为了实现虚拟地址内存，设计了大量的数据结构 虚拟地址区间kmvarsdsc_t 结构 管理虚拟地址区间的虚拟地址空间 virmemadrs_t 结构 包含virmemadrs_t 结构和 mmudsc_t 结构的 mmadrsdsc_t 结构 用于挂载 msadsc_t 结构的页面盒子的 kvmemcbox_t 结构 管理所有的 kvmemcbox_t 结构的kvmemcboxmgr_t 结构 6.6 如何分配和释放虚拟内存 虚拟地址的空间的分配与释放 分配一个虚拟地址空间就是在整个虚拟地址空间分割出一个区域，释放一块虚拟地址空间就是把这个区域合并到整个虚拟地址空间中去 虚拟地址空间分配接口 分配虚拟地址空间有大小,类型,相关标志，从哪里开始分配等信息,在krlvadrsmem.c文件中设计好分配虚拟地址空间的接口 接口函数进行参数检查,然后调用核心函数完成的实际工作;核心函数中会调用 vma_find_kmvarsdsc 函数去查找 virmemadrs_t 结构中所有 kmvarsdsc_t 结构，找出合适的虚拟地址区间 分配时查找虚拟地址区间 vma_find_kmvarsdsc 函数根据分配的开始地址和大小,在 virmemadrs_t 结构中查找相应的 kmvarsdsc_t 结构,分配虚拟地址空间算法的核心 例子:virmemadrs_t 结构中有两个 kmvarsdsc_t 结构，A_kmvarsdsc_t 结构表示 0x1000～0x4000 的虚拟地址空间，B_kmvarsdsc_t 结构表示0x7000～0x9000 的虚拟地址空间;分配 2KB 的虚拟地址空间，vma_find_kmvarsdsc 函数查找发现A_kmvarsdsc_t 结构和 B_kmvarsdsc_t 结构之间正好有 0x4000～0x7000 的空间，刚好放得下 0x2000 大小的空间，于是函数就会返回 A_kmvarsdsc_t 结构，否则就会继续向后查找 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162// ------------------// 虚拟地址空间分配接口// ------------------adr_t vma_new_vadrs_core(mmadrsdsc_t *mm, adr_t start, size_t vassize, u64_t v&#123; adr_t retadrs = NULL; kmvarsdsc_t *newkmvd = NULL, *currkmvd = NULL; virmemadrs_t *vma = &amp;mm-&gt;msd_virmemadrs; knl_spinlock(&amp;vma-&gt;vs_lock); //查找虚拟地址区间 currkmvd = vma_find_kmvarsdsc(vma, start, vassize); if (NULL == currkmvd) &#123; retadrs = NULL; goto out; &#125; //进行虚拟地址区间进行检查看能否复用这个数据结构 if (((NULL == start) || (start == currkmvd-&gt;kva_end)) &amp;&amp; (vaslimits == cur &#123;//能复用的话，当前虚拟地址区间的结束地址返回 retadrs = currkmvd-&gt;kva_end; //扩展当前虚拟地址区间的结束地址为分配虚拟地址区间的大小 currkmvd-&gt;kva_end += vassize; vma-&gt;vs_currkmvdsc = currkmvd; goto out; &#125; //建立一个新的kmvarsdsc_t虚拟地址区间结构 newkmvd = new_kmvarsdsc(); if (NULL == newkmvd) &#123; retadrs = NULL; goto out; &#125; //如果分配的开始地址为NULL就由系统动态决定 if (NULL == start) &#123;//当然是接着当前虚拟地址区间之后开始 newkmvd-&gt;kva_start = currkmvd-&gt;kva_end; &#125; else &#123;//否则这个新的虚拟地址区间的开始就是请求分配的开始地址 newkmvd-&gt;kva_start = start; &#125; //设置新的虚拟地址区间的结束地址 newkmvd-&gt;kva_end = newkmvd-&gt;kva_start + vassize; newkmvd-&gt;kva_limits = vaslimits; newkmvd-&gt;kva_maptype = vastype; newkmvd-&gt;kva_mcstruct = vma; vma-&gt;vs_currkmvdsc = newkmvd; //将新的虚拟地址区间加入到virmemadrs_t结构中 list_add(&amp;newkmvd-&gt;kva_list, &amp;currkmvd-&gt;kva_list); //看看新的虚拟地址区间是否是最后一个 if (list_is_last(&amp;newkmvd-&gt;kva_list, &amp;vma-&gt;vs_list) == TRUE) &#123; vma-&gt;vs_endkmvdsc = newkmvd; &#125; //返回新的虚拟地址区间的开始地址 retadrs = newkmvd-&gt;kva_start; out: knl_spinunlock(&amp;vma-&gt;vs_lock); return retadrs;&#125;//分配虚拟地址空间的接口adr_t vma_new_vadrs(mmadrsdsc_t *mm, adr_t start, size_t vassize, u64_t vaslim&#123; if (NULL == mm || 1 &gt; vassize) &#123; return NULL; &#125; if (NULL != start) &#123;//进行参数检查，开始地址要和页面（1KB）对齐，结束地址不能超过整个虚拟地址空间 if (((start &amp; 0xfff) != 0) || (0x1000 &gt; start) || (USER_VIRTUAL_ADDRES &#123; return NULL; &#125; &#125; //调用虚拟地址空间分配的核心函数 return vma_new_vadrs_core(mm, start, VADSZ_ALIGN(vassize), vaslimits, vast&#125;// --------------------// 分配时查找虚拟地址区间// --------------------//检查kmvarsdsc_t结构kmvarsdsc_t *vma_find_kmvarsdsc_is_ok(virmemadrs_t *vmalocked, kmvarsdsc_t *cu&#123; kmvarsdsc_t *nextkmvd = NULL; adr_t newend = start + (adr_t)vassize; //如果curr不是最后一个先检查当前kmvarsdsc_t结构 if (list_is_last(&amp;curr-&gt;kva_list, &amp;vmalocked-&gt;vs_list) == FALSE) &#123;//就获取curr的下一个kmvarsdsc_t结构 nextkmvd = list_next_entry(curr, kmvarsdsc_t, kva_list); //由系统动态决定分配虚拟空间的开始地址 if (NULL == start) &#123;//如果curr的结束地址加上分配的大小小于等于下一个kmvarsdsc_t结构的开始地址就返回c if ((curr-&gt;kva_end + (adr_t)vassize) &lt;= nextkmvd-&gt;kva_start) &#123; return curr; &#125; &#125; else &#123;//否则比较应用指定分配的开始、结束地址是不是在curr和下一个kmvarsdsc_t结构之间 if ((curr-&gt;kva_end &lt;= start) &amp;&amp; (newend &lt;= nextkmvd-&gt;kva_start)) &#123; return curr; &#125; &#125; &#125; else &#123;//否则curr为最后一个kmvarsdsc_t结构 if (NULL == start) &#123;//curr的结束地址加上分配空间的大小是不是小于整个虚拟地址空间 if ((curr-&gt;kva_end + (adr_t)vassize) &lt; vmalocked-&gt;vs_isalcend) &#123; return curr; &#125; &#125; else &#123;//否则比较应用指定分配的开始、结束地址是不是在curr的结束地址和整个虚拟地址空间的结 if ((curr-&gt;kva_end &lt;= start) &amp;&amp; (newend &lt; vmalocked-&gt;vs_isalcend)) &#123; return curr; &#125; &#125; &#125; return NULL;&#125;//查找kmvarsdsc_t结构kmvarsdsc_t *vma_find_kmvarsdsc(virmemadrs_t *vmalocked, adr_t start, size_t v&#123; kmvarsdsc_t *kmvdcurrent = NULL, *curr = vmalocked-&gt;vs_currkmvdsc; adr_t newend = start + vassize; list_h_t *listpos = NULL; //分配的虚拟空间大小小于4KB不行 if (0x1000 &gt; vassize) &#123; return NULL; &#125; //将要分配虚拟地址空间的结束地址大于整个虚拟地址空间 不行 if (newend &gt; vmalocked-&gt;vs_isalcend) &#123; return NULL; &#125; if (NULL != curr) &#123;//先检查当前kmvarsdsc_t结构行不行 kmvdcurrent = vma_find_kmvarsdsc_is_ok(vmalocked, curr, start, vassize if (NULL != kmvdcurrent) &#123; return kmvdcurrent; &#125; &#125; //遍历virmemadrs_t中的所有的kmvarsdsc_t结构 list_for_each(listpos, &amp;vmalocked-&gt;vs_list) &#123; curr = list_entry(listpos, kmvarsdsc_t, kva_list); //检查每个kmvarsdsc_t结构 kmvdcurrent = vma_find_kmvarsdsc_is_ok(vmalocked, curr, start, vassize if (NULL != kmvdcurrent) &#123;//如果符合要求就返回 return kmvdcurrent; &#125; &#125; return NULL;&#125; 虚拟地址空间释放接口 只需要释放虚拟空间的开始地址和大小 分配虚拟地址空间时,为了节约 kmvarsdsc_t 结构占用的内存空间,规定只要分配的虚拟地址空间上一个虚拟地址空间是连续且类型相同的,就借用上一个 kmvarsdsc_t 结构,而不是重新分配表示新分配的虚拟地址空间(避免物理内存被很快耗尽) 释放时查找虚拟地址区间 释放时仅仅需要保证，释放的虚拟地址空间的开始地址和结束地址落在某一个 kmvarsdsc_t 结构表示的虚拟地址区间 释放时查找虚拟地址空间的函数仅仅检查释放的虚拟地址是否落在查找 kmvarsdsc_t 结构表示的虚拟地址区间中,可能的四种变换形式交给核心释放函数处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118// -----------------// 虚拟地址空间释放接口// -----------------//释放虚拟地址空间的核心函数bool_t vma_del_vadrs_core(mmadrsdsc_t *mm, adr_t start, size_t vassize)&#123; bool_t rets = FALSE; kmvarsdsc_t *newkmvd = NULL, *delkmvd = NULL; virmemadrs_t *vma = &amp;mm-&gt;msd_virmemadrs; knl_spinlock(&amp;vma-&gt;vs_lock); //查找要释放虚拟地址空间的kmvarsdsc_t结构 delkmvd = vma_del_find_kmvarsdsc(vma, start, vassize); if (NULL == delkmvd) &#123; rets = FALSE; goto out; &#125; //第一种情况要释放的虚拟地址空间正好等于查找的kmvarsdsc_t结构 if ((delkmvd-&gt;kva_start == start) &amp;&amp; (delkmvd-&gt;kva_end == (start + (adr_t) &#123; //脱链 list_del(&amp;delkmvd-&gt;kva_list); //删除kmvarsdsc_t结构 del_kmvarsdsc(delkmvd); vma-&gt;vs_kmvdscnr--; rets = TRUE; goto out; &#125; //第二种情况要释放的虚拟地址空间是在查找的kmvarsdsc_t结构的上半部分 if ((delkmvd-&gt;kva_start == start) &amp;&amp; (delkmvd-&gt;kva_end &gt; (start + (adr_t)v &#123; //所以直接把查找的kmvarsdsc_t结构的开始地址设置为释放虚拟地址空间的结束地址 delkmvd-&gt;kva_start = start + (adr_t)vassize; rets = TRUE; goto out; &#125; //第三种情况要释放的虚拟地址空间是在查找的kmvarsdsc_t结构的下半部分 if ((delkmvd-&gt;kva_start &lt; start) &amp;&amp; (delkmvd-&gt;kva_end == (start + (adr_t)v &#123;//所以直接把查找的kmvarsdsc_t结构的结束地址设置为释放虚拟地址空间的开始地址 delkmvd-&gt;kva_end = start; rets = TRUE; goto out; &#125; //第四种情况要释放的虚拟地址空间是在查找的kmvarsdsc_t结构的中间 if ((delkmvd-&gt;kva_start &lt; start) &amp;&amp; (delkmvd-&gt;kva_end &gt; (start + (adr_t)va &#123;//所以要再新建一个kmvarsdsc_t结构来处理释放虚拟地址空间之后的下半虚拟部分地址空间 newkmvd = new_kmvarsdsc(); if (NULL == newkmvd) &#123; rets = FALSE; goto out; &#125; //让新的kmvarsdsc_t结构指向查找的kmvarsdsc_t结构的后半部分虚拟地址空间 newkmvd-&gt;kva_end = delkmvd-&gt;kva_end; newkmvd-&gt;kva_start = start + (adr_t)vassize; //和查找到的kmvarsdsc_t结构保持一致 newkmvd-&gt;kva_limits = delkmvd-&gt;kva_limits; newkmvd-&gt;kva_maptype = delkmvd-&gt;kva_maptype; newkmvd-&gt;kva_mcstruct = vma; delkmvd-&gt;kva_end = start; //加入链表 list_add(&amp;newkmvd-&gt;kva_list, &amp;delkmvd-&gt;kva_list); vma-&gt;vs_kmvdscnr++; //是否为最后一个kmvarsdsc_t结构 if (list_is_last(&amp;newkmvd-&gt;kva_list, &amp;vma-&gt;vs_list) == TRUE) &#123; vma-&gt;vs_endkmvdsc = newkmvd; vma-&gt;vs_currkmvdsc = newkmvd; &#125; else &#123; vma-&gt;vs_currkmvdsc = newkmvd; &#125; rets = TRUE; goto out; &#125; rets = FALSE; out: knl_spinunlock(&amp;vma-&gt;vs_lock); return rets;&#125;//释放虚拟地址空间的接口bool_t vma_del_vadrs(mmadrsdsc_t *mm, adr_t start, size_t vassize)&#123; //对参数进行检查 if (NULL == mm || 1 &gt; vassize || NULL == start) &#123; return FALSE; &#125; //调用核心处理函数 return vma_del_vadrs_core(mm, start, VADSZ_ALIGN(vassize));&#125;// --------------------// 释放时查找虚拟地址空间// --------------------kmvarsdsc_t *vma_del_find_kmvarsdsc(virmemadrs_t *vmalocked, adr_t start, size&#123; kmvarsdsc_t *curr = vmalocked-&gt;vs_currkmvdsc; adr_t newend = start + (adr_t)vassize; list_h_t *listpos = NULL; if (NULL != curr) &#123;//释放的虚拟地址空间落在了当前kmvarsdsc_t结构表示的虚拟地址区间 if ((curr-&gt;kva_start) &lt;= start &amp;&amp; (newend &lt;= curr-&gt;kva_end)) &#123; return curr; &#125; &#125; //遍历所有的kmvarsdsc_t结构 list_for_each(listpos, &amp;vmalocked-&gt;vs_list) &#123; curr = list_entry(listpos, kmvarsdsc_t, kva_list); //释放的虚拟地址空间是否落在了其中的某个kmvarsdsc_t结构表示的虚拟地址区间 if ((start &gt;= curr-&gt;kva_start) &amp;&amp; (newend &lt;= curr-&gt;kva_end)) &#123; return curr; &#125; &#125; return NULL;&#125; 测试虚拟空间能正常访问 准备工作:先分配一个虚拟地址空间,分配一个虚拟地址空间并访问 在 init_kvirmemadrs 函数的最后调用的 test_vadr 函数，一旦执行，一定会发生异常。为了显示异常要在异常分发器函数中写点代码 缺页异常 原因:访问一个虚拟地址,该虚拟地址由CPU发送给MMU，而MMU无法将它转换成对应的物理地址，CPU访存指令无法执行，产生缺页异常。CPU 跳转到缺页异常处理的入口地址（kernel.asm 文件中的 exc_page_fault 标号处）开始执行代码，处理这个缺页异常 延迟内存分配技术(最大限度的节约物理内存)：等到发生缺页异常，才分配物理内存页面，建立对应的MMU页表;只要实际访问到了才分配对应的物理内存页面 开始处理缺页异常 缺页异常是从 kernel.asm 文件中的 exc_page_fault 标号处开始，但它只是保存了 CPU 的上下文，然后调用了内核的通用异常分发器函数，最后由异常分发器函数调用不同的异常处理函数，如果是缺页异常，就要调用缺页异常处理的接口函数，实现缺页异常处理的接口函数 处理缺页异常的核心 首先，查找缺页地址对应的 kmvarsdsc_t 结构，没找到说明没有分配该虚拟地址空间，那属于非法访问不予处理；然后，查找 kmvarsdsc_t 结构下面的对应 kvmemcbox_t 结构，它是用来挂载物理内存页面的；最后，分配物理内存页面并建立 MMU 页表映射关系 缺页地址是否合法 判断一个缺页地址是否合法要确定它是不是已经分配的虚拟地址，也就是看这个虚拟地址是不是会落在某个 kmvarsdsc_t 结构表示的虚拟地址区间；要去查找相应的 kmvarsdsc_t 结构，如果没有找到则虚拟地址没有分配，即这个缺页地址不合法 核心逻辑就是用虚拟地址和 kmvarsdsc_t 结构中的数据做比较，大于等于 kmvarsdsc_t 结构的开始地址并且小于 kmvarsdsc_t 结构的结束地址就可以 建立 kvmembox_t 结构 kvmemcbox_t 结构可以用来挂载物理内存页面 msadsc_t 结构，而这个 msadsc_t 结构是由虚拟地址区间 kmvarsdsc_t 结构代表的虚拟空间所映射的物理内存页面 一个kmvarsdsc_t 结构，必须要有一个 kvmemcbox_t 结构，才能分配物理内存。除了这个功能，kvmemcbox_t 结构还可以在内存共享的时候使用 映射物理内存页面 给虚拟地址分配对应的物理内存页面，建立对应的 MMU 页表，使虚拟地址到物理地址可以转换成功，数据终于能写入到物理内存之中 vma_map_msa_fault 的实际工作: 首先，它会调用vma_new_usermsa 函数，在 vma_new_usermsa 函数内部调用了我们前面学过的页面内存管理接口，分配一个物理内存页面并把对应的 msadsc_t 结构挂载到 kvmemcbox_t 结构上 接着获取 msadsc_t 结构对应内存页面的物理地址 最后是调用 hal_mmu_transform 函数完成虚拟地址到物理地址的映射工作，它主要是建立 MMU 页表 vma_map_phyadrs 函数一旦成功返回，就会随着原有的代码路径层层返回 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213//测试函数void test_vadr()&#123;//分配一个0x1000大小的虚拟地址空间adr_t vadr = vma_new_vadrs(&amp;initmmadrsdsc, NULL, 0x1000, 0, 0);//返回NULL表示分配失败if(NULL == vadr)&#123;kprint(&quot;分配虚拟地址空间失败\\n&quot;);&#125;//在刷屏幕上打印分配虚拟地址空间的开始地址kprint(&quot;分配虚拟地址空间地址:%x\\n&quot;, vadr);kprint(&quot;开始写入分配虚拟地址空间\\n&quot;);//访问虚拟地址空间，把这空间全部设置为0hal_memset((void*)vadr, 0, 0x1000);kprint(&quot;结束写入分配虚拟地址空间\\n&quot;);return;&#125;void init_kvirmemadrs()&#123;//……//调用测试函数test_vadr();return;&#125;// -------------// 异常分发器中的函数// -------------//cosmos/hal/x86/halintupt.cvoid hal_fault_allocator(uint_t faultnumb, void *krnlsframp)&#123;//打印异常号kprint(&quot;faultnumb is :%d\\n&quot;, faultnumb);//如果异常号等于14则是内存缺页异常if (faultnumb == 14)&#123;//打印缺页地址，这地址保存在CPU的CR2寄存器中kprint(&quot;异常地址:%x,此地址禁止访问\\n&quot;, read_cr2());&#125;//死机，不让这个函数返回了die(0);return;&#125;// -------------//缺页异常处理接口// -------------sint_t vma_map_fairvadrs(mmadrsdsc_t *mm, adr_t vadrs)&#123;//对参数进行检查 if ((0x1000 &gt; vadrs) || (USER_VIRTUAL_ADDRESS_END &lt; vadrs) || (NULL == mm) &#123; return -EPARAM; &#125; //进行缺页异常的核心处理 return vma_map_fairvadrs_core(mm, vadrs);&#125;//由异常分发器调用的接口sint_t krluserspace_accessfailed(adr_t fairvadrs)&#123;//这里应该获取当前进程的mm，但是现在我们没有进程，才initmmadrsdsc代替 mmadrsdsc_t* mm = &amp;initmmadrsdsc; //应用程序的虚拟地址不可能大于USER_VIRTUAL_ADDRESS_END if(USER_VIRTUAL_ADDRESS_END &lt; fairvadrs) &#123; return -EACCES; &#125; return vma_map_fairvadrs(mm, fairvadrs);&#125;// --------------------------------------------------------// 在 cosmos/hal/x86/halintupt.c 文件的异常分发器函数中调用它// --------------------------------------------------------void hal_fault_allocator(uint_t faultnumb, void *krnlsframp)&#123; adr_t fairvadrs; kprint(&quot;faultnumb is :%d\\n&quot;, faultnumb); if (faultnumb == 14) &#123; //获取缺页的地址 fairvadrs = (adr_t)read_cr2(); kprint(&quot;异常地址:%x,此地址禁止访问\\n&quot;, fairvadrs); if (krluserspace_accessfailed(fairvadrs) != 0) &#123;//处理缺页失败就死机 system_error(&quot;缺页处理失败\\n&quot;); &#125; //成功就返回 return; &#125; die(0); return;&#125;// ---------------// 处理缺页异常的核心// ---------------sint_t vma_map_fairvadrs_core(mmadrsdsc_t *mm, adr_t vadrs)&#123; sint_t rets = FALSE; adr_t phyadrs = NULL; virmemadrs_t *vma = &amp;mm-&gt;msd_virmemadrs; kmvarsdsc_t *kmvd = NULL; kvmemcbox_t *kmbox = NULL; knl_spinlock(&amp;vma-&gt;vs_lock); //查找对应的kmvarsdsc_t结构 kmvd = vma_map_find_kmvarsdsc(vma, vadrs); if (NULL == kmvd) &#123; rets = -EFAULT; goto out; &#125; //返回kmvarsdsc_t结构下对应kvmemcbox_t结构 kmbox = vma_map_retn_kvmemcbox(kmvd); if (NULL == kmbox) &#123; rets = -ENOMEM; goto out; &#125; //分配物理内存页面并建立MMU页表 phyadrs = vma_map_phyadrs(mm, kmvd, vadrs, (0 | PML4E_US | PML4E_RW | PML4 if (NULL == phyadrs) &#123; rets = -ENOMEM; goto out; &#125; rets = EOK; out: knl_spinunlock(&amp;vma-&gt;vs_lock); return rets;&#125;// ---------------// 缺页地址是否合法// ---------------kmvarsdsc_t *vma_map_find_kmvarsdsc(virmemadrs_t *vmalocked, adr_t vadrs)&#123; list_h_t *pos = NULL; kmvarsdsc_t *curr = vmalocked-&gt;vs_currkmvdsc; //看看上一次刚刚被操作的kmvarsdsc_t结构 if (NULL != curr) &#123;//虚拟地址是否落在kmvarsdsc_t结构表示的虚拟地址区间 if ((vadrs &gt;= curr-&gt;kva_start) &amp;&amp; (vadrs &lt; curr-&gt;kva_end)) &#123; return curr; &#125; &#125; //遍历每个kmvarsdsc_t结构 list_for_each(pos, &amp;vmalocked-&gt;vs_list) &#123; curr = list_entry(pos, kmvarsdsc_t, kva_list); //虚拟地址是否落在kmvarsdsc_t结构表示的虚拟地址区间 if ((vadrs &gt;= curr-&gt;kva_start) &amp;&amp; (vadrs &lt; curr-&gt;kva_end)) &#123; return curr; &#125; &#125; return NULL;&#125;// --------------------// 建立 kvmemcbox_t结构// --------------------kvmemcbox_t *vma_map_retn_kvmemcbox(kmvarsdsc_t *kmvd)&#123; kvmemcbox_t *kmbox = NULL; //如果kmvarsdsc_t结构中已经存在了kvmemcbox_t结构，则直接返回 if (NULL != kmvd-&gt;kva_kvmbox) &#123; return kmvd-&gt;kva_kvmbox; &#125; //新建一个kvmemcbox_t结构 kmbox = knl_get_kvmemcbox(); if (NULL == kmbox) &#123; return NULL; &#125; //指向这个新建的kvmemcbox_t结构 kmvd-&gt;kva_kvmbox = kmbox; return kmvd-&gt;kva_kvmbox;&#125;// ------------------// 映射物理内存页面// ------------------adr_t vma_map_msa_fault(mmadrsdsc_t *mm, kvmemcbox_t *kmbox, adr_t vadrs, u64_&#123; msadsc_t *usermsa; adr_t phyadrs = NULL; //分配一个物理内存页面，挂载到kvmemcbox_t中，并返回对应的msadsc_t结构 usermsa = vma_new_usermsa(mm, kmbox); if (NULL == usermsa) &#123;//没有物理内存页面返回NULL表示失败 return NULL; &#125; //获取msadsc_t对应的内存页面的物理地址 phyadrs = msadsc_ret_addr(usermsa); //建立MMU页表完成虚拟地址到物理地址的映射 if (hal_mmu_transform(&amp;mm-&gt;msd_mmu, vadrs, phyadrs, flags) == TRUE) &#123;//映射成功则返回物理地址 return phyadrs; &#125; //映射失败就要先释放分配的物理内存页面 vma_del_usermsa(mm, kmbox, usermsa, phyadrs); return NULL;&#125;//接口函数adr_t vma_map_phyadrs(mmadrsdsc_t *mm, kmvarsdsc_t *kmvd, adr_t vadrs, u64_t f&#123; kvmemcbox_t *kmbox = kmvd-&gt;kva_kvmbox; if (NULL == kmbox) &#123; return NULL; &#125; //调用核心函数，flags表示页表条目中的相关权限、存在、类型等位段 return vma_map_msa_fault(mm, kmbox, vadrs, flags);&#125; 6.7 瞧一瞧Linux:伙伴系统如何分配内存 Linux系统中用来管理物理内存页面的伙伴系统,以及负责分配比页更小的内存对象的SLAB分配器 伙伴系统：源于Sun公司的Solaris操作系统 怎样表示一个页 Linux使用分页机制管理物理内存,即将物理内存分成4KB大小的页面进行管理 早期的Linux使用位图,后来使用字节数组,如今使用Page结构体 page结构体巨大,信息量很多,但占用的内存很少，大量使用C语言union联合体定义结构字段 使用page结构通过flags表示状态,Linux内核中，一个page结构表示一个物理内存页面 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374struct page &#123; // page结构体的标志，它决定页面是什么状态 unsigned long flags; union &#123; struct &#123; //挂载上级结构的链表 struct list_head lru; //用于文件系统，address_space结构描述上文件占用了哪些内存页面 struct address_space *mapping; pgoff_t index; unsigned long private; &#125;; //DMA设备的地址 struct &#123; dma_addr_t dma_addr; &#125;; //当页面用于内存对象时指向相关的数据结构 struct &#123; union &#123; struct list_head slab_list; struct &#123; struct page *next; #ifdef CONFIG_64BIT int pages; int pobjects; #else short int pages; short int pobjects; #endif &#125;; &#125;; //指向管理SLAB的结构kmem_cache struct kmem_cache *slab_cache; //指向SLAB的第一个对象 void *freelist; union &#123; void *s_mem; unsigned long counters; struct &#123; unsigned inuse:16; unsigned objects:15; unsigned frozen:1; &#125;; &#125;; &#125;; //用于页表映射相关的字段 struct &#123; unsigned long _pt_pad_1; pgtable_t pmd_huge_pte; unsigned long _pt_pad_2; union &#123; struct mm_struct *pt_mm; atomic_t pt_frag_refcount; &#125;; //自旋锁 #if ALLOC_SPLIT_PTLOCKS spinlock_t *ptl; #else spinlock_t ptl; #endif &#125;; //用于设备映射 struct &#123; struct dev_pagemap *pgmap; void *zone_device_data; &#125;; struct rcu_head rcu_head; &#125;; //页面引用计数 atomic_t _refcount; #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS int _last_cpupid; #endif&#125; struct page_alignment; 怎样表示一个区 因为硬件限制,linux内核不能对所有物理内存页统一对待，把属性相同物理内存页面归结到一个区 在32位的x86平台,一些使用DMA设备只能访问016MB物理空间，因此将016MB划分为DMA区 高内存区适用于要访问物理地址空间大于虚拟地址空间,linux内核不能建立直接映射的情况 64位的x86平台没有高内存区 除了这两个区,物理内存中剩余页面被划分到常规内存区 在linux查看机器的内存区:cat /proc/zoneinfo | grep Node linux内核用zone数据结构表示一个区 _watermark表示内存页面总量的水位线有min,low,high三种状态,可以作为启动内存页面回收的判断标准 spanned_pages是该内存区总的页面数 present_pages表示页面真正存在,一些内存区中存在内存空洞,空洞对应的page结构不能用 在zone中需要关注的是 free_area 结构的数组,用于实现伙伴系统,其中 MAX_ORDER 的值默认为11，分别表示挂载地址连续的page结构数目为1,2,4,8,…1024 free_area结构是一个 list_head 链表数组,该数组将具有相同迁移类型的page结构尽可能地分组，同一类型的所有相同 order 的 page 结构构成一组 page 结构体 分配时会先按请求的 migratetype 从对应的 page 结构块中寻找,若不成功才会从其他 migratetype 的page结构块中分配,为了让内存页迁移更加高效，可以有效降低内存碎片 指向 pglist_data 的指针(重要结构) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// zone数据结构enum migratetype &#123; MIGRATE_UNMOVABLE, //不能移动的 MIGRATE_MOVABLE, //可移动和 MIGRATE_RECLAIMABLE, MIGRATE_PCPTYPES, //属于pcp list的 MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES, #ifdef CONFIG_CMA MIGRATE_CMA, //属于CMA区的 #endif #ifdef CONFIG_MEMORY_ISOLATION MIGRATE_ISOLATE, #endif MIGRATE_TYPES&#125;;//页面空闲链表头struct free_area &#123; struct list_head free_list[MIGRATE_TYPES]; unsigned long nr_free;&#125;;struct zone &#123; unsigned long _watermark[NR_WMARK]; unsigned long watermark_boost; //预留的内存页面数 unsigned long nr_reserved_highatomic; //内存区属于哪个内存节点 #ifdef CONFIG_NUMA int node; #endif struct pglist_data *zone_pgdat; //内存区开始的page结构数组的开始下标 unsigned long zone_start_pfn; atomic_long_t managed_pages; //内存区总的页面数 unsigned long spanned_pages; //内存区存在的页面数 unsigned long present_pages; //内存区名字 const char *name; //挂载页面page结构的链表 struct free_area free_area[MAX_ORDER]; //内存区的标志 unsigned long flags; /*保护free_area的自旋锁*/ spinlock_t lock;&#125;; 怎样表示一个节点 NUMA体系结构:在很多服务器和大型计算机上,如果物理内存时分布式的,有多个计算节点组成,那么每个CPU核都会有自己的本地内存,CPU在访问本地内存时较快,访问其他CPU核内存较慢 Linux对NUMA进行抽象可以将一整块连续物理内存划分成几个内存节点,也可以将不连续的物理内存当成真正的NUMA 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859enum &#123; ZONELIST_FALLBACK, #ifdef CONFIG_NUMA ZONELIST_NOFALLBACK, #endif MAX_ZONELISTS&#125;;struct zoneref &#123; struct zone *zone;//内存区指针 int zone_idx; //内存区对应的索引&#125;;struct zonelist &#123; struct zoneref _zonerefs[MAX_ZONES_PER_ZONELIST + 1];&#125;;//zone枚举类型 从0开始enum zone_type &#123; #ifdef CONFIG_ZONE_DMA ZONE_DMA, #endif #ifdef CONFIG_ZONE_DMA32 ZONE_DMA32, #endif ZONE_NORMAL, #ifdef CONFIG_HIGHMEM ZONE_HIGHMEM, #endif ZONE_MOVABLE, #ifdef CONFIG_ZONE_DEVICE ZONE_DEVICE, #endif __MAX_NR_ZONES&#125;;//定义MAX_NR_ZONES为__MAX_NR_ZONES 最大为6DEFINE(MAX_NR_ZONES, __MAX_NR_ZONES);//内存节点typedef struct pglist_data &#123;//定一个内存区数组，最大为6个zone元素 struct zone node_zones[MAX_NR_ZONES]; //两个zonelist，一个是指向本节点的的内存区，另一个指向由本节点分配不到内存时可选的备用内存区 struct zonelist node_zonelists[MAX_ZONELISTS]; //本节点有多少个内存区 int nr_zones; //本节点开始的page索引号 unsigned long node_start_pfn; //本节点有多少个可用的页面 unsigned long node_present_pages; //本节点有多少个可用的页面包含内存空洞 unsigned long node_spanned_pages; //节点id int node_id; //交换内存页面相关的字段 wait_queue_head_t kswapd_wait; wait_queue_head_t pfmemalloc_wait; struct task_struct *kswapd; //本节点保留的内存页面 unsigned long totalreserve_pages; //自旋锁 spinlock_t lru_lock;&#125; pg_data t; 数据结构之间的关系 pglist_data,zonelist,zone,page 数据结构的核心内容 何为伙伴 Linux物理内存页面管理中,连续且相同大小的pages可表示为伙伴 分配页面 首先要找到内存节点,接着找到内存区,然后合适的空闲链表,最后在其中找到页的page结构完成物理内存页面的分配 通过接口找到内存节点 虚线框中为接口函数，所有接口函数都会调用 alloc_pages 函数,该函数会调用 __alloc_pages_nodemask 函数完成内存页面的分配 alloc_pages_current函数最终调用__alloc_pages_nodemask 函数，参数order表示请求分配2的order次方个页面,gfp_t类型的gfp_mask参数为重点 gfp_t 是 int 类型，用其中位的状态表示请求分配不同的内存区的内存页面，以及分配内存页面的不同方式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// alloc_pages 函数的形式struct page *alloc_pages_current(gfp_t gfp, unsigned order)&#123; struct mempolicy *pol = &amp;default_policy; struct page *page; if (!in_interrupt() &amp;&amp; !(gfp &amp; __GFP_THISNODE)) pol = get_task_policy(current); if (pol-&gt;mode == MPOL_INTERLEAVE) page = alloc_page_interleave(gfp, order, interleave_nodes(pol)); else page = __alloc_pages_nodemask(gfp, order, policy_node(gfp, pol, numa_node_id()), policy_nodemask(gfp, pol)); return page;&#125;static inline struct page * alloc_pages(gfp_t gfp_mask, unsigned int order)&#123; return alloc_pages_current(gfp_mask, order);&#125;// gfp_mask 的类型和取值typedef unsigned int __bitwise gfp_t;#define ___GFP_DMA 0x01u#define ___GFP_HIGHMEM 0x02u#define ___GFP_DMA32 0x04u#define ___GFP_MOVABLE 0x08u#define ___GFP_RECLAIMABLE 0x10u#define ___GFP_HIGH 0x20u#define ___GFP_IO 0x40u#define ___GFP_FS 0x80u#define ___GFP_ZERO 0x100u#define ___GFP_ATOMIC 0x200u#define ___GFP_DIRECT_RECLAIM 0x400u#define ___GFP_KSWAPD_RECLAIM 0x800u#define ___GFP_WRITE 0x1000u#define ___GFP_NOWARN 0x2000u#define ___GFP_RETRY_MAYFAIL 0x4000u#define ___GFP_NOFAIL 0x8000u#define ___GFP_NORETRY 0x10000u#define ___GFP_MEMALLOC 0x20000u#define ___GFP_COMP 0x40000u#define ___GFP_NOMEMALLOC 0x80000u#define ___GFP_HARDWALL 0x100000u#define ___GFP_THISNODE 0x200000u#define ___GFP_ACCOUNT 0x400000u//需要原子分配内存不得让请求者进入睡眠#define GFP_ATOMIC (__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)//分配用于内核自己使用的内存，可以有IO和文件系统相关的操作#define GFP_KERNEL (__GFP_RECLAIM | __GFP_IO | __GFP_FS)#define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT)//分配内存不能睡眠，不能有I/O和文件系统相关的操作#define GFP_NOWAIT (__GFP_KSWAPD_RECLAIM)#define GFP_NOIO (__GFP_RECLAIM)#define GFP_NOFS (__GFP_RECLAIM | __GFP_IO)//分配用于用户进程的内存#define GFP_USER (__GFP_RECLAIM | __GFP_IO | __GFP_FS | __GFP_HARDWALL)//用于DMA设备的内存#define GFP_DMA __GFP_DMA#define GFP_DMA32 __GFP_DMA32//把高端内存区的内存分配给用户进程#define GFP_HIGHUSER (GFP_USER | __GFP_HIGHMEM)#define GFP_HIGHUSER_MOVABLE (GFP_HIGHUSER | __GFP_MOVABLE)#define GFP_TRANSHUGE_LIGHT ((GFP_HIGHUSER_MOVABLE | __GFP_COMP | \\__GFP_NOMEM#define GFP TRANSHUGE (GFP TRANSHUGE LIGHT | GFP DIRECT RECLAIM) 开始分配 分配内存页面的函数__alloc_pages_nodemask 函数完成3件事: 准备分配页面的参数 进入快速分配路径 若快速分配路径没有分配页面，进入慢速分配路径 准备分配页面的参数 在 __alloc_pages_nodemask 函数中,具有一个变量ac时 alloc_context 类型的,分配参数就保存在ac变量中 prepare_alloc_pages 函数根据传递进来的参数对ac变量进一步处理 prepare_alloc_pages 函数根据传递进入的参数，就能找出要分配内存区、候选内存区以及内存区中空闲链表的 migratetype 类型，把这些全部收集到 ac 结构中返回 true 说明分配内存页面的参数已准备好 Plan A:快速分配路径 快速分配路径不会处理内存页面合并和回收 遍历所有的候选内存区,然后针对每个内存区检查水位线,是否执行内存回收机制,当一切检查通过之后欧就开始调用 rmqueue 函数执行内存页面分配 Plan B:慢速分配路径 当快速分配路径没有分配到页时,进入慢速分配路径,慢速分配路径会执行页面回收,回收页面之后会进行多次重复分配,直到最后分配到内存页面或分配失败 __alloc_pages_slowpath 函数一开始会唤醒所有用于内存交换回收的线程 get_page_from_freelist 函数分配失败了就会进行内存回收，内存回收主要是释放一些文件占用的内存页面。如果内存回收不行，就会就进入到内存压缩环节 内存压缩是指移动内存页面进行内存碎片整理,腾出更大的连续的内存空间 如何分配内存页面 最终执行内存页面分配动作的始终是 get_page_from_freelist 函数,准确是实际完成分配任务的是 rmqueue 函数 需要重点关注 rmqueue_pcplist 和 __rmqueue_smallest 函数 rmqueue_pcplist 函数，在请求分配一个页面时，用它从 pcplist 中分配页面的;主要是优化了请求分配单个内存页面的性能,遇到多个内存页面的分配请求会调用 __rmqueue_smallest 函数，从 free_area 数组中分配 pcp 是指，每个 CPU 都有一个内存页面高速缓冲，由数据结构per_cpu_pageset 描述，包含在内存区中 针对每个 CPU，都建立出预先分配了单个内存页面的链表，用于满足本地 CPU 发出的单一内存请求提升系统的性能 __rmqueue_smallest 函数 首先要取得 current_order 对应的free_area 区中 page，若没有，就继续增加 current_order，直到最大的 MAX_ORDER；要是得到一组连续 page 的首地址，就对其脱链，然后调用 expand 函数分割伙伴 expand 函数是完成伙伴算法的核心 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344// 代码实现struct page *__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid, nodemask_t *nodemask)&#123; struct page *page; unsigned int alloc_flags = ALLOC_WMARK_LOW; gfp_t alloc_mask; struct alloc_context ac = &#123; &#125;; //分配页面的order大于等于最大的order直接返回NULL if (unlikely(order &gt;= MAX_ORDER)) &#123; WARN_ON_ONCE(!(gfp_mask &amp; __GFP_NOWARN)); return NULL; &#125; gfp_mask &amp;= gfp_allowed_mask; alloc_mask = gfp_mask; //准备分配页面的参数放在ac变量中 if (!prepare_alloc_pages(gfp_mask, order, preferred_nid, nodemask, &amp;ac, &amp;alloc_mask, &amp;alloc_flags)) return NULL; alloc_flags |= alloc_flags_nofragment(ac.preferred_zoneref-&gt;zone, gfp_mask); //进入快速分配路径 page = get_page_from_freelist(alloc_mask, order, alloc_flags, &amp;ac); if (likely(page)) goto out; alloc_mask = current_gfp_context(gfp_mask); ac.spread_dirty_pages = false; ac.nodemask = nodemask; //进入慢速分配路径 page = __alloc_pages_slowpath(alloc_mask, order, &amp;ac); out: return page;&#125;// ------------// 准备分配页面的参数// ------------struct alloc_context &#123;struct zonelist *zonelist;nodemask_t *nodemask;struct zoneref *preferred_zoneref;int migratetype;enum zone_type highest_zoneidx;bool spread_dirty_pages;&#125;;static inline bool prepare_alloc_pages(gfp_t gfp_mask, unsigned int order,int preferred_nid, nodemask_t *nodemask,struct alloc_context *ac, gfp_t *alloc_mask,unsigned int *alloc_flags)&#123;//从哪个内存区分配内存ac-&gt;highest_zoneidx = gfp_zone(gfp_mask);//根据节点id计算出zone的指针ac-&gt;zonelist = node_zonelist(preferred_nid, gfp_mask);ac-&gt;nodemask = nodemask;//计算出free_area中的migratetype值，比如如分配的掩码为GFP_KERNEL，那么其类型为MIGRac-&gt;migratetype = gfp_migratetype(gfp_mask);//处理CMA相关的分配选项*alloc_flags = current_alloc_flags(gfp_mask, *alloc_flags);ac-&gt;spread_dirty_pages = (gfp_mask &amp; __GFP_WRITE);//搜索nodemask表示的节点中可用的zone保存在preferred_zonerefac-&gt;preferred_zoneref = first_zones_zonelist(ac-&gt;zonelist,ac-&gt;highest_zoneidx, ac-&gt;nodemask);return true;&#125;// -----------// 快速分配路径// -----------static struct page *get_page_from_freelist(gfp_t gfp_mask, unsigned int order, int alloc_flags,const struct alloc_context *ac)&#123;struct zoneref *z;struct zone *zone;struct pglist_data *last_pgdat_dirty_limit = NULL;bool no_fallback;retry:no_fallback = alloc_flags &amp; ALLOC_NOFRAGMENT;z = ac-&gt;preferred_zoneref;//遍历ac-&gt;preferred_zoneref中每个内存区for_next_zone_zonelist_nodemask(zone, z, ac-&gt;highest_zoneidx,ac-&gt;nodemask) &#123;struct page *page;unsigned long mark;//查看内存水位线mark = wmark_pages(zone, alloc_flags &amp; ALLOC_WMARK_MASK);//检查内存区中空闲内存是否在水印之上if (!zone_watermark_fast(zone, order, mark,ac-&gt;highest_zoneidx, alloc_flags,gfp_mask)) &#123;int ret;//当前内存区的内存结点需要做内存回收吗ret = node_reclaim(zone-&gt;zone_pgdat, gfp_mask, order);switch (ret) &#123;//快速分配路径不处理页面回收的问题case NODE_RECLAIM_NOSCAN:continue;case NODE_RECLAIM_FULL:continue;default://根据分配的order数量判断内存区的水位线是否满足要求if (zone_watermark_ok(zone, order, mark,ac-&gt;highest_zoneidx, alloc_flags))//如果可以可就从这个内存区开始分配goto try_this_zone;continue;&#125;&#125;try_this_zone://真正分配内存页面page = rmqueue(ac-&gt;preferred_zoneref-&gt;zone, zone, order,gfp_mask, alloc_flags, ac-&gt;migratetype);if (page) &#123;//清除一些标志或者设置联合页等等prep_new_page(page, order, gfp_mask, alloc_flags);return page;&#125;&#125;if (no_fallback) &#123;alloc_flags &amp;= ~ALLOC_NOFRAGMENT;goto retry;&#125;return NULL;&#125;// -------------// 慢速分配路径// -------------static inline struct page *__alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,struct alloc_context *ac)&#123;bool can_direct_reclaim = gfp_mask &amp; __GFP_DIRECT_RECLAIM;const bool costly_order = order &gt; PAGE_ALLOC_COSTLY_ORDER;struct page *page = NULL;unsigned int alloc_flags;unsigned long did_some_progress;enum compact_priority compact_priority;enum compact_result compact_result;int compaction_retries;int no_progress_loops;unsigned int cpuset_mems_cookie;int reserve_flags;retry://唤醒所有交换内存的线程if (alloc_flags &amp; ALLOC_KSWAPD)wake_all_kswapds(order, gfp_mask, ac);//依然调用快速分配路径入口函数尝试分配内存页面page = get_page_from_freelist(gfp_mask, order, alloc_flags, ac);if (page)goto got_pg;//尝试直接回收内存并且再分配内存页面page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac,&amp;did_some_progress);if (page)goto got_pg;//尝试直接压缩内存并且再分配内存页面page = __alloc_pages_direct_compact(gfp_mask, order, alloc_flags, ac,compact_priority, &amp;compact_result);if (page)goto got_pg;//检查对于给定的分配请求，重试回收是否有意义if (should_reclaim_retry(gfp_mask, order, ac, alloc_flags,did_some_progress &gt; 0, &amp;no_progress_loops))goto retry;//检查对于给定的分配请求，重试压缩是否有意义if (did_some_progress &gt; 0 &amp;&amp;should_compact_retry(ac, order, alloc_flags,compact_result, &amp;compact_priority,&amp;compaction_retries))goto retry;//回收、压缩内存已经失败了，开始尝试杀死进程，回收内存页面page = __alloc_pages_may_oom(gfp_mask, order, ac, &amp;did_some_progress);if (page)goto got_pg;got_pg:return page;&#125;// -------------// 如何分配内存页面// -------------static inline struct page *rmqueue(struct zone *preferred_zone,struct zone *zone, unsigned int order,gfp_t gfp_flags, unsigned int alloc_flags,int migratetype)&#123;unsigned long flags;struct page *page;if (likely(order == 0)) &#123;if (!IS_ENABLED(CONFIG_CMA) || alloc_flags &amp; ALLOC_CMA ||migratetype != MIGRATE_MOVABLE) &#123;//如果order等于0,就说明是分配一个页面，说就从pcplist中分配page = rmqueue_pcplist(preferred_zone, zone, gfp_flags,migratetype, alloc_flags);goto out;&#125;&#125;//加锁并关中断spin_lock_irqsave(&amp;zone-&gt;lock, flags);do &#123;page = NULL;if (order &gt; 0 &amp;&amp; alloc_flags &amp; ALLOC_HARDER) &#123;//从free_area中分配page = __rmqueue_smallest(zone, order, MIGRATE_HIGHATOMIC);&#125;if (!page)//它最后也是调用__rmqueue_smallest函数page = __rmqueue(zone, order, migratetype, alloc_flags);&#125; while (page &amp;&amp; check_new_pages(page, order));spin_unlock(&amp;zone-&gt;lock);zone_statistics(preferred_zone, zone);local_irq_restore(flags);out:return page;&#125;// ----------// rmqueue_pcplist函数// ----------struct per_cpu_pages &#123;int count; //列表中的页面数int high; //页面数高于水位线，需要清空int batch; //从伙伴系统增加/删除的块数//页面列表，每个迁移类型一个。struct list_head lists[MIGRATE_PCPTYPES];&#125;;struct per_cpu_pageset &#123;struct per_cpu_pages pcp;#ifdef CONFIG_NUMAs8 expire;u16 vm_numa_stat_diff[NR_VM_NUMA_STAT_ITEMS];#endif#ifdef CONFIG_SMPs8 stat_threshold;s8 vm_stat_diff[NR_VM_ZONE_STAT_ITEMS];#endif&#125;;static struct page *__rmqueue_pcplist(struct zone *zone, int migratetype,unsigstruct list_head *list)&#123;struct page *page;do &#123;if (list_empty(list)) &#123;//如果list为空，就从这个内存区中分配一部分页面到pcp中来pcp-&gt;count += rmqueue_bulk(zone, 0,pcp-&gt;batch, list,migratetype, alloc_flags);if (unlikely(list_empty(list)))return NULL;&#125;//获取list上第一个page结构page = list_first_entry(list, struct page, lru);//脱链list_del(&amp;page-&gt;lru);//减少pcp页面计数pcp-&gt;count--;&#125; while (check_new_pcp(page));return page;&#125;static struct page *rmqueue_pcplist(struct zone *preferred_zone,struct zone *zone, gfp_t gfp_flags,int migratetype, unsigned int a&#123;struct per_cpu_pages *pcp;struct list_head *list;struct page *page;unsigned long flags;//关中断local_irq_save(flags);//获取当前CPU下的pcppcp = &amp;this_cpu_ptr(zone-&gt;pageset)-&gt;pcp;//获取pcp下迁移的list链表list = &amp;pcp-&gt;lists[migratetype];//摘取list上的page结构page = __rmqueue_pcplist(zone, migratetype, alloc_flags, pcp, list);//开中断local_irq_restore(flags);return page;&#125;// ----------------// _rmqueue_smallest// ----------------static inline struct page *get_page_from_free_area(struct free_area *area,int&#123;//返回free_list[migratetype]中的第一个page若没有就返回NULLreturn list_first_entry_or_null(&amp;area-&gt;free_list[migratetype],struct page, lru);&#125;static inline void del_page_from_free_list(struct page *page, struct zone *zon&#123;if (page_reported(page))__ClearPageReported(page);//脱链list_del(&amp;page-&gt;lru);//清除page中伙伴系统的标志__ClearPageBuddy(page);set_page_private(page, 0);//减少free_area中页面计数zone-&gt;free_area[order].nr_free--;&#125;static inline void add_to_free_list(struct page *page, struct zone *zone,unsigned int order, int migratetype)&#123;struct free_area *area = &amp;zone-&gt;free_area[order];//把一组page的首个page加入对应的free_area中list_add(&amp;page-&gt;lru, &amp;area-&gt;free_list[migratetype]);area-&gt;nr_free++;&#125;//分割一组页static inline void expand(struct zone *zone, struct page *page,int low, int high, int migratetype)&#123;//最高order下连续的page数 比如high = 3 size=8unsigned long size = 1 &lt;&lt; high;while (high &gt; low) &#123;high--;size &gt;&gt;= 1;//每次循环左移一位 4,2,1//标记为保护页，当其伙伴被释放时，允许合并if (set_page_guard(zone, &amp;page[size], high, migratetype))continue;//把另一半pages加入对应的free_area中add_to_free_list(&amp;page[size], zone, high, migratetype);//设置伙伴set_buddy_order(&amp;page[size], high);&#125;&#125;static __always_inline struct page *__rmqueue_smallest(struct zone *zone, unsi&#123;unsigned int current_order;struct free_area *area;struct page *page;for (current_order = order; current_order &lt; MAX_ORDER; ++current_order) &#123;//获取current_order对应的free_areaarea = &amp;(zone-&gt;free_area[current_order]);//获取free_area中对应migratetype为下标的free_list中的pagepage = get_page_from_free_area(area, migratetype);if (!page)continue;//脱链pagedel_page_from_free_list(page, zone, current_order);//分割伙伴expand(zone, page, order, current_order, migratetype);set_pcppage_migratetype(page, migratetype);return page;&#125;return NULL;&#125; 6.8 瞧一瞧Linux:SLAB如何分配内存 SLAB 与cosmos物理内存页面管理器一样,linux中的伙伴系统是以页面为最小单位分配的,现实中需要根据内核对象的实例变量大小来申请和释放内存空间，使用slab分配器实现内核中更小粒度的内存分配 SLAB对象 在slab分配器中,把一个内存页面或一组连续的内存页面划分成大小相同的块,其中一个小的内存块就是slab对象,但这一组连续的内存页面中不只是slab对象，还有slab管理头和着色区 着色区为一块动态的内存块,建立slab时设置大小，目的时为了错开不同slab中的对象地址,降低硬件cache行中的地址争用，以免导致cache抖动效应，降低系统性能 slab头是一种数据结构，不一定存放在保存对象内存页面的开始;通常会有一个保存slab管理头的slab,在linux中slab管理头用 kmem_cache 结构表示 有多少个CPU就会有多少个 array_cache 类型的变量 为每个CPU构造一个变量副本的同步机制为每CPU变量 array_cache结构中entry[]表示一个遵循LIFO顺序的数组,avail和limit分别指向了当前可用独享的数目和允许容纳对象的最大数目 第一个kmem_cache：静态定义在代码中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// -------// slab对象// -------struct array_cache &#123; unsigned int avail; unsigned int limit; void *entry[];&#125;;struct kmem_cache &#123; //是每个CPU一个array_cache类型的变量，cpu_cache是用于管理空闲对象的 struct array_cache __percpu *cpu_cache; unsigned int size; //cache大小 slab_flags_t flags;//slab标志 unsigned int num;//对象个数 unsigned int gfporder;//分配内存页面的order gfp_t allocflags; size_t colour;//着色区大小 unsigned int colour_off;//着色区的开始偏移 const char *name;//本SLAB的名字 struct list_head list;//所有的SLAB都要链接起来 int refcount;//引用计数 int object_size;//对象大小 int align;//对齐大小 struct kmem_cache_node *node[MAX_NUMNODES];//指向管理kmemcache的上层结构&#125;;// ---------------// 第一个kmem_cache// ---------------static struct kmem_cache kmem_cache_boot = &#123; .batchcount = 1, .limit = BOOT_CPUCACHE_ENTRIES, .shared = 1, .size = sizeof(struct kmem_cache), .name = &quot;kmem_cache&quot;,&#125;;void __init kmem_cache_init(void)&#123; int i; // 指向静态定义的kmem_cache_boot kmem_cache = &amp;kmem_cache_boot; for (i = 0; i &lt; NUM_INIT_LISTS; i++) kmem_cache_node_init(&amp;init_kmem_cache_node[i]); //建立保存kmem_cache结构的kmem_cache create_boot_cache(kmem_cache, &quot;kmem_cache&quot;, offsetof(struct kmem_cache, node) + nr_node_ids * sizeof(struct kmem_cache_node *), SLAB_HWCACHE_ALIGN, 0, 0); //加入全局slab_caches链表中 list_add(&amp;kmem_cache-&gt;list, &amp;slab_caches); &#123; int nid; for_each_online_node(nid) &#123; init_list(kmem_cache, &amp;init_kmem_cache_node[CACHE_CACHE + nid], ni init_list(kmalloc_caches[KMALLOC_NORMAL][INDEX_NODE], &#125; &#125; //建立kmalloc函数使用的的kmem_cache create_kmalloc_caches(ARCH_KMALLOC_FLAGS);&#125; 管理 kmem_cache kmem_cache_node 结构是每个内存节点中对应一个用来管理 kmem_cache 结构,开始是静态定义的 初始化时建立了第一个 kmem_cache 结构之后，init_list 函数负责一个个分配内存空间 第一次分配对象时,没有对应的内存页面存放对象,slab模块会调用 cache_grow_begin 函数获取内存页面,然后用获取的页面存放对象 cache_grow_begin 函数会为 kmem_cache 结构分配用来存放对象的页面，随后调用与之对应的 cache_grow_end 函数，把这页面挂载到kmem_cache_node 结构的链表中，并让页面指向 kmem_cache 结构 全局结构 page 可能是一组连续的 pages，但是只会把第一个 page 挂载到kmem_cache_node 中，同时，在 slab_map_pages 函数中又让 page 指向了kmem_cache kmem_cache_node 中的三个链表 分别挂载的 pages，有一部分是空闲对象的 page、还有对象全部都已经分配的 page，以及全部都为空闲对象的page(为了提高分配时查找 kmem_cache 的性能) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// -------------// 管理keme_cache// -------------#define NUM_INIT_LISTS (2 * MAX_NUMNODES)//定义的kmem_cache_node结构数组static struct kmem_cache_node __initdata init_kmem_cache_node[NUM_INIT_LISTS];struct kmem_cache_node &#123; spinlock_t list_lock;//自旋锁 struct list_head slabs_partial;//有一部分空闲对象的kmem_cache结构 struct list_head slabs_full;//没有空闲对象的kmem_cache结构 struct list_head slabs_free;//对象全部空闲kmem_cache结构 unsigned long total_slabs; //一共多少kmem_cache结构 unsigned long free_slabs; //空闲的kmem_cache结构 unsigned long free_objects;//空闲的对象 unsigned int free_limit;&#125;;static void __init init_list(struct kmem_cache *cachep, struct kmem_cache_nodeint nodeid)&#123; struct kmem_cache_node *ptr; //分配新的 kmem_cache_node 结构的空间 ptr = kmalloc_node(sizeof(struct kmem_cache_node), GFP_NOWAIT, nodeid); BUG_ON(!ptr); //复制初始时的静态kmem_cache_node结构 memcpy(ptr, list, sizeof(struct kmem_cache_node)); spin_lock_init(&amp;ptr-&gt;list_lock); MAKE_ALL_LISTS(cachep, ptr, nodeid); //设置kmem_cache_node的地址 cachep-&gt;node[nodeid] = ptr;&#125;// 第一次分配对象时,没有对应的内存页面存放对象,slab模块会调用 cache_grow_begin 函数获取内存页面,然后用获取的页面存放对象static void slab_map_pages(struct kmem_cache *cache, struct page *page,void *f&#123; //页面结构指向kmem_cache结构 page-&gt;slab_cache = cache; //指向空闲对象的链表 page-&gt;freelist = freelist;&#125;static struct page *cache_grow_begin(struct kmem_cache *cachep,gfp_t flags, int nodeid)&#123; void *freelist; size_t offset; gfp_t local_flags; int page_node; struct kmem_cache_node *n; struct page *page; WARN_ON_ONCE(cachep-&gt;ctor &amp;&amp; (flags &amp; __GFP_ZERO)); local_flags = flags &amp; (GFP_CONSTRAINT_MASK|GFP_RECLAIM_MASK); //获取页面 page = kmem_getpages(cachep, local_flags, nodeid); //获取页面所在的内存节点号 page_node = page_to_nid(page); //根据内存节点获取对应kmem_cache_node结构 n = get_node(cachep, page_node); //分配管理空闲对象的数据结构 freelist = alloc_slabmgmt(cachep, page, offset, local_flags &amp; ~GFP_CONSTRAINT_MASK, page_node); //让页面中相关的字段指向kmem_cache和空闲对象 slab_map_pages(cachep, page, freelist); //初始化空闲对象管理数据 cache_init_objs(cachep, page); return page;&#125;static void cache_grow_end(struct kmem_cache *cachep, struct page *page)&#123; struct kmem_cache_node *n; void *list = NULL; if (!page) return; //初始化结page构的slab_list链表 INIT_LIST_HEAD(&amp;page-&gt;slab_list); //根据内存节点获取对应kmem_cache_node结构. n = get_node(cachep, page_to_nid(page)); spin_lock(&amp;n-&gt;list_lock); //slab计数增加 n-&gt;total_slabs++; if (!page-&gt;active) &#123; //把这个page结构加入到kmem_cache_node结构的空闲链表中 list_add_tail(&amp;page-&gt;slab_list, &amp;n-&gt;slabs_free); n-&gt;free_slabs++; &#125; spin_unlock(&amp;n-&gt;list_lock);&#125; SLAB分配对象的过程 根据请求分配对象的大小,查找对应的 kmem_cache 结构,接着从结构中获取 array_cache 结构,然后分配对象 如果没有空闲对象了，就需要在 kmem_cache 对应的 kmem_cache_node 结构中查找有空闲对象的 kmem_cache 如果还是没找到，就要分配内存页面新增 kmem_cache结构 slab分配接口 在linux中用的最多的是 kmalloc 函数,经常用于分配小的缓存区,或者数据结构分配实例空间为slab分配接口,用来分配一小块内存空间 在__do_kmalloc 函数中，查找出分配大小对应的kmem_cache 结构，然后调用 slab_alloc 函数进行分配 slab_alloc 函数才是SLAB 的接口函数，但是参数中必须要有 kmem_cache 结构 如何查找 kmem_cache 结构 调用 kmalloc_slab 函数 kmalloc_caches 就是个全局的二维数组，kmalloc_slab 函数只是根据分配大小和分配标志计算出了数组下标，最后取出其中 kmem_cache 结构指针 __do_kmalloc 函数中根据分配对象大小查找的所有 kmem_cache 结构，kmem_cache 结构就建立好了，保存在 kmalloc_caches 数组中 分配对象 从 slab_alloc 函数开始探索对象的分配过程,第一个参数就是 kmem_cache 结构的指针,表示从该 kmem_cache 结构中分配对象 真正做事的函数是 ____cache_alloc 函数，首先获取了当前 kmem_cache 结构中指向 array_cache 结构的指针，找到它里面空闲对象的地址，然后在 array_cache 结构中取出一个空闲对象地址返回，这样就分配成功了 速度是很快的，如果 array_cache 结构中没有空闲对象了，就会调用cache_alloc_refill 函数 调用 cache_alloc_refill 函数的过程的主要的工作 获取 cachep 所属的 kmem_cache_node 然后调用 get_first_slab，获取 kmem_cache_node 结构还有没有包含空闲对象的kmem_cache 但是请注意，这里返回的是 page，因为 page 会指向 kmem_cache 结构，page 所代表的物理内存页面，也保存着 kmem_cache 结构中的对象 最后，如果 kmem_cache_node 结构没有包含空闲对象的 kmem_cache 了，就必须调用cache_grow_begin 函数，找伙伴系统分配新的内存页面，而且还要找第一个kmem_cache 分配新的对象，来存放 kmem_cache 结构的实例变量，并进行必要的初始化 这些步骤完成之后，再调用 cache_grow_end 函数，把刚刚分配的 page 挂载到kmem_cache_node 结构的 slabs_list 链表上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236// -----------// slab分配接口// -----------static __always_inline void *__do_kmalloc(size_t size, gfp_t flags,unsigned long caller)&#123; struct kmem_cache *cachep; void *ret; if (unlikely(size &gt; KMALLOC_MAX_CACHE_SIZE)) return NULL; //查找size对应的kmem_cache cachep = kmalloc_slab(size, flags); if (unlikely(ZERO_OR_NULL_PTR(cachep))) return cachep; //分配对象 ret = slab_alloc(cachep, flags, caller); return ret;&#125;void *__kmalloc(size_t size, gfp_t flags)&#123; return __do_kmalloc(size, flags, _RET_IP_);&#125;static __always_inline void *kmalloc(size_t size, gfp_t flags)&#123; return __kmalloc(size, flags);&#125;// -----------------------// 如何查找 kmem_cache 结构// -----------------------enum kmalloc_cache_type &#123; KMALLOC_NORMAL = 0, KMALLOC_RECLAIM,#ifdef CONFIG_ZONE_DMA KMALLOC_DMA,#endif NR_KMALLOC_TYPES&#125;;struct kmem_cache *kmalloc_caches[NR_KMALLOC_TYPES][KMALLOC_SHIFT_HIGH + 1] __ro_after_init()&#123; 3, /* 8 */ 4, /* 16 */ 5, /* 24 */ 5, /* 32 */ 6, /* 40 */ 6, /* 48 */ 6, /* 56 */ 6, /* 64 */ 1, /* 72 */ 1, /* 80 */ 1, /* 88 */ 1, /* 96 */ 7, /* 104 */ 7, /* 112 */ 7, /* 120 */ 7, /* 128 */ 2, /* 136 */ 2, /* 144 */ 2, /* 152 */ 2, /* 160 */ 2, /* 168 */ 2, /* 176 */ 2, /* 184 */ 2 /* 192 */&#125;;//根据分配标志返回枚举类型，其实是0、1、2其中之一static __always_inline enum kmalloc_cache_type kmalloc_type(gfp_t flags)&#123; #ifdef CONFIG_ZONE_DMA if (likely((flags &amp; (__GFP_DMA | __GFP_RECLAIMABLE)) == 0)) return KMALLOC_NORMAL; return flags &amp; __GFP_DMA ? KMALLOC_DMA : KMALLOC_RECLAIM; #else return flags &amp; __GFP_RECLAIMABLE ? KMALLOC_RECLAIM : KMALLOC_NORMAL; #endif&#125;struct kmem_cache *kmalloc_slab(size_t size, gfp_t flags)&#123; unsigned int index; //计算出index if (size &lt;= 192) &#123; if (!size) return ZERO_SIZE_PTR; index = size_index[size_index_elem(size)]; &#125; else &#123; if (WARN_ON_ONCE(size &gt; KMALLOC_MAX_CACHE_SIZE)) return NULL; index = fls(size - 1); &#125; return kmalloc_caches[kmalloc_type(flags)][index];&#125;// ---------------------------------// 建立 kmalloc_caches 中的 kmem_cache// ---------------------------------struct kmem_cache *__init create_kmalloc_cache(const char *name,unsigned int size, slab_flags_t flags,unsigned int useroffset, unsigned int usersize)&#123; //从第一个kmem_cache中分配一个对象放kmem_cache struct kmem_cache *s = kmem_cache_zalloc(kmem_cache, GFP_NOWAIT); if (!s) panic(&quot;Out of memory when creating slab %s\\n&quot;, name); //设置s的对齐参数，处理s的freelist就是arr_cache create_boot_cache(s, name, size, flags, useroffset, usersize); list_add(&amp;s-&gt;list, &amp;slab_caches); s-&gt;refcount = 1; return s;&#125;//新建一个kmem_cachestatic void __init new_kmalloc_cache(int idx, enum kmalloc_cache_type type, sl&#123; if (type == KMALLOC_RECLAIM) flags |= SLAB_RECLAIM_ACCOUNT; //根据kmalloc_info中信息建立一个kmem_cache kmalloc_caches[type][idx] = create_kmalloc_cache( kmalloc_info[idx].name[type], kmalloc_info[idx].size, flags, 0, kmalloc_info[idx].size);&#125;//建立所有的kmalloc_caches中的kmem_cachevoid __init create_kmalloc_caches(slab_flags_t flags)&#123;int i;enum kmalloc_cache_type type;for (type = KMALLOC_NORMAL; type &lt;= KMALLOC_RECLAIM; type++) &#123; for (i = KMALLOC_SHIFT_LOW; i &lt;= KMALLOC_SHIFT_HIGH; i++) &#123; if (!kmalloc_caches[type][i]) //建立一个新的kmem_cache new_kmalloc_cache(i, type, flags); if (KMALLOC_MIN_SIZE &lt;= 32 &amp;&amp; i == 6 &amp;&amp; !kmalloc_caches[type][1]) new_kmalloc_cache(1, type, flags); if (KMALLOC_MIN_SIZE &lt;= 64 &amp;&amp; i == 7 &amp;&amp; !kmalloc_caches[type][2]) new_kmalloc_cache(2, type, flags); &#125; &#125;&#125;// -------// 分配对象// -------static __always_inline void *slab_alloc(struct kmem_cache *cachep, gfp_t flags&#123; unsigned long save_flags; void *objp; //关中断 local_irq_save(save_flags); //分配对象 objp = __do_cache_alloc(cachep, flags); //恢复中断 local_irq_restore(save_flags); return objp;&#125;// 真正干活的 \\__do_cache_alloc函数static inline void *____cache_alloc(struct kmem_cache *cachep, gfp_t flags)&#123; void *objp; struct array_cache *ac; //获取当前cpu在cachep结构中的array_cache结构的指针 ac = cpu_cache_get(cachep); //如果ac中的avail不为0,说明当前kmem_cache结构中freelist是有空闲对象 if (likely(ac-&gt;avail)) &#123; ac-&gt;touched = 1; //空间对象的地址保存在ac-&gt;entry objp = ac-&gt;entry[--ac-&gt;avail]; goto out; &#125; objp = cache_alloc_refill(cachep, flags); out: return objp;&#125;static __always_inline void *__do_cache_alloc(struct kmem_cache *cachep, gfp_t&#123; return ____cache_alloc(cachep, flags);&#125;// cache_alloc_refill函数static struct page *get_first_slab(struct kmem_cache_node *n, bool pfmemalloc)&#123; struct page *page; assert_spin_locked(&amp;n-&gt;list_lock); //首先从kmem_cache_node结构中的slabs_partial链表上查看有没有page page = list_first_entry_or_null(&amp;n-&gt;slabs_partial, struct page,slab_list); if (!page) &#123; //如果没有 n-&gt;free_touched = 1; //从kmem_cache_node结构中的slabs_free链表上查看有没有page page = list_first_entry_or_null(&amp;n-&gt;slabs_free, struct page,slab_list) if (page) n-&gt;free_slabs--; //空闲slab计数减一 &#125; //返回page return page;&#125;static void *cache_alloc_refill(struct kmem_cache *cachep, gfp_t flags)&#123; int batchcount; struct kmem_cache_node *n; struct array_cache *ac, *shared; int node; void *list = NULL; struct page *page; //获取内存节点 node = numa_mem_id(); ac = cpu_cache_get(cachep); batchcount = ac-&gt;batchcount; //获取cachep所属的kmem_cache_node n = get_node(cachep, node); shared = READ_ONCE(n-&gt;shared); if (!n-&gt;free_objects &amp;&amp; (!shared || !shared-&gt;avail)) goto direct_grow; while (batchcount &gt; 0) &#123; //获取kmem_cache_node结构中其它kmem_cache,返回的是page，而page会指向kmem_cac page = get_first_slab(n, false); if (!page) goto must_grow; batchcount = alloc_block(cachep, ac, page, batchcount); &#125; must_grow: n-&gt;free_objects -= ac-&gt;avail; direct_grow: if (unlikely(!ac-&gt;avail)) &#123; //分配新的kmem_cache并初始化 page = cache_grow_begin(cachep, gfp_exact_node(flags), node); ac = cpu_cache_get(cachep); if (!ac-&gt;avail &amp;&amp; page) alloc_block(cachep, ac, page, batchcount); //让page挂载到kmem_cache_node结构的slabs_list链表上 cache_grow_end(cachep, page); if (!ac-&gt;avail) return NULL; &#125; ac-&gt;touched = 1; //重新分配 return ac-&gt;entry[--ac-&gt;avail];&#125; 7 进程 7.1 到底什么是进程 在linux下使用ps命令,可以看出系统有多少个进程 展示的只是具体进程的数据(如创建进程和用户,进程ID,使用CPU的百分比,进程运行状态,进程的建立时间,进程的运行时间,进程名等综合起来代表一个进程) 什么是进程 进程是一个应用程序运行时的实例(从进程的结构);进程是应用程序运行时所需资源的容器(进程的功能);甚至进程是一堆数据结构(从操作系统对进程实现的角度) 进程的结构 进程是一个应用程序运行时刻的实例,目的是操作系统用于管理和运行多个应用程序;其次从实现的内存管理组件角度看,操作系统是给应用程序提供服务的 进程必须要有一个地址空间,地址空间至少包括两部分内容:一部分是内核,一部分是用户的应用程序 整体结构 上图中8个进程,每个进程拥有x86 CPU的整个虚拟地址空间，虚拟地址空间被分成两部分,上半部分是所有进程都共享的内核部分,里面放着一份内核代码和数据,下半部分是应用程序,分别独立,互不干扰 CPU在R0特权级运行时,就运行在上半部分内核的地址空间中 CPU在R3特权级时,就运行在下半部分的应用程序地址空间中 各进程的虚拟地址空间相同,之间的物理地址不同,由MMU页进行隔离,所以每个进程的应用程序不能随意访问内核代码和数据 细节结构 从应用程序和内核的关系看,应用程序需要提供资源,内核需要控制应用程序的运行,内核必须能命令应用程序让它随时中断(进入内核地址空间)或恢复执行，因此需要保存应用程序的机器上下文和运行时刻的栈 内核提供服务的机制:通过停止应用程序代码执行,进入内核地址空间运行内核代码,然后返回结果 使用资源描述符,表示打开某个文件或访问某个设备的记录表 进程细化结构中,带*号的是每个进程都独立一份的,根据该细化结构可以实现多个进程并发运行 如何表示一个进程 一个进程有状态,id,运行时间,优先级,应用程序栈,内核栈您机器上下文,资源描述符,地址空间等信息 使用 thread_t 结构的一个实例变量代表一个进程,进程的内核栈和进程的应用程序栈是两块内存空间,进程的权限表示一个进程是用户进程还是系统进程(权限不同完成功能不同) 进程有64个优先级,td_priority 数值越小，优先级越高 td_handtbl 只是一个 objnode_t 结构的指针类型数组 进程的地址空间 在 thread_t 结构中有 mmadrsdsc_t 结构的指针，在结构中有虚拟地址区间结构和 MMU 相关信息 mmadrsdsc_t 结构描述了一个进程的完整地址空间; 常规情况下,新建进程就要建立一个 mmadrsdsc_t 结构,让 thread_t 结构的 td_mmdsc 的指针变量指向它 进程的机器上下文 一部分是CPU寄存器,一部分是内核函数调用路径 CPU的通用寄存器,是中断发生进入内核时,压入内核栈中的,从中断入口处开始调用的函数,都是属于内核的函数 函数的调用路径存在内核栈中,进程调度器函数会调用进程切换函数,完成切换进程操作后,在进程切换函数中保存栈寄存器的值 context_t 结构中的 x64tss_t 结构的指针是CPU要求的一个结构,结构本身的地址放在一个 GDT 表项中 由CPU的tr寄存器指向,tr寄存器中的值是 GDT 中x64tss_t结构项对应的索引 CPU 发生中断时，会根据中断门描述里的目标段选择子，进行必要的特权级切换，特权级的切换就必须要切换栈，CPU 硬件会自己把当前 rsp 寄存器保存到内部的临时寄存器tmprsp；然后从 x64tss_t 结构体中找出对应的栈地址，装入 rsp 寄存器中；接着，再把当前的 ss、tmprsp、rflags、cs、rip，依次压入当前 rsp 指向的栈中 建立进程 建立进程不是建立 thread_t 结构的实例变量,还需要建立进程的应用程序栈和进程的内核栈，进程地址空间等 建立进程接口 接口函数在 cosmos/kernel/krlthread.c krlnew_thread 函数对参数进行合理检查,参数为应用程序启动运行的地址,创建标志,进程权限和进程优先级,进程的应用程序栈和内核栈大小 进程对栈的大小有要求,小于默认8kb就使用默认的栈大小,最后根据创建标志确认是建立内核态进程还是建立普通进程 建立内核进程 内核进程是用进程的方式运行一段内核代码,那么这段代码就可以随时暂停或继续运行,又或者和其他代码段并发运行,只有这种进程永远不会回到进程应用程序地址空间中去,只会在内核地址空间中运行 代码逻辑:首先分配一个内核栈的内存空间,接着创建 thread_t 结构的实例变量,然后对 thread_t 结构体的字段进行设置,最后初始化进程内核栈把这个新进程加入到进程的调度系统中 创建 thread_t 结构 创建 thread_t 结构其实就是分配一块内存用于存放 thread_t 结构的实例变量 首先以 thread_t 结构地地址作为进程的ID(具有唯一性); 其次目前没有为一个进程分配 mmadrsdsc_t 结构体,而是指向了默认的地址空间结构 initmmadrsdsc; 最后,hal_retn_cpuid 函数在目前情况下永远为0(因为使用了一个CPU) 初始化内核栈 初始化内核栈是为了在进程的内核栈中放置一份CPU的寄存器数据(一个进程机器上下文的一部分) 当一个进程开始运行时,将会pop指令从进程的内核栈弹出到CPU中,CPU开始运行进程,CPU的一些寄存器有位置关系需要一个结构体来操作 intstkregs_t 结构中,每个字段都是8字节64位的,x86CPU在长模式下rsp栈指针寄存器始终8字节对齐 栈是向下伸长(从高地址向低地址),结构是反向定义 建立普通进程 在建立进程的接口函数 krlnew_thread 进程中,会根据参数 flg 的值选择调用不同的函数来建立不同类型的进程 和建立内核进程相比，建立普通进程有两点不同 第一，多分配了一个应用程序栈。因为内核进程不会返回到进程的应用程序空间，所以不需要应用程序栈，而普通进程则需要； 第二，在最后调用的是 krlthread_userstack_init 函数，该函数初始化返回进程应用程序空间的内核栈 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355// -------// 进程结构// -------// cosmos/include/knlinc/krlthread_t.htypedef struct s_THREAD&#123; spinlock_t td_lock; //进程的自旋锁 list_h_t td_list; //进程链表 uint_t td_flgs; //进程的标志 uint_t td_stus; //进程的状态 uint_t td_cpuid; //进程所在的CPU的id uint_t td_id; //进程的id uint_t td_tick; //进程运行了多少tick uint_t td_privilege; //进程的权限 uint_t td_priority; //进程的优先级 uint_t td_runmode; //进程的运行模式 adr_t td_krlstktop; //应用程序内核栈顶地址 adr_t td_krlstkstart; //应用程序内核栈开始地址 adr_t td_usrstktop; //应用程序栈顶地址 adr_t td_usrstkstart; //应用程序栈开始地址 mmadrsdsc_t* td_mmdsc; //地址空间结构 context_t td_context; //机器上下文件结构 objnode_t* td_handtbl[TD_HAND_MAX];//打开的对象数组&#125;thread_t;// ------------// 进程的地址空间// ------------typedef struct s_MMADRSDSC&#123; spinlock_t msd_lock; //保护自身的自旋锁 list_h_t msd_list; //链表 uint_t msd_flag; //状态和标志 uint_t msd_stus; uint_t msd_scount; //计数，该结构可能被共享 sem_t msd_sem; //信号量 mmudsc_t msd_mmu; //MMU页表相关的信息 virmemadrs_t msd_virmemadrs; //虚拟地址空间结构 adr_t msd_stext; //应用的指令区的开始、结束地址 adr_t msd_etext; adr_t msd_sdata; //应用的数据区的开始、结束地址 adr_t msd_edata; adr_t msd_sbss; //应用初始化为0的区域开始、结束地址 adr_t msd_ebss; adr_t msd_sbrk; //应用的堆区的开始、结束地址 adr_t msd_ebrk;&#125;mmadrsdsc_t;// ------------// 进程的机器上下文// ------------typedef struct s_CONTEXT&#123; uint_t ctx_nextrip; //保存下一次运行的地址 uint_t ctx_nextrsp; //保存下一次运行时内核栈的地址 x64tss_t* ctx_nexttss; //指向tss结构&#125;context_t;// cosmos/hal/x86/halglobal.c// 每个CPU核心一个tssHAL_DEFGLOB_VARIABLE(x64tss_t,x64tss)[CPUCORE_MAX];typedef struct s_X64TSS&#123;u32_t reserv0; //保留u64_t rsp0; //R0特权级的栈地址u64_t rsp1; //R1特权级的栈地址，我们未使用u64_t rsp2; //R2特权级的栈地址，我们未使用u64_t reserv28;//保留u64_t ist[7]; //我们未使用u64_t reserv92;//保留u16_t reserv100;//保留u16_t iobase; //我们未使用&#125;__attribute__((packed)) x64tss_t;// ---------------// 建立进程接口// cosmos/kernel/krlthread.c// ---------------thread_t *krlnew_thread(void *filerun, uint_t flg, uint_t prilg, uint_t prity,&#123; size_t tustksz = usrstksz, tkstksz = krlstksz; //对参数进行检查，不合乎要求就返回NULL表示创建失败 if (filerun == NULL || usrstksz &gt; DAFT_TDUSRSTKSZ || krlstksz &gt; DAFT_TDKRL &#123; return NULL; &#125; if ((prilg != PRILG_USR &amp;&amp; prilg != PRILG_SYS) || (prity &gt;= PRITY_MAX)) &#123; return NULL; &#125; //进程应用程序栈大小检查，大于默认大小则使用默认大小 if (usrstksz &lt; DAFT_TDUSRSTKSZ) &#123; tustksz = DAFT_TDUSRSTKSZ; &#125; //进程内核栈大小检查，大于默认大小则使用默认大小 if (krlstksz &lt; DAFT_TDKRLSTKSZ) &#123; tkstksz = DAFT_TDKRLSTKSZ; &#125; //是否建立内核进程 if (KERNTHREAD_FLG == flg) &#123; return krlnew_kern_thread_core(filerun, flg, prilg, prity, tustksz, tk &#125; //是否建立普通进程 else if (USERTHREAD_FLG == flg) &#123; return krlnew_user_thread_core(filerun, flg, prilg, prity, tustksz, tk &#125; return NULL;&#125;// ------------// 建立内核态进程// ------------thread_t *krlnew_kern_thread_core(void *filerun, uint_t flg, uint_t prilg, uin&#123; thread_t *ret_td = NULL; bool_t acs = FALSE; adr_t krlstkadr = NULL; //分配内核栈空间 krlstkadr = krlnew(krlstksz); if (krlstkadr == NULL) &#123; return NULL; &#125; //建立thread_t结构体的实例变量 ret_td = krlnew_thread_dsc(); if (ret_td == NULL) &#123;//创建失败必须要释放之前的栈空间 acs = krldelete(krlstkadr, krlstksz); if (acs == FALSE) &#123; return NULL; &#125; return NULL; &#125; //设置进程权限 ret_td-&gt;td_privilege = prilg; //设置进程优先级 ret_td-&gt;td_priority = prity; //设置进程的内核栈顶和内核栈开始地址 ret_td-&gt;td_krlstktop = krlstkadr + (adr_t)(krlstksz - 1); ret_td-&gt;td_krlstkstart = krlstkadr; //初始化进程的内核栈 krlthread_kernstack_init(ret_td, filerun, KMOD_EFLAGS); //加入进程调度系统 krlschdclass_add_thread(ret_td); //返回进程指针 return ret_td;&#125;// -----------------// 创建 thread_t 结构// -----------------//初始化context_t结构void context_t_init(context_t *initp)&#123;initp-&gt;ctx_nextrip = 0;initp-&gt;ctx_nextrsp = 0;//指向当前CPU的tssinitp-&gt;ctx_nexttss = &amp;x64tss[hal_retn_cpuid()];return;&#125;//返回进程id其实就thread_t结构的地址uint_t krlretn_thread_id(thread_t *tdp)&#123;return (uint_t)tdp;&#125;//初始化thread_t结构void thread_t_init(thread_t *initp)&#123;krlspinlock_init(&amp;initp-&gt;td_lock);list_init(&amp;initp-&gt;td_list);initp-&gt;td_flgs = TDFLAG_FREE;initp-&gt;td_stus = TDSTUS_NEW;//进程状态为新建initp-&gt;td_cpuid = hal_retn_cpuid();initp-&gt;td_id = krlretn_thread_id(initp);initp-&gt;td_tick = 0;initp-&gt;td_privilege = PRILG_USR;//普通进程权限initp-&gt;td_priority = PRITY_MIN;//最高优先级initp-&gt;td_runmode = 0;initp-&gt;td_krlstktop = NULL;initp-&gt;td_krlstkstart = NULL;initp-&gt;td_usrstktop = NULL;initp-&gt;td_usrstkstart = NULL;initp-&gt;td_mmdsc = &amp;initmmadrsdsc;//指向默认的地址空间结构context_t_init(&amp;initp-&gt;td_context);//初始化td_handtbl数组for (uint_t hand = 0; hand &lt; TD_HAND_MAX; hand++)&#123;initp-&gt;td_handtbl[hand] = NULL;&#125;return;&#125;//创建thread_t结构thread_t *krlnew_thread_dsc()&#123;//分配thread_t结构大小的内存空间thread_t *rettdp = (thread_t *)(krlnew((size_t)(sizeof(thread_t))));if (rettdp == NULL)&#123;return NULL;&#125;//初始化刚刚分配的thread_t结构thread_t_init(rettdp);return rettdp;&#125;// -------------// 初始化内核栈// -------------typedef struct s_INTSTKREGS&#123; uint_t r_gs; uint_t r_fs; uint_t r_es; uint_t r_ds; //段寄存器 uint_t r_r15; uint_t r_r14; uint_t r_r13; uint_t r_r12; uint_t r_r11; uint_t r_r10; uint_t r_r9; uint_t r_r8; uint_t r_rdi; uint_t r_rsi; uint_t r_rbp; uint_t r_rdx; //通用寄存器 uint_t r_rcx; uint_t r_rbx; uint_t r_rax; uint_t r_rip_old;//程序的指针寄存器 uint_t r_cs_old;//代码段寄存器 uint_t r_rflgs; //rflags标志寄存 uint_t r_rsp_old;//栈指针寄存器 uint_t r_ss_old; //栈段寄存器&#125;intstkregs_t;// 初始化内核栈void krlthread_kernstack_init(thread_t *thdp, void *runadr, uint_t cpuflags)&#123; //处理栈顶16字节对齐 thdp-&gt;td_krlstktop &amp;= (~0xf); thdp-&gt;td_usrstktop &amp;= (~0xf); //内核栈顶减去intstkregs_t结构的大小 intstkregs_t *arp = (intstkregs_t *)(thdp-&gt;td_krlstktop - sizeof(intstkreg //把intstkregs_t结构的空间初始化为0 hal_memset((void*)arp, 0, sizeof(intstkregs_t)); //rip寄存器的值设为程序运行首地址 arp-&gt;r_rip_old = (uint_t)runadr; //cs寄存器的值设为内核代码段选择子 arp-&gt;r_cs_old = K_CS_IDX; arp-&gt;r_rflgs = cpuflags; //返回进程的内核栈 arp-&gt;r_rsp_old = thdp-&gt;td_krlstktop; arp-&gt;r_ss_old = 0; //其它段寄存器的值设为内核数据段选择子 arp-&gt;r_ds = K_DS_IDX; arp-&gt;r_es = K_DS_IDX; arp-&gt;r_fs = K_DS_IDX; arp-&gt;r_gs = K_DS_IDX; //设置进程下一次运行的地址为runadr thdp-&gt;td_context.ctx_nextrip = (uint_t)runadr; //设置进程下一次运行的栈地址为arp thdp-&gt;td_context.ctx_nextrsp = (uint_t)arp; return;&#125;// 初始化返回进程应用程序空间的内核栈void krlthread_userstack_init(thread_t *thdp, void *runadr, uint_t cpuflags)&#123; //处理栈顶16字节对齐 thdp-&gt;td_krlstktop &amp;= (~0xf); thdp-&gt;td_usrstktop &amp;= (~0xf); //内核栈顶减去intstkregs_t结构的大小 intstkregs_t *arp = (intstkregs_t *)(thdp-&gt;td_krlstktop - sizeof(intstkregs_t)); //把intstkregs_t结构的空间初始化为0 hal_memset((void*)arp, 0, sizeof(intstkregs_t)); //rip寄存器的值设为程序运行首地址 arp-&gt;r_rip_old = (uint_t)runadr; //cs寄存器的值设为应用程序代码段选择子 arp-&gt;r_cs_old = U_CS_IDX; arp-&gt;r_rflgs = cpuflags; //返回进程应用程序空间的栈 arp-&gt;r_rsp_old = thdp-&gt;td_usrstktop; //其它段寄存器的值设为应用程序数据段选择子 arp-&gt;r_ss_old = U_DS_IDX; arp-&gt;r_ds = U_DS_IDX; arp-&gt;r_es = U_DS_IDX; arp-&gt;r_fs = U_DS_IDX; arp-&gt;r_gs = U_DS_IDX; //设置进程下一次运行的地址为runadr thdp-&gt;td_context.ctx_nextrip = (uint_t)runadr; //设置进程下一次运行的栈地址为arp thdp-&gt;td_context.ctx_nextrsp = (uint_t)arp; return;&#125;// 初始化进程的内核栈所使用的段选择子指向的是应用程序的代码段和数据段，这个代码段和数据段它们特权级为 R3，CPU 正是根据这个代码段、数据段选择子来切换 CPU 工作特权级的// -----------// 建立普通进程// -----------thread_t *krlnew_user_thread_core(void *filerun, uint_t flg, uint_t prilg, uin&#123; thread_t *ret_td = NULL; bool_t acs = FALSE; adr_t usrstkadr = NULL, krlstkadr = NULL; //分配应用程序栈空间 usrstkadr = krlnew(usrstksz); if (usrstkadr == NULL) &#123; return NULL; &#125; //分配内核栈空间 krlstkadr = krlnew(krlstksz); if (krlstkadr == NULL) &#123; if (krldelete(usrstkadr, usrstksz) == FALSE) &#123; return NULL; &#125; return NULL; &#125; //建立thread_t结构体的实例变量 ret_td = krlnew_thread_dsc(); //创建失败必须要释放之前的栈空间 if (ret_td == NULL) &#123; acs = krldelete(usrstkadr, usrstksz); acs = krldelete(krlstkadr, krlstksz); if (acs == FALSE) &#123; return NULL; &#125; return NULL; &#125; //设置进程权限 ret_td-&gt;td_privilege = prilg; //设置进程优先级 ret_td-&gt;td_priority = prity; //设置进程的内核栈顶和内核栈开始地址 ret_td-&gt;td_krlstktop = krlstkadr + (adr_t)(krlstksz - 1); ret_td-&gt;td_krlstkstart = krlstkadr; //设置进程的应用程序栈顶和内核应用程序栈开始地址 ret_td-&gt;td_usrstktop = usrstkadr + (adr_t)(usrstksz - 1); ret_td-&gt;td_usrstkstart = usrstkadr; //初始化返回进程应用程序空间的内核栈 krlthread_userstack_init(ret_td, filerun, UMOD_EFLAGS); //加入调度器系统 krlschdclass_add_thread(ret_td); return ret_td;&#125; 7.2 多进程如何调度 为什么需要多进程调度 第一,CPU同一时刻只能运行一个进程,而CPU个数总是比进程个数少,需要让多进程共用一个CPU,每个进程在这个CPU上运行一段时间 第二,当一个进程不能获取某种资源,导致不能继续运行时就应该让出CPU;进程拿不到资源就要让出CPU 进程的生命周期 进程的生命周期,通常用进程的状态表示 只用宏来定义进程的状态 进程僵尸状态,表示进程将要系统不再进行调度 12345#define TDSTUS_RUN 0 //进程运行状态#define TDSTUS_SLEEP 3 //进程睡眠状态#define TDSTUS_WAIT 4 //进程等待状态#define TDSTUS_NEW 5 //进程新建状态#define TDSTUS_ZOMB 6 //进程僵死状态 如何组织进程 系统中会随时分配或删除 thread_t 结构 最简单的处理办法就是使用链表数据结构,但进程有优先级,可以设计成每一个优先级对应一个链表头 schedclass_t 是一个全局数据结构,包含一个 schdata_t结构数组,数组大小根据CPU的数量决定,每个 schdata_t 结构中,又包含一个进程优先级大小的 thrdlst_t 结构数组 123456789101112131415161718192021222324252627// 由于是调度器模块,故需要建立 krlsched.h 和 krlsched.ctypedef struct s_THRDLST&#123;list_h_t tdl_lsth; //挂载进程的链表头thread_t* tdl_curruntd; //该链表上正在运行的进程uint_t tdl_nr; //该链表上进程个数&#125;thrdlst_t;typedef struct s_SCHDATA&#123;spinlock_t sda_lock; //自旋锁uint_t sda_cpuid; //当前CPU iduint_t sda_schdflgs; //标志uint_t sda_premptidx; //进程抢占计数uint_t sda_threadnr; //进程数uint_t sda_prityidx; //当前优先级thread_t* sda_cpuidle; //当前CPU的空转进程thread_t* sda_currtd; //当前正在运行的进程thrdlst_t sda_thdlst[PRITY_MAX]; //进程链表数组&#125;schdata_t;typedef struct s_SCHEDCALSS&#123;spinlock_t scls_lock; //自旋锁uint_t scls_cpunr; //CPU个数uint_t scls_threadnr; //系统中所有的进程数uint_t scls_threadid_inc; //分配进程id所用schdata_t scls_schda[CPUCORE_MAX]; //每个CPU调度数据结构&#125;schedclass_t; 管理进程的初始化 就是对 schdata_t 结构的变量的初始化 schdata_t 结构的变量应该是全局变量,所以在 cosmos/kernel/krlglobal.c文件中定义 schedclass_t 结构的全局变量 在 cosmos/kernel/krlsched.c文件中写初始化 osschedcls 变量的代码 由 init_krlsched 函数调用 schedclass_t_init 函数,对 osschedcls 变量进行初始化工作 init_krlsched 函数由 cosmos/kernel/krlinit.c文件中的init_krl 函数中调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950KRL_DEFGLOB_VARIABLE(schedclass_t,osschedcls);void thrdlst_t_init(thrdlst_t *initp)&#123;list_init(&amp;initp-&gt;tdl_lsth); //初始化挂载进程的链表initp-&gt;tdl_curruntd = NULL; //开始没有运行进程initp-&gt;tdl_nr = 0; //开始没有进程return;&#125;void schdata_t_init(schdata_t *initp)&#123;krlspinlock_init(&amp;initp-&gt;sda_lock);initp-&gt;sda_cpuid = hal_retn_cpuid(); //获取CPU idinitp-&gt;sda_schdflgs = NOTS_SCHED_FLGS;initp-&gt;sda_premptidx = 0;initp-&gt;sda_threadnr = 0;initp-&gt;sda_prityidx = 0;initp-&gt;sda_cpuidle = NULL; //开始没有空转进程和运行的进程initp-&gt;sda_currtd = NULL;for (uint_t ti = 0; ti &lt; PRITY_MAX; ti++)&#123;//初始化schdata_t结构中的每个thrdlst_t结构thrdlst_t_init(&amp;initp-&gt;sda_thdlst[ti]);&#125;return;&#125;void schedclass_t_init(schedclass_t *initp)&#123;krlspinlock_init(&amp;initp-&gt;scls_lock);initp-&gt;scls_cpunr = CPUCORE_MAX; //CPU最大个数initp-&gt;scls_threadnr = 0; //开始没有进程initp-&gt;scls_threadid_inc = 0;for (uint_t si = 0; si &lt; CPUCORE_MAX; si++)&#123;//初始化osschedcls变量中的每个schdata_tschdata_t_init(&amp;initp-&gt;scls_schda[si]);&#125;return;&#125;void init_krlsched()&#123; //初始化osschedcls变量schedclass_t_init(&amp;osschedcls);return;&#125;// init_krl 函数void init_krl()&#123;init_krlsched();die(0);//控制不让init_krl函数返回return;&#125; 设计实现进程调度器 进程调度器是为了在合适的时间点,合适的代码执行路径上进行进程调度(从当前运行进程切换到另一个进程上裕兴,让当前进程停止运行,由CPU开始执行另一个进程的代码) 进程调度器入口 进程调度器为函数:确定当前正在运行的进程,然后选择下一个将要运行的进程,最后从当前运行的进程,切换到下一个将要运行的进程 如何获取当前运行的进程 目的:为了保存当前进程的运行上下文,确保在下一次调度到当前运行的进程时能恢复运行 每次切换到下一个进程运行时会将下一个运行的进程设置为当前运行的进程 schdata_t 结构中的 sda_currtd 字段正是保存当前正在运行进程的过程,返回这个字段的值就能取得当前正在运行的进程 选择下一个进程 根据调度器入口函数的设计,取得了当前正在运行的进程之后,下一步就是选择下个将要投入运行的进程 进程调度算法的核心:关乎到进程的吞吐量,能否及时响应请求,CPU的利用率,各个进程之间运行获取资源的公平性,影响整个操作系统的性能,可靠性 实现简单的优先级调度算法:始终选择优先级最高的进程作为下一个运行的进程 首先，从高到低扫描优先级进程链表，然后若当前优先级进程链表不为空，就取出该链表上的第一个进程，放入 thrdlst_t 结构中的 tdl_curruntd 字段中，并把之前 thrdlst_t 结构的 tdl_curruntd 字段中的进程挂入该链表的尾部，并返回 最后，当扫描到最低优先级时也没有找到进程，就返回默认的空转进程 获取空转进程 在选择下一个进程的函数中,若没有找到合适的进程返回默认的空转进程 调度器的功能必须完成从一个进程到下一个进程的切换,若没有下一个进程,而上一个进程又不能运行，调度器将无路可去，整个系统将停止，故需要为系统留下一个空转进程 进程切换 函数调用路径是通过栈来保存的,对于运行在内核空间中的进程就是保存在对应的内核栈中 进程切换函数: 首先，把当前进程的通用寄存器保存到当前进程的内核栈中 然后，保存 CPU 的 RSP寄存器到当前进程的机器上下文结构中，并且读取保存在下一个进程机器上下文结构中的RSP 的值，把它存到 CPU 的 RSP 寄存器中 接着，调用一个函数切换 MMU 页表 最后，从下一个进程的内核栈中恢复下一个进程的通用寄存器 save_to_new_context 进程切换函数:通过切换进程的内核栈导致切换进程 因为进程的函数调用路径就保存在对应的内核栈中，只要调用 krlschedul 函数，最后的函数调用路径一定会停在 save_to_new_context 函数中，当 save_to_new_context 函数一返回，就会导致回到调用save_to_new_context 函数的 krlschedul 函数中，最后层层返回 切换机制能正常运行必须保证下一个进程被正常调用过,即调用过 krlschedul 函数 在 _to_new_context 函数中完成该特殊操作 __to_new_context 负责设置当前运行的进程，处理 CPU 发生中断时需要切换栈的问题，又切换了一个进程的 MMU 页表（即使用新进程的地址空间），最后如果是新建进程第一次运行，就调用 retnfrom_first_sched 函数进行处理 retnfrom_first_sched 函数不会返回到调用它的 __to_new_context 函数中，而是直接运行新建进程的相关代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185// 进程调度器的入口函数void krlschedul()&#123; thread_t *prev = krlsched_retn_currthread(),//返回当前运行进程 *next = krlsched_select_thread();//选择下一个运行的进程 save_to_new_context(next, prev);//从当前进程切换到下一个进程 return;&#125;// 获取当前运行进程函数thread_t *krlsched_retn_currthread()&#123; uint_t cpuid = hal_retn_cpuid(); //通过cpuid获取当前cpu的调度数据结构 schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid]; if (schdap-&gt;sda_currtd == NULL) &#123;//若调度数据结构中当前运行进程的指针为空，就出错死机 hal_sysdie(&quot;schdap-&gt;sda_currtd NULL&quot;); &#125; return schdap-&gt;sda_currtd;//返回当前运行的进程&#125;// 简单的优先级调度算法thread_t *krlsched_select_thread()&#123;thread_t *retthd, *tdtmp;cpuflg_t cufg;uint_t cpuid = hal_retn_cpuid();schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid];krlspinlock_cli(&amp;schdap-&gt;sda_lock, &amp;cufg);for (uint_t pity = 0; pity &lt; PRITY_MAX; pity++)&#123;//从最高优先级开始扫描if (schdap-&gt;sda_thdlst[pity].tdl_nr &gt; 0)&#123;//若当前优先级的进程链表不为空if (list_is_empty_careful(&amp;(schdap-&gt;sda_thdlst[pity].tdl_lsth)) ==&#123;//取出当前优先级进程链表下的第一个进程tdtmp = list_entry(schdap-&gt;sda_thdlst[pity].tdl_lsth.next, thrlist_del(&amp;tdtmp-&gt;td_list);//脱链if (schdap-&gt;sda_thdlst[pity].tdl_curruntd != NULL)&#123;//将这sda_thdlst[pity].tdl_curruntd的进程挂入链表尾list_add_tail(&amp;(schdap-&gt;sda_thdlst[pity].tdl_curruntd-&gt;td_&#125;schdap-&gt;sda_thdlst[pity].tdl_curruntd = tdtmp;retthd = tdtmp;//将选择的进程放入sda_thdlst[pity].tdl_curruntd中，goto return_step;&#125;if (schdap-&gt;sda_thdlst[pity].tdl_curruntd != NULL)&#123;//若sda_thdlst[pity].tdl_curruntd不为空就直接返回它retthd = schdap-&gt;sda_thdlst[pity].tdl_curruntd;goto return_step;&#125;&#125;&#125;//如果最后也没有找到进程就返回默认的空转进程schdap-&gt;sda_prityidx = PRITY_MIN;retthd = krlsched_retn_idlethread();return_step://解锁并返回进程krlspinunlock_sti(&amp;schdap-&gt;sda_lock, &amp;cufg);return retthd;&#125;// 获取空转进程的函数thread_t *krlsched_retn_idlethread()&#123;uint_t cpuid = hal_retn_cpuid();//通过cpuid获取当前cpu的调度数据结构schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid];if (schdap-&gt;sda_cpuidle == NULL)&#123;//若调度数据结构中空转进程的指针为空，就出错死机hal_sysdie(&quot;schdap-&gt;sda_cpuidle NULL&quot;);&#125;return schdap-&gt;sda_cpuidle;//返回空转进程&#125;// 进程切换函数void save_to_new_context(thread_t *next, thread_t *prev)&#123; __asm__ __volatile__( &quot;pushfq \\n\\t&quot;//保存当前进程的标志寄存器 &quot;cli \\n\\t&quot; //关中断 //保存当前进程的通用寄存器 &quot;pushq %%rax\\n\\t&quot; &quot;pushq %%rbx\\n\\t&quot; &quot;pushq %%rcx\\n\\t&quot; &quot;pushq %%rdx\\n\\t&quot; &quot;pushq %%rbp\\n\\t&quot; &quot;pushq %%rsi\\n\\t&quot; &quot;pushq %%rdi\\n\\t&quot; &quot;pushq %%r8\\n\\t&quot; &quot;pushq %%r9\\n\\t&quot; &quot;pushq %%r10\\n\\t&quot; &quot;pushq %%r11\\n\\t&quot; &quot;pushq %%r12\\n\\t&quot; &quot;pushq %%r13\\n\\t&quot; &quot;pushq %%r14\\n\\t&quot; &quot;pushq %%r15\\n\\t&quot; //保存CPU的RSP寄存器到当前进程的机器上下文结构中 &quot;movq %%rsp,%[PREV_RSP] \\n\\t&quot; //把下一个进程的机器上下文结构中的RSP的值，写入CPU的RSP寄存器中 &quot;movq %[NEXT_RSP],%%rsp \\n\\t&quot;//事实上这里已经切换到下一个进程了，因为切换进程的 //调用__to_new_context函数切换MMU页表 &quot;callq __to_new_context\\n\\t&quot; //恢复下一个进程的通用寄存器 &quot;popq %%r15\\n\\t&quot; &quot;popq %%r14\\n\\t&quot; &quot;popq %%r13\\n\\t&quot; &quot;popq %%r12\\n\\t&quot; &quot;popq %%r11\\n\\t&quot; &quot;popq %%r10\\n\\t&quot; &quot;popq %%r9\\n\\t&quot; &quot;popq %%r8\\n\\t&quot; &quot;popq %%rdi\\n\\t&quot; &quot;popq %%rsi\\n\\t&quot; &quot;popq %%rbp\\n\\t&quot; &quot;popq %%rdx\\n\\t&quot; &quot;popq %%rcx\\n\\t&quot; &quot;popq %%rbx\\n\\t&quot; &quot;popq %%rax\\n\\t&quot; &quot;popfq \\n\\t&quot; //恢复下一个进程的标志寄存器 //输出当前进程的内核栈地址 : [ PREV_RSP ] &quot;=m&quot;(prev-&gt;td_context.ctx_nextrsp) //读取下一个进程的内核栈地址 : [ NEXT_RSP ] &quot;m&quot;(next-&gt;td_context.ctx_nextrsp), &quot;D&quot;(next), &quot;S&quot;(prev) : &quot;memory&quot;); return;&#125;// 完成特殊处理void __to_new_context(thread_t *next, thread_t *prev)&#123;uint_t cpuid = hal_retn_cpuid();schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid];//设置当前运行进程为下一个运行的进程schdap-&gt;sda_currtd = next;//设置下一个运行进程的tss为当前CPU的tssnext-&gt;td_context.ctx_nexttss = &amp;x64tss[cpuid];//设置当前CPU的tss中的R0栈为下一个运行进程的内核栈next-&gt;td_context.ctx_nexttss-&gt;rsp0 = next-&gt;td_krlstktop;//装载下一个运行进程的MMU页表hal_mmu_load(&amp;next-&gt;td_mmdsc-&gt;msd_mmu);if (next-&gt;td_stus == TDSTUS_NEW)&#123; //如果是新建进程第一次运行就要进行处理next-&gt;td_stus = TDSTUS_RUN;retnfrom_first_sched(next);&#125;return;&#125;// 新建进程第一次运行时调用 retnfrom_first_sched 函数进行处理void retnfrom_first_sched(thread_t *thrdp)&#123; __asm__ __volatile__( &quot;movq %[NEXT_RSP],%%rsp\\n\\t&quot; //设置CPU的RSP寄存器为该进程机器上下文结构中的 //恢复进程保存在内核栈中的段寄存器 &quot;popq %%r14\\n\\t&quot; &quot;movw %%r14w,%%gs\\n\\t&quot; &quot;popq %%r14\\n\\t&quot; &quot;movw %%r14w,%%fs\\n\\t&quot; &quot;popq %%r14\\n\\t&quot; &quot;movw %%r14w,%%es\\n\\t&quot; &quot;popq %%r14\\n\\t&quot; &quot;movw %%r14w,%%ds\\n\\t&quot; //恢复进程保存在内核栈中的通用寄存器 &quot;popq %%r15\\n\\t&quot; &quot;popq %%r14\\n\\t&quot; &quot;popq %%r13\\n\\t&quot; &quot;popq %%r12\\n\\t&quot; &quot;popq %%r11\\n\\t&quot; &quot;popq %%r10\\n\\t&quot; &quot;popq %%r9\\n\\t&quot; &quot;popq %%r8\\n\\t&quot; &quot;popq %%rdi\\n\\t&quot; &quot;popq %%rsi\\n\\t&quot; &quot;popq %%rbp\\n\\t&quot; &quot;popq %%rdx\\n\\t&quot; &quot;popq %%rcx\\n\\t&quot; &quot;popq %%rbx\\n\\t&quot; &quot;popq %%rax\\n\\t&quot; //恢复进程保存在内核栈中的RIP、CS、RFLAGS，（有可能需要恢复进程应用程序的RSP、SS &quot;iretq\\n\\t&quot; : : [ NEXT_RSP ] &quot;m&quot;(thrdp-&gt;td_context.ctx_nextrsp) : &quot;memory&quot;);&#125; 7.3 如何实现进程的等待与唤醒机制 进程的等待与唤醒 进程得不到所需的资源时就会进入等待状态,直到资源可用时才会被唤醒 进程等待结构 需要一种数据结构用于挂载等待的进程,在唤醒时才可以找到等待的进程 进程等待 让进程进入等待状态的机制是一个函数:会设置进程状态为等待状态,让进程从调度系统数据结构中脱落,最后让进程加入到 kwlst_t 等待结构中 函数使进程进入等待状态,而进程是当前正在运行的进程,而当前正在运行的进程正式调用这个函数的进程,故一个进程想要进入等待状态,只需要调用 krlsched_wait 函数即可 进程唤醒 从等待数据结构中获取进程,然后设置进程的状态为运行状态,最后将进程加入到进程调度系统数据结构中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// ----------// 进程等待结构// ----------typedef struct s_KWLST&#123; spinlock_t wl_lock; //自旋锁 uint_t wl_tdnr; //等待进程的个数 list_h_t wl_list; //挂载等待进程的链表头&#125;kwlst_t;// -------// 进程等待// -------void krlsched_wait(kwlst_t *wlst)&#123; cpuflg_t cufg, tcufg; uint_t cpuid = hal_retn_cpuid(); schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid]; //获取当前正在运行的进程 thread_t *tdp = krlsched_retn_currthread(); uint_t pity = tdp-&gt;td_priority; krlspinlock_cli(&amp;schdap-&gt;sda_lock, &amp;cufg); krlspinlock_cli(&amp;tdp-&gt;td_lock, &amp;tcufg); tdp-&gt;td_stus = TDSTUS_WAIT;//设置进程状态为等待状态 list_del(&amp;tdp-&gt;td_list);//脱链 krlspinunlock_sti(&amp;tdp-&gt;td_lock, &amp;tcufg); if (schdap-&gt;sda_thdlst[pity].tdl_curruntd == tdp) &#123; schdap-&gt;sda_thdlst[pity].tdl_curruntd = NULL; &#125; schdap-&gt;sda_thdlst[pity].tdl_nr--; krlspinunlock_sti(&amp;schdap-&gt;sda_lock, &amp;cufg); krlwlst_add_thread(wlst, tdp);//将进程加入等待结构中 return;&#125;// --------// 进程唤醒// --------void krlsched_up(kwlst_t *wlst)&#123; cpuflg_t cufg, tcufg; uint_t cpuid = hal_retn_cpuid(); schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid]; thread_t *tdp; uint_t pity; //取出等待数据结构第一个进程并从等待数据结构中删除 tdp = krlwlst_del_thread(wlst); pity = tdp-&gt;td_priority;//获取进程的优先级 krlspinlock_cli(&amp;schdap-&gt;sda_lock, &amp;cufg); krlspinlock_cli(&amp;tdp-&gt;td_lock, &amp;tcufg); tdp-&gt;td_stus = TDSTUS_RUN;//设置进程的状态为运行状态 krlspinunlock_sti(&amp;tdp-&gt;td_lock, &amp;tcufg); list_add_tail(&amp;tdp-&gt;td_list, &amp;(schdap-&gt;sda_thdlst[pity].tdl_lsth));//加入进 schdap-&gt;sda_thdlst[pity].tdl_nr++; krlspinunlock_sti(&amp;schdap-&gt;sda_lock, &amp;cufg); return;&#125; 空转进程 空转进程是操作系统在没有任何进程可以调度运行时进程调度器最后的选择 建立空转进程 空转进程是内核进程,但不加入调度系统,而是用专用的指针指向 建立空转进程由 new_cpuidle 函数调用 new_cpuidle_thread 函数完成 new_cpuidle_thread 函数的操作与建立内核进程差不多,但在函数最后，让调度系统数据结构的空转进程和当前进程的指针，指向刚刚建立的过程 在调用初始内核栈函数时，将 krlcpuidle_main 函数(空转进程的主函数)传了进去 空转进程的主函数本质就是个死循环，在死循环中打印一行信息，然后进行进程调度，这个函数就是永无休止地执行这两个步骤 空转进程运行 由于空转进程是第一进程故没法用调度器调度,需要手动开启 首先取出空转进程，设置机器上下文结构和运行状态,最后调用 retnfrom_first_sched 函数,恢复进程内核栈中的内容,让进程启动运行 还应该将建立空转和启动空转进程运行函数封装在一个初始化空转进程的函数中,并在内核层初始化init_kel函数的最后调用 多进程运行 在空转进程中调用了调度器函数，然后进程调度器会发现系统中没有进程，又不得不调度空转进程 所以最后结果就是：空转进程调用进程调度器，而调度器又选择了空转进程，导致形成了一个闭环 建立多个进程验证进程调度器正常工作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135// ----------// 建立空转进程// cosmos/kernel/krlcpuidle.c// ----------thread_t *new_cpuidle_thread()&#123;thread_t *ret_td = NULL;bool_t acs = FALSE;adr_t krlstkadr = NULL;uint_t cpuid = hal_retn_cpuid();schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid];krlstkadr = krlnew(DAFT_TDKRLSTKSZ);//分配进程的内核栈if (krlstkadr == NULL)&#123;return NULL;&#125;//分配thread_t结构体变量ret_td = krlnew_thread_dsc();if (ret_td == NULL)&#123;acs = krldelete(krlstkadr, DAFT_TDKRLSTKSZ);if (acs == FALSE)&#123;return NULL;&#125;return NULL;&#125;//设置进程具有系统权限ret_td-&gt;td_privilege = PRILG_SYS;ret_td-&gt;td_priority = PRITY_MIN;//设置进程的内核栈顶和内核栈开始地址ret_td-&gt;td_krlstktop = krlstkadr + (adr_t)(DAFT_TDKRLSTKSZ - 1);ret_td-&gt;td_krlstkstart = krlstkadr;//初始化进程的内核栈krlthread_kernstack_init(ret_td, (void *)krlcpuidle_main, KMOD_EFLAGS);//设置调度系统数据结构的空转进程和当前进程为ret_tdschdap-&gt;sda_cpuidle = ret_td;schdap-&gt;sda_currtd = ret_td;return ret_td;&#125;//新建空转进程void new_cpuidle()&#123;thread_t *thp = new_cpuidle_thread();//建立空转进程if (thp == NULL)&#123;//失败则主动死机hal_sysdie(&quot;newcpuilde err&quot;);&#125;kprint(&quot;CPUIDLETASK: %x\\n&quot;, (uint_t)thp);return;&#125;// 空转进程的主函数void krlcpuidle_main()&#123; uint_t i = 0; for (;; i++) &#123; kprint(&quot;空转进程运行:%x\\n&quot;, i);//打印 krlschedul();//调度进程 &#125; return;&#125;// ------------// 空转进程运行// ------------void krlcpuidle_start()&#123; uint_t cpuid = hal_retn_cpuid(); schdata_t *schdap = &amp;osschedcls.scls_schda[cpuid]; //取得空转进程 thread_t *tdp = schdap-&gt;sda_cpuidle; //设置空转进程的tss和R0特权级的栈 tdp-&gt;td_context.ctx_nexttss = &amp;x64tss[cpuid]; tdp-&gt;td_context.ctx_nexttss-&gt;rsp0 = tdp-&gt;td_krlstktop; //设置空转进程的状态为运行状态 tdp-&gt;td_stus = TDSTUS_RUN; //启动进程运行 retnfrom_first_sched(tdp); return;&#125;// init_kel函数void init_krl()&#123; init_krlsched();//初始化进程调度器 init_krlcpuidle();//初始化空转进程 die(0);//防止init_krl函数返回 return;&#125;//初始化空转进程void init_krlcpuidle()&#123; new_cpuidle();//建立空转进程 krlcpuidle_start();//启动空转进程运行 return;&#125;// ---------// 多进程运行// ---------void thread_a_main()//进程A主函数&#123; uint_t i = 0; for (;; i++) &#123; kprint(&quot;进程A运行:%x\\n&quot;, i); krlschedul(); &#125; return;&#125;void thread_b_main()//进程B主函数&#123; uint_t i = 0; for (;; i++) &#123; kprint(&quot;进程B运行:%x\\n&quot;, i); krlschedul(); &#125; return;&#125;void init_ab_thread()&#123; krlnew_thread((void*)thread_a_main, KERNTHREAD_FLG, PRILG_SYS, PRITY_MIN, DAFT_TDUSRSTKSZ, DAFT_TDKRLSTKSZ); krlnew_thread((void*)thread_b_main, KERNTHREAD_FLG, PRILG_SYS, PRITY_MIN, DAFT_TDUSRSTKSZ, DAFT_TDKRLSTKSZ); return;&#125;void init_krlcpuidle()&#123; new_cpuidle();//建立空转进程 init_ab_thread();//初始化建立A、B进程 krlcpuidle_start();//开始运行空转进程 return;&#125; 7.4 Linux如何实现进程与进程调度 Linux进程的数据结构 Linux把运行中的应用程序抽象成 task_struct，应用程序所需要的各种资源,内存,文件等都包含在其中 一个 task_struct 结构体的实例变量代表一个 Linux 进程 创建 task_struct 结构 Linux早期创建 task_struct 结构体的实例变量:找伙伴内存管理系统,分配两个连续的页面(8KB),作为进程的内核栈,再把 task_struct 结构体的实例变量,放在这8KB内存空间的开始地址处,内核栈是从上向下伸长的,task_struct数据结构是从下向上伸长的 Linux把 task_struct 结构和内核栈放在一起,只要把 RSP 寄存器的值读取出来,然后将其低13位清零,就得到了当前 task_struct 结构体的地址,由于内核栈比较大且会向下伸长,覆盖掉 task_struct 结构体的概率较小 最新版本,task_struct 和内核栈是分开的 Linux进程地址空间 Linux支持虚拟内存的操作系统内核，Linux用于描述一个进程的地址空间的数据结构,就是 mm_struct 结构 mm_struct 结构中 vm_area_struct 结构，相当于之前 Cosmos 的 kmvarsdsc_t 结构，是用来描述一段虚拟地址空间的 mm_struct 结构中也包含了 MMU 页表相关的信息 建立 mm_struct 结构的实例变量 copy_mm 函数在 copy_process 函数中被调用的, copy_mm 函数调用 dup_mm 函数，把当前进程的 mm_struct 结构复制到 allocate_mm 宏分配的一个 mm_struct 结构中 Linux进程文件表 一个文件进行读写操作之前,必须先打开文件,这个文件就记录在进程的文件表中,它由 task_struct 结构中的 files 字段指向 files_struct 结构 Linux建立新进程时,复制当前进程的 files_struct 结构以建立一个 files_struct 结构 copy_files 函数由 copy_process 函数调用，copy_files 最终会复制当前进程的files_struct 结构到一个新的 files_struct 结构实例变量中，并让新进程的 files 指针指向这个新的 files_struct 结构实例变量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186// -----------------// Linux进程的数据结构// -----------------struct task_struct &#123; struct thread_info thread_info;//处理器特有数据 volatile long state; //进程状态 void *stack; //进程内核栈地址 refcount_t usage; //进程使用计数 int on_rq; //进程是否在运行队列上 int prio; //动态优先级 int static_prio; //静态优先级 int normal_prio; //取决于静态优先级和调度策略 unsigned int rt_priority; //实时优先级 const struct sched_class *sched_class;//指向其所在的调度类 struct sched_entity se;//普通进程的调度实体 struct sched_rt_entity rt;//实时进程的调度实体 struct sched_dl_entity dl;//采用EDF算法调度实时进程的调度实体 struct sched_info sched_info;//用于调度器统计进程的运行信息 struct list_head tasks;//所有进程的链表 struct mm_struct *mm; //指向进程内存结构 struct mm_struct *active_mm; pid_t pid; //进程id struct task_struct __rcu *parent;//指向其父进程 struct list_head children; //链表中的所有元素都是它的子进程 struct list_head sibling; //用于把当前进程插入到兄弟链表中 struct task_struct *group_leader;//指向其所在进程组的领头进程 u64 utime; //用于记录进程在用户态下所经过的节拍数 u64 stime; //用于记录进程在内核态下所经过的节拍数 u64 gtime; //用于记录作为虚拟机进程所经过的节拍数 unsigned long min_flt;//缺页统计 unsigned long maj_flt; struct fs_struct *fs; //进程相关的文件系统信息 struct files_struct *files;//进程打开的所有文件 struct vm_struct *stack_vm_area;//内核栈的内存区&#125;;// --------------------// 创建 task_struct 结构// --------------------static unsigned long *alloc_thread_stack_node(struct task_struct *tsk, int nod&#123; struct page *page = alloc_pages_node(node, THREADINFO_GFP, THREAD_SIZE_ORDER);//分配两个页面 if (likely(page)) &#123; tsk-&gt;stack = kasan_reset_tag(page_address(page)); return tsk-&gt;stack;//让task_struct结构的stack字段指向page的地址 &#125; return NULL;&#125;static inline struct task_struct *alloc_task_struct_node(int node)&#123; return kmem_cache_alloc_node(task_struct_cachep, GFP_KERNEL, node);//在tas&#125;static struct task_struct *dup_task_struct(struct task_struct *orig, int node)&#123; struct task_struct *tsk; unsigned long *stack; tsk = alloc_task_struct_node(node);//分配task_struct结构体 if (!tsk) return NULL; stack = alloc_thread_stack_node(tsk, node);//分配内核栈 tsk-&gt;stack = stack; return tsk;&#125;static __latent_entropy struct task_struct *copy_process(struct pid *pid, int trace, int node,struct kernel_clone_args *args)&#123; int pidfd = -1, retval; struct task_struct *p; //…… retval = -ENOMEM; p = dup_task_struct(current, node);//分配task_struct和内核栈 //…… return ERR_PTR(retval);&#125;pid_t kernel_clone(struct kernel_clone_args *args)&#123; u64 clone_flags = args-&gt;flags; struct task_struct *p; pid_t nr; //…… //复制进程 p = copy_process(NULL, trace, NUMA_NO_NODE, args); //…… return nr;&#125;//建立进程接口SYSCALL_DEFINE0(fork)&#123; struct kernel_clone_args args = &#123; .exit_signal = SIGCHLD, &#125;; return kernel_clone(&amp;args);&#125;// ----------------// Linux进程地址空间// ----------------struct mm_struct &#123; struct vm_area_struct *mmap; //虚拟地址区间链表VMAs struct rb_root mm_rb; //组织vm_area_struct结构的红黑树的根 unsigned long task_size; //进程虚拟地址空间大小 pgd_t * pgd; //指向MMU页表 atomic_t mm_users; //多个进程共享这个mm_struct atomic_t mm_count; //mm_struct结构本身计数 atomic_long_t pgtables_bytes;//页表占用了多个页 int map_count; //多少个VMA spinlock_t page_table_lock; //保护页表的自旋锁 struct list_head mmlist; //挂入mm_struct结构的链表 //进程应用程序代码开始、结束地址，应用程序数据的开始、结束地址 unsigned long start_code, end_code, start_data, end_data; //进程应用程序堆区的开始、当前地址、栈开始地址 unsigned long start_brk, brk, start_stack; //进程应用程序参数区开始、结束地址 unsigned long arg_start, arg_end, env_start, env_end;&#125;;// mm_struct 结构建立对应的实例变量//在mm_cachep内存对象中分配一个mm_struct结构休对象#define allocate_mm() (kmem_cache_alloc(mm_cachep, GFP_KERNEL))static struct mm_struct *dup_mm(struct task_struct *tsk,struct mm_struct *oldmm)&#123; struct mm_struct *mm; //分配mm_struct结构 mm = allocate_mm(); if (!mm) goto fail_nomem; //复制mm_struct结构 memcpy(mm, oldmm, sizeof(*mm)); //…… return mm;&#125;static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)&#123; struct mm_struct *mm, *oldmm; int retval; tsk-&gt;min_flt = tsk-&gt;maj_flt = 0; tsk-&gt;nvcsw = tsk-&gt;nivcsw = 0; retval = -ENOMEM; mm = dup_mm(tsk, current-&gt;mm);//分配mm_struct结构的实例变量 if (!mm) goto fail_nomem; good_mm: tsk-&gt;mm = mm; tsk-&gt;active_mm = mm; return 0; fail_nomem: return retval;&#125;// --------------// Linux进程文件表// --------------struct files_struct &#123; atomic_t count;//自动计数 struct fdtable __rcu *fdt; struct fdtable fdtab; spinlock_t file_lock; //自旋锁 unsigned int next_fd;//下一个文件句柄 unsigned long close_on_exec_init[1];//执行exec()时要关闭的文件句柄 unsigned long open_fds_init[1]; unsigned long full_fds_bits_init[1]; struct file __rcu * fd_array[NR_OPEN_DEFAULT];//默认情况下打开文件的指针数组&#125;;static int copy_files(unsigned long clone_flags, struct task_struct *tsk)&#123;struct files_struct *oldf, *newf;int error = 0;oldf = current-&gt;files;//获取当前进程的files_struct的指针if (!oldf)goto out;if (clone_flags &amp; CLONE_FILES) &#123;atomic_inc(&amp;oldf-&gt;count);goto out;&#125;//分配新files_struct结构的实例变量，并复制当前的files_struct结构newf = dup_fd(oldf, NR_OPEN_MAX, &amp;error);if (!newf)goto out;tsk-&gt;files = newf;//新进程的files_struct结构指针指向新的files_struct结构error = 0;out:return error;&#125; Linux进程调度 Linux有多重调度算法,支持调度算法,具有给予优先级的调度算法,实时调度算法,完全公平调度算法(CFQ) 进程调度实体 进程调度实体是Linux进程调度系统的一部分,被嵌入到Linux进程数据结构中,与调度器进行关联,能间接地访问进程 高内聚低耦合的方式保证进程数据结构和调度数据结构相关独立 task_struct 结构中包含至少一个 sched_entity 结构的变量 使用 sched_entity 访问 task_struct 结构:只要通过 sched_entity 结构变量的地址，减去它在 task_struct 结构中的偏移(由编译器自动计算)，就能获取到 task_struct 结构的地址 123456789101112131415161718192021222324// -----------// 进程调度实体// -----------struct sched_entity &#123; struct load_weight load;//表示当前调度实体的权重 struct rb_node run_node;//红黑树的数据节点 struct list_head group_node;// 链表节点，被链接到 percpu 的 rq-&gt;cfs_tasks unsigned int on_rq; //当前调度实体是否在就绪队列上 u64 exec_start;//当前实体上次被调度执行的时间 u64 sum_exec_runtime;//当前实体总执行时间 u64 prev_sum_exec_runtime;//截止到上次统计，进程执行的时间 u64 vruntime;//当前实体的虚拟时间 u64 nr_migrations;//实体执行迁移的次数 struct sched_statistics statistics;//统计信息包含进程的睡眠统计、等待延迟统计、CP #ifdef CONFIG_FAIR_GROUP_SCHED int depth;// 表示当前实体处于调度组中的深度 struct sched_entity *parent;//指向父级调度实体 struct cfs_rq *cfs_rq;//当前调度实体属于的 cfs_rq. struct cfs_rq *my_q; #endif #ifdef CONFIG_SMP struct sched_avg avg ;// 记录当前实体对于CPU的负载 #endif&#125;; 进程运行队列 首先Linux定义了一个进程运行队列结构,每个CPU分配进程运行队列结构实例变量 rq结构中, 通过cfs_rq，rt_rq,dl_rq来关联调度实体,task_struct结构指针是为了快速访问特殊进程 cfs_rq，rt_rq,dl_rq作用于三种不同的调度算法,重点关注cfs_rq 其中 load、exec_clock、min_vruntime、tasks_timeline 字段是 CFS 调度算法得以实现的关键 cfs_rq结构中的 tasks_timeline 字段：调度实体是通过红黑树组织起来的 1234567891011121314151617181920212223242526272829303132// 进程运行队列结构struct rq &#123; raw_spinlock_t lock;//自旋锁 unsigned int nr_running;//多个就绪运行进程 struct cfs_rq cfs; //作用于完全公平调度算法的运行队列 struct rt_rq rt;//作用于实时调度算法的运行队列 struct dl_rq dl;//作用于EDF调度算法的运行队列 struct task_struct __rcu *curr;//这个运行队列当前正在运行的进程 struct task_struct *idle;//这个运行队列的空转进程 struct task_struct *stop;//这个运行队列的停止进程 struct mm_struct *prev_mm;//这个运行队列上一次运行进程的mm_struct unsigned int clock_update_flags;//时钟更新标志 u64 clock; //运行队列的时间 //后面的代码省略&#125;;struct rb_root_cached &#123; struct rb_root rb_root; //红黑树的根 struct rb_node *rb_leftmost;//红黑树最左子节点&#125;;struct cfs_rq &#123; struct load_weight load;//cfs_rq上所有调度实体的负载总和 unsigned int nr_running;//cfs_rq上所有的调度实体不含调度组中的调度实体 unsigned int h_nr_running;//cfs_rq上所有的调度实体包含调度组中所有调度实体 u64 exec_clock;//当前 cfs_rq 上执行的时间 u64 min_vruntime;//最小虚拟运行时间 struct rb_root_cached tasks_timeline;//所有调度实体的根 struct sched_entity *curr;//当前调度实体 struct sched_entity *next;//下一个调度实体 struct sched_entity *last;//上次执行过的调度实体 //省略不关注的代码&#125;; 调度实体和运行队列的关系 task_struct 结构中包含了 sched_entity 结构 sched_entity 结构是通过红黑树组织,红黑树的根在 cfs_rq 结构中,cfs_rq 结构被包含在 rq 结构,每个CPU对应一个 rq 结构 调度器类 为了支持不同的调度器,Linux定义调度器类数据结构,定义了调度器需要实现的函数 sched_class 结构定义了一组函数指针 Linux 系统一共定义了五个 sched_class 结构的实例变量，五个 sched_class 结构紧靠在一起，形成了 sched_class 结构数组 类的优先级:stop_sched_class &gt; dl_sched_class &gt; rt_sched_class &gt; fair_sched_class &gt; idle_sched_class 1234567891011121314151617181920212223242526272829303132333435363738// -----------// 调度器类// -----------struct sched_class &#123; //向运行队列中添加一个进程，入队 void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags); //向运行队列中删除一个进程，出队 void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags); //检查当前进程是否可抢占 void (*check_preempt_curr)(struct rq *rq, struct task_struct *p, int flags //从运行队列中返回可以投入运行的一个进程 struct task_struct *(*pick_next_task)(struct rq *rq);&#125; ;//定义在链接脚本文件中extern struct sched_class __begin_sched_classes[];extern struct sched_class __end_sched_classes[];#define sched_class_highest (__end_sched_classes - 1)#define sched_class_lowest (__begin_sched_classes - 1)#define for_class_range(class, _from, _to) \\for (class = (_from); class != (_to); class--)//遍历每个调度类#define for_each_class(class) \\for_class_range(class, sched_class_highest, sched_class_lowest)extern const struct sched_class stop_sched_class;//停止调度类extern const struct sched_class dl_sched_class;//Deadline调度类extern const struct sched_class rt_sched_class;//实时调度类extern const struct sched_class fair_sched_class;//CFS调度类extern const struct sched_class idle_sched_class;//空转调度类// cfs调度器需要的 fair_sched_classconst struct sched_class fair_sched_class__section(&quot;__fair_sched_class&quot;) = &#123; .enqueue_task = enqueue_task_fair, .dequeue_task = dequeue_task_fair, .check_preempt_curr = check_preempt_wakeup, .pick_next_task = __pick_next_task_fair,&#125;; Linux的CFS调度器 普通进程的权重 cfs调度器与其他进程调度器的不同之处在于没有时间片的概念,是分配CPU使用时间的比例 cfs调度器具有权重,权重表示进程的优先级,各个进程按权重的比例分配CPU时间 分配给进程的时间计算公式:进程的时间=CPU总时间∗进程的权重/就绪队列所有进程权重之和进程的时间= CPU总时间*进程的权重/就绪队列所有进程权重之和进程的时间=CPU总时间∗进程的权重/就绪队列所有进程权重之和 进程对外的编程接口使用的是nice值,大小为-20~19，数值越小优先级越大,意味着权重值越大 nice值和权重之间可进行转换，每降低一个nice值就能获得多10%的CPU时间 1024 权重对应 nice 值为0，被称为 NICE_0_LOAD。默认情况下，大多数进程的权重都是 NICE_0_LOAD 进程调度延迟 调度延迟为了保证每一个可运行的进程都至少运行一次的时间间隔 随着进程的增加,每个进程分配的时间在减少,进程调度次数增加,调度器占用的时间就会增加,因此cfs调度器的调度延迟时间的设定并不固定 当进程小于8时,调度延迟是固定的6ms 超过8时,就要保证每个进程至少运行一段时间(最小调度粒度时间)才会被调度 CFS默认设置中,最小调度粒度时间为0.75ms,用变量sysctl_sched_min_granularity 记录，由 __sched_period 函数负责计算 参数 nr_running 是 Linux 系统中可运行的进程数量，当超过sched_nr_latency 时无法保证调度延迟，因此转为保证最小调度粒度 虚拟时间 vruntime 表示虚拟时间,CFS调度器记录每个进程的执行时间,为保证每个进程运行时间的公平,进程运行时间最少的进程先运行 进程的实际执行时间不等,但CFS引入虚拟时间,将实际执行时间转换为相同的虚拟时间,即保证每个进程运行的虚拟时间相等 转换公式vruntime=wtime∗(NICE_0_LOAD/weight)vruntime = wtime*( NICE\\_0\\_LOAD/weight)vruntime=wtime∗(NICE_0_LOAD/weight) CFS 调度主要保证每个进程运行的虚拟时间一致即可。在选择下一个即将运行的进程时，只需要找到虚拟时间最小的进程就行了,计算过程由 calc_delta_fair 函数完成 调用 __calc_delta 函数的时候，传递的 weight 参数是NICE_0_LOAD，lw 参数正是调度实体中的 load_weight 结构体 在运行队列中用红黑树结构组织进程的调度实体，进程虚拟时间正是红黑树的 key 红黑树的最左子节点，就是虚拟时间最小的进程，随着时间的推移进程会从红黑树的左边跑到右，然后从右边跑到左边 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// ------------// 普通进程的权重// ------------const int sched_prio_to_weight[40] = &#123; /* -20 */ 88761, 71755, 56483, 46273, 36291, /* -15 */ 29154, 23254, 18705, 14949, 11916, /* -10 */ 9548, 7620, 6100, 4904, 3906, /* -5 */ 3121, 2501, 1991, 1586, 1277, /* 0 */ 1024, 820, 655, 526, 423, /* 5 */ 335, 272, 215, 172, 137, /* 10 */ 110, 87, 70, 56, 45, /* 15 */ 36, 29, 23, 18, 15,&#125;;// -----------// 进程调度延迟// -----------unsigned int sysctl_sched_min_granularity = 750000ULL;static unsigned int normalized_sysctl_sched_min_granularity = 750000ULL;static unsigned int sched_nr_latency = 8;static u64 __sched_period(unsigned long nr_running)&#123; if (unlikely(nr_running &gt; sched_nr_latency)) return nr_running * sysctl_sched_min_granularity; else return sysctl_sched_latency;&#125;// -------// 虚拟时间// -------static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weig&#123;u64 fact = scale_load_down(weight);int shift = WMULT_SHIFT;__update_inv_weight(lw);if (unlikely(fact &gt;&gt; 32)) &#123;while (fact &gt;&gt; 32) &#123;fact &gt;&gt;= 1;shift--;&#125;&#125;//为了避免使用浮点计算fact = mul_u32_u32(fact, lw-&gt;inv_weight);while (fact &gt;&gt; 32) &#123;fact &gt;&gt;= 1;shift--;&#125;return mul_u64_u32_shr(delta_exec, fact, shift);&#125;static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se)&#123;if (unlikely(se-&gt;load.weight != NICE_0_LOAD))delta = __calc_delta(delta, NICE_0_LOAD, &amp;se-&gt;load);return delta;&#125; CFS调度进程 CFS 调度器就是要维持各个可运行进程的虚拟时间相等，不相等就需要被调度运行。如果一个进程比其它进程的虚拟时间小，它就应该运行达到和其它进程的虚拟时间持平，直到它的虚拟时间超过其它进程，这时就要停下来，这样其它进程才能被调度运行 定时周期调度 虚拟时间为一个数据,但需要更新机制,以免导致一个进程永远运行下去(虚拟时间永远最小) Linux启动会启动定时器,每1/1000,1/250,1/100秒产生一个时钟中断,在中断处理函数中调用 scheduler_tick 函数 scheduler_tick 函数会调用进程调度类的 task_tick 函数，对于 CFS 调度器就是 task_tick_fair 函数 真正做事的是 entity_tick 函数，其调用了update_curr 函数更新当前进程虚拟时间并更新了运行队列的相关数据 entity_tick 函数的最后调用了 check_preempt_tick 函数,检查是否可以抢占调度 如果需要抢占就会调用 resched_curr 函数设置进程的抢占标志，但是这个函数本身不会调用进程调度器函数，而是在进程从中断或者系统调用返回到用户态空间时，检查当前进程的调度标志，然后根据需要调用进程调度器函数 调度器入口 需要进行进程抢占调度,Linux就会在适当的时机进行进程调度(就是调用进程调度器入口函数,该函数会选择一个最合适投入运行的进程,然后切换到该进程上运行) 在循环中调用 _schedule 函数执行真正的进程调度，因为在执行调度的过程中有更高优先级的进程进入可运行状态需要抢占当前进程 __schedule 函数中会更新一些统计数据，然后调用 pick_next_task 函数挑选出下一个进程投入运行 最后，如果当前进程和下一个要运行的进程不同，就要进行进程机器上下文切换，其中会切换地址空间和 CPU 寄存器 挑选下一个进程 挑选下一个进程过程是在 pick_next_task 函数(框架函数)中完成，会依照优先级调用具体调度器类的函数完成工作，对于 CFS 则会调用 pick_next_task_fair 函数 pick_next_task_fair 调用 pick_next_entity 函数选择虚拟时间最小的调度实体，然后调用set_next_entity 函数，对选择的调度实体进行一些必要的处理，主要是将这调度实体从运行队列中拿出来 pick_next_entity 调用了相关函数，从运行队列上的红黑树中查找虚拟时间最少的调度实体，然后处理要跳过调度的情况，最后决定挑选的调度实体是否可以抢占并返回它 代码的调用路径最终会返回到 __schedule 函数中，这个函数中就是上一个运行的进程和将要投入运行的下一个进程，最后调用 context_switch 函数，完成两个进程的地址空间和机器上下文的切换，一次进程调度工作结束(机制和 Cosmos 的save_to_new_context 函数类似) 核心就是让虚拟时间最小的进程最先运行， 一旦进程运行虚拟时间就会增加，最后尽量保证所有进程的虚拟时间相等，谁小了就要多运行，谁大了就要暂停运行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194// -----------// 定时周期调度// -----------static void update_curr(struct cfs_rq *cfs_rq)&#123;struct sched_entity *curr = cfs_rq-&gt;curr;u64 now = rq_clock_task(rq_of(cfs_rq));//获取当前时间u64 delta_exec;delta_exec = now - curr-&gt;exec_start;//间隔时间curr-&gt;exec_start = now;curr-&gt;sum_exec_runtime += delta_exec;//累计运行时间curr-&gt;vruntime += calc_delta_fair(delta_exec, curr);//计算进程的虚拟时间update_min_vruntime(cfs_rq);//更新运行队列中的最小虚拟时间，这是新建进程的虚拟时间&#125;static void entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr, int queued)&#123;update_curr(cfs_rq);//更新当前运行进程和运行队列相关的时间if (cfs_rq-&gt;nr_running &gt; 1)//当运行进程数量大于1就检查是否可抢占check_preempt_tick(cfs_rq, curr);&#125;#define for_each_sched_entity(se) \\for (; se; se = NULL)static void task_tick_fair(struct rq *rq, struct task_struct *curr, int queued)&#123;struct cfs_rq *cfs_rq;struct sched_entity *se = &amp;curr-&gt;se;//获取当前进程的调度实体for_each_sched_entity(se) &#123;//仅对当前进程的调度实体cfs_rq = cfs_rq_of(se);//获取当前进程的调度实体对应运行队列entity_tick(cfs_rq, se, queued);&#125;&#125;void scheduler_tick(void)&#123;int cpu = smp_processor_id();struct rq *rq = cpu_rq(cpu);//获取运行CPU运行进程队列struct task_struct *curr = rq-&gt;curr;//获取当进程update_rq_clock(rq);//更新运行队列的时间等数据curr-&gt;sched_class-&gt;task_tick(rq, curr, 0);//更新当前时间的虚拟时间&#125;// check_preempt_tick 函数,检查是否抢占调度static void check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *cur&#123;unsigned long ideal_runtime, delta_exec;struct sched_entity *se;s64 delta;//计算当前进程在本次调度中分配的运行时间ideal_runtime = sched_slice(cfs_rq, curr);//当前进程已经运行的实际时间delta_exec = curr-&gt;sum_exec_runtime - curr-&gt;prev_sum_exec_runtime;//如果实际运行时间已经超过分配给进程的运行时间，就需要抢占当前进程。设置进程的TIF_NEED_if (delta_exec &gt; ideal_runtime) &#123;resched_curr(rq_of(cfs_rq));return;&#125;//因此如果进程运行时间小于最小调度粒度时间，不应该抢占if (delta_exec &lt; sysctl_sched_min_granularity)return;//从红黑树中找到虚拟时间最小的调度实体se = __pick_first_entity(cfs_rq);delta = curr-&gt;vruntime - se-&gt;vruntime;//如果当前进程的虚拟时间仍然比红黑树中最左边调度实体虚拟时间小，也不应该发生调度if (delta &lt; 0)return;&#125;// ---------// 调度器入口// ---------static void __sched notrace __schedule(bool preempt)&#123;struct task_struct *prev, *next;unsigned long *switch_count;unsigned long prev_state;struct rq_flags rf;struct rq *rq;int cpu;cpu = smp_processor_id();rq = cpu_rq(cpu);//获取当前CPU的运行队列prev = rq-&gt;curr; //获取当前进程rq_lock(rq, &amp;rf);//运行队列加锁update_rq_clock(rq);//更新运行队列时钟switch_count = &amp;prev-&gt;nivcsw;next = pick_next_task(rq, prev, &amp;rf);//获取下一个投入运行的进程clear_tsk_need_resched(prev); //清除抢占标志clear_preempt_need_resched();if (likely(prev != next)) &#123;//当前运行进程和下一个运行进程不同，就要进程切换rq-&gt;nr_switches++; //切换计数统计++*switch_count;rq = context_switch(rq, prev, next, &amp;rf);//进程机器上下文切换&#125; else &#123;rq-&gt;clock_update_flags &amp;= ~(RQCF_ACT_SKIP|RQCF_REQ_SKIP);rq_unlock_irq(rq, &amp;rf);//解锁运行队列&#125;&#125;void schedule(void)&#123;struct task_struct *tsk = current;//获取当前进程do &#123;preempt_disable();//关闭内核抢占__schedule(false);//进程调用sched_preempt_enable_no_resched();//开启内核抢占&#125; while (need_resched());//是否需要再次重新调用&#125;// -------------// 挑选下一个进程// -------------static inline struct task_struct *pick_next_task(struct rq *rq, struct task_struct)&#123;const struct sched_class *class;struct task_struct *p;//这是对CFS的一种优化处理，因为大部分进程属于CFS管理if (likely(prev-&gt;sched_class &lt;= &amp;fair_sched_class &amp;&amp;rq-&gt;nr_running == rq-&gt;cfs.h_nr_running)) &#123;p = pick_next_task_fair(rq, prev, rf);//调用CFS的对应的函数if (unlikely(p == RETRY_TASK))goto restart;if (!p) &#123;//如果没有获取到运行进程put_prev_task(rq, prev);//将上一个进程放回运行队列中p = pick_next_task_idle(rq);//获取空转进程&#125;return p;&#125;restart:for_each_class(class) &#123;//依次从最高优先级的调度类开始遍历p = class-&gt;pick_next_task(rq);if (p)//如果在一个调度类所管理的运行队列中挑选到一个进程，立即返回return p;&#125;BUG();//出错&#125;struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev)&#123;struct cfs_rq *cfs_rq = &amp;rq-&gt;cfs;struct sched_entity *se;struct task_struct *p;if (prev)put_prev_task(rq, prev);//把上一个进程放回运行队列do &#123;se = pick_next_entity(cfs_rq, NULL);//选择最适合运行的调度实体set_next_entity(cfs_rq, se);//对选择的调度实体进行一些处理cfs_rq = group_cfs_rq(se);&#125; while (cfs_rq);//在没有调度组的情况下，循环一次就结束了p = task_of(se);//通过se获取包含se的进程task_structreturn p;&#125;struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)&#123;struct rb_node *left = rb_first_cached(&amp;cfs_rq-&gt;tasks_timeline);//先读取在taif (!left)return NULL;//如果为空直接返回NULL//通过红黑树结点指针取得包含它的调度实体结构地址return rb_entry(left, struct sched_entity, run_node);&#125;static struct sched_entity *__pick_next_entity(struct sched_entity *se)&#123; //获取当前红黑树节点的下一个结点struct rb_node *next = rb_next(&amp;se-&gt;run_node);if (!next)return NULL;//如果为空直接返回NULLreturn rb_entry(next, struct sched_entity, run_node);&#125;static struct sched_entity *pick_next_entity(struct cfs_rq *cfs_rq, struct sch&#123;//获取Cfs_rq中的红黑树上最左节点上调度实体，虚拟时间最小struct sched_entity *left = __pick_first_entity(cfs_rq);struct sched_entity *se;if (!left || (curr &amp;&amp; entity_before(curr, left)))left = curr;//可能当前进程主动放弃CPU，它的虚拟时间比红黑树上的还小，所以left指向se = left;if (cfs_rq-&gt;skip == se) &#123; //如果选择的调度实体是要跳过的调度实体struct sched_entity *second;if (se == curr) &#123;//如果是当前调度实体second = __pick_first_entity(cfs_rq);//选择运行队列中虚拟时间最小的调度实&#125; else &#123;//否则选择红黑树上第二左的进程节点second = __pick_next_entity(se);//如果次优的调度实体的虚拟时间，还是比当前的调度实体的虚拟时间大if (!second || (curr &amp;&amp; entity_before(curr, second)))second = curr;//让次优的调度实体也指向当前调度实体&#125;//判断left和second的虚拟时间的差距是否小于sysctl_sched_wakeup_granularityif (second &amp;&amp; wakeup_preempt_entity(second, left) &lt; 1)se = second;&#125;if (cfs_rq-&gt;next &amp;&amp; wakeup_preempt_entity(cfs_rq-&gt;next, left) &lt; 1) &#123;se = cfs_rq-&gt;next;&#125; else if (cfs_rq-&gt;last &amp;&amp; wakeup_preempt_entity(cfs_rq-&gt;last, left) &lt; 1)se = cfs_rq-&gt;last;&#125;clear_buddies(cfs_rq, se);//需要清除掉last、next、skip指针return se;&#125; 8 设备IO 8.1 如何表示设备类型与设备驱动 计算机的结构 各种硬件以总线为基础连接在一起，各自完成工作，互相配合实现用户要求的功能 总线有层级关系,各种设备通过总线连接 分权而治 操作系统要控制各个设备,就是要包含每个设备的控制代码,但如果操作系统内核被设计为通用可移植的内核,内核代码庞大,危险性高；且操作系统内核开发人员并不能写一套为所有设备写一套控制代码;设备厂商不愿意公开设备代码细节;更新设备需要重写控制代码,重新编译 操作系统内核不包含或仅包含基本的通用的设备控制代码,控制设备时加载相应设备的独立的设备控制代码(灵活性提高) 设备分类 操作系统内核定义的设备可称为内核设备或逻辑设备(对物理计算平台中几种类型设备的抽象) 在 cosmos/include/knlinc/krldevice.h文件中对设备进行分类 设备驱动 操作系统内核如何表示多个设备与驱动的存在,如何组织多个设备和多个驱动程序,驱动程序提供哪些服务 设备 在操作系统内核建立设备数据结构的实例变量就表示操作系统内核中存在一个逻辑设备 设备信息中，设备ID结构十分重要，表示设备的类型,设备号，子设备号，指向设备驱动程序的指针 子设备号为了解决多个相同设备,指针用于访问设备时调用设备驱动程序 驱动 需要定义数据结构表示驱动程序,数据结构中应包含驱动程序名,驱动程序ID，驱动程序所管理的设备,最重要的是完成功能设备相关功能的函数 cosmos内核每加载一个驱动程序模块,就会自动分配一个驱动程序数据结构并将其初始化,在首次启动驱动程序时会调用驱动程序的入口点函数,分配设备数据结构,并用相关的信息将其实例化 握手动作:cosmos内核负责建立驱动数据结构,驱动程序负责建立设备数据结构 设备驱动的组织:利用设备表的数据结构组织驱动程序数据结构和设备数据结构 devtable_t 是每个设备类型一个,表示一类设备,在 devtlst_t 中,具有设备技术和设备链表 在 cosmos 中需要定义 devtable_t 结构的全局变量 首先 devtable_t 结构中能找到所有的设备和驱动，然后从设备能找到对应的驱动，从驱动也能找到其管理的所有设备 ，最后就能实现一个驱动管理多个设备 驱动程序功能 每个驱动程序提供的操作定义成函数由驱动程序实现,函数的形式不能改变(操作系统内核与驱动程序沟通的桥梁) 利用 driver_t 结构中的函数指针数组使驱动程序的功能函数与操作系统内核关联起来, driver_t 中 drv_dipfun 函数指针数组存放上述驱动程序函数的指针 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208// -------// 设备分类// 在 cosmos/include/knlinc/krldevice.h文件中对设备进行分类// -------#define NOT_DEVICE 0 //不表示任何设备#define BRIDGE_DEVICE 4 //总线桥接器设备#define CPUCORE_DEVICE 5 //CPU设备，CPU也是设备#define RAMCONTER_DEVICE 6 //内存控制器设备#define RAM_DEVICE 7 //内存设备#define USBHOSTCONTER_DEVICE 8 //USB主控制设备#define INTUPTCONTER_DEVICE 9 //中断控制器设备#define DMA_DEVICE 10 //DMA设备#define CLOCKPOWER_DEVICE 11 //时钟电源设备#define LCDCONTER_DEVICE 12 //LCD控制器设备#define NANDFLASH_DEVICE 13 //nandflash设备#define CAMERA_DEVICE 14 //摄像头设备#define UART_DEVICE 15 //串口设备#define TIMER_DEVICE 16 //定时器设备#define USB_DEVICE 17 //USB设备#define WATCHDOG_DEVICE 18 //看门狗设备#define RTC_DEVICE 22 //实时时钟设备#define SD_DEVICE 25 //SD卡设备#define AUDIO_DEVICE 26 //音频设备#define TOUCH_DEVICE 27 //触控设备#define NETWORK_DEVICE 28 //网络设备#define VIR_DEVICE 29 //虚拟设备#define FILESYS_DEVICE 30 //文件系统设备#define SYSTICK_DEVICE 31 //系统TICK设备#define UNKNOWN_DEVICE 32 //未知设备，也是设备#define HD_DEVICE 33 //硬盘设备// ---// 设备// ---typedef struct s_DEVID&#123; uint_t dev_mtype;//设备类型号 uint_t dev_stype; //设备子类型号 uint_t dev_nr; //设备序号&#125;devid_t;typedef struct s_DEVICE&#123; list_h_t dev_list;//设备链表 list_h_t dev_indrvlst; //设备在驱动程序数据结构中对应的挂载链表 list_h_t dev_intbllst; //设备在设备表数据结构中对应的挂载链表 spinlock_t dev_lock; //设备自旋锁 uint_t dev_count; //设备计数 sem_t dev_sem; //设备信号量 uint_t dev_stus; //设备状态 uint_t dev_flgs; //设备标志 devid_t dev_id; //设备ID uint_t dev_intlnenr; //设备中断服务例程的个数 list_h_t dev_intserlst; //设备中断服务例程的链表 list_h_t dev_rqlist; //对设备的请求服务链表 uint_t dev_rqlnr; //对设备的请求服务个数 sem_t dev_waitints; //用于等待设备的信号量 struct s_DRIVER* dev_drv; //设备对应的驱动程序数据结构的指针 void* dev_attrb; //设备属性指针 void* dev_privdata; //设备私有数据指针 void* dev_userdata;//将来扩展所用 void* dev_extdata;//将来扩展所用 char_t* dev_name; //设备名&#125;device_t;// ---// 驱动// ---typedef struct s_DRIVER&#123; spinlock_t drv_lock; //保护驱动程序数据结构的自旋锁 list_h_t drv_list;//挂载驱动程序数据结构的链表 uint_t drv_stuts; //驱动程序的相关状态 uint_t drv_flg; //驱动程序的相关标志 uint_t drv_id; //驱动程序ID uint_t drv_count; //驱动程序的计数器 sem_t drv_sem; //驱动程序的信号量 void* drv_safedsc; //驱动程序的安全体 void* drv_attrb; //LMOSEM内核要求的驱动程序属性体 void* drv_privdata; //驱动程序私有数据的指针 drivcallfun_t drv_dipfun[IOIF_CODE_MAX]; //驱动程序功能派发函数指针数组 list_h_t drv_alldevlist; //挂载驱动程序所管理的所有设备的链表 drventyexit_t drv_entry; //驱动程序的入口函数指针 drventyexit_t drv_exit; //驱动程序的退出函数指针 void* drv_userdata;//用于将来扩展 void* drv_extdata; //用于将来扩展 char_t* drv_name; //驱动程序的名字&#125;driver_t;// ----------// 设备驱动的组织// ----------#define DEVICE_MAX 34typedef struct s_DEVTLST&#123; uint_t dtl_type;//设备类型 uint_t dtl_nr;//设备计数 list_h_t dtl_list;//挂载设备device_t结构的链表&#125;devtlst_t;typedef struct s_DEVTABLE&#123; list_h_t devt_list; //设备表自身的链表 spinlock_t devt_lock; //设备表自旋锁 list_h_t devt_devlist; //全局设备链表 list_h_t devt_drvlist; //全局驱动程序链表，驱动程序不需要分类，一个链表就行 uint_t devt_devnr; //全局设备计数 uint_t devt_drvnr; //全局驱动程序计数 devtlst_t devt_devclsl[DEVICE_MAX]; //分类存放设备数据结构的devtlst_t结构数组&#125;devtable_t;// 定义一个 devtable_t 结构的全局变量//在 cosmos/kernel/krlglobal.c文件中KRL_DEFGLOB_VARIABLE(devtable_t,osdevtable);//在 cosmos/kernel/krldevice.c文件中void devtlst_t_init(devtlst_t *initp, uint_t dtype)&#123; initp-&gt;dtl_type = dtype;//设置设备类型 initp-&gt;dtl_nr = 0; list_init(&amp;initp-&gt;dtl_list); return;&#125;void devtable_t_init(devtable_t *initp)&#123; list_init(&amp;initp-&gt;devt_list); krlspinlock_init(&amp;initp-&gt;devt_lock); list_init(&amp;initp-&gt;devt_devlist); list_init(&amp;initp-&gt;devt_drvlist); initp-&gt;devt_devnr = 0; initp-&gt;devt_drvnr = 0; for (uint_t t = 0; t &lt; DEVICE_MAX; t++) &#123;//初始化设备链表 devtlst_t_init(&amp;initp-&gt;devt_devclsl[t], t); &#125; return;&#125;void init_krldevice()&#123; devtable_t_init(&amp;osdevtable);//初始化系统全局设备表 return;&#125;//在 cosmos/kernel/krlinit.c文件中void init_krl()&#123; init_krlmm(); init_krldevice(); //记住一定要在初始化调度器之前，初始化设备表 init_krlsched(); init_krlcpuidle(); return;&#125;// ----------// 驱动程序功能// ----------// 驱动程序的几种主要函数//驱动程序入口和退出函数drvstus_t device_entry(driver_t* drvp,uint_t val,void* p);drvstus_t device_exit(driver_t* drvp,uint_t val,void* p);//设备中断处理函数drvstus_t device_handle(uint_t ift_nr,void* devp,void* sframe);//打开、关闭设备函数drvstus_t device_open(device_t* devp,void* iopack);drvstus_t device_close(device_t* devp,void* iopack);//读、写设备数据函数drvstus_t device_read(device_t* devp,void* iopack);drvstus_t device_write(device_t* devp,void* iopack);//调整读写设备数据位置函数drvstus_t device_lseek(device_t* devp,void* iopack);//控制设备函数drvstus_t device_ioctrl(device_t* devp,void* iopack);//开启、停止设备函数drvstus_t device_dev_start(device_t* devp,void* iopack);drvstus_t device_dev_stop(device_t* devp,void* iopack);//设置设备电源函数drvstus_t device_set_powerstus(device_t* devp,void* iopack);//枚举设备函数drvstus_t device_enum_dev(device_t* devp,void* iopack);//刷新设备缓存函数drvstus_t device_flush(device_t* devp,void* iopack);//设备关机函数drvstus_t device_shutdown(device_t* devp,void* iopack);// 功能函数与系统内核关联#define IOIF_CODE_OPEN 0 //对应于open操作#define IOIF_CODE_CLOSE 1 //对应于close操作#define IOIF_CODE_READ 2 //对应于read操作#define IOIF_CODE_WRITE 3 //对应于write操作#define IOIF_CODE_LSEEK 4 //对应于lseek操作#define IOIF_CODE_IOCTRL 5 //对应于ioctrl操作#define IOIF_CODE_DEV_START 6 //对应于start操作#define IOIF_CODE_DEV_STOP 7 //对应于stop操作#define IOIF_CODE_SET_POWERSTUS 8 //对应于powerstus操作#define IOIF_CODE_ENUM_DEV 9 //对应于enum操作#define IOIF_CODE_FLUSH 10 //对应于flush操作#define IOIF_CODE_SHUTDOWN 11 //对应于shutdown操作#define IOIF_CODE_MAX 12 //最大功能码//驱动程序分派函数指针类型typedef drvstus_t (*drivcallfun_t)(device_t*,void*);//驱动程序入口、退出函数指针类型typedef drvstus_t (*drventyexit_t)(struct s_DRIVER*,uint_t,void*);typedef struct s_DRIVER&#123;//……drivcallfun_t drv_dipfun[IOIF_CODE_MAX];//驱动程序分派函数指针数组。list_h_t drv_alldevlist;//驱动所管理的所有设备。drventyexit_t drv_entry;drventyexit_t drv_exit;//……&#125;driver t; 8.2 如何在内核中注册设备 设备的注册流程(以USB鼠标为例) 操作系统收到中断 USB总线驱动的中断处理程序会执行 调用操作系统内核相关服务，查找USB鼠标对应的驱动程序 操作系统加载驱动程序 驱动程序开始执行，向操作系统内核注册一个鼠标设备 对于安装在主板上的设备，操作系统会枚举设备信息，然后加载驱动程序，让驱动程序创建并注册相应的设备 简单实现:不支持设备热拔插功能,cosmos自动加载驱动,在驱动中向cosmos注册相应的设备,大大降低复杂性 cosmos在初始化驱动时会扫描整个驱动表,然后加载表中每个驱动,分别调用各个驱动的入口函数,最后在驱动中建立设备并向内核注册 驱动程序表 把驱动程序和内核链接在一起，省略加载驱动程序的过程，因为加载驱动程序不仅仅是把驱动程序放在内存中,还要进行程序链接相关操作 将内核和驱动程序链接在一起,需要用驱动程序表让内核知道驱动程序的存在 drventyexit_t类型,为函数指针类型,存放的是驱动程序的入口函数,内核需要扫描这个函数指针数组就可以调用每个驱动程序 init_krldriver 函数的主要工作:遍历驱动程序表中的每个驱动程序入口,将它作为参数传递给 krlrun_driverentry 函数 init_krldevice 函数需要在 init_krl 函数中调用 一定要先初始化设备表，然后才能初始化驱动程序，否则在驱动程序中建立的设备和驱动无处安放 运行驱动程序:使用驱动程序表省略加载驱动程序的步骤,但驱动程序必须要运行才能工作 调用驱动程序入口函数 使用**驱动描述符指针(drvp)**调用驱动程序入口函数 先调用 new_driver_dsc 函数建立一个 driver_t 结构实例变量 然后调用传递的函数指针,并将drvp作为参数传送进去 接着再进入驱动程序中运行 最后当驱动程序入口函数返回时将驱动程序加入cosmos系统中 一个驱动程序入口函数的例子 一个驱动程序被操作系统调用,产生实际作用,这个驱动程序入口函数，就至少有一套标准流程要走，否则只需要返回DFCOKSTUS(宏,表成功) 标准流程:首先要建立一个设备描述符,接着把驱动程序的功能函数设置到 driver_t 结构中的 drv_dipfun 数组中，并将设备挂载到驱动上,然后要向内核注册设备,最后驱动程序初始化自己的物理设备,安装中断回调函数 设备与驱动的联系 第一个接口函数是将设备挂载到驱动上,将设备和驱动产生联系,确保驱动能找到设备,设备能找到驱动 代码中,遍历驱动设备链表中的所有设备,看是否有设备ID冲突,没有冲突就将设备载入驱动,并把设备中的相关字段指向管理自己的驱动,设备和驱动就联系在一起 向内核注册设备 向内核注册设备，注册过程由内核实现并提供接口 在注册设备过程中,内核通过设备的类型和ID，把用来表示设备的 device_t 结构挂载到设备表中 krlnew_device 函数检查在设备表中有没有设备 ID 冲突，如果没有的话就加入设备类型链表和全局设备链表中，最后对其计数器变量加一 完成了这些操作之后，在操作设备时，通过设备 ID 就可以找到对应的设备了 安装中断回调函数 设备很多时候必须和CPU进行通信,通过中断的形式进行 中断回调函数是驱动程序提供的,内核必须提供相应的接口用于安装中断回调函数 krlnew_devhandle 函数有三个参数，分别是安装中断回调函数的设备，驱动程序提供的中断回调函数，还有一个是设备在中断控制器中断线的号码 krlnew_devhandle 函数中一开始就会调用内核层的中断框架接口，在 cosmos/kernel/krlintupt.c 文件中实现 krladd_irqhandle 函数的主要工作是创建了一个 intserdsc_t 结构，用来保存设备和其驱动程序提供的中断回调函数 通过 intserdsc_t 结构也让中断处理框架和设备驱动联系起来 中断来了之后,，中断处理框架既能找到对应的 intserdsc_t 结构，又能从 intserdsc_t 结构中得到中断回调函数和对应的设备描述符，从而调用中断回调函数，进行具体设备的中断处理 驱动加入内核 当操作系统内核调用了驱动程序入口函数，驱动程序入口函数就会进行一系列操作，包括建立设备，安装中断回调函数等等，再之后就会返回到操作系统内核 接下来，操作系统内核会根据返回状态，决定是否将该驱动程序加入到操作系统内核中，即将 river_t 结构的实例变量挂载到设备表中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228// ---------// 驱动程序表// ---------//cosmos/kernel/krlglobal.cKRL_DEFGLOB_VARIABLE(drventyexit_t,osdrvetytabl)[]=&#123;NULL&#125;;// 初始化函数void init_krldriver()&#123; //遍历驱动程序表中的每个驱动程序入口函数 for (uint_t ei = 0; osdrvetytabl[ei] != NULL; ei++) &#123; //运行一个驱动程序入口 if (krlrun_driverentry(osdrvetytabl[ei]) == DFCERRSTUS) &#123; hal_sysdie(&quot;init driver err&quot;); &#125; &#125; return;&#125;void init_krl()&#123; init_krlmm(); init_krldevice(); init_krldriver(); //…… return;&#125;// ------------------// 调用驱动程序入口函数// ------------------drvstus_t krlrun_driverentry(drventyexit_t drventry)&#123; driver_t *drvp = new_driver_dsc();//建立driver_t实例变量 if (drvp == NULL) &#123; return DFCERRSTUS; &#125; if (drventry(drvp, 0, NULL) == DFCERRSTUS)//运行驱动程序入口函数 &#123; return DFCERRSTUS; &#125; if (krldriver_add_system(drvp) == DFCERRSTUS)//把驱动程序加入系统 &#123; return DFCERRSTUS; &#125; return DFCOKSTUS;&#125;// -----------------------// 一个驱动程序入口函数的例子(不可运行)// -----------------------drvstus_t systick_entry(driver_t* drvp,uint_t val,void* p)&#123;if(drvp==NULL) //drvp是内核传递进来的参数，不能为NULL&#123;return DFCERRSTUS;&#125;device_t* devp=new_device_dsc();//建立设备描述符结构的变量实例if(devp==NULL)//不能失败&#123;return DFCERRSTUS;&#125;systick_set_device(devp,drvp);//驱动程序的功能函数设置到driver_t结构中的drv_dipif(krldev_add_driver(devp,drvp)==DFCERRSTUS)//将设备挂载到驱动中&#123;if(del_device_dsc(devp)==DFCERRSTUS)//注意释放资源&#123;return DFCERRSTUS;&#125;return DFCERRSTUS;&#125;if(krlnew_device(devp)==DFCERRSTUS)//向内核注册设备&#123;if(del_device_dsc(devp)==DFCERRSTUS)//注意释放资源&#123;return DFCERRSTUS;&#125;return DFCERRSTUS;&#125;//安装中断回调函数systick_handleif(krlnew_devhandle(devp,systick_handle,20)==DFCERRSTUS)&#123;return DFCERRSTUS; //注意释放资源&#125;init_8254();//初始化物理设备if(krlenable_intline(20)==DFCERRSTUS)&#123;return DFCERRSTUS;&#125;return DFCOKSTUS;&#125;// --------------// 设备与驱动的联系// --------------drvstus_t krldev_add_driver(device_t *devp, driver_t *drvp)&#123; list_h_t *lst; device_t *fdevp; //遍历这个驱动上所有设备 list_for_each(lst, &amp;drvp-&gt;drv_alldevlist) &#123; fdevp = list_entry(lst, device_t, dev_indrvlst); //比较设备ID有相同的则返回错误 if (krlcmp_devid(&amp;devp-&gt;dev_id, &amp;fdevp-&gt;dev_id) == TRUE) &#123; return DFCERRSTUS; &#125; &#125; //将设备挂载到驱动上 list_add(&amp;devp-&gt;dev_indrvlst, &amp;drvp-&gt;drv_alldevlist); devp-&gt;dev_drv = drvp;//让设备中dev_drv字段指向管理自己的驱动 return DFCOKSTUS;&#125;// ------------// 向内核注册设备// ------------drvstus_t krlnew_device(device_t *devp)&#123; device_t *findevp; drvstus_t rets = DFCERRSTUS; cpuflg_t cpufg; list_h_t *lstp; devtable_t *dtbp = &amp;osdevtable; uint_t devmty = devp-&gt;dev_id.dev_mtype; if (devp-&gt;dev_drv == NULL)//没有驱动的设备不行 &#123; return DFCERRSTUS; &#125; krlspinlock_cli(&amp;dtbp-&gt;devt_lock, &amp;cpufg);//加锁 //遍历设备类型链表上的所有设备 list_for_each(lstp, &amp;dtbp-&gt;devt_devclsl[devmty].dtl_list) &#123; findevp = list_entry(lstp, device_t, dev_intbllst); //不能有设备ID相同的设备，如果有则出错 if (krlcmp_devid(&amp;devp-&gt;dev_id, &amp;findevp-&gt;dev_id) == TRUE) &#123; rets = DFCERRSTUS; goto return_step; &#125; &#125; //先把设备加入设备表的全局设备链表 list_add(&amp;devp-&gt;dev_intbllst, &amp;dtbp-&gt;devt_devclsl[devmty].dtl_list) //将设备加入对应设备类型的链表中 list_add(&amp;devp-&gt;dev_list, &amp;dtbp-&gt;devt_devlist); dtbp-&gt;devt_devclsl[devmty].dtl_nr++;//设备计数加一 dtbp-&gt;devt_devnr++;//总的设备数加一 rets = DFCOKSTUS; return_step: krlspinunlock_sti(&amp;dtbp-&gt;devt_lock, &amp;cpufg);//解锁 return rets;&#125;// ---------------// 安装中断回调函数// ---------------//中断回调函数类型typedef drvstus_t (*intflthandle_t)(uint_t ift_nr,void* device,void* sframe);//安装中断回调函数接口drvstus_t krlnew_devhandle(device_t *devp, intflthandle_t handle, uint_t phyil&#123; //调用内核层中断框架接口函数 intserdsc_t *sdp = krladd_irqhandle(devp, handle, phyiline); if (sdp == NULL) &#123; return DFCERRSTUS; &#125; cpuflg_t cpufg; krlspinlock_cli(&amp;devp-&gt;dev_lock, &amp;cpufg); //将中断服务描述符结构挂入这个设备结构中 list_add(&amp;sdp-&gt;s_indevlst, &amp;devp-&gt;dev_intserlst); devp-&gt;dev_intlnenr++; krlspinunlock_sti(&amp;devp-&gt;dev_lock, &amp;cpufg); return DFCOKSTUS;&#125;// 内核层的中断框架接口typedef struct s_INTSERDSC&#123;list_h_t s_list; //在中断异常描述符中的链表list_h_t s_indevlst; //在设备描述描述符中的链表u32_t s_flg; //标志intfltdsc_t* s_intfltp; //指向中断异常描述符void* s_device; //指向设备描述符uint_t s_indx; //中断回调函数运行计数intflthandle_t s_handle; //中断处理的回调函数指针&#125;intserdsc_t;intserdsc_t *krladd_irqhandle(void *device, intflthandle_t handle, uint_t phyi&#123; //根据设备中断线返回对应中断异常描述符intfltdsc_t *intp = hal_retn_intfltdsc(phyiline);if (intp == NULL)&#123;return NULL;&#125;intserdsc_t *serdscp = (intserdsc_t *)krlnew(sizeof(intserdsc_t));//建立一个if (serdscp == NULL)&#123;return NULL;&#125;//初始化intserdsc_t结构体实例变量，并把设备指针和回调函数放入其中intserdsc_t_init(serdscp, 0, intp, device, handle);//把intserdsc_t结构体实例变量挂载到中断异常描述符结构中if (hal_add_ihandle(intp, serdscp) == FALSE)&#123;if (krldelete((adr_t)serdscp, sizeof(intserdsc_t)) == FALSE)&#123;hal_sysdie(&quot;krladd_irqhandle ERR&quot;);&#125;return NULL;&#125;return serdscp;&#125;// ----------// 驱动加入内核// ----------// 实现挂载功能的函数drvstus_t krldriver_add_system(driver_t *drvp)&#123; cpuflg_t cpufg; devtable_t *dtbp = &amp;osdevtable;//设备表 krlspinlock_cli(&amp;dtbp-&gt;devt_lock, &amp;cpufg);//加锁 list_add(&amp;drvp-&gt;drv_list, &amp;dtbp-&gt;devt_drvlist);//挂载 dtbp-&gt;devt_drvnr++;//增加驱动程序计数 krlspinunlock_sti(&amp;dtbp-&gt;devt_lock, &amp;cpufg);//解锁 return DFCOKSTUS;&#125; 8.3 设备如何处理内核IO包 什么是IO包 内核要求设备完成任务,无非是调用设备的驱动程序函数,把完成任务的细节用参数的形式传递给设备的驱动程序 IO包：使用更高效的管理方法,需要把操作所需的各种参数封装在一个数据结构中，统一驱动程序功能函数的形式 **objnode_t 的数据结构(当做IO包看)**中包括各个驱动程序功能函数的所有参数,不单是完成了IO包传递参数的功能,在整个IO生命周期中,都起着重要的作用 创建和删除IO包 创建IO包是在内存中建立 objnode_t 结构的实例变量并初始化它 在 cosmos/kernel/建立 krlobjnode.c 文件 krlnew_objnode,krldel_objnode 完成了建立,删除 objnode_t 结构,分配和释放 objnode_t 结构的内存空间 内存管理组件在操作系统内核中的重要性, objnode_t_init 函数会初始化 objnode_t 结构中的字段 向设备发送IO包 向设备发送IO包标志着一个设备驱动程序开始运行,之后内核就实际的控制权交给驱动程序,由驱动程序代表内核操控设备 函数属于驱动模型函数,在 krldevice.c 文件中实现函数 krldev_io 函数，只接受一个参数，也就是 objnode_t 结构的指针。它会首先检查 objnode_t 结构中的 IO 操作码是不是合乎要求的，还要检查被操作的对象即设备是不是为空，然后调用 krldev_call_driver 函数 krldev_call_driver 函数会再次确认传递进来的设备和 IO 操作码，然后重点检查设备有没有驱动程序。这一切检查通过之后，就用 IO 操作码为索引调用驱动程序功能分派函数数组中的函数，并把设备和 objnode_t 结构传递进去 驱动程序实例 systick 设备驱动是系统的心跳，主要功能和作用是每隔 1ms 产生一个中断 8254是一个古老且常用的定时器，对它进行编程设定，可以周期的产生定时器中断 以8254定时器为基础,实现系统的systick设备，先从systick设备驱动程序的整体框架入手，然后建立systick设备，最后一步一步实现systick设备驱动程序 systick设备驱动程序的整体框架 cosmos/drivers/下建立 drctick.c文件实现整体框架 在各个函数可以返回一个错误状态,而不做任何实际工作,但必须要有这个函数以给予适当的响应 systick设备驱动程序的入口:建立设备,向内核注册设备，安装中断回调函数等操作 函数最后的 krlenable_intline 函数的主要功能是开启一个中断源上的中断;而 init_8254 函数则是为了初始化8254 将驱动程序入口函数 systick_entry 函数放入驱动表中 之后系统启动时就会执行初始驱动初始化 init_krldriver 函数，接着这个函数就会启动运行 systick 设备驱动程序入口函数，建立 systick 设备, 不断的产生时钟中断 配置设备和驱动 在驱动程序入口函数中，除了那些标准的流程之外还要对设备和驱动进行适当的配置，就是设置一些标志、状态、名称、驱动功能派发函数等等。有了这些信息，设备才能加入到驱动程序中，然后注册到内核，才能被内核所识别 实现设置驱动程序的函数,主要设置设备驱动程序的名称,功能派发函数 systick_set_driver 函数，无非就是将12个驱动功能函数的地址，分别设置到 driver_t 结构的 drv_dipfun 数组中。其中，驱动功能函数在该数组中的元素位置，正好与 IO 操作码一一对应，当内核用 IO 操作码调用驱动时，就是调用了这个数据中的函数。最后将驱动程序的名称设置为systick0drv 新建的设备需要配置相关的信息才能工作,设备类型非常重要,内核通过类型类区分各种设备 systick_set_device 函数需要两个参数，但是第二个参数暂时没起作用，而第一个参数其实是一个 device_t 结构的指针，在 systick_entry 函数中调用 new_device_dsc 函数的时候，就会返回这个指针。后面我们会把设备加载到内核中，那时这个指针指向的设备才会被注册 打开与关闭设备 实现打开与关闭设备功能:只是简单地增加与减少设备的引用计数，然后返回成功完成的状态。而增加与减少设备的引用计数，是为了统计有多少个进程打开了这个设备，当设备引用计数为 0 时，就说明没有进程使用该设备. systick设备中断回调函数 systick 设备产生的中断，以及在中断回调函数中执行的操作，即周期性的执行系统中的某些动作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283// -----------// IO包数据结构// -----------typedef struct s_OBJNODE&#123; spinlock_t on_lock; //自旋锁 list_h_t on_list; //链表 sem_t on_complesem; //完成信号量 uint_t on_flgs; //标志 uint_t on_stus; //状态 sint_t on_opercode; //操作码 uint_t on_objtype; //对象类型 void* on_objadr; //对象地址 uint_t on_acsflgs; //访问设备、文件标志 uint_t on_acsstus; //访问设备、文件状态 uint_t on_currops; //对应于读写数据的当前位置 uint_t on_len; //对应于读写数据的长度 uint_t on_ioctrd; //IO控制码 buf_t on_buf; //对应于读写数据的缓冲区 uint_t on_bufcurops; //对应于读写数据的缓冲区的当前位置 size_t on_bufsz; //对应于读写数据的缓冲区的大小 uint_t on_count; //对应于对象节点的计数 void* on_safedsc; //对应于对象节点的安全描述符 void* on_fname; //对应于访问数据文件的名称 void* on_finode; //对应于访问数据文件的结点 void* on_extp; //用于扩展&#125;objnode_t;// -------------// 创建和删除IO包// -------------//建立objnode_t结构objnode_t *krlnew_objnode()&#123; objnode_t *ondp = (objnode_t *)krlnew((size_t)sizeof(objnode_t));//分配objn if (ondp == NULL) &#123; return NULL; &#125; objnode_t_init(ondp);//初始化objnode_t结构 return ondp;&#125;//删除objnode_t结构bool_t krldel_objnode(objnode_t *onodep)&#123; if (krldelete((adr_t)onodep, (size_t)sizeof(objnode_t)) == FALSE)//删除objn &#123; hal_sysdie(&quot;krldel_objnode err&quot;); return FALSE; &#125; return TRUE;&#125;// -------------// 向设备发送IO包// -------------//发送设备IOdrvstus_t krldev_io(objnode_t *nodep)&#123; //获取设备对象 device_t *devp = (device_t *)(nodep-&gt;on_objadr); if ((nodep-&gt;on_objtype != OBJN_TY_DEV &amp;&amp; nodep-&gt;on_objtype != OBJN_TY_FIL) &#123;//检查操作对象类型是不是文件或者设备，对象地址是不是为空 return DFCERRSTUS; &#125; if (nodep-&gt;on_opercode &lt; 0 || nodep-&gt;on_opercode &gt;= IOIF_CODE_MAX) &#123;//检查IO操作码是不是合乎要求 return DFCERRSTUS; &#125; return krldev_call_driver(devp, nodep-&gt;on_opercode, 0, 0, NULL, nodep);//调&#125;//调用设备驱动drvstus_t krldev_call_driver(device_t *devp, uint_t iocode, uint_t val1, uint_&#123; driver_t *drvp = NULL; if (devp == NULL || iocode &gt;= IOIF_CODE_MAX) &#123;//检查设备和IO操作码 return DFCERRSTUS; &#125; drvp = devp-&gt;dev_drv; if (drvp == NULL)//检查设备是否有驱动程序 &#123; return DFCERRSTUS; &#125; //用IO操作码为索引调用驱动程序功能分派函数数组中的函数 return drvp-&gt;drv_dipfun[iocode](devp, p2);&#125;// ---------------------------// systick设备驱动程序的整体框架// ---------------------------//驱动程序入口和退出函数drvstus_t systick_entry(driver_t *drvp, uint_t val, void *p)&#123;return DFCERRSTUS;&#125;drvstus_t systick_exit(driver_t *drvp, uint_t val, void *p)&#123;return DFCERRSTUS;&#125;//设备中断处理函数drvstus_t systick_handle(uint_t ift_nr, void *devp, void *sframe)&#123;return DFCEERSTUS;&#125;//打开、关闭设备函数drvstus_t systick_open(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;drvstus_t systick_close(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//读、写设备数据函数drvstus_t systick_read(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;drvstus_t systick_write(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//调整读写设备数据位置函数drvstus_t systick_lseek(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//控制设备函数drvstus_t systick_ioctrl(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//开启、停止设备函数drvstus_t systick_dev_start(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;drvstus_t systick_dev_stop(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//设置设备电源函数drvstus_t systick_set_powerstus(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//枚举设备函数drvstus_t systick_enum_dev(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//刷新设备缓存函数drvstus_t systick_flush(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;//设备关机函数drvstus_t systick_shutdown(device_t *devp, void *iopack)&#123;return DFCERRSTUS;&#125;// -----------------------// systick设备驱动程序的入口// -----------------------drvstus_t systick_entry(driver_t* drvp,uint_t val,void* p)&#123; if(drvp==NULL) //drvp是内核传递进来的参数，不能为NULL &#123; return DFCERRSTUS; &#125; device_t* devp=new_device_dsc();//建立设备描述符结构的变量实例 if(devp==NULL)//不能失败 &#123; return DFCERRSTUS; &#125; systick_set_driver(drvp); systick_set_device(devp,drvp);//驱动程序的功能函数设置到driver_t结构中的 drv_dipfun if(krldev_add_driver(devp,drvp)==DFCERRSTUS)//将设备挂载到驱动中 &#123; if(del_device_dsc(devp)==DFCERRSTUS)//注意释放资源。 &#123; return DFCERRSTUS; &#125; return DFCERRSTUS; &#125; if(krlnew_device(devp)==DFCERRSTUS)//向内核注册设备 &#123; if(del_device_dsc(devp)==DFCERRSTUS)//注意释放资源 &#123; return DFCERRSTUS; &#125; return DFCERRSTUS; &#125; //安装中断回调函数systick_handle if(krlnew_devhandle(devp,systick_handle,20)==DFCERRSTUS) &#123; return DFCERRSTUS; //注意释放资源。 &#125; init_8254();//初始化物理设备 if(krlenable_intline(0x20)==DFCERRSTUS) &#123; return DFCERRSTUS; &#125; return DFCOKSTUS;&#125;// 将 systick_entry 函数放在驱动表里//cosmos/kernel/krlglobal.cKRL_DEFGLOB_VARIABLE(drventyexit_t,osdrvetytabl)[]=&#123;systick_entry,NULL&#125;;// -------------// 配置设备和驱动// -------------void systick_set_driver(driver_t *drvp)&#123; //设置驱动程序功能派发函数 drvp-&gt;drv_dipfun[IOIF_CODE_OPEN] = systick_open; drvp-&gt;drv_dipfun[IOIF_CODE_CLOSE] = systick_close; drvp-&gt;drv_dipfun[IOIF_CODE_READ] = systick_read; drvp-&gt;drv_dipfun[IOIF_CODE_WRITE] = systick_write; drvp-&gt;drv_dipfun[IOIF_CODE_LSEEK] = systick_lseek; drvp-&gt;drv_dipfun[IOIF_CODE_IOCTRL] = systick_ioctrl; drvp-&gt;drv_dipfun[IOIF_CODE_DEV_START] = systick_dev_start; drvp-&gt;drv_dipfun[IOIF_CODE_DEV_STOP] = systick_dev_stop; drvp-&gt;drv_dipfun[IOIF_CODE_SET_POWERSTUS] = systick_set_powerstus; drvp-&gt;drv_dipfun[IOIF_CODE_ENUM_DEV] = systick_enum_dev; drvp-&gt;drv_dipfun[IOIF_CODE_FLUSH] = systick_flush; drvp-&gt;drv_dipfun[IOIF_CODE_SHUTDOWN] = systick_shutdown; drvp-&gt;drv_name = &quot;systick0drv&quot;;//设置驱动程序名称 return;&#125;// ------------// 打开与关闭设备// ------------//打开设备drvstus_t systick_open(device_t *devp, void *iopack)&#123; krldev_inc_devcount(devp);//增加设备计数 return DFCOKSTUS;//返回成功完成的状态&#125;//关闭设备drvstus_t systick_close(device_t *devp, void *iopack)&#123; krldev_dec_devcount(devp);//减少设备计数 return DFCOKSTUS;//返回成功完成的状态&#125;// ----------------------// systick 设备中断回调函数// ----------------------// 中断函数drvstus_t systick_handle(uint_t ift_nr, void *devp, void *sframe)&#123; kprint(&quot;systick_handle run devname:%s intptnr:%d\\n&quot;, ((device_t *)devp)-&gt;d return DFCOKSTUS;&#125;// 修改内核初始化函数void init_krl()&#123; init_krlmm(); init_krldevice();//初始化设备 init_krldriver();//初始化驱动程序 init_krlsched(); //init_krlcpuidle();禁止进程运行 STI();//打开CPU响应中断的能力 die(0);//进入死循环 return;&#125;// 在每个进程中都要主动调用进程调度器函数，否则进程就会永远霸占 CPU，永远运行下去// 需要使用定时器周期性的检查进程运行多少时间,若进程运行时间超过了,就应该强制调度,让别的进程开始运行// 更新进程运行时间的代码,在中断回调函数中调用即可drvstus_t systick_handle(uint_t ift_nr, void *devp, void *sframe)&#123; krlthd_inc_tick(krlsched_retn_currthread());//更新当前进程的tick return DFCOKSTUS;&#125;// krlthd_inc_tick 函数需要一个进程指针的参数，而 krlsched_retn_currthread 函数是返回当前正在运行进程的指针。在 krlthd_inc_tick 函数中对进程的 tick 值加 1，如果大于 20（也就是 20 毫秒）就重新置 0，并进行调度 8.4 瞧一瞧Linux:如何获取所有设备信息 感受Linux的设备信息 linux设备文件在sys/bus目录下 linux用bus总线组织设备和驱动,在sys/bus目录下输入tree命令就可以看到所有总线下的所有设备 总线目录下有设备目录,设备目录下是设备文件 数据结构 Linux的驱动模型至少有三个核心数据结构,分别是总线,设备和驱动，还需要 kobject 和 kset kobject 与 kset kobject 和 kset 是构成 /sys 目录下的目录节点和文件节点的核心,也是层次化组织总线,设备,驱动的核心数据结构, kobject，kset数据结构都能表示一个目录或文件节点 每一个 kobject，都对应着 /sys 目录下的一个目录或者文件，目录或者文件的名字就是 kobject 结构中的 name kset 结构中包含一个 kobject 结构,既是 kobject 的容器,同时本身还是一个 kobject kset不仅是个kobject，还能挂载多个kobject，是kobject的集合容器 在Linux内核中,至少有两个顶层kset kset与kobject只是基础数据结构,肯定是嵌入到更高级的数据结构之中使用 文件操作函数 在Linux系统中,提供更高级的封装,Linux设备将设备分为几类:字符设备,块设备,网络设备以及杂项设备 设备的数据结构都会直接或间接包含基础的 device 结构 12345678910111213141516171819202122232425262728293031323334353637383940414243// --------------// kobject 与 kset// --------------struct kobject &#123; const char *name; //名称，反映在sysfs中 struct list_head entry; //挂入kset结构的链表 struct kobject *parent; //指向父结构 struct kset *kset; //指向所属的kset struct kobj_type *ktype; struct kernfs_node *sd; //指向sysfs文件系统目录项 struct kref kref; //引用计数器结构 unsigned int state_initialized:1;//初始化状态 unsigned int state_in_sysfs:1; //是否在sysfs中 unsigned int state_add_uevent_sent:1; unsigned int state_remove_uevent_sent:1; unsigned int uevent_suppress:1;&#125;;struct kset &#123; struct list_head list; //挂载kobject结构的链表 spinlock_t list_lock; //自旋锁 struct kobject kobj;//自身包含一个kobject结构 const struct kset_uevent_ops *uevent_ops;//暂时不关注&#125; __randomize_layout;struct kset *devices_kset;//管理所有设备static struct kset *bus_kset;//管理所有总线static struct kset *system_kset;int __init devices_init(void)&#123;devices_kset = kset_create_and_add(&quot;devices&quot;, &amp;device_uevent_ops, NULL);//return 0;&#125;int __init buses_init(void)&#123;bus_kset = kset_create_and_add(&quot;bus&quot;, &amp;bus_uevent_ops, NULL);//建立总线ksetif (!bus_kset)return -ENOMEM;system_kset = kset_create_and_add(&quot;system&quot;, NULL, &amp;devices_kset-&gt;kobj);//在if (!system_kset)return -ENOMEM;return 0;&#125; 总线 总线可以表示CPU与设备的连接,抽象为bus_type结构 bus_type结构包括总线名字,总线属性,还有操作该总线下所有设备通用操作函数的指针 总线不仅仅是组织设备和驱动的容器,还是同类设备的共有功能的抽象 subsys_private 是总线的驱动核心的私有数据 通过 bus_kset 可以找到所有的 kset，通过 kset 又能找到 subsys_private，再通过 subsys_private 就可以找到总线了，也可以找到该总线上所有的设备与驱动 设备 Linux抽象出总线结构,但是还需要一个设备,设备也是一个数据结构,里面包含一个设备的所有信息 device 结构很大，结构中同样包含了 kobject 结构，使得设备可以加入 kset 和 kobject 组建的层次结构中 device 结构中有总线和驱动指针，能帮助设备找到自己的驱动程序和总线 驱动 驱动需要数据结构,其中包含了驱动程序的相关信息,在device结构中就是device_driver结构 在 device_driver 结构中，包含了驱动程序的名字、驱动程序所在模块、设备探查和电源相关的回调函数的指针 在 driver_private 结构中同样包含了 kobject 结构，用于组织所有的驱动，还指向了驱动本身 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202// ---// 总线// ---struct bus_type &#123; const char *name;//总线名称 const char *dev_name;//用于列举设备，如（&quot;foo%u&quot;, dev-&gt;id） struct device *dev_root;//父设备 const struct attribute_group **bus_groups;//总线的默认属性 const struct attribute_group **dev_groups;//总线上设备的默认属性 const struct attribute_group **drv_groups;//总线上驱动的默认属性 //每当有新的设备或驱动程序被添加到这个总线上时调用 int (*match)(struct device *dev, struct device_driver *drv); //当一个设备被添加、移除或其他一些事情时被调用产生uevent来添加环境变量。 int (*uevent)(struct device *dev, struct kobj_uevent_env *env); //当一个新的设备或驱动程序添加到这个总线时被调用，并回调特定驱动程序探查函数，以初始化匹配 int (*probe)(struct device *dev); //将设备状态同步到软件状态时调用 void (*sync_state)(struct device *dev); //当一个设备从这个总线上删除时被调用 int (*remove)(struct device *dev); //当系统关闭时被调用 void (*shutdown)(struct device *dev); //调用以使设备重新上线（在下线后） int (*online)(struct device *dev); //调用以使设备离线，以便热移除。可能会失败。 int (*offline)(struct device *dev); //当这个总线上的设备想进入睡眠模式时调用 int (*suspend)(struct device *dev, pm_message_t state); //调用以使该总线上的一个设备脱离睡眠模式 int (*resume)(struct device *dev); //调用以找出该总线上的一个设备支持多少个虚拟设备功能 int (*num_vf)(struct device *dev); //调用以在该总线上的设备配置DMA int (*dma_configure)(struct device *dev); //该总线的电源管理操作，回调特定的设备驱动的pm-ops const struct dev_pm_ops *pm; //此总线的IOMMU具体操作，用于将IOMMU驱动程序实现到总线上 const struct iommu_ops *iommu_ops; //驱动核心的私有数据，只有驱动核心能够接触这个 struct subsys_private *p; struct lock_class_key lock_key; //当探测或移除该总线上的一个设备时，设备驱动核心应该锁定该设备 bool need_parent_lock;&#125;;//通过kobject找到对应的subsys_private#define to_subsys_private(obj) container_of(obj, struct subsys_private, subsysstruct subsys_private &#123; struct kset subsys;//定义这个子系统结构的kset struct kset *devices_kset;//该总线的&quot;设备&quot;目录，包含所有的设备 struct list_head interfaces;//总线相关接口的列表 struct mutex mutex;//保护设备，和接口列表 struct kset *drivers_kset;//该总线的&quot;驱动&quot;目录，包含所有的驱动 struct klist klist_devices;//挂载总线上所有设备的可迭代链表 struct klist klist_drivers;//挂载总线上所有驱动的可迭代链表 struct blocking_notifier_head bus_notifier; unsigned int drivers_autoprobe:1; struct bus_type *bus; //指向所属总线 struct kset glue_dirs; struct class *class;//指向这个结构所关联类结构的指针&#125;;// ---// 设备// ---struct device &#123; struct kobject kobj; struct device *parent;//指向父设备 struct device_private *p;//设备的私有数据 const char *init_name; //设备初始化名字 const struct device_type *type;//设备类型 struct bus_type *bus; //指向设备所属总线 struct device_driver *driver;//指向设备的驱动 void *platform_data;//设备平台数据 void *driver_data;//设备驱动的私有数据 struct dev_links_info links;//设备供应商链接 struct dev_pm_info power;//用于设备的电源管理 struct dev_pm_domain *pm_domain;//提供在系统暂停时执行调用 #ifdef CONFIG_GENERIC_MSI_IRQ struct list_head msi_list;//主机的MSI描述符链表 #endif struct dev_archdata archdata; struct device_node *of_node; //用访问设备树节点 struct fwnode_handle *fwnode; //设备固件节点 dev_t devt; //用于创建sysfs &quot;dev&quot; u32 id; //设备实例id spinlock_t devres_lock;//设备资源链表锁 struct list_head devres_head;//设备资源链表 struct class *class;//设备的类 const struct attribute_group **groups; //可选的属性组 void (*release)(struct device *dev);//在所有引用结束后释放设备 struct iommu_group *iommu_group;//该设备属于的IOMMU组 struct dev_iommu *iommu;//每个设备的通用IOMMU运行时数据&#125;;// ---// 驱动// ---struct device_driver &#123; const char *name;//驱动名称 struct bus_type *bus;//指向总线 struct module *owner;//模块持有者 const char *mod_name;//用于内置模块 bool suppress_bind_attrs;//禁用通过sysfs的绑定/解绑 enum probe_type probe_type;//要使用的探查类型（同步或异步） const struct of_device_id *of_match_table;//开放固件表 const struct acpi_device_id *acpi_match_table;//ACPI匹配表 //被调用来查询一个特定设备的存在 int (*probe) (struct device *dev); //将设备状态同步到软件状态时调用 void (*sync_state)(struct device *dev); //当设备被从系统中移除时被调用，以便解除设备与该驱动的绑定 int (*remove) (struct device *dev); //关机时调用，使设备停止 void (*shutdown) (struct device *dev); //调用以使设备进入睡眠模式，通常是进入一个低功率状态 int (*suspend) (struct device *dev, pm_message_t state); //调用以使设备从睡眠模式中恢复 int (*resume) (struct device *dev); //默认属性 const struct attribute_group **groups; //绑定设备的属性 const struct attribute_group **dev_groups; //设备电源操作 const struct dev_pm_ops *pm; //当sysfs目录被写入时被调用 void (*coredump) (struct device *dev); //驱动程序私有数据 struct driver_private *p;&#125;;struct driver_private &#123; struct kobject kobj; struct klist klist_devices;//驱动管理的所有设备的链表 struct klist_node knode_bus;//加入bus链表的节点 struct module_kobject *mkobj;//指向用kobject管理模块节点 struct device_driver *driver;//指向驱动本身&#125;// -----------// 文件操作函数// -----------// 用miscdevice结构表示杂项设备，this_device指针指向下层，属于这个杂项设备的device结构struct miscdevice &#123; int minor;//设备号 const char *name;//设备名称 const struct file_operations *fops;//文件操作函数结构 struct list_head list;//链表 struct device *parent;//指向父设备的device结构 struct device *this_device;//指向本设备的device结构 const struct attribute_group **groups; const char *nodename;//节点名字 umode_t mode;//访问权限&#125;;// 重点是 file_operations 结构，设备一经注册，就会在 sys 相关的目录下建立设备对应的文件结点，对这个文件结点打开、读写等操作，最终会调用到驱动程序对应的函数，而对应的函数指针就保存在 file_operations 结构中// file_operations 结构中的函数指针有 31 个struct file_operations &#123; struct module *owner;//所在的模块 loff_t (*llseek) (struct file *, loff_t, int);//调整读写偏移 ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);//读 ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);// int (*mmap) (struct file *, struct vm_area_struct *);//映射 int (*open) (struct inode *, struct file *);//打开 int (*flush) (struct file *, fl_owner_t id);//刷新 int (*release) (struct inode *, struct file *);//关闭&#125; randomize_layout;// Linux 的打开系统调用接口会调用 filp_open 函数,其调用路径// filp_open// file_open_name// do_filp_open// path_openatstatic int do_o_path(struct nameidata *nd, unsigned flags, struct file *file)&#123; struct path path; int error = path_lookupat(nd, flags, &amp;path);//解析文件路径得到文件inode节点 if (!error) &#123; audit_inode(nd-&gt;name, path.dentry, 0); error = vfs_open(&amp;path, file);//vfs层打开文件接口 path_put(&amp;path); &#125; return error;&#125;int vfs_open(const struct path *path, struct file *file)&#123; file-&gt;f_path = *path; return do_dentry_open(file, d_backing_inode(path-&gt;dentry), NULL);&#125;static int do_dentry_open(struct file *f, struct inode *inode,int (*open)(stru&#123; //略过我们不想看的代码 f-&gt;f_op = fops_get(inode-&gt;i_fop);//获取文件节点的file_operations if (!open)//如果open为空则调用file_operations结构中的open函数 open = f-&gt;f_op-&gt;open; if (open) &#123; error = open(inode, f); &#125; //略过我们不想看的代码 return 0;&#125;// file_operations 结构的地址存在一个文件的inode结构中// 在Linux 系统中，都是用inode结构表示一个文件，不管它是数据文件还是设备文件 驱动程序实例 该驱动程序的主要工作就是获取所有总线和其下所有设备的名字;需要先了解驱动程序的整体框架,接着建立总线和设备,然后实现驱动程序的打开,关闭，读写操作函数,最后写个应用程序测试驱动程序 驱动程序框架 Linux内核的驱动程序是在一个可加载的内核模块中实现，可加载的内核模块只需要两个函数和模块信息 要在模块中实现总线和设备驱动,需要更多的函数和数据结构 模块一旦加载就会执行 miscdrv_init 函数，卸载时就会执行 miscdrv_exit 函数 建立设备 先建立总线，然后在总线下建立一个设备 Linux系统提供 bus_register 函数向内核注册一个总线，相当于建立一个总线,需要在 miscdrv_init 函数中调用 bus_register 函数会在系统中注册一个总线,所需参数就是总线结构的地址(&amp;deviceinfo_bus)，返回非0表示注册失败 建立 misc 杂项设备:misc杂项设备需要定一个数据结构,然后调用 misc 杂项设备注册接口函数 misc_register 函数只是负责分配设备号，以及把 miscdev 加入链表，真正的核心工作由device_create_with_groups 函数来完成 执行make命令，产生 miscdvrv.ko内核模块文件,把该文件加载到 Linux系统中即可 终端中使用 sudo cat /proc/kmsg指令读取/proc/kmsg文件,内核prink函数输出信息 在 /dev 目录看到一个 devicesinfo 文件，同时在 /sys/bus/ 目录下也可以看到一个 devicesinfobus 文件(建立的设备和总线的文件节点的名称) 打开,关系,读写函数 正常情况下不能获取 bus_kset 地址的，它是所有总线的根，包含了所有总线的kobject，Linux 为了保护 bus_kset，并没有在 bus_type 结构中直接包含 kobject，而是让总线指向一个 subsys_private 结构，在其中包含了 kobject 结构 要注册一个总线得到 bus_kset，根据它又能找到所有 subsys_private 结构中的 kobject，接着找到 subsys_private 结构，反向查询到bus_type 结构的地址 然后调用 Linux 提供的 bus_for_each_dev 函数，就可以遍历一个总线上的所有设备，它每遍历到一个设备，就调用一个函数，这个函数是用参数的方式传给它的，在代码中就是 misc_find_match 函数 在调用 misc_find_match 函数时，会把一个设备结构的地址和另一个指针作为参数传递进来。最后就能打印每个设备的名称了 测试驱动 加载驱动之后会自动建立设备文件，但驱动程序不会主动工作，需要写应用程序对设备文件进行读写才能测试驱动 切换到代码目录 make 一下，然后加载 miscdrv.ko 模块，最后在终端中执行 sudo ./app，就能在另一个已经执行了 sudo cat /proc/kmsg 的终端中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295#define DEV_NAME &quot;devicesinfo&quot;#define BUS_DEV_NAME &quot;devicesinfobus&quot;static int misc_find_match(struct device *dev, void *data)&#123;printk(KERN_EMERG &quot;device name is:%s\\n&quot;, dev-&gt;kobj.name);return 0;&#125;//对应于设备文件的读操作函数static ssize_t misc_read (struct file *pfile, char __user *buff, size_t size)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;//对应于设备文件的写操作函数static ssize_t misc_write(struct file *pfile, const char __user *buff, size_t size)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;//对应于设备文件的打开操作函数static int misc_open(struct inode *pinode, struct file *pfile)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;//对应于设备文件的关闭操作函数static int misc_release(struct inode *pinode, struct file *pfile)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;static int devicesinfo_bus_match(struct device *dev, struct device_driver *driver)&#123;return !strncmp(dev-&gt;kobj.name, driver-&gt;name, strlen(driver-&gt;name));&#125;//对应于设备文件的操作函数结构static const struct file_operations misc_fops = &#123;.read = misc_read,.write = misc_write,.release = misc_release,.open = misc_open,&#125;;//misc设备的结构static struct miscdevice misc_dev = &#123;.fops = &amp;misc_fops, //设备文件操作方法.minor = 255, //次设备号.name = DEV_NAME, //设备名/dev/下的设备节点名&#125;;//总线结构struct bus_type devicesinfo_bus = &#123;.name = BUS_DEV_NAME, //总线名字.match = devicesinfo_bus_match, //总线match函数指针&#125;;//内核模块入口函数static int __init miscdrv_init(void)&#123;printk(KERN_EMERG &quot;INIT misc\\n&quot;)；return 0;&#125;//内核模块退出函数static void __exit miscdrv_exit(void)&#123;printk(KERN_EMERG &quot;EXIT,misc\\n&quot;);&#125;module_init(miscdrv_init);//申明内核模块入口函数module_exit(miscdrv_exit);//申明内核模块退出函数MODULE_LICENSE(&quot;GPL&quot;);//模块许可MODULE_AUTHOR(&quot;LMOS&quot;);//模块开发者// -------// 建立设备// -------static int __init miscdrv_init(void)&#123; printk(KERN_EMERG &quot;INIT misc\\n&quot;); busok = bus_register(&amp;devicesinfo_bus);//注册总线 return 0;&#125;int bus_register(struct bus_type *bus)&#123;int retval;struct subsys_private *priv;//分配一个subsys_private结构priv = kzalloc(sizeof(struct subsys_private), GFP_KERNEL);//bus_type和subsys_private结构互相指向priv-&gt;bus = bus;bus-&gt;p = priv;//把总线的名称加入subsys_private的kobject中retval = kobject_set_name(&amp;priv-&gt;subsys.kobj, &quot;%s&quot;, bus-&gt;name);priv-&gt;subsys.kobj.kset = bus_kset;//指向bus_kset//把subsys_private中的kset注册到系统中retval = kset_register(&amp;priv-&gt;subsys);//建立总线的文件结构在sysfs中retval = bus_create_file(bus, &amp;bus_attr_uevent);//建立subsys_private中的devices和drivers的ksetpriv-&gt;devices_kset = kset_create_and_add(&quot;devices&quot;, NULL,&amp;priv-&gt;subsys.kobj);priv-&gt;drivers_kset = kset_create_and_add(&quot;drivers&quot;, NULL,&amp;priv-&gt;subsys.kobj);//建立subsys_private中的devices和drivers链表，用于属于总线的设备和驱动klist_init(&amp;priv-&gt;klist_devices, klist_devices_get, klist_devices_put);klist_init(&amp;priv-&gt;klist_drivers, NULL, NULL);return 0;&#125;// 静态定义了 miscdevice 结构的变量 misc_dev#define DEV_NAME &quot;devicesinfo&quot;static const struct file_operations misc_fops = &#123;.read = misc_read,.write = misc_write,.release = misc_release,.open = misc_open,&#125;;static struct miscdevice misc_dev = &#123;.fops = &amp;misc_fops, //设备文件操作方法.minor = 255, //次设备号.name = DEV_NAME, //设备名/dev/下的设备节点名&#125;;static int __init miscdrv_init(void)&#123;misc_register(&amp;misc_dev);//注册misc杂项设备printk(KERN_EMERG &quot;INIT misc busok\\n&quot;);busok = bus_register(&amp;devicesinfo_bus);//注册总线return 0;&#125;// misc_register 函数int misc_register(struct miscdevice *misc)&#123; dev_t dev; int err = 0; bool is_dynamic = (misc-&gt;minor == MISC_DYNAMIC_MINOR); INIT_LIST_HEAD(&amp;misc-&gt;list); mutex_lock(&amp;misc_mtx); if (is_dynamic) &#123;//minor次设备号如果等于255就自动分配次设备 int i = find_first_zero_bit(misc_minors, DYNAMIC_MINORS); if (i &gt;= DYNAMIC_MINORS) &#123; err = -EBUSY; goto out; &#125; misc-&gt;minor = DYNAMIC_MINORS - i - 1; set_bit(i, misc_minors); &#125; else &#123;//否则检查次设备号是否已经被占有 struct miscdevice *c; list_for_each_entry(c, &amp;misc_list, list) &#123; if (c-&gt;minor == misc-&gt;minor) &#123; err = -EBUSY; goto out; &#125; &#125; &#125; dev = MKDEV(MISC_MAJOR, misc-&gt;minor);//合并主、次设备号 //建立设备 misc-&gt;this_device = device_create_with_groups(misc_class, misc-&gt;parent, dev, misc, misc-&gt;groups, &quot;%s&quot;, misc-&gt;name); //把这个misc加入到全局misc_list链表 list_add(&amp;misc-&gt;list, &amp;misc_list); out: mutex_unlock(&amp;misc_mtx); return err;&#125;struct device *device_create_with_groups(struct class *class,struct device *parent, dev_t devt,void *drvdata,const struct )&#123;va_list vargs;struct device *dev;va_start(vargs, fmt);dev = device_create_groups_vargs(class, parent, devt, drvdata, groups,fmt,va_end(vargs);return dev;&#125;struct device *device_create_groups_vargs(struct class *class, struct device *&#123; struct device *dev = NULL; int retval = -ENODEV; dev = kzalloc(sizeof(*dev), GFP_KERNEL);//分配设备结构的内存空间 device_initialize(dev);//初始化设备结构 dev-&gt;devt = devt;//设置设备号 dev-&gt;class = class;//设置设备类 dev-&gt;parent = parent;//设置设备的父设备 dev-&gt;groups = groups;////设置设备属性 dev-&gt;release = device_create_release; dev_set_drvdata(dev, drvdata);//设置miscdev的地址到设备结构中 retval = kobject_set_name_vargs(&amp;dev-&gt;kobj, fmt, args);//把名称设置到设备的ko retval = device_add(dev);//把设备加入到系统中 if (retval) goto error; return dev;//返回设备 error: put_device(dev); return ERR_PTR(retval);&#125;#第一步在终端中执行如下指令sudo cat /proc/kmsg#第二步在另一个终端中执行如下指令makesudo insmod miscdrv.ko#不用这个模块了可以用以下指令卸载sudo rmmod miscdrv.ko// insmod 指令是加载一个内核模块，一旦加载成功就会执行 miscdrv_init 函数// -----------------// 打开,关系,读写函数// -----------------//打开static int misc_open(struct inode *pinode, struct file *pfile)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;//关闭static int misc_release(struct inode *pinode, struct file *pfile)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;//写static ssize_t misc_write(struct file *pfile, const char __user *buff, size_t size)&#123;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);return 0;&#125;#define to_subsys_private(obj) container_of(obj, struct subsys_private, subsys *p)struct kset *ret_buskset(void)&#123;struct subsys_private *p;if(busok)return NULL;if(!devicesinfo_bus.p)return NULL;p = devicesinfo_bus.p;if(!p-&gt;subsys.kobj.kset)return NULL;//返回devicesinfo_bus总线上的kset，正是bus_ksetreturn p-&gt;subsys.kobj.kset;&#125;static int misc_find_match(struct device *dev, void *data)&#123;struct bus_type* b = (struct bus_type*)data;printk(KERN_EMERG &quot;%s----&gt;device name is:%s\\n&quot;, b-&gt;name, dev-&gt;kobj.name);/return 0;&#125;static ssize_t misc_read (struct file *pfile, char __user *buff, size_t size)&#123;struct kobject* kobj;struct kset* kset;struct subsys_private* p;kset = ret_buskset();//获取bus_kset的地址if(!kset)return 0;printk(KERN_EMERG &quot;line:%d,%s is call\\n&quot;,__LINE__,__FUNCTION__);//打印这个函//扫描所有总线的kobjectlist_for_each_entry(kobj, &amp;kset-&gt;list, entry)&#123;p = to_subsys_private(kobj);printk(KERN_EMERG &quot;Bus name is:%s\\n&quot;,p-&gt;bus-&gt;name);//遍历具体总线上的所有设备bus_for_each_dev(p-&gt;bus, NULL, p-&gt;bus, misc_find_match);&#125;return 0;&#125;// -------// 测试驱动// -------#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#define DEV_NAME &quot;/dev/devicesinfo&quot;int main(void)&#123;char buf[] = &#123;0, 0, 0, 0&#125;;int fd;//打开设备文件fd = open(DEV_NAME, O_RDWR);if (fd &lt; 0) &#123;printf(&quot;打开 :%s 失败!\\n&quot;, DEV_NAME);&#125;//写数据到内核空间write(fd, buf, 4);//从内核空间中读取数据read(fd, buf, 4);//关闭设备,也可以不调用，程序关闭时系统自动调用close(fd);return 0;&#125; 9 文件系统 9.1 如何组织文件 什么是文件系统 文件系统解决的是如何把许多文件储存在某一种储存设备上,方便进程对各种文件执行打开，关系，读写，增加和删除等操作，操作系统中分出一个子系统专门处理问题，该系统是文件系统 文件系统在上层为用户或进程提供了一个逻辑视图,也就是目录结构 文件系统只是一个设备 文件系统建立的文件系统格式:FAT32,NTFS,Ext4,Btrfs,ZFS,HPFS等 文件系统组件是独立的与内核分开的 操作系统需要动态加载和删除不同的文件系统组件 文件系统是系统内核下的一个设备，因为不同的设备驱动程序可以动态加载，而且可以建立多个文件系统设备,对各个文件系统设备驱动程序的实现就是各个文件系统的实现 为了减少程序的复杂度使用4mb大小的内存地址来模拟储存设备 在文件系统设备驱动程序的入口函数中，分配4MB大小的内存空间 文件格式与储存块 一个文件就是一个可以动态增加,减少的线性字节数组,即文件数据的每个字节都一一对应到这个线性数组中的每个元素 文件系统把文件数据定义成一个动态的线性字节数组 一开始不知道数组大小，需要分配多少个物理储存块,最好把动态的线性字节数组分成一个个数据块 不同的储存设备的物理储存块的大小不同,为了文件系统在不同的储存设备上,故将数据块定义为文件系统逻辑块,其大小为4096字节,最后将逻辑块映射到一个或多个物理储存块 如何组织文件 使用文件目录或文件夹(目录)进行组织,可以建立层次关系 整个文件层次结构为树结构 文件系统数据结构 表示文件系统本身的一些数据结构称为文件系统元数据 设计超级块 一个文件系统有很多信息,如文件系统标识,版本,状态,储存介质大小,文件系统逻辑储存块大小,位图所在的储存块,根目录等,包含这些信息的数据块叫做文件系统的超级块或文件系统描述块 在 cosmos/include/drvinc目录下建立 drvrfs_t.h文件写下 rfssublk_t结构 建立的文件系统的超级块保存在储存设备的第一个 4KB 大小的逻辑储存块中，但是其本身的大小没有 4KB，多余的空间用于以后扩展 rfsdir_t 数据结构是一个目录数据结构 位图 使用位图来表示逻辑储存块是空闲还是分配占用状态,利用一块储存空间中所有位的状态达到映射逻辑储存块状态的目的 一个字节是 8 个位，那么 4KB 的储存空间中，就有（4096*8）个位，这每个位映射到一个逻辑储存块，其中一个位的值为 0，就表示该位对应的逻辑储存块是空闲的，反之就表示对应的逻辑储存块是占用的 在实际操作中,把位图这个储存块当做一个字节数组 用了一块 4MB 的内存空间模拟储存设备，所以一共只有 1024个 4KB 大小的逻辑储存块。因为远远小于 4096，所以用不着把所有位都利用起来，操作一个个位很麻烦，完全可以用一个字节表示一个逻辑储存块是否空闲还是占用 文件系统 目录也是一种数据结构，其中包含了目录类型，状态，指向文件数据管理头的块号，名称等信息 将这些信息整理成 rfsdir_t 数据结构,写在 drvrfs_t.h 文件中 DR_NM_MAX 宏，可以看出 rfsdir_t 数据结构最多只有 128 字节大小。而名称数组的大小就是 128 减去 3 个 8 字节，由于储存设备不能用字节地址访问，它只能一块一块的访问，所以 rfsdir_t 结构中有个域，指向文件数据管理头的块号 为什么 rfsdir_t 结构中会有很多类型呢，目录也是一种特殊的文件，里面就是保存着一系列 rfsdir_t 结构的实例变量,再次表明它代表的是一个文件，还是一个目录 超级块中的 rfsdir_t 结构保存了根目录的名称和指向管理根目录数据的文件管理头的块号。而实际的目录数据保存在逻辑储存块中，这表明目录也是一种数据 文件管理头 文件管理头包含,文件名,状态,类型,创建时间，访问时间，大小，使用那些逻辑储存块等信息 在 drvrfs_t.h 文件中建立 fimgrhd_t 文件管理头 fmd_fleblk 数组,里面的每个元素都保存一块连续的逻辑储存块 文件特别大时,fmd_fleblk 数组元素不够用,再分配一个逻辑储存块,在里面再次存放同一个文件的 fimgrhd_t 结构，让上一个 fimgrhd_t 结构中的 fmd_linknblk域指向这个逻辑储存块，再让这个逻辑储存块中 fimgrhd_t 结构中的 fmd_linkpblk 域，指向上一个 fimgrhd_t 结构所在的逻辑储存块 fimgrhd_t 结构如何管理一个文件占有的所有逻辑储存块，并且可以通过类似链表的形式动态增加 fimgrhd_t 结构，实际上就是在动态增加文件的逻辑储存块。同时我们不难发现，文件的第一个逻辑储存块的首个 512 字节空间中，存放的就是 fimgrhd_t 数据结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364typedef struct s_RFSSUBLK&#123; spinlock_t rsb_lock;//超级块在内存中使用的自旋锁 uint_t rsb_mgic;//文件系统标识 uint_t rsb_vec;//文件系统版本 uint_t rsb_flg;//标志 uint_t rsb_stus;//状态 size_t rsb_sz;//该数据结构本身的大小 size_t rsb_sblksz;//超级块大小 size_t rsb_dblksz;//文件系统逻辑储存块大小，我们这里用的是4KB uint_t rsb_bmpbks;//位图的开始逻辑储存块 uint_t rsb_bmpbknr;//位图占用多少个逻辑储存块 uint_t rsb_fsysallblk;//文件系统有多少个逻辑储存块 rfsdir_t rsb_rootdir;//根目录，后面会看到这个数据结构的&#125;rfssublk_t;// ---------// 文件系统// ---------#define DR_NM_MAX (128-(sizeof(uint_t)*3))#define RDR_NUL_TYPE 0#define RDR_DIR_TYPE 1#define RDR_FIL_TYPE 2#define RDR_DEL_TYPE 5typedef struct s_RFSDIR&#123;uint_t rdr_stus;//目录状态uint_t rdr_type;//目录类型，可以是空类型、目录类型、文件类型、已删除的类型uint_t rdr_blknr;//指向文件数据管理头的块号，不像内存可以用指针，只能按块访问char_t rdr_name[DR_NM_MAX];//名称数组，大小为DR_NM_MAX&#125;rfsdir t;// ---------// 文件管理头// ---------#define FBLKS_MAX 32#define FMD_NUL_TYPE 0#define FMD_DIR_TYPE 1#define FMD_FIL_TYPE 2#define FMD_DEL_TYPE 5//文件管理头也需要表明它管理的是目录文件还是普通文件typedef struct s_FILBLKS&#123;uint_t fb_blkstart;//开始的逻辑储存块号uint_t fb_blknr;//逻辑储存块的块数，从blkstart开始的连续块数&#125;filblks_t;typedef struct s_fimgrhd&#123;uint_t fmd_stus;//文件状态uint_t fmd_type;//文件类型：可以是目录文件、普通文件、空文件、已删除的文件uint_t fmd_flg;//文件标志uint_t fmd_sfblk;//文件管理头自身所在的逻辑储存块uint_t fmd_acss;//文件访问权限uint_t fmd_newtime;//文件的创建时间，换算成秒uint_t fmd_acstime;//文件的访问时间，换算成秒uint_t fmd_fileallbk;//文件一共占用多少个逻辑储存块uint_t fmd_filesz;//文件大小uint_t fmd_fileifstbkoff;//文件数据在第一块逻辑储存块中的偏移uint_t fmd_fileiendbkoff;//文件数据在最后一块逻辑储存块中的偏移uint_t fmd_curfwritebk;//文件数据当前将要写入的逻辑储存块uint_t fmd_curfinwbkoff;//文件数据当前将要写入的逻辑储存块中的偏移filblks_t fmd_fleblk[FBLKS_MAX];//文件占用逻辑储存块的数组，一共32个filblks_t结构uint_t fmd_linkpblk;//指向文件的上一个文件管理头的逻辑储存块uint_t fmd_linknblk;//指向文件的下一个文件管理头的逻辑储存块&#125;fimgrhd t; 9.2 文件系统的格式化操作 文件系统设备 首先需要编写相应的设备驱动程序,在 cosmos/drivers目录下建立 drvrfs.c 文件,编写文件系统驱动程序框架 4MB大小的内存空间的数据结构的分配内存空间,使用一个数据结构来描述: new_rfsdevext_mmblk 函数分配了一个内存空间和一个 rfsdevext_t 结构实例变量 rfsdevext_t 结构保存了内存空间的地址和大小 rfsdevext_t 结构的地址存放在 device_t 结构的 dev_extdata 字段中 建立文件系统设备,与建立systick驱动程序差不多,需要分配一个模拟储存设备的空间,并把它放在 device_t 结构相关字段中,这个设备类型需要在 rfs_set_device 函数中设置好,设置为文件系统类型 需要将 rfs_entry 函数放在驱动表中,文件系统程序才能运行,在系统启动时,在 init_krldriver 函数中会运行 rfs_entry 函数 文件系统格式化 格式化操作是在这个设备上重建了文件系统用于管理文件的那一套数据结构 在储存设备上建立文件系统其实就是执行格式化操作,即重建文件系统的数据结构 建立超级块:即初始化超级块的数据结构将其写入到储存设备中的第一块逻辑储存块 现在内存缓冲区建立文件系统的超级块,最后调用 write_rfsdevblk 函数 由于使用内存模拟储存设备,故需要 ret_rfsdevext 函数返回设备扩展数据结构,该函数和 ret_rfsdevblk 函数一起根据块号,计算出内存地址，然后将缓冲区的内容复制到这个地址开始的内存空间 建立位图 使用一个逻辑储存块空间中的所有字节来管理逻辑储存块的状态 建立位图就是把储存设备中的位图块清零 位图块的块号和储存介质的逻辑储存块总数都保存在超级块中,需要实现获取,释放超级块的函数,还需要一个读取逻辑储存块的函数,写入逻辑储存块的函数 第0块是超级块,第1块是位图本身,故代码从缓冲区中的第3个字节开始清零,一直到 devmaxblk 个字节(devmaxblk是储存介质的逻辑储存块总数) 最后把缓冲区的数据写入到储存介质的第 bitmapblk 个逻辑储存块中就完成了位图的建立 建立根目录 根目录是文件,要为其分配相应的逻辑储存块,根目录下的文件和目录对应的 rfsdir_t 结构就是保存在这个逻辑储存块中 需要在逻辑储存块的首512字节空间中建立 fimgrhd_t 结构,即文件管理头数据结构 最后要将这个逻辑储存块的块号储存在超级块中的 rfsdir_t 结构中,同事修改该 rfsdir_t 结构中的文件名为&quot;/&quot; 获取位图块:根据超级块中的位图块号,把储存设备中的位图数据块读取到缓冲区中 释放位图块:把缓冲区的输入写入到储存设备对应的逻辑块中 扫描位图块找出空闲的逻辑储存块,rfs_new_blk 函数会返回新分配的逻辑储存块号，如果没有空闲的逻辑储存块了，就会返回0 建立根目录:首先分配一个新的逻辑储存区,接着设置超级块中的 rfsdir_t 结构中的名称以及类型和块号;然后设置文件管理头,类型为 FMD_DIR_TYPE,表示文件数据存放的是目录结构,最后回写对应的逻辑储存块即可 串联 rfs_fmat函数将操作包装,调用它们完成文件系统格式化流程;还可以把 init_rfs 函数实现调用 rfs_fmat函数，随后 init_rfs 函数本身会在 rfs_entry 函数最后被调用 测试文件系统的超级块 需要把超级块读取到一个缓冲区中,然后把其中重要的数据打印出来 测试文件系统位图 先读取位图块到一个缓冲区,然后循环扫描缓冲区,看里面有多少个为0的字节,即表明存储介质上有多少个空闲的逻辑储存块 测试文件系统根目录 先得到根目录文件的 rfsdir_t 结构，然后读取其中指向的逻辑储存块到缓冲区,最后将数据打印出来 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441// ---------// 文件系统设备// ---------drvstus_t rfs_entry(driver_t* drvp,uint_t val,void* p)&#123;……&#125;drvstus_t rfs_exit(driver_t* drvp,uint_t val,void* p)&#123;……&#125;drvstus_t rfs_open(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_close(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_read(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_write(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_lseek(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_ioctrl(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_dev_start(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_dev_stop(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_set_powerstus(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_enum_dev(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_flush(device_t* devp,void* iopack)&#123;……&#125;drvstus_t rfs_shutdown(device_t* devp,void* iopack)&#123;……&#125;// 4MB大小的内存空间的数据结构的分配内存空间typedef struct s_RFSDEVEXT&#123;spinlock_t rde_lock;//自旋锁list_h_t rde_list;//链表uint_t rde_flg;//标志uint_t rde_stus;//状态void* rde_mstart;//用于模拟储存介质的内存块的开始地址size_t rde_msize;//内存块的大小void* rde_ext;//扩展所用&#125;rfsdevext_t;drvstus_t new_rfsdevext_mmblk(device_t* devp,size_t blksz)&#123;//分配模拟储存介质的内存空间，大小为4MBadr_t blkp= krlnew(blksz);//分配rfsdevext_t结构实例的内存空间rfsdevext_t* rfsexp=(rfsdevext_t*)krlnew(sizeof(rfsdevext_t));//初始化rfsdevext_t结构rfsdevext_t_init(rfsexp);rfsexp-&gt;rde_mstart=(void*)blkp;rfsexp-&gt;rde_msize=blksz;//把rfsdevext_t结构的地址放入device_t 结构的dev_extdata字段中，这里dev_extdata字devp-&gt;dev_extdata=(void*)rfsexp;.return DFCOKSTUS;&#125;// 建立文件系统设备void rfs_set_device(device_t* devp,driver_t* drvp)&#123;//设备类型为文件系统类型devp-&gt;dev_id.dev_mtype = FILESYS_DEVICE;devp-&gt;dev_id.dev_stype = 0;devp-&gt;dev_id.dev_nr = 0;//设备名称为rfsdevp-&gt;dev_name = &quot;rfs&quot;;return;&#125;drvstus_t rfs_entry(driver_t* drvp,uint_t val,void* p)&#123;//分配device_t结构并对其进行初级初始化device_t* devp = new_device_dsc();rfs_set_driver(drvp);rfs_set_device(devp,drvp);//分配模拟储存设备的内存空间if(new_rfsdevext_mmblk(devp,FSMM_BLK) == DFCERRSTUS)&#123;……&#125;//把设备加入到驱动程序之中if(krldev_add_driver(devp,drvp) == DFCERRSTUS)&#123;……&#125;//向内核注册设备if(krlnew_device(devp)==DFCERRSTUS)&#123;……&#125;return DFCOKSTUS;&#125;// 将 rfs_entry 函数放在驱动表中//cosmos/kernel/krlglobal.cKRL_DEFGLOB_VARIABLE(drventyexit_t,osdrvetytabl)[]=&#123;systick_entry,rfs_entry,NULL&#125;// ----------// 建立超级块// ----------void *new_buf(size_t bufsz)&#123;return (void *)krlnew(bufsz);//分配缓冲区&#125;void del_buf(void *buf, size_t bufsz)&#123;krldelete((adr_t)buf, bufsz)//释放缓冲区return;&#125;void rfssublk_t_init(rfssublk_t* initp)&#123;krlspinlock_init(&amp;initp-&gt;rsb_lock);initp-&gt;rsb_mgic = 0x142422;//标志就是一个数字而已，无其它意义initp-&gt;rsb_vec = 1;//文件系统版本为1initp-&gt;rsb_flg = 0;initp-&gt;rsb_stus = 0;initp-&gt;rsb_sz = sizeof(rfssublk_t);//超级块本身的大小initp-&gt;rsb_sblksz = 1;//超级块占用多少个逻辑储存块initp-&gt;rsb_dblksz = FSYS_ALCBLKSZ;//逻辑储存块的大小为4KB//位图块从第1个逻辑储存块开始，超级块占用第0个逻辑储存块initp-&gt;rsb_bmpbks = 1;initp-&gt;rsb_bmpbknr = 0;initp-&gt;rsb_fsysallblk = 0;rfsdir_t_init(&amp;initp-&gt;rsb_rootdir);//初始化根目录return;&#125;bool_t create_superblk(device_t *devp)&#123;void *buf = new_buf(FSYS_ALCBLKSZ);//分配4KB大小的缓冲区，清零hal_memset(buf, 0, FSYS_ALCBLKSZ);//使rfssublk_t结构的指针指向缓冲区并进行初始化rfssublk_t *sbp = (rfssublk_t *)buf;rfssublk_t_init(sbp);//获取储存设备的逻辑储存块数并保存到超级块中sbp-&gt;rsb_fsysallblk = ret_rfsdevmaxblknr(devp);//把缓冲区中超级块的数据写入到储存设备的第0个逻辑储存块中if (write_rfsdevblk(devp, buf, 0) == DFCERRSTUS)&#123;return FALSE;&#125;del_buf(buf, FSYS_ALCBLKSZ);//释放缓冲区return TRUE;&#125;// write_rfsdevblk 函数//返回设备扩展数据结构rfsdevext_t* ret_rfsdevext(device_t* devp)&#123;return (rfsdevext_t*)devp-&gt;dev_extdata;&#125;//根据块号返回储存设备的块地址void* ret_rfsdevblk(device_t* devp,uint_t blknr)&#123;rfsdevext_t* rfsexp = ret_rfsdevext(devp);//块号乘于块大小的结果再加上开始地址（用于模拟储存设备的内存空间的开始地址）void* blkp = rfsexp-&gt;rde_mstart + (blknr*FSYS_ALCBLKSZ);//如果该地址没有落在储存入设备的空间中，就返回NULL表示出错if(blkp &gt;= (void*)((size_t)rfsexp-&gt;rde_mstart+rfsexp-&gt;rde_msize))return NULL;//返回块地址return blkp;&#125;//把4KB大小的缓冲区中的内容，写入到储存设备的某个逻辑储存块中drvstus_t write_rfsdevblk(device_t* devp,void* weadr,uint_t blknr)&#123;//返回储存设备中第blknr块的逻辑存储块的地址void* p = ret_rfsdevblk(devp,blknr);//复制数据到逻辑储存块中hal_memcpy(weadr,p,FSYS_ALCBLKSZ);return DFCOKSTUS;&#125;// --------// 建立位图// --------//把逻辑储存块中的数据，读取到4KB大小的缓冲区中drvstus_t read_rfsdevblk(device_t* devp,void* rdadr,uint_t blknr)&#123;//获取逻辑储存块地址void* p=ret_rfsdevblk(devp,blknr);//把逻辑储存块中的数据复制到缓冲区中hal_memcpy(p,rdadr,FSYS_ALCBLKSZ);return DFCOKSTUS;&#125;//获取超级块rfssublk_t* get_superblk(device_t* devp)&#123;//分配4KB大小的缓冲区void* buf=new_buf(FSYS_ALCBLKSZ);//清零缓冲区hal_memset(buf,FSYS_ALCBLKSZ,0);//读取第0个逻辑储存块中的数据到缓冲区中，如果读取失败则释放缓冲区read_rfsdevblk(devp,buf,0);//返回超级块数据结构的地址，即缓冲区的首地址return (rfssublk_t*)buf;&#125;//释放超级块void del_superblk(device_t* devp,rfssublk_t* sbp)&#123;//回写超级块，因为超级块中的数据可能已经发生了改变，如果出错则死机write_rfsdevblk(devp,(void*)sbp,0);//释放先前分配的4KB大小的缓冲区del_buf((void*)sbp,FSYS_ALCBLKSZ);return;&#125;//建立位图bool_t create_bitmap(device_t* devp)&#123;bool_t rets=FALSE;//获取超级块，失败则返回FALSErfssublk_t* sbp = get_superblk(devp);//分配4KB大小的缓冲区void* buf = new_buf(FSYS_ALCBLKSZ);//获取超级块中位图块的开始块号uint_t bitmapblk=sbp-&gt;rsb_bmpbks;//获取超级块中储存介质的逻辑储存块总数uint_t devmaxblk=sbp-&gt;rsb_fsysallblk;//如果逻辑储存块总数大于4096，就认为出错了if(devmaxblk&gt;FSYS_ALCBLKSZ)&#123;rets=FALSE;goto errlable;&#125;//把缓冲区中每个字节都置成1hal_memset(buf,FSYS_ALCBLKSZ,1);u8_t* bitmap=(u8_t*)buf;//把缓冲区中的第3个字节到第devmaxblk个字节都置成0for(uint_t bi=2;bi&lt;devmaxblk;bi++)&#123;bitmap[bi]=0;&#125;//把缓冲区中的数据写入到储存介质中的第bitmapblk个逻辑储存块中，即位图块中if(write_rfsdevblk(devp,buf,bitmapblk)==DFCERRSTUS)&#123;rets = FALSE;goto errlable;&#125;//设置返回状态rets=TRUE;errlable://释放超级块del_superblk(devp,sbp);//释放缓冲区del_buf(buf,FSYS_ALCBLKSZ);return rets;&#125;// -----------// 建立根目录// -----------// 辅助功能函数，实现获取 / 释放位图块的代码//获取位图块u8_t* get_bitmapblk(device_t* devp)&#123;//获取超级块rfssublk_t* sbp = get_superblk(devp);//分配4KB大小的缓冲区void* buf = new_buf(FSYS_ALCBLKSZ);//缓冲区清零hal_memset(buf, FSYS_ALCBLKSZ, 0);//读取sbp-&gt;rsb_bmpbks块（位图块），到缓冲区中read_rfsdevblk(devp, buf, sbp-&gt;rsb_bmpbks)//释放超级块del_superblk(devp, sbp);//返回缓冲区的首地址return (u8_t*)buf;&#125;//释放位图块void del_bitmapblk(device_t* devp,u8_t* bitmap)&#123;//获取超级块rfssublk_t* sbp = get_superblk(devp);//回写位图块，因为位图块中的数据可能已经发生改变write_rfsdevblk(devp, (void*)bitmap, sbp-&gt;rsb_bmpbks)//释放超级块和存放位图块的缓冲区del_superblk(devp, sbp);del_buf((void*)bitmap, FSYS_ALCBLKSZ);return;&#125;//分配新的空闲逻辑储存块uint_t rfs_new_blk(device_t* devp)&#123;uint_t retblk=0;//获取位图块u8_t* bitmap = get_bitmapblk(devp);if(bitmap == NULL)&#123;return 0;&#125;for(uint_t blknr = 2; blknr &lt; FSYS_ALCBLKSZ; blknr++)&#123;//找到一个为0的字节就置为1，并返回该字节对应的空闲块号if(bitmap[blknr] == 0)&#123;bitmap[blknr] = 1;retblk = blknr;goto retl;&#125;&#125;//如果到这里就说明没有空闲块了，所以返回0retblk=0;retl://释放位图块del_bitmapblk(devp,bitmap);return retblk;&#125;//建立根目录bool_t create_rootdir(device_t* devp)&#123; bool_t rets = FALSE; //获取超级块 rfssublk_t* sbp = get_superblk(devp); //分配4KB大小的缓冲区 void* buf = new_buf(FSYS_ALCBLKSZ); //缓冲区清零 hal_memset(buf,FSYS_ALCBLKSZ,0); //分配一个空闲的逻辑储存块 uint_t blk = rfs_new_blk(devp); if(blk == 0) &#123; rets = FALSE; goto errlable; &#125; //设置超级块中的rfsdir_t结构中的名称为“/” sbp-&gt;rsb_rootdir.rdr_name[0] = &#x27;/&#x27;; //设置超级块中的rfsdir_t结构中的类型为目录类型 sbp-&gt;rsb_rootdir.rdr_type = RDR_DIR_TYPE; //设置超级块中的rfsdir_t结构中的块号为新分配的空闲逻辑储存块的块号 sbp-&gt;rsb_rootdir.rdr_blknr = blk; fimgrhd_t* fmp = (fimgrhd_t*)buf; //初始化fimgrhd_t结构 fimgrhd_t_init(fmp); //因为这是目录文件所以fimgrhd_t结构的类型设置为目录类型 fmp-&gt;fmd_type = FMD_DIR_TYPE; //fimgrhd_t结构自身所在的块设置为新分配的空闲逻辑储存块 fmp-&gt;fmd_sfblk = blk; //fimgrhd_t结构中正在写入的块设置为新分配的空闲逻辑储存块 fmp-&gt;fmd_curfwritebk = blk; //fimgrhd_t结构中正在写入的块的偏移设置为512字节 fmp-&gt;fmd_curfinwbkoff = 0x200; //设置文件数据占有块数组的第0个元素 fmp-&gt;fmd_fleblk[0].fb_blkstart = blk; fmp-&gt;fmd_fleblk[0].fb_blknr = 1; //把缓冲区中的数据写入到新分配的空闲逻辑储存块中，其中包含已经设置好的 fimgrhd_t结 if(write_rfsdevblk(devp, buf, blk) == DFCERRSTUS) &#123; rets = FALSE; goto errlable; &#125; rets = TRUE; errlable: //释放缓冲区 del_buf(buf, FSYS_ALCBLKSZ); errlable1: //释放超级块 del_superblk(devp, sbp); return rets;&#125;// ----// 串联// ----//rfs初始化void init_rfs(device_t *devp)&#123;//格式化rfsrfs_fmat(devp);return;&#125;//rfs格式化void rfs_fmat(device_t *devp)&#123;//建立超级块if (create_superblk(devp) == FALSE)&#123;hal_sysdie(&quot;create superblk err&quot;);&#125;//建立位图if (create_bitmap(devp) == FALSE)&#123;hal_sysdie(&quot;create bitmap err&quot;);&#125;//建立根目录if (create_rootdir(devp) == FALSE)&#123;hal_sysdie(&quot;create rootdir err&quot;);&#125;return;&#125;//rfs驱动程序入口drvstus_t rfs_entry(driver_t *drvp, uint_t val, void *p)&#123;//……init_rfs(devp);//初始化rfsreturn DFCOKSTUS;&#125;// ----------------// 测试文件系统超级块// ----------------//测试文件系统超级块void test_rfs_superblk(device_t *devp)&#123;kprint(&quot;开始文件系统超级块测试\\n&quot;);rfssublk_t *sbp = get_superblk(devp);kprint(&quot;文件系统标识:%d,版本:%d\\n&quot;, sbp-&gt;rsb_mgic, sbp-&gt;rsb_vec);kprint(&quot;文件系统超级块占用的块数:%d,逻辑储存块大小:%d\\n&quot;, sbp-&gt;rsb_sblksz, sbp-&gt;kprint(&quot;文件系统位图块号:%d,文件系统整个逻辑储存块数:%d\\n&quot;, sbp-&gt;rsb_bmpbks, sbp\u0002kprint(&quot;文件系统根目录块号:%d 类型:%d\\n&quot;, sbp-&gt;rsb_rootdir.rdr_blknr, sbp-&gt;rsbkprint(&quot;文件系统根目录名称:%s\\n&quot;, sbp-&gt;rsb_rootdir.rdr_name);del_superblk(devp, sbp);hal_sysdie(&quot;结束文件系统超级块测试&quot;);//死机用于观察测试结果return;&#125;//rfs驱动程序入口drvstus_t rfs_entry(driver_t *drvp, uint_t val, void *p)&#123;init_rfs(devp);//初始化rfstest_rfs_superblk(devp);//测试文件系统超级块return DFCOKSTUS;&#125;// --------------// 测试文件系统位图// --------------// 需要在 rfs_entry 函数的末尾调用void test_rfs_bitmap(device_t *devp)&#123;kprint(&quot;开始文件系统位图测试\\n&quot;);void *buf = new_buf(FSYS_ALCBLKSZ);hal_memset(buf, 0, FSYS_ALCBLKSZ);read_rfsdevblk(devp, buf, 1)//读取位图块u8_t *bmp = (u8_t *)buf;uint_t b = 0;//扫描位图块for (uint_t i = 0; i &lt; FSYS_ALCBLKSZ; i++)&#123;if (bmp[i] == 0)&#123;b++;//记录空闲块&#125;&#125;kprint(&quot;文件系统空闲块数:%d\\n&quot;, b);del_buf(buf, FSYS_ALCBLKSZ);hal_sysdie(&quot;结束文件系统位图测试\\n&quot;);//死机用于观察测试结果return;&#125;// ----------------// 测试文件系统根目录// ----------------// 需要在 rfs_entry 函数的末尾调用void test_rfs_rootdir(device_t *devp)&#123;kprint(&quot;开始文件系统根目录测试\\n&quot;);rfsdir_t *dr = get_rootdir(devp);void *buf = new_buf(FSYS_ALCBLKSZ);hal_memset(buf, 0, FSYS_ALCBLKSZ);read_rfsdevblk(devp, buf, dr-&gt;rdr_blknr)fimgrhd_t *fmp = (fimgrhd_t *)buf;kprint(&quot;文件管理头类型:%d 文件数据大小:%d 文件在开始块中偏移:%d 文件在结束块中的偏移:fmp-&gt;fmd_type, fmp-&gt;fmd_filesz, fmp-&gt;fmd_fileifstbkoff, fmp-&gt;fmd_fkprint(&quot;文件第一组开始块号:%d 块数:%d\\n&quot;, fmp-&gt;fmd_fleblk[0].fb_blkstart, fmp\u0002del_buf(buf, FSYS_ALCBLKSZ);del_rootdir(devp, dr);hal_sysdie(&quot;结束文件系统根目录测试\\n&quot;);//死机用于观察测试结果return;&#125; 9.3 如何实现文件的六大基础操作 操作根目录文件 不管是新建,删除,打开一个文件,首先都要找到与该文件对应的 rfsdir_t 结构 一个文件的 rfsdir_t 结构储存在根目录文件中,故需要获取和释放根目录文件 获取根目录文件:根据超级块中的 rfsdir_t 结构中的信息,读取根目录文件的逻辑储存块即可 get_rootdir函数:读取文件系统超级块中 rfsdir_t 结构到一个缓冲区 释放根目录文件:把根目录中的储存块回写到储存设备中,最后释放对应的缓冲器即可 del_rootdir函数:释放缓冲区 获取文件名 实现去除路径分隔符提取文件名称 rfs_chkfilepath 函数检查路径名是不是/xxx形式,实现获取文件名的必要前提 rfs_ret_fname 函数可以把 fpath 指向的路径名中的文件名提取出来,放到buf指向的缓冲区中 判断文件是否存在 rfs_chkfileisindev 函数首先检查文件名的长度,接着获取根目录文件,然后遍历根目录中所有 rfsdir_t 结构并比较文件名是否相同,相同返回1,最后释放根目录文件 get_rootdirfile_blk 函数已将根目录文件读取到内存里,故可用 dirp 指针和 maxchkp 指针操作其中的数据 新建文件 分成4步进行: 从文件路径名中提取出纯文件名,检查储存设备上是否存在该文件 分配一个空闲的逻辑储存块，并在根目录文件的末尾写入新建文件对应的 rfsdir_t结构 在一个新的4KB大小的缓冲区中初始化新建文件对应的 fimgrhd_t 结构 把第3步对应的缓冲区里的数据写入到先前分配的空间逻辑储存块中 rfs_new_dirfileblk 函数两个关键点: 目录文件中存放的就是一系列的 rfsdir_t 结构 fmp 和 ffmp 这两个指针很重要 fmp 指针指向的是根目录文件的 fimgrhd_t 结构，因为要写入一个新的 rfsdir_t 结构，所以要获取并改写根目录文件的 fimgrhd_t 结构中的数据 ffmp 指针指向的是新建文件的 fimgrhd_t 结构，并且初始化了其中的一些数据。最后，该函数把这个缓冲区中的数据写入到分配的空闲逻辑储存块中，同时释放了根目录文件和缓冲区 删除文件 分成4步进行 从文件路径中提取出纯文件名 获取根目录文件,从根目录文件中查找待删除文件的 rfsdir_t 结构,然后释放该文件占用的逻辑储存块 初始化与待删除文件对应的 rfsdir_t 结构，并设置 rfsdir_t结构的类型为 RDR_DEL_TYPE 释放根目录文件 删除一个文件，就是把这个文件对应的 rfsdir_t 结构中的数据清空(无法查找到文件) 同时要释放该文件占用的逻辑储存块(避免反删除软件找回文件) 打开文件 Cosmos 内核上层组件调用设备驱动程序时，都需要建立一个相应的 objnode_t 结构，把I/O包发送给相应的驱动程序，但是 objnode_t 结构不仅仅是用于驱动程序，它还用于表示进程使用了哪些资源，例如打开了哪些设备或者文件，而每打开一个设备或者文件就建立一个 objnode_t 结构，放在特定进程的资源表中 为了适应文件系统设备驱动程序，在 cosmos/include/krlinc/krlobjnode_t.h 文件中需要在 objnode_t 结构中增加一些东西 objnode_t 结构里增加了两个字段，指向文件路径名的指针表示打开哪个文件；增加了指向对应文件的 fimgrhd_t 结构指针 打开文件的四步 从 objnode_t 结构的文件路径提取文件名 获取根目录文件，在该文件中搜索对应的 rfsdir_t 结构，看看文件是否存在 分配一个 4KB 缓存区，把该文件对应的 rfsdir_t 结构中指向的逻辑储存块读取到缓存区中，然后释放根目录文件 把缓冲区中的 fimgrhd_t 结构的地址，保存到 objnode_t 结构的 on_finode 域中 通过 rfs_openfileblk 函数中的 for 循环，可以遍历要打开的文件在根目录文件中对应的 rfsdir_t 结构，然后把对应文件占用的逻辑储存块读取到缓冲区中，最后返回这个缓冲区的首地址;因为这个缓冲区开始的空间中，就存放着其文件对应的 fimgrhd_t 结构，所以返回fimgrhd_t 结构的地址，整个打开文件的流程就结束了 读写文件 读取已经打开的文件的大致流程: 检查 objnode_t 结构中用于存放文件数据的缓冲区及其大小 检查 imgrhd_t 结构中文件相关的信息 把文件的数据读取到 objnode_t 结构中指向的缓冲区中 写文件:将写入的数据复制到打开文件时为其分配的缓存区中,最后把打开文件时为其分配的缓冲区中的数据写入到相应的逻辑储存块中 rfs_writefileblk 函数永远都是从 fimgrhd_t 结构的 fmd_curfinwbkoff 字段中的偏移量开始写入文件数据的，为追加写入数据方式;函数最后调用 write_rfsdevblk函数把文件数据写入到相应的逻辑储存块中完成数据同步 关闭文件 流程: 首先检查文件是否打开 然后把文件写入到对应的逻辑储存块中,完成数据的同步 最后释放文件数据占用的缓冲区 rfs_closefileblk 函数没有必要调用write_rfsdevblk 函数，因为前面在写入文件数据的同时，就已经把文件的数据写入到逻辑储存块中。最后释放了先前打开文件时分配的缓冲区，而 objnode_t 结构不应该在此释放，它是由 Cosmos 内核上层组件进行释放的 测试 cosmos下任何设备驱动程序都必须要有 objnode_t 结构才能运行 故手动建立 objnode_t 结构并设置好其中字段进行测试 测试逻辑：开始会建立并打开一个文件，接着写入数据，然后读取文件中数据进行比较，看看是不是和之前写入的数据相等，最后删除这个文件并再次打开，看是否会出错。因为文件已经删除了，打开一个已经删除的文件自然要出错，出错就说明测试成功 把 test_fsys 函数放在 rfs_entry 函数的最后调用进行测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501// ------------// 操作根目录文件// ------------//获取根目录文件void* get_rootdirfile_blk(device_t* devp)&#123;void* retptr = NULL;rfsdir_t* rtdir = get_rootdir(devp);//获取根目录文件的rfsdir_t结构//分配4KB大小的缓冲区并清零void* buf = new_buf(FSYS_ALCBLKSZ);hal_memset(buf, FSYS_ALCBLKSZ, 0);//读取根目录文件的逻辑储存块到缓冲区中read_rfsdevblk(devp, buf, rtdir-&gt;rdr_blknr)retptr = buf;//设置缓冲区的首地址为返回值goto errl1;errl:del_buf(buf, FSYS_ALCBLKSZ);errl1:del_rootdir(devp, rtdir);//释放根目录文件的rfsdir_t结构return retptr;&#125;//释放根目录文件void del_rootdirfile_blk(device_t* devp,void* blkp)&#123;//因为逻辑储存块的头512字节的空间中，保存的就是fimgrhd_t结构fimgrhd_t* fmp = (fimgrhd_t*)blkp;//把根目录文件回写到储存设备中去，块号为fimgrhd_t结构自身所在的块号write_rfsdevblk(devp, blkp, fmp-&gt;fmd_sfblk)//释放缓冲区del_buf(blkp, FSYS_ALCBLKSZ);return;&#125;// ---------// 获取文件名// ---------//检查文件路径名sint_t rfs_chkfilepath(char_t* fname)&#123;char_t* chp = fname;//检查文件路径名的第一个字符是否为“/”，不是则返回2if(chp[0] != &#x27;/&#x27;) &#123; return 2; &#125;for(uint_t i = 1; ; i++)&#123;//检查除第1个字符外其它字符中还有没有为“/”的，有就返回3if(chp[i] == &#x27;/&#x27;) &#123; return 3; &#125;//如果这里i大于等于文件名称的最大长度，就返回4if(i &gt;= DR_NM_MAX) &#123; return 4; &#125;//到文件路径字符串的末尾就跳出循环if(chp[i] == 0 &amp;&amp; i &gt; 1) &#123; break; &#125;&#125;//返回0表示正确return 0;&#125;//提取纯文件名sint_t rfs_ret_fname(char_t* buf,char_t* fpath)&#123;//检查文件路径名是不是“/xxxx”的形式sint_t stus = rfs_chkfilepath(fpath);//如果不为0就直接返回这个状态值表示错误if(stus != 0) &#123; return stus; &#125;//从路径名字符串的第2个字符开始复制字符到buf中rfs_strcpy(&amp;fpath[1], buf);return 0;&#125;// ---------------// 判断文件是否存在// ---------------sint_t rfs_chkfileisindev(device_t* devp,char_t* fname)&#123;sint_t rets = 6;sint_t ch = rfs_strlen(fname);//获取文件名的长度，注意不是文件路径名//检查文件名的长度是不是合乎要求if(ch &lt; 1 || ch &gt;= (sint_t)DR_NM_MAX) &#123; return 4; &#125;void* rdblkp = get_rootdirfile_blk(devp);fimgrhd_t* fmp = (fimgrhd_t*)rdblkp;//检查该fimgrhd_t结构的类型是不是FMD_DIR_TYPE，即这个文件是不是目录文件if(fmp-&gt;fmd_type != FMD_DIR_TYPE) &#123; rets = 3; goto err; &#125;//检查根目录文件是不是为空，即没有写入任何数据，所以返回0，表示根目录下没有对应的文件if(fmp-&gt;fmd_curfwritebk == fmp-&gt;fmd_fleblk[0].fb_blkstart &amp;&amp;fmp-&gt;fmd_curfinwbkoff == fmp-&gt;fmd_fileifstbkoff) &#123;rets = 0; goto err;&#125;rfsdir_t* dirp = (rfsdir_t*)((uint_t)(fmp) + fmp-&gt;fmd_fileifstbkoff);//指向//指向根目录文件的结束地址void* maxchkp = (void*)((uint_t)rdblkp + FSYS_ALCBLKSZ - 1);//当前的rfsdir_t结构的指针比根目录文件的结束地址小，就继续循环for(;(void*)dirp &lt; maxchkp;) &#123;//如果这个rfsdir_t结构的类型是RDR_FIL_TYPE，说明它对应的是文件而不是目录，所以下if(dirp-&gt;rdr_type == RDR_FIL_TYPE) &#123;if(rfs_strcmp(dirp-&gt;rdr_name,fname) == 1) &#123;//比较其文件名rets = 1; goto err;&#125;&#125;dirp++;&#125;rets = 0; //到了这里说明没有找到相同的文件err:del_rootdirfile_blk(devp,rdblkp);//释放根目录文件return rets;&#125;// -------// 新建文件// -------//新建文件的接口函数drvstus_t rfs_new_file(device_t* devp, char_t* fname, uint_t flg)&#123;//在栈中分配一个字符缓冲区并清零char_t fne[DR_NM_MAX];hal_memset((void*)fne, DR_NM_MAX, 0);//从文件路径名中提取出纯文件名if(rfs_ret_fname(fne, fname) != 0) &#123; return DFCERRSTUS; &#125;//检查储存介质上是否已经存在这个新建的文件，如果是则返回错误if(rfs_chkfileisindev(devp, fne) != 0) &#123;return DFCERRSTUS; &#125;//调用实际建立文件的函数return rfs_new_dirfileblk(devp, fne, RDR_FIL_TYPE, 0);&#125;// 新建文件的函数 rfs_new_dirfileblkdrvstus_t rfs_new_dirfileblk(device_t* devp,char_t* fname,uint_t flgtype,uint_t flg)&#123;drvstus_t rets = DFCERRSTUS;void* buf = new_buf(FSYS_ALCBLKSZ);//分配一个4KB大小的缓冲区hal_memset(buf, FSYS_ALCBLKSZ, 0);//清零该缓冲区uint_t fblk = rfs_new_blk(devp);//分配一个新的空闲逻辑储存块void* rdirblk = get_rootdirfile_blk(devp);//获取根目录文件fimgrhd_t* fmp = (fimgrhd_t*)rdirblk;//指向文件当前的写入地址，因为根目录文件已经被读取到内存中了rfsdir_t* wrdirp = (rfsdir_t*)((uint_t)rdirblk + fmp-&gt;fmd_curfinwbkoff);//对文件当前的写入地址进行检查if(((uint_t)wrdirp) &gt;= ((uint_t)rdirblk + FSYS_ALCBLKSZ)) &#123;rets=DFCERRSTUS; goto err;&#125;wrdirp-&gt;rdr_stus = 0;wrdirp-&gt;rdr_type = flgtype;//设为文件类型wrdirp-&gt;rdr_blknr = fblk;//设为刚刚分配的空闲逻辑储存块rfs_strcpy(fname, wrdirp-&gt;rdr_name);//把文件名复制到rfsdir_t结构fmp-&gt;fmd_filesz += (uint_t)(sizeof(rfsdir_t));//增加根目录文件的大小//增加根目录文件当前的写入地址，保证下次不被覆盖fmp-&gt;fmd_curfinwbkoff += (uint_t)(sizeof(rfsdir_t));fimgrhd_t* ffmp = (fimgrhd_t*)buf;//指向新分配的缓冲区fimgrhd_t_init(ffmp);//调用fimgrhd_t结构默认的初始化函数ffmp-&gt;fmd_type = FMD_FIL_TYPE;//因为建立的是文件，所以设为文件类型ffmp-&gt;fmd_sfblk = fblk;//把自身所在的块，设为分配的逻辑储存块ffmp-&gt;fmd_curfwritebk = fblk;//把当前写入的块，设为分配的逻辑储存块ffmp-&gt;fmd_curfinwbkoff = 0x200;//把当前写入块的写入偏移量设为512//把文件储存块数组的第1个元素的开始块，设为刚刚分配的空闲逻辑储存块ffmp-&gt;fmd_fleblk[0].fb_blkstart = fblk;//因为只分配了一个逻辑储存块，所以设为1ffmp-&gt;fmd_fleblk[0].fb_blknr = 1;//把缓冲区中的数据写入到刚刚分配的空闲逻辑储存块中if(write_rfsdevblk(devp, buf, fblk) == DFCERRSTUS) &#123;rets = DFCERRSTUS; goto err;&#125;rets = DFCOKSTUS;err:del_rootdirfile_blk(devp, rdirblk);//释放根目录文件err1:del_buf(buf, FSYS_ALCBLKSZ);//释放缓冲区return rets;&#125;// -------// 删除文件// -------//文件删除的接口函数drvstus_t rfs_del_file(device_t* devp, char_t* fname, uint_t flg)&#123;if(flg != 0) &#123;return DFCERRSTUS;&#125;return rfs_del_dirfileblk(devp, fname, RDR_FIL_TYPE, 0);&#125;drvstus_t rfs_del_dirfileblk(device_t* devp, char_t* fname, uint_t flgtype, uint_t flg)&#123;if(flgtype != RDR_FIL_TYPE || val != 0) &#123; return DFCERRSTUS; &#125;char_t fne[DR_NM_MAX];hal_memset((void*)fne, DR_NM_MAX, 0);//提取纯文件名if(rfs_ret_fname(fne,fname) != 0) &#123; return DFCERRSTUS; &#125;//调用删除文件的核心函数if(del_dirfileblk_core(devp, fne) != 0) &#123; return DFCERRSTUS; &#125;return DFCOKSTUS;&#125;// rfs_del_dirfileblk 函数只是提取了文件名，然后调用删除文件的核心函数 del_dirfileblk_core//删除文件的核心函数sint_t del_dirfileblk_core(device_t* devp, char_t* fname)&#123; sint_t rets = 6; void* rblkp=get_rootdirfile_blk(devp);//获取根目录文件 fimgrhd_t* fmp = (fimgrhd_t*)rblkp; if(fmp-&gt;fmd_type!=FMD_DIR_TYPE) &#123; //检查根目录文件的类型 rets=4; goto err; &#125; if(fmp-&gt;fmd_curfwritebk == fmp-&gt;fmd_fleblk[0].fb_blkstart &amp;&amp; fmp-&gt;fmd_curf)&#123; rets = 3; goto err; &#125; rfsdir_t* dirp = (rfsdir_t*)((uint_t)(fmp) + fmp-&gt;fmd_fileifstbkoff); void* maxchkp = (void*)((uint_t)rblkp + FSYS_ALCBLKSZ-1); for(;(void*)dirp &lt; maxchkp;) &#123; if(dirp-&gt;rdr_type == RDR_FIL_TYPE) &#123;//检查其类型是否为文件类型 //如果文件名相同，就执行以下删除动作 if(rfs_strcmp(dirp-&gt;rdr_name, fname) == 1) &#123; //释放rfsdir_t结构的rdr_blknr中指向的逻辑储存块 rfs_del_blk(devp, dirp-&gt;rdr_blknr); //初始化rfsdir_t结构，实际上是清除其中的数据 rfsdir_t_init(dirp); //设置rfsdir_t结构的类型为删除类型，表示它已经删除 dirp-&gt;rdr_type = RDR_DEL_TYPE; rets = 0; goto err; &#125; &#125; dirp++;//下一个rfsdir_t &#125; rets=1; err: del_rootdirfile_blk(devp,rblkp);//释放根目录文件 return rets;&#125;// ------------// 打开文件// -----------// 在 cosmos/include/krlinc/krlobjnode_t.h 文件中在 objnode_t 结构中增加一些东西#define OBJN_TY_DEV 1//设备类型#define OBJN_TY_FIL 2//文件类型#define OBJN_TY_NUL 0//默认类型typedef struct s_OBJNODE&#123;spinlock_t on_lock;list_h_t on_list;sem_t on_complesem;uint_t on_flgs;uint_t on_stus;//……void* on_fname;//文件路径名指针void* on_finode;//文件对应的fimgrhd_t结构指针void* on_extp;//扩展所用&#125;objnode_t;// 打开文件的接口函数//打开文件的接口函数drvstus_t rfs_open_file(device_t* devp, void* iopack)&#123;objnode_t* obp = (objnode_t*)iopack;//检查objnode_t中的文件路径名if(obp-&gt;on_fname == NULL) &#123;return DFCERRSTUS;&#125;//调用打开文件的核心函数void* fmdp = rfs_openfileblk(devp, (char_t*)obp-&gt;on_fname);if(fmdp == NULL) &#123;return DFCERRSTUS;&#125;//把返回的fimgrhd_t结构的地址保存到objnode_t中的on_finode字段中obp-&gt;on_finode = fmdp;return DFCOKSTUS;&#125;//打开文件的核心函数void* rfs_openfileblk(device_t *devp, char_t* fname)&#123;char_t fne[DR_NM_MAX]; void* rets = NULL,*buf = NULL;hal_memset((void*)fne,DR_NM_MAX,0);if(rfs_ret_fname(fne, fname) != 0) &#123;//从文件路径名中提取纯文件名return NULL;&#125;void* rblkp = get_rootdirfile_blk(devp); //获取根目录文件fimgrhd_t* fmp = (fimgrhd_t*)rblkp;if(fmp-&gt;fmd_type != FMD_DIR_TYPE) &#123;//判断根目录文件的类型是否合理rets = NULL; goto err;&#125;//判断根目录文件里有没有数据if(fmp-&gt;fmd_curfwritebk == fmp-&gt;fmd_fleblk[0].fb_blkstart &amp;&amp;fmp-&gt;fmd_curfinwbkoff == fmp-&gt;fmd_fileifstbkoff) &#123;rets = NULL; goto err;&#125;rfsdir_t* dirp = (rfsdir_t*)((uint_t)(fmp) + fmp-&gt;fmd_fileifstbkoff);void* maxchkp = (void*)((uint_t)rblkp + FSYS_ALCBLKSZ - 1);for(;(void*)dirp &lt; maxchkp;) &#123;//开始遍历文件对应的rfsdir_t结构if(dirp-&gt;rdr_type == RDR_FIL_TYPE) &#123;//如果文件名相同就跳转到opfblk标号处运行if(rfs_strcmp(dirp-&gt;rdr_name, fne) == 1) &#123;goto opfblk;&#125;&#125;dirp++;&#125;//如果到这里说明没有找到该文件对应的rfsdir_t结构，所以设置返回值为NULLrets = NULL; goto err;opfblk:buf = new_buf(FSYS_ALCBLKSZ);//分配4KB大小的缓冲区//读取该文件占用的逻辑储存块if(read_rfsdevblk(devp, buf, dirp-&gt;rdr_blknr) == DFCERRSTUS) &#123;rets = NULL; goto err1;&#125;fimgrhd_t* ffmp = (fimgrhd_t*)buf;if(ffmp-&gt;fmd_type == FMD_NUL_TYPE || ffmp-&gt;fmd_fileifstbkoff != 0x200) &#123;//rets = NULL; goto err1;&#125;rets = buf; goto err;//设置缓冲区首地址为返回值err1:del_buf(buf, FSYS_ALCBLKSZ); //上面的步骤若出现问题就要释放缓冲区err:del_rootdirfile_blk(devp, rblkp); //释放根目录文件return rets;&#125;// ---------// 读写文件// ---------//读取文件数据的接口函数drvstus_t rfs_read_file(device_t* devp,void* iopack)&#123; objnode_t* obp = (objnode_t*)iopack; //检查文件是否已经打开，以及用于存放文件数据的缓冲区和它的大小是否合理 if(obp-&gt;on_finode == NULL || obp-&gt;on_buf == NULL || obp-&gt;on_bufsz != FSYS)&#123; return DFCERRSTUS; &#125; return rfs_readfileblk(devp, (fimgrhd_t*)obp-&gt;on_finode, obp-&gt;on_buf, obp-&gt;on_finode)&#125;//实际读取文件数据的函数drvstus_t rfs_readfileblk(device_t* devp, fimgrhd_t* fmp, void* buf, uint_t leal)&#123; //检查文件的相关信息是否合理 if(fmp-&gt;fmd_sfblk != fmp-&gt;fmd_curfwritebk || fmp-&gt;fmd_curfwritebk != fmp-&gt;fmd_sfblk)&#123; return DFCERRSTUS; &#125; //检查读取文件数据的长度是否大于（4096-512） if(len &gt; (FSYS_ALCBLKSZ - fmp-&gt;fmd_fileifstbkoff)) &#123; return DFCERRSTUS; &#125; //指向文件数据的开始地址 void* wrp = (void*)((uint_t)fmp + fmp-&gt;fmd_fileifstbkoff); //把文件开始处的数据复制len个字节到buf指向的缓冲区中 hal_memcpy(wrp, buf, len); return DFCOKSTUS;&#125;// 写文件的接口函数和核心函数//写入文件数据的接口函数drvstus_t rfs_write_file(device_t* devp, void* iopack)&#123; objnode_t* obp = (objnode_t*)iopack; //检查文件是否已经打开，以及用于存放文件数据的缓冲区和它的大小是否合理 if(obp-&gt;on_finode == NULL || obp-&gt;on_buf == NULL || obp-&gt;on_bufsz != FSYS)&#123; return DFCERRSTUS; &#125; return rfs_writefileblk(devp, (fimgrhd_t*)obp-&gt;on_finode, obp-&gt;on_buf, obp)&#125;//实际写入文件数据的函数drvstus_t rfs_writefileblk(device_t* devp, fimgrhd_t* fmp, void* buf)&#123;&#123;//检查文件的相关信息是否合理if(fmp-&gt;fmd_sfblk != fmp-&gt;fmd_curfwritebk || fmp-&gt;fmd_curfwritebk != fmp-&gt;fmd_sfblk)return DFCERRSTUS;&#125;//检查当前将要写入数据的偏移量加上写入数据的长度，是否大于等于4KBif((fmp-&gt;fmd_curfinwbkoff + len) &gt;= FSYS_ALCBLKSZ) &#123;return DFCERRSTUS;&#125;//指向将要写入数据的内存空间void* wrp = (void*)((uint_t)fmp + fmp-&gt;fmd_curfinwbkoff);//把buf缓冲区中的数据复制len个字节到wrp指向的内存空间中去hal_memcpy(buf, wrp, len);fmp-&gt;fmd_filesz += len;//增加文件大小//使fmd_curfinwbkoff指向下一次将要写入数据的位置fmp-&gt;fmd_curfinwbkoff += len;//把文件数据写入到相应的逻辑储存块中，完成数据同步write_rfsdevblk(devp, (void*)fmp, fmp-&gt;fmd_curfwritebk);return DFCOKSTUS;&#125;// -------// 关闭文件// -------//关闭文件的接口函数drvstus_t rfs_close_file(device_t* devp, void* iopack)&#123;objnode_t* obp = (objnode_t*)iopack;//检查文件是否已经打开了if(obp-&gt;on_finode == NULL) &#123;return DFCERRSTUS;&#125;return rfs_closefileblk(devp, obp-&gt;on_finode);&#125;//关闭文件的核心函数drvstus_t rfs_closefileblk(device_t *devp, void* fblkp)&#123;//指向文件的fimgrhd_t结构fimgrhd_t* fmp = (fimgrhd_t*)fblkp;//完成文件数据的同步write_rfsdevblk(devp, fblkp, fmp-&gt;fmd_sfblk);//释放缓冲区del_buf(fblkp, FSYS_ALCBLKSZ);return DFCOKSTUS;&#125;// -------// 串联整合// -------// 串联整合文件系统打开文件操作和新建文件操作drvstus_t rfs_open(device_t* devp, void* iopack)&#123;objnode_t* obp=(objnode_t*)iopack;//根据objnode_t结构中的访问标志进行判断if(obp-&gt;on_acsflgs == FSDEV_OPENFLG_OPEFILE) &#123;return rfs_open_file(devp, iopack);&#125;if(obp-&gt;on_acsflgs == FSDEV_OPENFLG_NEWFILE) &#123;return rfs_new_file(devp, obp-&gt;on_fname, 0);&#125;return DFCERRSTUS;&#125;// 整合关闭文件操作drvstus_t rfs_close(device_t* devp, void* iopack)&#123;return rfs_close_file(devp, iopack);&#125;// 整合文件读写操作drvstus_t rfs_read(device_t* devp, void* iopack)&#123;//调用读文件操作的接口函数return rfs_read_file(devp, iopack);&#125;drvstus_t rfs_write(device_t* devp, void* iopack)&#123;//调用写文件操作的接口函数return rfs_write_file(devp, iopack);&#125;// 整合删除文件操作drvstus_t rfs_ioctrl(device_t* devp, void* iopack)&#123;objnode_t* obp = (objnode_t*)iopack;//根据objnode_t结构中的控制码进行判断if(obp-&gt;on_ioctrd == FSDEV_IOCTRCD_DELFILE)&#123;//调用删除文件操作的接口函数return rfs_del_file(devp, obp-&gt;on_fname, 0);&#125;return DFCERRSTUS;&#125;// ----// 测试// ----// 写 test_fsys 函数进行测试void test_fsys(device_t *devp)&#123;kprint(&quot;开始文件操作测试\\n&quot;);void *rwbuf = new_buf(FSYS_ALCBLKSZ);//分配缓冲区//把缓冲区中的所有字节都置为0xffhal_memset(rwbuf, 0xff, FSYS_ALCBLKSZ);objnode_t *ondp = krlnew_objnode();//新建一个objnode_t结构ondp-&gt;on_acsflgs = FSDEV_OPENFLG_NEWFILE;//设置新建文件标志ondp-&gt;on_fname = &quot;/testfile&quot;;//设置新建文件名ondp-&gt;on_buf = rwbuf;//设置缓冲区ondp-&gt;on_bufsz = FSYS_ALCBLKSZ;//设置缓冲区大小ondp-&gt;on_len = 512;//设置读写多少字节ondp-&gt;on_ioctrd = FSDEV_IOCTRCD_DELFILE;//设置控制码if (rfs_open(devp, ondp) == DFCERRSTUS) &#123;//新建文件hal_sysdie(&quot;新建文件错误&quot;);&#125;ondp-&gt;on_acsflgs = FSDEV_OPENFLG_OPEFILE;//设置打开文件标志if (rfs_open(devp, ondp) == DFCERRSTUS) &#123;//打开文件hal_sysdie(&quot;打开文件错误&quot;);&#125;if (rfs_write(devp, ondp) == DFCERRSTUS) &#123;//把数据写入文件hal_sysdie(&quot;写入文件错误&quot;);&#125;hal_memset(rwbuf, 0, FSYS_ALCBLKSZ);//清零缓冲区if (rfs_read(devp, ondp) == DFCERRSTUS) &#123;//读取文件数据hal_sysdie(&quot;读取文件错误&quot;);&#125;if (rfs_close(devp, ondp) == DFCERRSTUS) &#123;//关闭文件hal_sysdie(&quot;关闭文件错误&quot;);&#125;u8_t *cb = (u8_t *)rwbuf;//指向缓冲区for (uint_t i = 0; i &lt; 512; i++) &#123;//检查缓冲区空间中的头512个字节的数据，是否为0xif (cb[i] != 0xff) &#123;//如果不等于0xff就死机hal_sysdie(&quot;检查文件内容错误&quot;);&#125;kprint(&quot;testfile文件第[%x]个字节数据:%x\\n&quot;, i, (uint_t)cb[i]);//打印文件内容&#125;if (rfs_ioctrl(devp, ondp) == DFCERRSTUS)&#123;//删除文件hal_sysdie(&quot;删除文件错误&quot;);&#125;ondp-&gt;on_acsflgs = FSDEV_OPENFLG_OPEFILE;//再次设置打开文件标志if (rfs_open(devp, ondp) == DFCERRSTUS) &#123;//再次打开文件hal_sysdie(&quot;再次打开文件失败&quot;);&#125;hal_sysdie(&quot;结束文件操作测试&quot;);return;&#125; 9.4 瞧一瞧Linux:虚拟文件系统如何管理文件 什么VFS VFS像伙伴系统,SLAB内存管理算法一样是SUN公司实现的虚拟文件系统,可理解为通用文件系统抽象层 在Linux中,支持ext,xfs,ntfs等文件系统,统一使用open(),read(),write(),close()接口 为适应不同的文件系统,VFS提供抽象层,让不同文件系统表现一致的行为 对用户空间和内核空间的其他部分,各种文件系统一样:文件都有目录,都支持建立,打开,读写,关闭和删除操作,不用关注不同文件系统的细节 Linux的VFS层是应用和许多文件系统之间的抽象层,向上对应用提供操作文件的标准接口,向下规范率文件系统要介入VFS必需要实现的机制 VFS提供一系列数据结构和具体文件系统应实现的回调函数,一个文件系统就可以被安装到VFS中,操作具体文件时,VFS会根据需要调用具体文件系统的函数 文件系统的细节被VFS屏蔽了,应用程序只需要调用标准接口即可 VFS数据结构 VFS为屏蔽各个文件系统的差异需要定义一组通用的数据结构,规范各个文件系统的实现,每种结构都对应一套回调函数集合(面向对象的设计方法) 这些数据结构包含描述文件系统信息的超级块,表示文件名称的目录结构,描述文件自身信息的索引节点结构,表示打开一个文件的实例结构 超级块结构 该结构用于一个具体文件系统的相关信息,其中包含了VFS规定的标准信息,也有具体文件系统的特有信息 Linux系统中的超级块结构是一个文件系统安装在VFS中的标识 在文件系统被挂载到 VFS 的某个目录下时，VFS 会调用获取文件系统自己的超级块的函数，用具体文件系统的信息构造一个上述结构的实例，有了这个结构实例，VFS 就能感知到一个文件系统插入了 超级块函数集合: super_operations 结构中所有函数指针所指向的函数都要由一个具体文件系统实现 文件系统只要实现了 super_block 和 super_operations 两个结构，就可以插入到 VFS 中,但该文件系统每任何实质性的功能 目录结构 randomize_layout 中的 dentry 结构中包含了目录的名字和挂载子目录的链表,同时也能指向父目录 目录也是文件,需要用 inode 索引结构来管理目录文件数据 该目录文件数据,可以想象成一个表,表有三列，分别为名称,类型,inode号 文件索引点 VFS用inode结构表示一个文件索引节点,里面包含文件权限,文件所属用户,文件访问和修改时间,文件数据块等一个文件的全部信息,一个inode结构对应一个文件,表示一个文件的全部信息,但该inode结构时VFS使用的,跟具体文件系统上的inode并不一一对应 inode结构有一套函数集合,用于具体文件系统根据信息构造出VFS使用的inode结构 VFS 通过定义 inode 结构和函数集合，并让具体文件系统实现这些函数，使得 VFS 及其上层只要关注 inode 结构，底层的具体文件系统根据自己的文件信息生成相应的 inode 结构，达到了 VFS 表示一个文件的目的 打开的文件 VFS设计文件对象结构解决表示应用程序打开的不同文件的问题，文件对象结构表示进程已打开的文件 文件对象结构包含了访问模式,当前读写偏移等信息 进程结构中具有文件表,该表是 file 结构的指针数组，进程每打开一个文件就会建立一个 file 结构实例，并将其地址放入数组中，最后返回对应的数组下标，就是调用 open 函数返回的那个整数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247// ----------// VFS数据结构// ----------struct super_block &#123; struct list_head s_list; //超级块链表 dev_t s_dev; //设备标识 unsigned char s_blocksize_bits;//以位为单位的块大小 unsigned long s_blocksize;//以字节为单位的块大小 loff_t s_maxbytes; //一个文件最大多少字节 struct file_system_type *s_type; //文件系统类型 const struct super_operations *s_op;//超级块函数集合 const struct dquot_operations *dq_op;//磁盘限额函数集合 unsigned long s_flags;//挂载标志 unsigned long s_magic;//文件系统魔数 struct dentry *s_root;//挂载目录 struct rw_semaphore s_umount;//卸载信号量 int s_count;//引用计数 atomic_t s_active;//活动计数 struct block_device *s_bdev;//块设备 void *s_fs_info;//文件系统信息 time64_t s_time_min;//最小时间限制 time64_t s_time_max;//最大时间限制 char s_id[32]; //标识名称 uuid_t s_uuid; //文件系统的UUID struct list_lru s_dentry_lru;//LRU方式挂载的目录 struct list_lru s_inode_lru;//LRU方式挂载的索引结点 struct mutex s_sync_lock;//同步锁 struct list_head s_inodes; //所有的索引节点 spinlock_t s_inode_wblist_lock;//回写索引节点的锁 struct list_head s_inodes_wb; //挂载所有要回写的索引节点&#125; __randomize_layout;// 超级块函数集合struct super_operations &#123; //分配一个新的索引结点结构 struct inode *(*alloc_inode)(struct super_block *sb); //销毁给定的索引节点 void (*destroy_inode)(struct inode *); //释放给定的索引节点 void (*free_inode)(struct inode *); //VFS在索引节点为脏(改变)时，会调用此函数 void (*dirty_inode) (struct inode *, int flags); //该函数用于将给定的索引节点写入磁盘 int (*write_inode) (struct inode *, struct writeback_control *wbc); //在最后一个指向索引节点的引用被释放后，VFS会调用该函数 int (*drop_inode) (struct inode *); void (*evict_inode) (struct inode *); //减少超级块计数调用 void (*put_super) (struct super_block *); //同步文件系统调用 int (*sync_fs)(struct super_block *sb, int wait); //释放超级块调用 int (*freeze_super) (struct super_block *); //释放文件系统调用 int (*freeze_fs) (struct super_block *); int (*thaw_super) (struct super_block *); int (*unfreeze_fs) (struct super_block *); //VFS通过调用该函数，获取文件系统状态 int (*statfs) (struct dentry *, struct kstatfs *); //当指定新的安装选项重新安装文件系统时，VFS会调用此函数 int (*remount_fs) (struct super_block *, int *, char *); //VFS调用该函数中断安装操作。该函数被网络文件系统使用，如NFS void (*umount_begin) (struct super_block *);&#125;;// -------// 目录结构// -------// VFS表示目录的数据结构//快速字符串保存关于字符串的 &quot;元数据&quot;（即长度和哈希值）struct qstr &#123; union &#123; struct &#123; HASH_LEN_DECLARE; &#125;; u64 hash_len; &#125;; const unsigned char *name;//指向名称字符串&#125;;struct dentry &#123; unsigned int d_flags; //目录标志 seqcount_spinlock_t d_seq; //锁 struct hlist_bl_node d_hash;//目录的哈希链表 struct dentry *d_parent; //指向父目录 struct qstr d_name; //目录名称 struct inode *d_inode; //指向目录文件的索引节点 unsigned char d_iname[DNAME_INLINE_LEN]; //短目录名 struct lockref d_lockref; //目录锁与计数 const struct dentry_operations *d_op;//目录的函数集 struct super_block *d_sb; //指向超级块 unsigned long d_time; //时间 void *d_fsdata; //指向具体文件系统的数据 union &#123; struct list_head d_lru; //LRU链表 wait_queue_head_t *d_wait; &#125;; struct list_head d_child; //挂入父目录的链表节点 struct list_head d_subdirs; //挂载所有子目录的链表&#125; randomize_layout;// 目录函数集struct dentry_operations &#123; //该函数判断目录对象是否有效 int (*d_revalidate)(struct dentry *, unsigned int); int (*d_weak_revalidate)(struct dentry *, unsigned int); //该函数为目录项生成散列值，当目录项要加入散列表中时，VFS调用该函数 int (*d_hash)(const struct dentry *, struct qstr *); //VFS调用该函数来比较name1和name2两个文件名。多数文件系统使用VFS的默认操作 int (*d_compare)(const struct dentry *, unsigned int, const char *, const struct qstr *); //当目录项对象的计数值等于0时，VFS调用该函数 int (*d_delete)(const struct dentry *); //当分配目录时调用 int (*d_init)(struct dentry *); //当目录项对象要被释放时，VFS调用该函数，默认情况下，它什么也不做 void (*d_release)(struct dentry *); void (*d_prune)(struct dentry *); //当一个目录项对象丢失了相关索引节点时，VFS调用该函数。默认情况下VFS会调用iput()函数 void (*d_iput)(struct dentry *, struct inode *); //当需要生成一个dentry的路径名时被调用 char *(*d_dname)(struct dentry *, char *, int); //当要遍历一个自动挂载时被调用（可选），这应该创建一个新的VFS挂载记录并将该记录返回给调用函数 struct vfsmount *(*d_automount)(struct path *); //文件系统管理从dentry的过渡（可选）时，被调用 int (*d_manage)(const struct path *, bool); //叠加/联合类型的文件系统实现此方法 struct dentry *(*d_real)(struct dentry *, const struct inode *);&#125; ____cacheline_aligned;// ----------// 文件索引节点// -----------struct inode &#123; umode_t i_mode;//文件访问权限 unsigned short i_opflags;//打开文件时的标志 kuid_t i_uid;//文件所属的用户id kgid_t i_gid;//文件所属的用户组id unsigned int i_flags;//标志 const struct inode_operations *i_op;//inode函数集 struct super_block *i_sb;//指向所属超级块 struct address_space *i_mapping;//文件数据在内存中的页缓存 unsigned long i_ino;//inode号 dev_t i_rdev;//实际设备标志符 loff_t i_size;//文件大小，以字节为单位 struct timespec64 i_atime;//文件访问时间 struct timespec64 i_mtime;//文件修改时间 struct timespec64 i_ctime;//最后修改时间 spinlock_t i_lock; //保护inode的自旋锁 unsigned short i_bytes;//使用的字节数 u8 i_blkbits;//以位为单位的块大小； u8 i_write_hint; blkcnt_t i_blocks; struct list_head i_io_list; struct list_head i_lru; //在缓存LRU中的链表节点 struct list_head i_sb_list;//在超级块中中的链表节点 struct list_head i_wb_list; atomic64_t i_version;//版本号 atomic64_t i_sequence; atomic_t i_count;//计数 atomic_t i_dio_count;//直接io进程计数 atomic_t i_writecount;//写进程计数 union &#123; const struct file_operations *i_fop;//文件函数集合 void (*free_inode)(struct inode *); &#125;; struct file_lock_context *i_flctx; struct address_space i_data; void *i_private; //私有数据指针&#125; __randomize_layout;// 函数集合struct inode_operations &#123; //VFS通过系统create()和open()接口来调用该函数，从而为dentry对象创建一个新的索引节点 int (*create) (struct inode *, struct dentry *,int); //该函数在特定目录中寻找索引节点，该索引节点要对应于dentry中给出的文件名 struct dentry * (*lookup) (struct inode *, struct dentry *); //被系统link()接口调用，用来创建硬连接。硬链接名称由dentry参数指定 int (*link) (struct dentry *, struct inode *, struct dentry *); //被系统unlink()接口调用，删除由目录项dentry链接的索引节点对象 int (*unlink) (struct inode *, struct dentry *); //被系统symlik()接口调用，创建符号连接，该符号连接名称由symname指定，连接对象是dir目录 int (*symlink) (struct inode *, struct dentry *, const char *); //被mkdir()接口调用，创建一个新目录。 int (*mkdir) (struct inode *, struct dentry *, int); //被rmdir()接口调用，删除dentry目录项代表的文件 int (*rmdir) (struct inode *, struct dentry *); //被mknod()接口调用，创建特殊文件(设备文件、命名管道或套接字)。 int (*mknod) (struct inode *, struct dentry *, int, dev_t); //VFS调用该函数来移动文件。文件源路径在old_dir目录中 int (*rename) (struct inode *, struct dentry *, struct inode *, struct den //被系统readlink()接口调用，拷贝数据到特定的缓冲buffer中。拷贝的数据来自dentry指定的 int (*readlink) (struct dentry *, char *, int); //被VFS调用，从一个符号连接查找他指向的索引节点 int (*follow_link) (struct dentry *, struct nameidata *); //在follow_link()调用之后，该函数由vfs调用进行清除工作 int (*put_link) (struct dentry *, struct nameidata *); //被VFS调用，修改文件的大小，在调用之前，索引节点的i_size项必须被设置成预期的大小 void (*truncate) (struct inode *); //该函数用来检查给定的inode所代表的文件是否允许特定的访问模式，如果允许特定的访问模式，返 int (*permission) (struct inode *, int); //被notify_change接口调用，在修改索引节点之后，通知发生了改变事件 int (*setattr) (struct dentry *, struct iattr *); //在通知索引节点需要从磁盘中更新时，VFS会调用该函数 int (*getattr) (struct vfsmount *, struct dentry *, struct kstat *); //被VFS调用，向dentry指定的文件设置扩展属性 int (*setxattr) (struct dentry *, const char *, const void *, size_t, int) //被VFS调用，拷贝给定文件的扩展属性name对应的数值 ssize_t (*getxattr) (struct dentry *, const char *, void *, size_t); //该函数将特定文件所有属性列表拷贝到一个缓冲列表中 ssize_t (*listxattr) (struct dentry *, char *, size_t); //该函数从给定文件中删除指定的属性 int (*removexattr) (struct dentry *, const char *);&#125;;// ---------// 打开的文件// ---------struct file &#123; union &#123; struct llist_node fu_llist; struct rcu_head fu_rcuhead; &#125; f_u; struct path f_path; //文件路径 struct inode *f_inode; //文件对应的inode const struct file_operations *f_op;//文件函数集合 spinlock_t f_lock; //自旋锁 enum rw_hint f_write_hint; atomic_long_t f_count;//文件对象计数据。 unsigned int f_flags;//文件标志 fmode_t f_mode;//文件权限 struct mutex f_pos_lock;//文件读写位置锁 loff_t f_pos;//进程读写文件的当前位置 u64 f_version;//文件版本 void *private_data;//私有数据&#125; __randomize_layout;// 对于file结构具有对应的函数集合 file_operations 结构struct file_operations &#123; struct module *owner;//所在的模块 loff_t (*llseek) (struct file *, loff_t, int);//调整读写偏移 ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);//读 ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);// int (*mmap) (struct file *, struct vm_area_struct *);//映射 int (*open) (struct inode *, struct file *);//打开 int (*flush) (struct file *, fl_owner_t id);//刷新 int (*release) (struct inode *, struct file *);//关闭&#125; __randomize_layout; 四个对象结构的关系 打开文件 在对文件进行读写之前,需要先用open函数打开文件(使用标准库的open函数) 在x86_64架构中,open函数会执行syscall指令，从用户态切换到内核态,并且最终调用到 do_sys_open 函数,然后调用 do_sys_openat2 函数 读写文件 读操作是数据从文件经由内核流向进程,写操作是数据从进程经由内核流向文件 关闭文件 回收file结构,其中最重要的是调用文件系统的flush函数,给文件系统一个刷新缓冲区,将数据写回储存设备保证储存设备的一致性 文件系统实例 trfs内存文件系统,支持文件的建立,打开,读写，关闭等操作,通过内存块存放数据 注册trfs 需要在模块初始化函数中注册文件系统 使用trfs文件系统 首先是编译 trfs 内核模块代码，在终端中 cd 到对应的目录下执行 make，然后把编译好的内核模块插入到系统中，最后就是将这个文件系统挂载到一个具体的目录下 12345678910111213141516171819202122232425262728293031323334// -------// 注册trfs// -------struct file_system_type trfs_fs_type = &#123;.owner = THIS_MODULE,.name = &quot;trfs&quot;,//文件系统名字.mount = trfs_mount,//文件系统挂载函数.kill_sb = trfs_kill_superblock,//文件系统卸载函数&#125;;static int trfs_init(void)&#123;int ret;init_fileinfo();//初始化trfs文件系统数据结构ret = register_filesystem(&amp;trfs_fs_type);//注册文件系统if (ret)printk(KERN_EMERG&quot;register trfs failed\\n&quot;);printk(KERN_EMERG&quot;trfs is ok\\n&quot;);return ret;&#125;static void trfs_exit(void)&#123;exit_fileinfo();//释放trfs文件系统数据结构unregister_filesystem(&amp;trfs_fs_type);//卸载文件系统&#125;module_init(trfs_init);module_exit(trfs_exit);// --------------// 使用trfs文件系统// --------------make //编译内核模块sudo insmod trfs.ko //把内核模块插入到内核sudo mount -t trfs none /mnt/ // 挂载trfs文件系统到mnt目录// 随后可以使用touch建立文件，然后用cat读取该文件 10 网络 10.1 如何全局观察网络数据流动 输入URL的请求到响应发生的事 常规的网络交互过程是从客户端发起网络请求,用户态的应用程序(浏览器)会生成HTTP请求报文,并通过DNS协议查找到对应的远端IP地址 在套接字生成之后进入内核态,浏览器会委托操作系统内核协议栈中的上半部分(TCP/UDP协议发起连接请求) 然后经由协议栈下半部分的IP协议进行封装,使数据包具有远程定位能力 经过MAC层梳理,找到接收方的目标MAC地址 最终数据包在经过网卡转化成电信号经过交换机,路由器发送到服务端,服务端经过处理拿到数据，再通过各种网络协议栈把数据响应给客户端 客户端拿到数据进行渲染 客户端和服务端之间反复交换数据,客户端的页面数据就会发生变化 前置知识:网络分层和网络协议 当前网络主要遵循IEEE802.3标准给予OSI模型提出,主要定义的是物理层和数据链路层有限物理数据流传输标准 网络分层解决了网络复杂的问题,在网路中传输数据中，对不同设备之间的传输数据的格式需要定义一个数据标准，即定义网络协议 以TCP/IP层的体系结构为例分析 发起请求阶段(应用层) 应用层只需要专注于用户提供应用功能,不需要关心数据如何传输 用户输入:在浏览器中输入URL 浏览器会根据输入内容,先匹配对应的URL以及关键词,给出输入建议,同时检验URL的合法性,并且在URL前后补全URL URL一般语法由5个分层序列组成 URI = scheme:[//authority]path[?query][#fragment] URI = 方案:[//授权]路径[?查询][#片段ID] 接着,浏览器从URL中会提取网络的地址(主机名host),一般主机名可以为域名或IP地址,以此使用域名 对URL进行解析之后,浏览器确定了服务器的主机名和请求路径,根据信息生成HTTP请求消息 网络请求前:查看浏览器缓存 浏览器在HTTP报文生成完成后,并不是马上开始网络请求 在请求发出之前,浏览器首先会检查保存在本地的缓存,若访问过当前的URL,会先进入缓存中查询是否有请求的文件 若没有在浏览器缓存里没有命中缓存,浏览器会做一个系统调用获得系统缓存中的记录,gethostbyname方法通过域名获取IP地址,返回hostent结构数据 若没有访问过该URL，则跳过缓存这一步进入网络操作 123456789struct hostent&#123;char *h_name;// 主机的别名.www.cosmos.com就是google他自己的别名char **h_aliases;// 主机ip地址的类型，到底是ipv4(AF_INET)，还是pv6(AF_INET6)int h_addrtype;// 主机ip地址的长度int h_length;// 主机ip地址的长度char **h_addr_list; // 主机的ip地址，注意，这个是以网络字节序存储的#define h_addr h_addr_list[0] 这个函数，是将类型为af的网络地址结构src，转换成主机序&#125;; 域名解析:DNS 在发送消息之前,需要查找服务端的IP地址,因为操作系统在发送消息时必须知道对应的IP地址才能发送 DNS服务器:将IP地址映射为域名,维护IP和域名的映射关系 DNS按照树形结构组织,可以一层层递归和迭代查找 DNS解析 &gt; 浏览器DNS缓存 &gt; hosts文件 &gt; 本地DNS服务器 &gt; ISP DNS服务器 操作系统协议栈(传输层和网络层) TCP/IP 协议栈是现在使用最广泛的网络协议栈，Internet 就是建立在 TCP/IP 协议栈基础上的 协议栈内部分为几部分，分别承担着不同的作用 协议栈的上半部分负责和应用层通过套接字（Socket）进行交互，它可以是 TCP 协议或 UDP 协议。应用层会委托协议栈的上部分完成收发数据的工作 协议栈的下半部分则负责把数据发送给到指定方的 IP 协议，由IP 协议连接下层的网卡驱动 可靠性传输:建立TCP连接 浏览器通过 DNS 解析拿到操作系统的 IP 地址后， 浏览器取出 URL 的端口（HTTP 默认 80，HTTPS 默认 443） 随即浏览器会委托操作系统协议栈的上半部分创建新的套接字（Socket）向对应的 IP 发起 TCP 连接请求 为了确保通信的可靠性,建立TCP首先会进行三次握手 首先浏览器作为客户端会发送一个小的 TCP 分组，这个分组设置了一个特殊的 SYN 标记，用来表示这是一条连接请求。同时设置初始序列号为 x 赋值给 Seq （这次捕获组的数据为: SYN=1, Seq=1） 服务器接受到客户端的 SYN 连接后，会选择服务器初始序号 y。同时向客户端发送含有连接确认（SYN+ACK）、Seq=0（本例中的服务器初始序号）、Ack=1（客户端的序号x+1）等信息的 TCP 分组 客户端收到了服务器的确定字段后，向服务器发送带有 ACK=1、Seq=1 (x+1)、Ack=1（服务器 Ack 信息的拷贝）等字段的 TCP 分组给服务器 目的地定位:IP层 TCP在维护状态的过程中，都需要委托 IP 层将数据封装，发送和处理网络数据包进入网络层 IP 协议是 TCP/IP 协议栈的核心，规定了在 Internet 上进行通信时应遵循的规则，包括 IP 数据包应如何构成、数据包的路由等，而 IP 层实现了网络上的点对点通信 IP层协议的函数对网络数据包进行5步操作 数据包校验和检验 防火墙对数据包过滤 IP 选项处理 数据分片和重组 接收、发送和前送 IP层被设计为三部分:IP寻址,路由和分包组包 点对点传输:MAC(链路层) MAC地址为计算机网卡的物理地址,被固化到网卡中,用来标识一个网络设备 MAC地址唯一且无重复 网络数据在 IP 层中加上 IP 头后，形成了 IP 包，进入 MAC 层对 IP 包加上 MAC 头，这个 MAC 头包括发送方的 MAC 头和接收方的 MAC 头，用于两个物理地址点对点的传输 此外还有一个头部字段为协议类型，在常规的 TCP/IP 协议中，MAC 头的协议类型只有 IP 和 ARP 两种 发送方的 MAC 头比较容易获取，读取当前设备网卡的 MAC 地址就可以获取 接收方的 MAC 头则需要通过 ARP 协议在网络中携带 IP 地址，在一个网络中发送广播信息就能获取网络中的 IP 地址对应的 MAC 地址，然后就能给 IP 包加上 MAC头了，最后这个加上 MAC 头的 IP 包，成为一个 MAC 数据包，就可以准备发送出去了 电信号的出口:网卡(物理层) MAC 数据包会交给网卡驱动程序，而网卡驱动程序会将 MAC 数据包写入网卡的缓冲区（网卡上的内存） 网卡会在 MAC 数据包的起止位置加入起止帧和校验序列，最后网卡会将加入起止帧和校验序列的 MAC 数据包转化为电信号，发送出去 客户端服务端的持续数据交换(应用层) 数据通过网卡离开计算机，进入到局域网，通过局域网中的设备，集线器、交换机和路由器等，数据会进入到互联网，最终到达目标服务器 接着，服务器就会先取下数据包的 MAC 头部，查看是否匹配自己 MAC 地址。然后继续取下数据包的 IP 头，数据包中的目标 IP 地址和自己的 IP 地址匹配，再根据 IP 头中协议项，知道自己上层是 TCP 协议 之后，还要继续取下数据包 TCP 的头。完成一系列的顺序校验和状态变更后，TCP 头部里面还有端口号，此时 HTTP 的 server 正在监听这个端口号，就把数据包再发给对应的 HTTP 进程 HTTP 进程从服务器中拿到对应的资源，再交给操作系统对数据进行处理。然后再重复上面的过程，层层携带 TCP、IP、MAC 头部 接下来数据从网卡出去，到达客户端，再重复刚才的过程拿到相应数据 客户端拿到对应的 HTML 资源，浏览器就可以开始解析渲染了，操作完成后，用户最终就能通过浏览器看到相应的页面 关闭网络需要进行四次挥手，两边的网络传输过程至此完成 10.2 网络数据在内核中如何流转 发送过程总览 应用程序通过网络发送数据的全过程 应用程序首先会准备好数据,调用用户态下的库函数 接着调用系统API接口函数，进入到内核态 内核态对应的系统服务函数会复制应用程序的数据到内核的内存空间,然后将数据交给网络协议栈,在网络协议栈中将数据层层打包 最好包装好的数据会交给网卡驱动,负责将打包好的数据写入网卡并让其发送出去 接受过程总览 首先网卡接受到数据,通过DMA复制到指定的内存 发送中断,以通知网卡驱动，由网卡驱动处理中断复制数据 然后网络协议收到网卡驱动传来的数据，层层解包,获取真正的有效数据 最后数据发送给用户态监听的应用进程 认识IwIP架构 IwIP是TCP/IP协议的轻量级开源项目 IwIP尽量用少量资源消耗,实现一个相对完整的TCP/IP协议栈,实现的关键点在于保持TCP协议主要功能的基础上减少对RAM的占用 IwIP在结构上可分为:OS层,API层,核心层,硬件驱动层 第一层 MCU 的业务层是 lwIP 的服务对象，也是其自身代码使用 lwIP 的地方 在典型的 TCP 通信的客户端应用程序中，一般先要通过 netconn_new 创建一个 structnetconn 对象，然后调用 netconn_connect 连接到服务器，并返回成功或失败 成功后，可以调用 netconn_write 向服务器发送数据，也可以调用 netconn_recv 接收数据 最后，关闭连接并通过 netconn_close 释放资源 第二层 api层是netconn的功能代码所在的层,负责为上层代码提供netconn的api 可以使用 lwip_socket等函数以标准的socket方式调用IwIP 第三层 IwIP的核心层存放了TCP/IP协议栈的核心代码,不仅实现了大部分的TCP和UDP功能,还实现了DNS,ICMP,IGMP等协议,同时也实现了内存管理和网络接口功能 第四层 硬件驱动层提供了PHY芯片驱动，用来匹配IwIP的使用,IwIP会调用该层的代码将组装好的数据包发送到网络，同时从网络接受数据包进行分析,实现通信功能 IwIP的三套应用程序编程接口 原始API:通过事件回调机制开发应用程序,提供了最佳的性能和优化的代码长度,增加了应用程序开发的复杂性 Netconn API:高级的有序API,需要实时操作系统的支持,支持多线程 BSD套接字API:类似伯克利的套接字API IwIP执行流程 数据发送 内核上层首先会调用IwIP的netconn层的接口函数netconn_write，通过该函数数据正式流进IwIP组件层 netconn层调用IwIP组件的TCP层的接口函数tcp_write，在TCP层对数据首次进行打包，然后TCP层将打包好的数据通过调用io_output函数向下传递给IwIP组件的IP层,进行打包 最后,IP层将打包好的数据发送给网卡驱动接口层netif,将数据发送出去 数据接收 首先调用IwIP的netconn层的netconn_recv接口 然后由netconn层调用 sys_arch_mbox_fetch函数,进入监听等待相关的mbox 接着数据会进入网卡,驱动程序相关的函数负责将它复制进内存 然后调用 ethernet_input函数,进入ethernet层,完成相关处理后,调用ip4_input函数,数据在IwIP组件的IP层对数据进行解包,进行相关处理之后调用 tcp_input函数,进入IwIP组件的TCP层对数据进行解包 最后,调用 sys_mbox_trypost函数把数据放入特定的mbox，等待监听的应用程序就能得到数据 协议栈移植 一种是NO_SYS，无操作系统模式,一种是操作系统模式 操作系统模式主要需要基于操作系统的 IPC 机制，对网络连接进行了抽象（信号量、邮箱/队列、互斥体等机制），从而保证内核与应用层 API 的通讯 好处是 lwIP 内核线程可以只负责数据包的 TCP/IP 封装和拆封，而不用进行数据的应用层处理，从而极大地提高系统对网络数据包的处理效率 操作系统模拟层的函数主要是在 sys.h 中声明的一般在 sys_arch.c 文件中完成其定义 所以带操作系统的移植就是在无操作系统的基础上添加操作系统模拟层 有操作系统模式 在cosmos系统提供的IPC等机制基础上,对照sys.h文件中声明的函数进行实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165/*创建一个空的邮箱。*/err_t sys_mbox_new(sys_mbox_t *mbox, int size)&#123;osMessageQDef(QUEUE, size, void *);*mbox = osMessageCreate(osMessageQ(QUEUE), NULL);#if SYS_STATS++lwip_stats.sys.mbox.used;if (lwip_stats.sys.mbox.max &lt; lwip_stats.sys.mbox.used) &#123;lwip_stats.sys.mbox.max = lwip_stats.sys.mbox.used;&#125;#endif /* SYS_STATS */if (*mbox == NULL)return ERR_MEM;return ERR_OK;&#125;/*重新分配一个邮箱。如果邮箱被释放时，邮箱中仍有消息，在lwIP中这是出现编码错误的指示，并通知开void sys_mbox_free(sys_mbox_t *mbox)&#123;if( osMessageWaiting(*mbox) )&#123;portNOP();#if SYS_STATSlwip_stats.sys.mbox.err++;#endif /* SYS_STATS */&#125;osMessageDelete(*mbox);#if SYS_STATS--lwip_stats.sys.mbox.used;#endif /* SYS_STATS */&#125;/*发送消息到邮箱*/void sys_mbox_post(sys_mbox_t *mbox, void *data)&#123;while(osMessagePut(*mbox, (uint32_t)data, osWaitForever) != osOK);&#125;/*尝试将消息发送到邮箱*/err_t sys_mbox_trypost(sys_mbox_t *mbox, void *msg)&#123;err_t result;if ( osMessagePut(*mbox, (uint32_t)msg, 0) == osOK)&#123;result = ERR_OK;&#125;else &#123;result = ERR_MEM;#if SYS_STATSlwip_stats.sys.mbox.err++;#endif /* SYS_STATS */&#125;return result;&#125;/*阻塞进程从邮箱获取消息*/u32_t sys_arch_mbox_fetch(sys_mbox_t *mbox, void **msg, u32_t timeout)&#123;osEvent event;uint32_t starttime = osKernelSysTick();;if(timeout != 0)&#123;event = osMessageGet (*mbox, timeout);if(event.status == osEventMessage)&#123;*msg = (void *)event.value.v;return (osKernelSysTick() - starttime);&#125;else&#123;return SYS_ARCH_TIMEOUT;&#125;&#125;else&#123;event = osMessageGet (*mbox, osWaitForever);*msg = (void *)event.value.v;return (osKernelSysTick() - starttime);&#125;&#125;/*尝试从邮箱获取消息*/u32_t sys_arch_mbox_tryfetch(sys_mbox_t *mbox, void **msg)&#123;osEvent event;event = osMessageGet (*mbox, 0);if(event.status == osEventMessage)&#123;*msg = (void *)event.value.v;return ERR_OK;&#125;else&#123;return SYS_MBOX_EMPTY;&#125;&#125;/*判断一个邮箱是否有效*/int sys_mbox_valid(sys_mbox_t *mbox)&#123;if (*mbox == SYS_MBOX_NULL)return 0;elsereturn 1;&#125;/*设置一个邮箱无效*/void sys_mbox_set_invalid(sys_mbox_t *mbox)&#123;*mbox = SYS_MBOX_NULL;&#125;// 创建一个新的信号量。而 &quot;count&quot;参数指示该信号量的初始状态err_t sys_sem_new(sys_sem_t *sem, u8_t count)&#123;osSemaphoreDef(SEM);*sem = osSemaphoreCreate (osSemaphore(SEM), 1);if(*sem == NULL)&#123;#if SYS_STATS++lwip_stats.sys.sem.err;#endif /* SYS_STATS */return ERR_MEM;&#125;if(count == 0) // Means it can&#x27;t be taken&#123;osSemaphoreWait(*sem,0);&#125;#if SYS_STATS++lwip_stats.sys.sem.used;if (lwip_stats.sys.sem.max &lt; lwip_stats.sys.sem.used) &#123;lwip_stats.sys.sem.max = lwip_stats.sys.sem.used;&#125;#endif /* SYS_STATS */return ERR_OK;&#125;// 此外还有一些函数也是协议栈需要的函数，特别是 sys_thread_new 函数，不但协议栈在初始化时需要用到，在后续实现各类基于 lwIP 的应用时也会用得到// 它的具体实现如下sys_thread_t sys_thread_new(const char *name, lwip_thread_fn thread , void *ar&#123;const osThreadDef_t os_thread_def = &#123; (char *)name, (os_pthread)thread, (osPrireturn osThreadCreate(&amp;os_thread_def, arg);&#125;osThreadId osThreadCreate (const osThreadDef_t *thread_def, void *argument)&#123;TaskHandle_t handle;#if( configSUPPORT_STATIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATif((thread_def-&gt;buffer != NULL) &amp;&amp; (thread_def-&gt;controlblock != NULL)) &#123;handle = xTaskCreateStatic((TaskFunction_t)thread_def-&gt;pthread,(const portCHARthread_def-&gt;stacksize, argument, makeFreeRtosPriority(thread_def-&gt;tpriority),thread_def-&gt;buffer, thread_def-&gt;controlblock);&#125;else &#123;if (xTaskCreate((TaskFunction_t)thread_def-&gt;pthread,(const portCHAR *)thread_dthread_def-&gt;stacksize, argument, makeFreeRtosPriority(thread_def-&gt;tpriority),&amp;handle) != pdPASS) &#123;return NULL;&#125;&#125;#elif( configSUPPORT_STATIC_ALLOCATION == 1 )handle = xTaskCreateStatic((TaskFunction_t)thread_def-&gt;pthread,(const portCHARthread_def-&gt;stacksize, argument, makeFreeRtosPriority(thread_def-&gt;tpriority),thread_def-&gt;buffer, thread_def-&gt;controlblock);#elseif (xTaskCreate((TaskFunction_t)thread_def-&gt;pthread,(const portCHAR *)thread_dthread_def-&gt;stacksize, argument, makeFreeRtosPriority(thread_def-&gt;tpriority),&amp;handle) != pdPASS) &#123;return NULL;&#125;#endifreturn handle;&#125; 10.3 详解操作系统的宏观网络架构 传统网络架构 三层网咯架构设计主要包括：核心层，汇聚层，接入层 核心层 交换层的核心交换机为进出数据中心的数据包提供高速转发的功能，为多个汇聚层提供连通性，同时为整个网络提供灵活的L3路由网络 汇聚层:汇聚交换机与接入交换机相连，提供防火墙,SSL卸载，入侵检测，网络分析等其他服务 接入层:接入交换机位于机架的顶部，称为ToR交换机，并且与服务器物理连接 经典的IP网络是逐跳转发数据,转发数据时，每台路由器都要根据包头的目的地址查询路由表，已获得下一跳的出口 优化与迭代:MPLS技术 传统网络架构转发路径不够灵活，在第二层之上第三层之下引入2.5层的技术方案为多协议标签交换(MPLS)技术 MPLS通过LDP标签分发协议,而路径计算元素协议最大的优点是收集整个网络的拓扑和链路状态信息 通过扩展的资源预留协议,可以实现灵活的转发路径选择或规划 只在OSI的2，3层之间做优化远远不够,为了满足百G传输需求，物理层也经历了从DWDM波分复用系统这种波分复用技术到OTN的技术演进 MPLS技术加重了耦合,并且存在资源利用率低,复杂度高,价格昂贵等缺点 SR技术可解决上述问题,随着IPv6的演进,用SRv6代替MPLS技术大势所趋 简单的CLOW网络是包含输入级别,中间级别和输出级别的三级互连体系结构 矩形表示规模较小的转发单元，其成本显然也相对较低 CLOS 的本质可以简单理解为是一种多级交换的架构思想，并且这种架构很适合在输入和输出持续增加的情况下将中间交叉数降至最低 m 是每个子模块的输入端口数，n 是每个子模块的输出端口数，r 是每一级的子模块数，经过合理的重排，只要满足公式r2&gt;=max(m1,n3)r2&gt;=max(m1,n3)r2&gt;=max(m1,n3) 对于任意的输入到输出，总是能找到一条无阻塞的通路 应用CLOS架构的交换机的开始密度与交换机端口数量N的关系:O(N3/2)O(N^{3/2})O(N3/2) 在N较大时CLOS模型能降低交换机内部的开关密度 谈谈Google B4 B4网络的核心架构由Google设计的控制软件和白盒交换机组成 谷歌的目标是建立一个类似于广域网的镜像网络,随着网络规模不断扩展,谷歌大部分业务都已运行在B4上 B4网络由三层组成:物理设备层,局部网络控制层和全局控制层 第一层:物理设备层 是Google自研的白盒交换机,使用了24颗16*10Gb的芯片,还携带了128个10Gb网口 交换机运行的是OpenFlow协议 专用的交换机跟OpenFlow进行协同,使用TTP方案,实际运行时交换机将访问控制列表(ACL),路由表,隧道表之类的关键数据通过BGP/IS-IS协议报文送到Controller,由Controller进行处理 第二层:局部网络控制层 一个交换机是可以连接多个Controller服务的,而同一时间只会有一个Controller服务为这台交换机提供服务,并且一个数据中心中会包含由多个Controller服务实例构成的服务集群 在局部网络控制层中,会使用Paxos协议负责所有控制功能的领导者选举 具体过程:每个节点上的 Paxos 实例对给定控制功能的可用副本集做应用程序级别的健康检测。当大多数的 Paxos 实例检测到故障时就会从剩余的可用服务器集中选出一个新的负责人。然后，Paxos 会将递增的 ID 号回调给当选的 leader。leader 使用这个 ID 来向客户表明自己的身份 第三层:全局控制层 负责全局控制的 TE Server 通过 SDN Gateway 从各个数据中心的控制器收集链路信息，从而掌握路径状态。这些路径以 IP-In-IP 隧道的方式创建，通过 SDN 网关到达 Onix 控制器，最后下达到交换机 当一个新的业务数据需要传输时，应用程序会估计它在传输时需要的带宽，并为它选择一个最佳路径，这样可以让链路的带宽利用率达到整体最佳 SDN原理 SDN架构也分为三层 应用层是由包含了各种不同的业务逻辑的应用构成的 控制层主要负责数据平面相关的资源的编排,调度,网络拓扑的维护以及状态信息管理等工作 数据层主要负责数据的转发,处理以及运行时的状态收集工作 SDN的基本特征和优势 SDN主要包含三个基本特征: 控制逻辑与转发逻辑分离。转发平面主要是由受控的转发设备构成，具体的转发方式和相关业务逻辑则由分离在控制面的控制应用程序控制 开放的 API。通过开放的南北向 API，可以实现应用和网络的无缝集成，让应用只需要关注自己的逻辑，不需要关注底层的实现细节 集中控制：集中的控制平面可以获取网络资源的全局信息，并根据业务需求进行全局分配和优化 SDN的优势 灵活性，动态调整网络设备的配置，不再需要手动配置每台设备 网络硬件简化（如白盒交换机等）。只需要关注数据处理和转发，与具体业务特性解耦，加速新业务特性的引入 自动化的网络部署、操作和维护以及故障诊断 开放网络操作系统ONOS组网实践 ONOS是开源的分布式网络操作系统控制平台,为控制面的具体实现,Mininet对应数据面实现，分别对应SDN的控制面和数据面 使用ONOS+Mininet可以快速创建一个包含主机,交换机,SDN控制器以及链路的虚拟网络,并且Mininet创建的交换机支持OpenFlow协议,具备高度的灵活性 可以轻松在本地搭建SDN开发,调试环境 123456789101112131415161718192021222324252627282930313233343536# 运行文稿中的命令安装dockersudo apt-get updatesudo apt install curlsudo apt install sshcurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun# 完成之后拉取ONOS镜像docker pull onosproject/onos# 创建onos容器docker run -t -d --name onos1 onosproject/onos# 获取onos容器的ipdocker inspect --format &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; &lt;container-ID&gt;# 使用ssh登录ssh -p 8101 karaf@172.17.0.2app activate org.onosproject.openflow #启用openflowapp activate org.onosproject.fwd #启用forward转发功能# 退出登录,返回虚拟机中配置mininet连接到onossudo mn --topo tree,2 --controller remote,ip=172.17.0.2 #创建临时网络pingall #网路连通性检测# 查看拓扑打开 URL：http://172.17.0.2:8181/onos/ui/login.html账号 / 密码：karaf# 说明：先把容器的网络映射到虚拟机，再把虚拟机的网络映射到本地即可# docker run的时候加上 -p 8000:80 这样的参数，就可以映射到虚机了，然后再改一下 VBox 的网络设置# onos cli# karaf 进入 ONOS 之后，除了开启各类设置，它本身也是一个 CLI，可以查看各类信息，例如后面这些信息# devices：查看交换机# links：查看链路# hosts：查看主机# flows &lt;tab 键 &gt;：查看所选交换机之间的路径 10.4 详解socket实现与网络编程接口 如何理解套接字 Internet 套接字是TCP/IP协议栈中传输层协议的接口，也是传输层以上所有协议的实现；同时，套接字接口在网络程序功能中是内核与应用层之间的接口 TCP/IP协议栈的所有数据和控制功能都来自于套接字接口，与OSI网络分层模型相比,TCP/IP协议栈本身在传输层以上就不包含任何其他协议 在linux操作系统中,替代传输层以上协议实体的标准接口称为套接字,负责实现传输层以上所有功能,可以说套接字是TCP/IP协议栈对外的窗口 Linux套接字API适合所有的应用标准,现在的应用层协议也全部移植到Linux系统中 在套接字层下的基础体系结构实现是Linux系统独有的 创建套接字是可通过参数选择协议族,为应用程序指定不同的网络机制 指定为PF_INET协议族,套接字称为INET套接字,接口函数提供TCP/IP网络服务功能 套接字的数据结构 Linux下套接字,套接字属性，套接字传输的数据格式还有管理套接字连接状态的数据结构做了抽象定义 每个程序使用的套接字都包含struct socket数据结构与 struct sock数据结构的实例 Linux 内核在套接字层定义了包含套接字通用属性的数据结构，分别是 struct socket 与struct sock，独立于具体协议 具体的协议族与协议实例继承了通用套接字的属性，加入协议相关属性，就形成了管理协议本身套接字的结构 struct socket数据结构 struct socket 套接字结构类型，每个套接字在内核中都对应唯一的struct socket结构 struct sock数据结构 struct sock数据一部分描述套接字的共用属性,所有协议族的这些属性相同;另一部分属性定义在 strcut sock_common数据结构中 struct sock数据另一部分为新套接字创建 struct sock数据结构实例时会从协议特有的缓冲槽中分配内存,不再从通用缓冲槽中分配内存 struct sock 数据结构包含了大量的内核管理套接字的信息，内核把最重要的成员存放在struct sock_common 数据结构中，struct sock_common 数据结构嵌入在 struct sock结构中，它是 struct sock 数据结构的第一个成员 struct sock_common数据结构时套接字在网络中的最小描述包含了内核管理套接字最重要的集合 系统中 struct sock 数据结构组织在特定协议的哈希链表中，skc_node 是连接哈希链表中成员的哈希节点，skc_hash 是引用的哈希值。接收和发送数据放在数据 struct sock 数据结构的两个等待队列中：sk_receive_queue 和sk_write_queue。这两个队列中包含的都是 Socket Buffer 内核使用 struct sock 数据结构实例中的回调函数，获取套接字上某些事件发生的消息或套接字状态发生变化。其中，使用最频繁的回调函数是 sk_data_ready，用户进程等待数据到达时，就会调用该回调函数 套接字与文件 套接字的连接建立后,用户进程就可以使用常规文件操作访问套接字 Linux虚拟文件系统层(VFS)的实现:每个文件都有一个VFS inode结构,每个套接字都分配一个该类型的inode,套接字中的inode指针连接管理常规文件的其他结构,操作文件的函数存放在一个独立的指针表中 套接字的文件描述符的文件访问的重定向,对网络协议栈各层是透明的,inode和socket的链接是通过直接分配一个辅助数据结构来实现 套接字缓存 Socket Buffer为套接字缓存,代表了一个要发送或处理的报文，贯穿于整个TCP/IP协议栈的各层 在Linux内核对网络数据打包处理的全过程中,始终伴随Socket Buffer Socket Buffer是网络数据包在内核中的对象实例 Socket Buffer主要包括两部分:数据包;管理数据结构(struct sk_buff) struct sk_buff 数据结构中存放了套接字接收 / 发送的数据 在发送数据时，在套接字层创建了 Socket Buffer 缓冲区与管理数据结构，存放来自应用程序的数据 在接收数据包时，Socket Buffer 则在网络设备的驱动程序中创建，存放来自网络的数据 在发送和接受数据的过程中，各层协议的头信息会不断从数据包中插入和去掉，sk_buff 结构中描述协议头信息的地址指针也会被不断地赋值和复位 套接字的初始化 Linux 内核支持的地址族非常多，TCP/IP 协议栈在套接字层注册的地址族是 AF_INET，AF_INET 地址族是在内核启动时注册到内核中的。TCP/IP 协议栈与 AF_INET 地址族相连的处理函数，既可以在套接字初始化时与 AF_INET 地址连接起来，也可以在套接字中动态地注册新的协议栈 套接字层的初始化要为以后各协议初始化 struct sock 数据结构对象、套接字缓冲区Socket Buffer 对象等做好准备，预留内存空间 基本任务 初始化套接字的缓存槽 为 Socket Buffer 创建内存缓存槽 创建虚拟文件系统 地址族的值和协议交换表 套接字是一个通用接口，它可以与多个协议族建立接口，每个协议族中又可以实现多个协议实例 TCP/IP 协议栈处理完输入数据包后，将数据包交给套接字层，放在套接字的接收缓冲区队列（sk_rcv_queue）。然后数据包从套接字层离开内核，送给应用层等待数据包的用户程序。用户程序向外发送的数据包缓存在套接字的传送缓冲区队列（sk_write_queue），从套接字层进入内核地址空间 如何确定哪个套接字是当前数据包的目标套接字 使用 struct inet_protosw 数据结构，管理和描述 struct proto_ops 和 struct proto 之间的对应关系 structproto_ops 就是系统调用套接字的操作函数块 struct proto 就是跟内核协议相关的套接字操作函数块 内核使用 struct inet_protosw 数据结构实现的协议交换表，将应用程序通过 socketcall 系统调用指定的套接字操作，转换成对某个协议实例实现的套接字操作函数的调用 struct inet_protosw 类型把 INET 套接字的协议族操作集与传输层协议操作集关联起来。该类型的 inetsw_array 数组变量实现了 INET 套接字的协议族操作集与具体的传输层协议关联。由 struct inet_protosw 数据结构类型数组 inetsw_array[]构成的向量表，称为协议交换表，协议交换表满足了套接字支持多协议栈功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// --------------------// struct socket数据结构// --------------------struct socket &#123; socket_state state; // 套接字的状态 unsigned long flags; // 套接字的设置标志。存放套接字等待缓冲区的状态信息 struct fasync_struct *fasync_list; // 等待被唤醒的套接字列表，该链表用于异步文 struct file *file; // 套接字所属的文件描述符 struct sock *sk; // 指向存放套接字属性的结构指针 wait_queue_head_t wait; //套接字的等待队列 short type; // 套接字的类型。其取值为SOCK_XXXX形式 const struct proto_ops *ops; // 套接字层的操作函数块&#125;// ------------------// struct sock数据结构// ------------------struct sock_common &#123; unsigned short skc_family; /*地址族*/ volatile unsigned char skc_state; /*连接状态*/ unsigned char skc_reuse; /*SO_REUSEADDR设置*/ int skc_bound_dev_if; struct hlist_node skc_node; struct hlist_node skc_bind_node; /*哈希表相关*/ atomic_t skc_refcnt; /*引用计数*/&#125;;// -----------// 套接字与文件// -----------struct inode&#123;struct file_operation *i_fop // 指向默认文件操作函数块&#125;struct socket_slloc &#123;struct socket socket;struct inode vfs_inode;&#125;// ------------// 套接字的初始化// ------------static int __init sock_init(void) &#123; int err; /* * 初始化.sock缓存 */ sk_init(); /* * 初始化sk_buff缓存 skb_init(); /* 初始化协议模块缓存 init_inodecache(); /* 注册文件系统类型 */ err = register_filesystem(&amp;sock_fs_type); if (err) goto out_fs; sock_mnt = kern_mount(&amp;sock_fs_type); if (IS_ERR(sock_mnt)) &#123; err = PTR_ERR(sock_mnt); goto out_mount; &#125;&#125;// ------------// inet_protosw// ------------struct inet_protosw &#123; struct list_head list; unsigned short type; /* AF_INET协议族套接字的类型,如TCP为SOCK_STREAM*/ unsigned short protocol; /* 协议族中某个协议实例的编号。如TCP协议的编码为IPPROTO_ struct proto *prot; const struct proto_ops *ops; unsigned char flags; /* 该套接字属性的相关标志 */&#125; 10.5 详解socket的接口实现 套接字接口 从 TCP/IP 协议栈的角度来看，传输层以上的都是应用程序的一部分，TCP/IP 协议栈驻留在内核中，与内核的其他组件共享内存。传输层以上执行的网络功能，都是在用户地址空间完成的 Linux 使用内核套接字概念与用户空间套接字通信，提供了一套 API 和套接字数据结构，这些服务向下与内核接口，向上与用户空间接口，应用程序正是使用这一套 API 访问内核中的网络功能 套接字的创建 必须调用套接字库函数API创建一个新的套接字,创建好之后对库函数创建套接字调用，会转换为内核套接字创建函数的系统调用,完成通用套接字创建的初始化功能 在应用程序中执行socket函数,产生系统调用中断执行内核的套接字分路函数sys_socketcall，在sys_socketcall套接字函数分路器中将调用传送到sys_socket函数，由sys_socket函数调用创建函数sock_create,该函数完成通用套接字创建,初始化任务后,再调用特定协议族的套接字创建函数 一个新的 struct socket 数据结构起始由 sock_create 函数创建，该函数直接调用__sock_create 函数，__sock_create 函数的任务是为套接字预留需要的内存空间，由sock_alloc 函数完成这项功能 sock_alloc 函数不仅会为 struct socket 数据结构实例预留空间，也会为 struct inode 数据结构实例分配需要的内存空间，可以使两个数据结构的实例相关联 套接字的绑定 完成套接字的创建后,应用程序需要调用 sys_bind 函数将套接字和地址绑定 sys_bind 函数首先会查找套接字对应的 socket 实例，调用sockfd_lookup_light。在绑定之前，将用户空间的地址拷贝到内核空间的缓冲区中，在拷贝过程中会检查用户传入的地址是否正确；上述的准备工作完成后，就会调用 inet_bind 函数来完成绑定操作 主动连接 应用程序是面向连接的网络服务,故需要在请求连接服务的进程与提供服务的进程之间建立连接 当应用程序调用connect函数发出连接请求时,内核会启动sys_connect 连接成功后返回socket描述符,否则返回错误码 监听套接字 调用listen函数,应用程序触发内核的sys_listen函数,将套接字描述符fd对应的套接字设置为监听模式,观察连接请求 被动连接 接受一个客户端的连接请求会调用 accept 函数，应用程序触发内核函数 sys_accept，等待接收连接请求 如果允许连接，则重新创建一个代表该连接的套接字，并返回其套接字描述符 发送数据 套接字应用中最简单的传送函数使send函数，允许应用程序指定标志,规定如何对待传送数据 调用send函数会触发内核的sys_send函数将发送缓冲区的数据发送出去 sys_send函数具体调用流程 应用程序的数据被复制到内核后，sys_send 函数调用 sock_sendmsg，依据协议族类型来执行发送操作 如果是 INET 协议族套接字，sock_sendmsg 将调用 inet_sendmsg 函数 如果采用 TCP 协议，inet_sendmsg 函数将调用 tcp_sendmsg，并按照 TCP 协议规则来发送数据包 接受数据 recv 函数中可以指定标志来控制如何接收数据，调用recv 函数时，应用程序会触发内核的 sys_recv 函数，把网络中的数据递交到应用程序 具体流程 sys_recv 函数依次调用sys_recvfrom、sock_recvfrom 和__sock_recvmsg，并依据协议族类型来执行具体的接收操作，将内核的网咯数据转入应用程序的接收缓冲区 如果是 INET 协议族套接字，__sock_recvmsg 将调用 sock_common_recvmsg 函数 如果采用 TCP 协议，sock_common_recvmsg 函数将调用 tcp_recvmsg，按照 TCP协议规则来接收数据包 如果接收方想获取数据包发送端的标识符，应用程序可以调用 sys_recvfrom 函数来获取数据包发送方的源地址 关闭连接 应用程序调用shutdown函数关闭连接内核会启动函数sys_shutdown 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313// -----------// 套接字的创建// -----------static int __sock_create(struct net *net, int family, int type, int protocol,struct socket **res, int kern)&#123;int err;struct socket *sock;const struct net_proto_family *pf;// 首先检验是否支持协议族/** 检查是否在内核支持的socket范围内*/if (family &lt; 0 || family &gt;= NPROTO)return -EAFNOSUPPORT;if (type &lt; 0 || type &gt;= SOCK_MAX)return -EINVAL;/** 为新的套接字分配内存空间，分配成功后返回新的指针*/sock = sock_alloc();&#125;static struct socket *sock_alloc(void) &#123;struct inode *inode;struct socket *sock;// 初始化一个可用的inode节点， 在fs/inode.c中inode = new_inode(sock_mnt-&gt;mnt_sb);if (!inode)return NULL;// 实际创建的是socket_alloc复合对象，因此要使用SOCKET_I宏从inode中取出关联的socketsock = SOCKET_I(inode);kmemcheck_annotate_bitfield(sock, type);// 文件类型为套接字inode-&gt;i_mode = S_IFSOCK | S_IRWXUGO;inode-&gt;i_uid = current_fsuid();inode-&gt;i_gid = current_fsgid();percpu_add(sockets_in_use, 1);return sock;&#125;// 函数将 struct socket 数据结构的 struct proto_ops *ops 设置为 NULL// 随后，当某个协议族中的协议成员的套接字创建函数被调用时，ops 将指向协议实例的操作函数// 这时将 struct socket 数据结构的 flags 数据域设置为 0，创建时还没有任何标志需要设置// 在之后的调用中，应用程序调用 send 或 receive 套接字库函数时会设置 flags 数据域。最后将其他两个数据域 sk 和 file 初始化为 NULL。sk 数据域随后会把由协议特有的套接字创建函数设置为指向内部套接字结构。file 将在调用 sock_ma_fd 函数时设置为分配的文件返回的指针// 文件指针用于访问打开套接字的虚拟文件系统的文件状态。在 sock_alloc 函数返回后，sock_create 函数调用协议族的套接字创建函数 err =pf-&gt;create(net, sock, protocol)，它通过访问 net_families 数组获取协议族的创建函数，对于 TCP/IP 协议栈，协议族将设置为 AF_INET// -----------// 套接字的绑定// -----------asmlinkage long sysbind (bind, int, fd, struct sockaddr __user *, umyaddr, int&#123;struct socket *sock;struct sockaddr_storage address;int err, fput_needed;// 获取socket实例sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);if (sock) &#123;err = move_addr_to_kernel(umyaddr, addrlen, (struct sockaddr *)&amp;address);if (err &gt;= 0) &#123;err = security_socket_bind(sock,(struct sockaddr *)&amp;address,addrlen);/** 如果是TCP套接字，sock-&gt;ops指向的是inet_stream_ops，* sock-&gt;ops是在inet_create()函数中初始化，所以bind接口* 调用的是inet_bind()函数。*/if (!err)err = sock-&gt;ops-&gt;bind(sock,(struct sockaddr *)&amp;address, addrlen);&#125;fput_light(sock-&gt;file, fput_needed);&#125;return err;&#125;int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)&#123;struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;struct sock *sk = sock-&gt;sk;struct inet_sock *inet = inet_sk(sk);unsigned short snum;int chk_addr_ret;int err;if (sk-&gt;sk_prot-&gt;bind) &#123;/* 如果传输层接口上实现了bind调用，则回调它。目前只有SOCK_err = sk-&gt;sk_prot-&gt;bind(sk, uaddr, addr_len);goto out;&#125;err = -EINVAL;if (addr_len &lt; sizeof(struct sockaddr_in))goto out;err = -EADDRNOTAVAIL;if (!sysctl_ip_nonlocal_bind &amp;&amp;/* 必须绑定到本地接口的地址 */!inet-&gt;freebind &amp;&amp;addr-&gt;sin_addr.s_addr != INADDR_ANY &amp;&amp;/* 绑定地址不合法 */chk_addr_ret != RTN_LOCAL &amp;&amp;chk_addr_ret != RTN_MULTICAST &amp;&amp;chk_addr_ret != RTN_BROADCAST)goto out;snum = ntohs(addr-&gt;sin_port);err = -EACCES;if (snum &amp;&amp; snum &lt; PROT_SOCK &amp;&amp; !capable(CAP_NET_BIND_SERVICE))goto out;lock_sock(sk);/* 对套接口进行加锁，因为后面要对其状态进行判断 *//* Check these errors (active socket, double bind). */err = -EINVAL;/*** 如果状态不为CLOSE，表示套接口已经处于活动状态，不能再绑定* 或者已经指定了本地端口号，也不能再绑定*/if (sk-&gt;sk_state != TCP_CLOSE || inet-&gt;num)goto out_release_sock;/* 设置地址到传输控制块中 */inet-&gt;rcv_saddr = inet-&gt;saddr = addr-&gt;sin_addr.s_addr;/* 如果是广播或者多播地址，则源地址使用设备地址。 */if (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)inet-&gt;saddr = 0; /* Use device *//* 调用传输层的get_port来进行地址绑定。如tcp_v4_get_port或udp_v4_get_port */if (sk-&gt;sk_prot-&gt;get_port(sk, snum)) &#123;…&#125;/* 设置标志，表示已经绑定了本地地址和端口 */if (inet-&gt;rcv_saddr)sk-&gt;sk_userlocks |= SOCK_BINDADDR_LOCK;if (snum)sk-&gt;sk_userlocks |= SOCK_BINDPORT_LOCK;inet-&gt;sport = htons(inet-&gt;num);/* 还没有连接到对方，清除远端地址和端口 */inet-&gt;daddr = 0;inet-&gt;dport = 0;/* 清除路由缓存 */sk_dst_reset(sk);err = 0;out_release_sock:release_sock(sk);out:return err;&#125;// -------// 主动连接// -------int __sys_connect(int fd, struct sockaddr __user *uservaddr, int addrlen)&#123;int ret = -EBADF;struct fd f;f = fdget(fd);if (f.file) &#123;struct sockaddr_storage address;ret = move_addr_to_kernel(uservaddr, addrlen, &amp;address);if (!ret)// 调用__sys_connect_fileret = __sys_connect_file(f.file, &amp;address, addrlen, 0);fdput(f);&#125;return ret;&#125;// ---------// 监听套接字// ---------int __sys_listen(int fd, int backlog)&#123;struct socket *sock;int err, fput_needed;int somaxconn;// 通过套接字描述符找到struct socketsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);if (sock) &#123;somaxconn = sock_net(sock-&gt;sk)-&gt;core.sysctl_somaxconn;if ((unsigned int)backlog &gt; somaxconn)backlog = somaxconn;err = security_socket_listen(sock, backlog);if (!err)// 根据套接字类型调用监听函数err = sock-&gt;ops-&gt;listen(sock, backlog);fput_light(sock-&gt;file, fput_needed);&#125;return err;&#125;// -----------// 被动接收连接// -----------int __sys_accept4_file(struct file *file, unsigned file_flags,struct sockaddr __user *upeer_sockaddr,int __user *upeer_addrlen, int flags,unsigned long nofile)&#123;struct socket *sock, *newsock;struct file *newfile;int err, len, newfd;struct sockaddr_storage address;if (flags &amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK))return -EINVAL;if (SOCK_NONBLOCK != O_NONBLOCK &amp;&amp; (flags &amp; SOCK_NONBLOCK))flags = (flags &amp; ~SOCK_NONBLOCK) | O_NONBLOCK;sock = sock_from_file(file, &amp;err);if (!sock)goto out;err = -ENFILE;// 创建一个新套接字newsock = sock_alloc();if (!newsock)goto out;newsock-&gt;type = sock-&gt;type;newsock-&gt;ops = sock-&gt;ops;__module_get(newsock-&gt;ops-&gt;owner);newfd = __get_unused_fd_flags(flags, nofile);if (unlikely(newfd &lt; 0)) &#123;err = newfd;sock_release(newsock);goto out;&#125;newfile = sock_alloc_file(newsock, flags, sock-&gt;sk-&gt;sk_prot_creator-&gt;name);if (IS_ERR(newfile)) &#123;err = PTR_ERR(newfile);put_unused_fd(newfd);goto out;&#125;err = security_socket_accept(sock, newsock);if (err)goto out_fd;// 根据套接字类型调用不同的函数inet_accepterr = sock-&gt;ops-&gt;accept(sock, newsock, sock-&gt;file-&gt;f_flags | file_flags,false);if (err &lt; 0)goto out_fd;if (upeer_sockaddr) &#123;len = newsock-&gt;ops-&gt;getname(newsock,(struct sockaddr *)&amp;address, 2);if (len &lt; 0) &#123;err = -ECONNABORTED;goto out_fd;&#125;// 从内核复制到用户空间err = move_addr_to_user(&amp;address,len, upeer_sockaddr, upeer_addrlen);if (err &lt; 0)goto out_fd;&#125;/* File flags are not inherited via accept() unlike another OSes. */fd_install(newfd, newfile);err = newfd;out:return err;out_fd:fput(newfile);put_unused_fd(newfd);goto out;&#125;// -------// 接收数据// -------int __sys_recvfrom(int fd, void __user *ubuf, size_t size, unsigned int flags,struct sockaddr __user *addr, int __user *addr_len)&#123;struct socket *sock;struct iovec iov;struct msghdr msg;struct sockaddr_storage address;int err, err2;int fput_needed;err = import_single_range(READ, ubuf, size, &amp;iov, &amp;msg.msg_iter);if (unlikely(err))return err;// 通过套接字描述符找到struct socketsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);if (!sock)goto out;msg.msg_control = NULL;msg.msg_controllen = 0;/* Save some cycles and don&#x27;t copy the address if not needed */msg.msg_name = addr ? (struct sockaddr *)&amp;address : NULL;/* We assume all kernel code knows the size of sockaddr_storage */msg.msg_namelen = 0;msg.msg_iocb = NULL;msg.msg_flags = 0;if (sock-&gt;file-&gt;f_flags &amp; O_NONBLOCK)flags |= MSG_DONTWAIT;// sock_recvmsg为具体的接收函数err = sock_recvmsg(sock, &amp;msg, flags);if (err &gt;= 0 &amp;&amp; addr != NULL) &#123;// 从内核复制到用户空间err2 = move_addr_to_user(&amp;address,msg.msg_namelen, addr, addr_len);if (err2 &lt; 0)err = err2;&#125;fput_light(sock-&gt;file, fput_needed);out:return err;&#125;// --------// 关闭连接// --------int __sys_shutdown(int fd, int how)&#123;int err, fput_needed;struct socket *sock;sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);/* 通过套接字，描述符找到对应的if (sock != NULL) &#123;err = security_socket_shutdown(sock, how);if (!err)/* 根据套接字协议族调用关闭函数*/err = sock-&gt;ops-&gt;shutdown(sock, how);fput_light(sock-&gt;file, fput_needed);&#125;return err;&#125; 创建套接字应用程序一般要经过 6 个步骤 创建套接字。 将套接字与地址绑定，设置套接字选项。 建立套接字之间的连接。 监听套接字 接收、发送数据。 关闭、释放套接字 11 接口 11.1 如何搭建沟通桥梁 服务接口的结构 cosmos的API数量很多,分为进程类,内存类,文件类和时间类的API,API被上层C库封装方便应用程序调用 应用程序库分为时间库,进程库,内存库,文件库几类 如何进入内核 应用程序和库函数在用户空间中,而系统服务在内核空间中,让代码控制流从用户空间进入内核空间需要穿过CPU保护模式 软中断指令 CPU长模式下处理中断 设备向CPU发送一个中断信号,CPU接受电子信号后在允许响应中断的情况下,会中断当前运行的程序切换到相应的CPU R0特权级,并跳转到中断门描述符中相应的地址运行中断处理代码(操作系统内核的代码,CPU的控制权转移到操作系统内核上) 应用程序也可以向CPU发送中断,软中断指令模拟中断的电子信号 在x86CPU上为int指令(如int255,常数表示CPU从中断表描述符表中取得第几个中断描述符进入内核) 传递参数 应用程序运行在用户空间时,用的是用户栈,切换到内核空间时用的是内核栈，故参数的传递需要硬性规定，要么所有的参数用寄存器传递，要么所有的参数都保存在用户栈中 用寄存器传递所有参数简单(操作系统常用) 使用 RBX、RCX、RDX、RDI、RSI 这 5 个寄存器来传递参数，事实上一个系统服务接口函数不会超过 5 个参数 RAX 寄存器中保存着一个整数，称为系统服务号。在系统服务分发器中，会根据这个系统服务号调用相应的函数 系统服务分发器 只是用一个中断描述符,然后通过系统服务号来区分各个服务，这就是系统服务器分发器完成的工作 实现系统服务分发器 系统服务分发器是一个函数，由中断处理代码调用,在内部根据系统服务号来调用相应的服务 系统服务分发器函数:先对服务号进行判断,若大于系统中最大的服务号,就返回一个错误状态表示服务失败,然后判断是否有服务接口函数，最后两个检查通过后,可以调用相应的服务接口 有中断处理的框架函数 hal_syscl_allocator 函数调用 krlservice 系统服务表 系统服务表用来存放各种系统服务的入口函数，在 krlservice函数中根据服务号,调用相应系统服务表中相应的服务入口函数 使用函数指针数组实现系统服务表 执行int指令后CPU会进入中断处理流程，中断处理流程的第一步将CPU的一寄存器压入内核栈,系统传递参数通过寄存器传递,故需要定义一个 stkparame_t 结构用来提取内核栈中的参数 接着查看 hal_syscl_allocator函数的第二个参数为传递的RSP寄存器的值,将该值转化为 stkparame_t 结构的地址,就能提取内核栈中的参数 但是目前 osservicetab 数组中为空，是因为没有实现相应服务接口函数 时间库:实现时间的库函数 时间API接口 在库中需要调用时间API接口,因为库和API接口函数不同层次的,应用程序直接调用API接口函数 建立 cosmos/lib/lapitime.c文件,实现 api_time函数 内核态时间服务接口 执行int指令后进入内核模式下开始执行内核代码 系统服务分发器会根据服务号从系统服务表中取出相应的函数并调用 系统服务函数的执行过程 应用程序在用户空间中运行，调用库函数，库函数调用 API 函数执行 INT 指令，进入中断门，从而运行内核代码。最后内核代码一步步执行了相关服务功能，返回到用户空间继续运行应用程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219// -------// 传递参数// -------// 建立 cosmos/include/libinc/lapinrentry.h文件//传递一个参数所用的宏#define API_ENTRY_PARE1(intnr,rets,pval1) \\__asm__ __volatile__(\\&quot;movq %[inr],%%rax\\n\\t&quot;\\//系统服务号&quot;movq %[prv1],%%rbx\\n\\t&quot;\\//第一个参数&quot;int $255 \\n\\t&quot;\\//触发中断&quot;movq %%rax,%[retval] \\n\\t&quot;\\//处理返回结果:[retval] &quot;=r&quot; (rets)\\:[inr] &quot;r&quot; (intnr),[prv1]&quot;r&quot; (pval1)\\:&quot;rax&quot;,&quot;rbx&quot;,&quot;cc&quot;,&quot;memory&quot;\\)//传递四个参数所用的宏#define API_ENTRY_PARE4(intnr,rets,pval1,pval2,pval3,pval4) \\__asm__ __volatile__(\\&quot;movq %[inr],%%rax \\n\\t&quot;\\//系统服务号&quot;movq %[prv1],%%rbx \\n\\t&quot;\\//第一个参数&quot;movq %[prv2],%%rcx \\n\\t&quot;\\//第二个参数&quot;movq %[prv3],%%rdx \\n\\t&quot;\\//第三个参数&quot;movq %[prv4],%%rsi \\n\\t&quot;\\//第四个参数&quot;int $255 \\n\\t&quot;\\//触发中断&quot;movq %%rax,%[retval] \\n\\t&quot;\\//处理返回结果:[retval] &quot;=r&quot; (rets)\\:[inr] &quot;r&quot; (intnr),[prv1]&quot;g&quot; (pval1),\\[prv2] &quot;g&quot; (pval2),[prv3]&quot;g&quot; (pval3),\\[prv4] &quot;g&quot; (pval4)\\:&quot;rax&quot;,&quot;rbx&quot;,&quot;rcx&quot;,&quot;rdx&quot;,&quot;rsi&quot;,&quot;cc&quot;,&quot;memory&quot;\\)// 上述两个主要功能是用来解决传递参数和触发中断问题，并且还需要处理系统返回的结果// 系统服务接口//请求分配内存服务// 可以被库函数调用，也可以由应用程序直接调用，它用 API_ENTRY_PARE1 宏传递参数和触发中断进入 Cosmos 内核，最终将由内存管理模块相应分配内存服务的请求void* api_mallocblk(size_t blksz)&#123;void* retadr;//把系统服务号，返回变量和请求分配的内存大小API_ENTRY_PARE1(INR_MM_ALLOC,retadr,blksz);return retadr;&#125;// ----------------// 实现系统服务分发器// ----------------// 在 cosmos/kernel/krlservice.c 文件中实现系统服务分发器sysstus_t krlservice(uint_t inr, void* sframe)&#123;if(INR_MAX &lt;= inr)//判断服务号是否大于最大服务号&#123;return SYSSTUSERR;&#125;if(NULL == osservicetab[inr])//判断是否有服务接口函数&#123;return SYSSTUSERR;&#125;return osservicetab[inr](inr, (stkparame_t*)sframe);//调用对应的服务接口函数&#125;sysstus_t hal_syscl_allocator(uint_t inr,void* krnlsframp)&#123;return krlservice(inr,krnlsframp);&#125;// hal_syscl_allocator 函数则是由系统中断处理的第一层汇编代码调用的，这个汇编代码主要是将进程的用户态 CPU 寄存器保存在内核栈中//cosmos/include/halinc/kernel.inc%macro EXI_SCALL 0push rbx//保存通用寄存器到内核栈push rcxpush rdxpush rbppush rsipush rdi//删除了一些代码mov rdi, rax //处理hal_syscl_allocator函数第一个参数inrmov rsi, rsp //处理hal_syscl_allocator函数第二个参数krnlsframpcall hal_syscl_allocator //调用hal_syscl_allocator函数//删除了一些代码pop rdipop rsipop rbppop rdxpop rcxpop rbx//从内核栈中恢复通用寄存器iretq //中断返回%endmacro//cosmos/hal/x86/kernel.asmexi_sys_call:EXI_SCALL// exi_sys_call 标号的地址保存在第 255 个中断门描述符中// 这样执行了 int$255 之后，CPU 就会自动跳转到 exi_sys_call 标号处运行，从而进入内核开始运行，最终调用 krlservice 函数，开始执行系统服务// ---------// 系统服务表// ---------// 放在cosmos/kernel/krlglobal.c 中typedef struct s_STKPARAME&#123;u64_t gs;u64_t fs;u64_t es;u64_t ds;u64_t r15;u64_t r14;u64_t r13;u64_t r12;u64_t r11;u64_t r10;u64_t r9;u64_t r8;u64_t parmv5;//rdi;u64_t parmv4;//rsi;u64_t rbp;u64_t parmv3;//rdx;u64_t parmv2;//rcx;u64_t parmv1;//rbx;u64_t rvsrip;u64_t rvscs;u64_t rvsrflags;u64_t rvsrsp;u64_t rvsss;&#125;stkparame_t;//服务函数类型typedef sysstus_t (*syscall_t)(uint_t inr,stkparame_t* stkparm);//cosmos/kernel/krlglobal.cKRL_DEFGLOB_VARIABLE(syscall_t,osservicetab)[INR_MAX]=&#123;&#125;;// -----// 时间库// -----// 实现时间的库函数// 在cosmos/lib/libtime.c文件//时间库函数sysstus_t time(times_t *ttime)&#123; sysstus_t rets = api_time(ttime);//调用时间API return rets;&#125;// time库函数非常简单，对系统API封装,应用程序需要传递一个times_t结构的地址,是这个系统API要求，该结构是由系统定义typedef struct s_TIME&#123;uint_t year;uint_t mon;uint_t day;uint_t date;uint_t hour;uint_t min;uint_t sec;&#125;times t;// ----------// 时间API接口// ----------// cosmos/lib/lapitime.csysstus_t api_time(buf_t ttime)&#123;sysstus_t rets;API_ENTRY_PARE1(INR_TIME,rets,ttime);//处理参数，执行int指令return rets;&#125;// INR_TIME 是系统服务号，它经过 API_ENTRY_PARE1 宏处理，把 INR_TIME 和 ttime、rets 关联到相应的寄存器，如果不明白可以参考前面的参数传递中使用寄存器的情况。最后就是执行 int 指令进入内核，开始运行时间服务代码// ----------------// 内核态时间服务接口// ----------------// 响应的是时间服务,取用时间服务的接口函数// 建立 cosmos/kernel/keltime.c文件,写时间服务的接口函数sysstus_t krlsvetabl_time(uint_t inr, stkparame_t *stkparv)&#123; if (inr != INR_TIME)//判断是否时间服务号 &#123; return SYSSTUSERR; &#125; //调用真正时间服务函数 return krlsve_time((time_t *)stkparv-&gt;parmv1);&#125;// krlsvetabl_time 函数一定要放在系统服务表中才可以，系统服务表其实是个函数指针数组// 将 kelsvetabl_time函数放入 osservicetab数组KRL_DEFGLOB_VARIABLE(syscall_t, osservicetab)[INR_MAX] = &#123;NULL, krlsvetabl_mallocblk,//内存分配服务接口krlsvetabl_mfreeblk, //内存释放服务接口krlsvetabl_exel_thread,//进程服务接口krlsvetabl_exit_thread,//进程退出服务接口krlsvetabl_retn_threadhand,//获取进程id服务接口krlsvetabl_retn_threadstats,//获取进程状态服务接口krlsvetabl_set_threadstats,//设置进程状态服务接口krlsvetabl_open, krlsvetabl_close,//文件打开、关闭服务接口krlsvetabl_read, krlsvetabl_write,//文件读、写服务接口krlsvetabl_ioctrl, krlsvetabl_lseek,//文件随机读写和控制服务接口krlsvetabl_time&#125;;//获取时间服务接口// 获取时间服务接口占最后一个，第 0 个要保留,这样就能调用到 krlsvetabl_time 函数// -----------// 实现时间服务// -----------// cosmos/kernel/krltime.c文件中实现sysstus_t krlsve_time(time_t *time)&#123;if (time == NULL)//对参数进行判断&#123;return SYSSTUSERR;&#125;ktime_t *initp = &amp;osktime;//操作系统保存时间的结构cpuflg_t cpufg;krlspinlock_cli(&amp;initp-&gt;kt_lock, &amp;cpufg);//加锁time-&gt;year = initp-&gt;kt_year;time-&gt;mon = initp-&gt;kt_mon;time-&gt;day = initp-&gt;kt_day;time-&gt;date = initp-&gt;kt_date;time-&gt;hour = initp-&gt;kt_hour;time-&gt;min = initp-&gt;kt_min;time-&gt;sec = initp-&gt;kt_sec;//把时间数据写入到参数指向的内存krlspinunlock_sti(&amp;initp-&gt;kt_lock, &amp;cpufg);//解锁return SYSSTUSOK;//返回正确的状态&#125;// krlsve_time 函数，只是把系统的时间数据读取出来，写入用户应用程序传入缓冲区中，由于 osktime 这个结构实例会由其它代码自动更新，所以要加锁访问 11.2 如何实现系统API Linux内核API接口的架构 在Linux内核之上使用最广泛的C库是glibc，其中包括C标准库的实现,也包括所有和系统API对应的库接口函数 glibc是Linux内核上C程序运行的基础 Linux内核有多少API接口 对Linux代码进行编译，在编译的过程中根据 syscall_32.tbl 和 syscall_64.tbl 生成自己的 syscalls_32.h 和 syscall_64.h 文件 生成方式在 arch/x86/entry/syscalls/Makefile文件中,使用两个脚本 syscallhdr.sh，syscalltbl.sh，最终生成的 syscalls_32.h 和 syscalls_64.h 两个文件中就保存了系统调用号和系统调用实现函数之间的对应关系,可以看到Linux内核的系统调用号(API号) Linux系统调用表 Linux内核有400多个系统调用，使用了一个函数指针数组,存放所有的系统调用函数的地址,通过数组下表就能索引到相应的系统调用 该数组为 sys_call_table，即Linux系统调用表 __SYSCALL_COMMON 首先会替换成 __SYSCALL_64，因为编译的 Linux 内核是 x86_64 架构的 sys_call_table 数组，第一次全部初始化为默认系统调用函数 sys_ni_syscall，该函数无实际工作是为了防止数组有些元素中没有函数地址，从而导致调用失败 下载 Linux 源码 可从github上获得 git clone git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git/ 申明系统调用 Linux内核的系统调用的申明文件和信息的具体实现:由一个 makefile 在编译 Linux 系统内核时调用了一个脚本，脚本会读取另一个叫 syscall_64.tbl 文件，根据其中信息生成相应的文件 syscall_64.h 定义系统调用 定义一个系统调用函数需要使用专门的宏 对于无参数的系统调用函数,应使用SYSCALL_DEFINE0宏来定义 编译Linux内核 源代码目录下执行make menuconfig指令 可以选择加载一个已经存在的配置文件，这个配置文件可以加载你机器上 boot 目录下的 config 开头的文件，加载之后选择 Save，就能保存配置 然后输入 make -j8 bzImage &amp;&amp; make -j8 modules 就可自行完成编译(j8表示开启8线程并行编译) 使用 sudo make modules_install &amp;&amp; sudo make install 安装内核模块,然后再安装内核,最后调用 update-grub，自动生成启动选项,重启计算机即可选择修改的Linux内核 编写应用测试 使用 gcc main.c -o cpus 指令进行编译，运行之后就可以看到结果了，但是没有写库代码，而是直接使用 syscall 函数 这个函数可以根据系统调用号触发系统调用，根据上面定义，441 正是对应咱们的 sys_get_cpus 系统调用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204// 以open库函数为例//glibc/intl/loadmsgcat.c#ifdef _LIBC# define open(name, flags) __open_nocancel (name, flags)# define close(fd) __close_nocancel_nostatus (fd)#endif//glibc/sysdeps/unix/sysv/linux/open_nocancel.cint __open_nocancel (const char *file, int oflag, ...)&#123;int mode = 0;if (__OPEN_NEEDS_MODE (oflag))&#123;va_list arg;va_start (arg, oflag);//解决可变参数mode = va_arg (arg, int);va_end (arg);&#125;return INLINE_SYSCALL_CALL (openat, AT_FDCWD, file, oflag, mode);&#125;//glibc/sysdeps/unix/sysdep.h//这是为了解决不同参数数量的问题#define __INLINE_SYSCALL0(name) \\INLINE_SYSCALL (name, 0)#define __INLINE_SYSCALL1(name, a1) \\INLINE_SYSCALL (name, 1, a1)#define __INLINE_SYSCALL2(name, a1, a2) \\INLINE_SYSCALL (name, 2, a1, a2)#define __INLINE_SYSCALL3(name, a1, a2, a3) \\INLINE_SYSCALL (name, 3, a1, a2, a3)#define __INLINE_SYSCALL_NARGS_X(a,b,c,d,e,f,g,h,n,...) n#define __INLINE_SYSCALL_NARGS(...) \\__INLINE_SYSCALL_NARGS_X (__VA_ARGS__,7,6,5,4,3,2,1,0,)#define __INLINE_SYSCALL_DISP(b,...) \\__SYSCALL_CONCAT (b,__INLINE_SYSCALL_NARGS(__VA_ARGS__))(__VA_ARGS__)#define INLINE_SYSCALL_CALL(...) \\__INLINE_SYSCALL_DISP (__INLINE_SYSCALL, __VA_ARGS__)//glibc/sysdeps/unix/sysv/linux/sysdep.h//关键是这个宏#define INLINE_SYSCALL(name, nr, args...) \\(&#123; \\long int sc_ret = INTERNAL_SYSCALL (name, nr, args); \\__glibc_unlikely (INTERNAL_SYSCALL_ERROR_P (sc_ret)) \\? SYSCALL_ERROR_LABEL (INTERNAL_SYSCALL_ERRNO (sc_ret)) \\: sc_ret; \\&#125;)#define INTERNAL_SYSCALL(name, nr, args...) \\internal_syscall##nr (SYS_ify (name), args)#define INTERNAL_SYSCALL_NCS(number, nr, args...) \\internal_syscall##nr (number, args)//这是需要6个参数的宏#define internal_syscall6(number, arg1, arg2, arg3, arg4, arg5, arg6) \\(&#123; \\unsigned long int resultvar; \\TYPEFY (arg6, __arg6) = ARGIFY (arg6); \\TYPEFY (arg5, __arg5) = ARGIFY (arg5); \\TYPEFY (arg4, __arg4) = ARGIFY (arg4); \\TYPEFY (arg3, __arg3) = ARGIFY (arg3); \\TYPEFY (arg2, __arg2) = ARGIFY (arg2); \\TYPEFY (arg1, __arg1) = ARGIFY (arg1); \\register TYPEFY (arg6, _a6) asm (&quot;r9&quot;) = __arg6; \\register TYPEFY (arg5, _a5) asm (&quot;r8&quot;) = __arg5; \\register TYPEFY (arg4, _a4) asm (&quot;r10&quot;) = __arg4; \\register TYPEFY (arg3, _a3) asm (&quot;rdx&quot;) = __arg3; \\register TYPEFY (arg2, _a2) asm (&quot;rsi&quot;) = __arg2; \\register TYPEFY (arg1, _a1) asm (&quot;rdi&quot;) = __arg1; \\asm volatile ( \\&quot;syscall\\n\\t&quot; \\: &quot;=a&quot; (resultvar) \\: &quot;0&quot; (number), &quot;r&quot; (_a1), &quot;r&quot; (_a2), &quot;r&quot; (_a3), &quot;r&quot; (_a4), \\&quot;r&quot; (_a5), &quot;r&quot; (_a6) \\: &quot;memory&quot;, REGISTERS_CLOBBERED_BY_SYSCALL); \\(long int) resultvar; \\&#125;)// open 只是宏，实际工作的是 __open_nocancel 函数，其中会用 INLINE_SYSCALL_CALL 宏经过一系列替换，最终根据参数的个数替换成相应的 internal_syscall##nr 宏// 其中 number 是系统调用号，参数通过寄存器传递的。但是这里没有发现 int 指令，这是因为这里用到的指令是最新处理器为其设计的系统调用指令 syscall。这个指令和 int 指令一样，都可以让 CPU 跳转到特定的地址上，只不过不经过中断门，系统调用返回时要用 sysexit 指令// ---------------------// Linux内核有多少API接口// ---------------------//linux/arch/x86/include/generated/asm/syscalls_64.h__SYSCALL_COMMON(0, sys_read)__SYSCALL_COMMON(1, sys_write)__SYSCALL_COMMON(2, sys_open)__SYSCALL_COMMON(3, sys_close)__SYSCALL_COMMON(4, sys_newstat)__SYSCALL_COMMON(5, sys_newfstat)__SYSCALL_COMMON(6, sys_newlstat)__SYSCALL_COMMON(7, sys_poll)__SYSCALL_COMMON(8, sys_lseek)//……__SYSCALL_COMMON(435, sys_clone3)__SYSCALL_COMMON(436, sys_close_range)__SYSCALL_COMMON(437, sys_openat2)__SYSCALL_COMMON(438, sys_pidfd_getfd)__SYSCALL_COMMON(439, sys_faccessat2)__SYSCALL_COMMON(440, sys_process_madvise)//linux/arch/x86/include/generated/uapi/asm/unistd_64.h#define __NR_read 0#define __NR_write 1#define __NR_open 2#define __NR_close 3#define __NR_stat 4#define __NR_fstat 5#define __NR_lstat 6#define __NR_poll 7#define __NR_lseek 8//……#define __NR_clone3 435#define __NR_close_range 436#define __NR_openat2 437#define __NR_pidfd_getfd 438#define __NR_faccessat2 439#define __NR_process_madvise 440#ifdef __KERNEL__#define __NR_syscall_max 440#endif// 定义了 __NR_syscall_max 为 440，这说明 Linux 内核一共有 441 个系统调用，而系统调用号从 0 开始到 440 结束，所以最后一个系统调用是sys_process_madvise// __SYSCALL_COMMON 除了表示系统调用号和系统调用函数之间的关系，还会在Linux 内核的系统调用表中进行相应的展开,Linux内核的系统调用表// --------------// Linux系统调用表// --------------#define __SYSCALL_COMMON(nr, sym) __SYSCALL_64(nr, sym)//第一次定义__SYSCALL_64#define __SYSCALL_64(nr, sym) extern asmlinkage long sym(unsigned long, unsign#include &lt;asm/syscalls_64.h&gt;//第一次包含syscalls_64.h文件，其中的宏会被展开一次，例如extern asmlinkage long sys_open(unsigned long, unsigned long, unsigned long, u这表示申明//取消__SYSCALL_64定义#undef __SYSCALL_64//第二次重新定义__SYSCALL_64#define __SYSCALL_64(nr, sym) [ nr ] = sym,extern asmlinkage long sys_ni_syscall(unsigned long, unsigned long, unsigned lconst sys_call_ptr_t sys_call_table[] ____cacheline_aligned = &#123;[0 ... __NR_syscall_max] = &amp;sys_ni_syscall,//默认系统调用函数，什么都不干#include &lt;asm/syscalls_64.h&gt;//包含前面生成文件//第二次包含syscalls_64.h文件，其中的宏会被再展开一次，例如__SYSCALL_COMMON(2, sys_ope[2] = sys_open, 用于初始化这个数组，即表示数组的第二个元素填入sys_open&#125;;int syscall_table_size = sizeof(sys_call_table);//系统调用表的大小// -----------// 申明系统调用// -----------//linux-5.10.13/arch/x86/entry/syscalls/syscall_64.tbl0 common read sys_read1 common write sys_write2 common open sys_open3 common close sys_close4 common stat sys_newstat5 common fstat sys_newfstat6 common lstat sys_newlstat7 common poll sys_poll8 common lseek sys_lseek9 common mmap sys_mmap10 common mprotect sys_mprotect11 common munmap sys_munmap12 common brk sys_brk//……435 common clone3 sys_clone3436 common close_range sys_close_range437 common openat2 sys_openat2438 common pidfd_getfd sys_pidfd_getfd439 common faccessat2 sys_faccessat2440 common process_madvise sys_process_madvise// 上述代码分为四列:系统调用号、架构、服务名，以及其相对应的服务入口函数// 申明自己的系统调用// 第一步在syscall_64.tbl文件中增加一项 441 common get_cpus sys_get_cpus// 还需要把 sys-get_cpus函数在syscall.h文件中声明//linux-5.10.13/include/linux/syscalls.hasmlinkage long sys_get_cpus(void)// -----------// 定义系统调用// -----------//linux-5.10.13/include/linux/syscalls.h#ifndef SYSCALL_DEFINE0#define SYSCALL_DEFINE0(sname) \\SYSCALL_METADATA(_##sname, 0); \\asmlinkage long sys_##sname(void); \\ALLOW_ERROR_INJECTION(sys_##sname, ERRNO); \\asmlinkage long sys_##sname(void)#endif /* SYSCALL_DEFINE0 *///linux-5.10.13/kernel/sys.cSYSCALL_DEFINE0(get_cpus)&#123;return num_present_cpus();//获取系统中有多少CPU&#125;// SYSCALL_DEFINE0 会将 get_cpus 转换成 sys_get_cpus 函数，调用了一个 Linux 内核中另一个函数 num_present_cpus，负责返回系统 CPU 的数量// -----------// 编写应用测试// -----------#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/syscall.h&gt;int main(int argc, char const *argv[])&#123;//syscall就是根据系统调用号调用相应的系统调用long cpus = syscall(441);printf(&quot;cpu num is:%d\\n&quot;, cpus);//输出结果return 0;&#125; 12 虚化的世界 12.1 KVM是什么 理解虚拟化的定义 虚拟化的本质是一种资源管理技术,可通过各种技术手段把计算机的实体资源进行转换和抽象,让资源可以重新分割,排列与组合，实现最大化使用物理资源的目的 虚拟化的核心思想 可以抽象出一个新的层次来解决资源复用的问题 引入Hypervisor/Virtual Machine Monitor层,向下统一管理和调度真实的物理资源,让每个虚拟机都以为自己独享独立的资源 KVM架构梳理 计算机最重要的资源为:CPU,RAM,ROM,以及连接各种设备抽象出的IO资源 Intel设计了VT-x指令集,VT-d指令集,VT-c指令集等技术实现硬件虚拟化 首先客户机看到的硬件资源基本都是有 Hypervisor模拟出来的,客户机对模拟设备进行操作时,命令会被截获并转发给实际设备/内核模块进行处理 通过该架构设计Hypervisor层,最终实现了把一个客户机映射到宿主机OS系统的一个进程,而一个客户机的vCPU映射到这个进程下的独立的线程中,同理IO也映射到同一个线程组内的独立线程中 CPU虚拟化原理 Intel定义了VMX处理器特性,即VT-x指令集,开启该特性后存在两种操作模式,根操作和非根操作 Hypervisor/VMM就是运行在根操作模式下,对处理器和平台硬件具有完全的控制权限 客户软件包括虚拟机在内的操作系统和应用程序,则运行在非根操作模式下;当客户软件执行特殊的敏感指令或异常指令,会触发VM-Exit指令切换会根操作模式，从而让 Hypervisor/VMM完全接管控制权限 两种模式间进行切换需要通过 VM-Entry和VM-Exit实现进入和退出 内存虚拟化原理 早期主要基于影子页表进行地址转换(性能有损耗),后来Intel设计了EPT机制(内存地址转换效率高) 内存从原先的虚拟地址,物理地址转换为4种内存地址 客户机虚拟地址 GVA（Guest Virtual Address） 客户机物理地址 GPA（Guest Physical Address） 宿主机虚拟地址 HVA（Host Virtual Address） 宿主机物理地址 HPA（Host Physical Address） IO虚拟化原理 I/O 虚拟化是基于 Intel 的 VT-d 指令集来实现的是基于 North Bridge 北桥芯片（或 MCH）的硬件辅助虚拟化技术 运用 VT-d 技术，虚拟机得以使用基于直接 I/O 设备分配方式，或者用 I/O 设备共享方式来代替传统的设备模拟 / 额外设备接口方式，不需要硬件改动，还省去了中间通道和VMM 的开销，从而大大提升了虚拟化的 I/O 性能，让虚拟机性能更接近于真实主机 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173// KVM关键代码走读// ---------// 创建虚拟机// ---------// 虚拟机初始化的入口部分virt/kvm/kvm_main.c:static int kvm_dev_ioctl_create_vm(void)&#123;int fd;struct kvm *kvm;kvm = kvm_create_vm(type);if (IS_ERR(kvm))return PTR_ERR(kvm);r = kvm_coalesced_mmio_init(kvm);r = get_unused_fd_flags(O_CLOEXEC);/*生成kvm-vm控制文件*/file = anon_inode_getfile(&quot;kvm-vm&quot;, &amp;kvm_vm_fops, kvm, O_RDWR);return fd;&#125;// 创建KVM中内存,IO等资源相关的数据结构并进行初始化virt/kvm/kvm_main.c:static struct kvm *kvm_create_vm(void)&#123;int r, i;struct kvm *kvm = kvm_arch_create_vm();/*设置kvm的mm结构为当前进程的mm,然后引用计数为1*/kvm-&gt;mm = current-&gt;mm;kvm_eventfd_init(kvm);mutex_init(&amp;kvm-&gt;lock);mutex_init(&amp;kvm-&gt;irq_lock);mutex_init(&amp;kvm-&gt;slots_lock);refcount_set(&amp;kvm-&gt;users_count, 1);INIT_LIST_HEAD(&amp;kvm-&gt;devices);INIT_HLIST_HEAD(&amp;kvm-&gt;irq_ack_notifier_list);r = kvm_arch_init_vm(kvm, type);r = hardware_enable_all()for (i = 0; i &lt; KVM_NR_BUSES; i++) &#123;rcu_assign_pointer(kvm-&gt;buses[i],kzalloc(sizeof(struct kvm_io_bus), GFP_KERNEL));&#125;kvm_init_mmu_notifier(kvm);/*把kvm链表加入总链表*/list_add(&amp;kvm-&gt;vm_list, &amp;vm_list);return kvm;&#125;// 初始化完毕后会将 KVM 加入到一个全局链表头，可以通过这个链表头，遍历所有的 VM 虚拟机了// --------// 创建vCPU// --------virt/kvm/kvm_main.c:static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)&#123;int r;struct kvm_vcpu *vcpu, *v;/*调用相关cpu的vcpu_create 通过arch/x86/x86.c 进入vmx.c*/vcpu = kvm_arch_vcpu_create(kvm, id);/*调用相关cpu的vcpu_setup*/r = kvm_arch_vcpu_setup(vcpu);/*判断是否达到最大cpu个数*/mutex_lock(&amp;kvm-&gt;lock);if (atomic_read(&amp;kvm-&gt;online_vcpus) == KVM_MAX_VCPUS) &#123;r = -EINVAL;goto vcpu_destroy;&#125;kvm-&gt;created_vcpus++;mutex_unlock(&amp;kvm-&gt;lock);/*生成kvm-vcpu控制文件*//* Now it&#x27;s all set up, let userspace reach it */kvm_get_kvm(kvm);r = create_vcpu_fd(vcpu);kvm_get_kvm(kvm);r = create_vcpu_fd(vcpu);if (r &lt; 0) &#123;kvm_put_kvm(kvm);goto unlock_vcpu_destroy;&#125;kvm-&gt;vcpus[atomic_read(&amp;kvm-&gt;online_vcpus)] = vcpu;/** Pairs with smp_rmb() in kvm_get_vcpu. Write kvm-&gt;vcpus* before kvm-&gt;online_vcpu&#x27;s incremented value.*/smp_wmb();atomic_inc(&amp;kvm-&gt;online_vcpus);mutex_unlock(&amp;kvm-&gt;lock);kvm_arch_vcpu_postcreate(vcpu);&#125;// 首先在第 7 行的 kvm_arch_vcpu_create() 函数内进行 vcpu_vmx 结构的申请操作，然后还对 vcpu_vmx 进行了初始化。在这个函数的执行过程中，同时还会设置 CPU 模式寄存器（MSR 寄存器）。// 接下来分别为 guest 和 host 申请页面，并在页面里保存 MSR 寄存器的信息。最后，还会申请一个 vmcs 结构，并调用 vmx_vcpu_setup 设置 vCPU 的工作模式，这里就是实模式// --------// vCPU运行// --------arch/x86/kvm/x86.c:static int vcpu_run(struct kvm_vcpu *vcpu)&#123;int r;struct kvm *kvm = vcpu-&gt;kvm;for (;;) &#123;/*vcpu进入guest模式*/if (kvm_vcpu_running(vcpu)) &#123;r = vcpu_enter_guest(vcpu);&#125; else &#123;r = vcpu_block(kvm, vcpu);&#125;kvm_clear_request(KVM_REQ_PENDING_TIMER, vcpu);/*检查是否有阻塞的时钟timer*/if (kvm_cpu_has_pending_timer(vcpu))kvm_inject_pending_timer_irqs(vcpu);/*检查是否有用户空间的中断注入*/if (dm_request_for_irq_injection(vcpu) &amp;&amp;kvm_vcpu_ready_for_interrupt_injection(vcpu)) &#123;r = 0;vcpu-&gt;run-&gt;exit_reason = KVM_EXIT_IRQ_WINDOW_OPEN;++vcpu-&gt;stat.request_irq_exits;break;&#125;kvm_check_async_pf_completion(vcpu);/*是否有阻塞的signal*/if (signal_pending(current)) &#123;r = -EINTR;vcpu-&gt;run-&gt;exit_reason = KVM_EXIT_INTR;++vcpu-&gt;stat.signal_exits;break;&#125;/*执行一个调度*/if (need_resched()) &#123;cond_resched();&#125;&#125;// 通过 vcpu_enter_guest 进入 / 退出 vCPU，在根模式之间来回切换、反复横跳// ---------// 内存虚拟化// ---------// 在 vcpu 初始化的时候，会调用 kvm_init_mmu 来设置虚拟内存初始化，一种是基于 EPT 的方式，另一种是基于影子页表实现的 soft mmu 方式arch/x86/kvm/mmu/mmu.cvoid kvm_init_mmu(struct kvm_vcpu *vcpu, bool reset_roots)&#123;....../*嵌套虚拟化，我们暂不考虑了 */if (mmu_is_nested(vcpu))init_kvm_nested_mmu(vcpu);else if (tdp_enabled)init_kvm_tdp_mmu(vcpu);elseinit_kvm_softmmu(vcpu);&#125;// -------// IO虚拟化// -------// 一种是全虚拟化方案，一种是半虚拟化方案// 全虚拟化会在 VM-exit 退出之后把 IO 交给 QEMU 处理// 半虚拟化则是把 I/O 变成了消息处理，从客户机（guest）机器发消息出来，宿主机（由 host）机器来处理arch/x86/kvm/vmx.c:static int handle_io(struct kvm_vcpu *vcpu)&#123;unsigned long exit_qualification;int size, in, string;unsigned port;exit_qualification = vmcs_readl(EXIT_QUALIFICATION);string = (exit_qualification &amp; 16) != 0;++vcpu-&gt;stat.io_exits;if (string)return kvm_emulate_instruction(vcpu, 0) == EMULATE_DONE;port = exit_qualification &gt;&gt; 16;size = (exit_qualification &amp; 7) + 1;in = (exit_qualification &amp; 8) != 0;return kvm_fast_pio(vcpu, size, port, in);&#125; 12.2 如何理解容器的实现机制 什么是容器 容器是一种工作模式:轻量,拥有一个模具(镜像),既可以规模生产出多个相同的集装箱(运行实例),又可以和外部环境(宿主机)隔离,最终实现对&quot;内容&quot;的打包隔离,方便其运输传送 容器目的就是提供一个独立的运行环境 和虚拟机的对比 传统的虚拟化技术通过硬件模拟实现，也可以通过操作系统软件实现 为了让虚拟的应用程序达到和物理机相似的效果,使用Hypervisor/VM虚拟机,允许多个操作系统共享一个或多个CPU,但是开销较大 容器是一种更加轻量级的操作系统虚拟化技术,将应用程序,依赖包,库文件等依赖环境打包到标准的镜像中,通过容器引擎提供进程隔离,资源可限制的运行环境,实现应用与os平台及底层硬件的解耦 容器的基础架构 Docker是最经典,使用最广泛的容器技术，采用C/S架构，包括3个核心部分 容器客户端(Client) 主要任务是接受并解析用户的操作指令和执行参数,收集所需要的配置信息,根据相应的Docker命令通过HTTP或REST API等方式与Docker daemon(守护进程)进行交互,并将处理结果返回给用户,实现Docker服务使用与管理 容器镜像仓库(Registry) Registry是存储容器的仓库,在容器的运行过程中,Client在接受到用户的指令后转发给Host下的Daemon,会通过网络与Registry进行通信 镜像仓库可以部署在公网环境,也可以私有化部署在内网,通过局域网对镜像进行管理 容器管理引擎进程(Host) 容器引擎进程是Docker架构的核心，包括Docker Daemon(守护进程), Image(镜像),Driver(驱动),Libcontainer(容器管理)等 Docker Daemon详解 为一个常驻后台的系统进程,负责监听客户端请求,然后执行后续的对应逻辑,还能管理DOcker对象(容器,镜像,网络,磁盘等) 可以把 Daemon 分为三大部分，分别是 Server、Job、Engine Server 负责接收客户端发来的请求（由 Daemon 在后台启动 Server）。接受请求以后Server 通过路由与分发调度找到相应的 Handler 执行请求，然后与容器镜像仓库交互（查询、拉取、推送）镜像并将结果返回给 Docker Client Engine 是 Daemon 架构中的运行引擎，同时也是 Docker 运行的核心模块。Engine 扮演了 Docker container 存储仓库的角色。Engine 执行的每一项工作，都可以拆解成多个最小动作——Job，这是 Engine 最基本的工作执行单元 Job 不光能用在 Engine 内部，Docker 内部每一步操作，都可以抽象为一个 Job。Job 负责执行各项操作时，如储存拉取的镜像，配置容器网络环境等，会使用下层的Driver（驱动）来完成 Docker Driver Driver是Docker中的驱动,依旧是解耦,将容器管理的镜像,网络和隔离执行逻辑从Docker Daemon的逻辑中剥离 可分为三类驱动 graphdriver 负责容器镜像的管理，主要就是镜像的存储和获取，当镜像下载的时候，会将镜像持久化存储到本地的指定目录 networkdriver 主要负责 Docker 容器网络环境的配置，如 Docker 运行时进行 IP 分配端口映射以及启动时创建网桥和虚拟网卡 execdriver 是Docker 的执行驱动，通过操作 Lxc 或者 libcontainer 实现资源隔离。它负责创建管理容器运行命名空间、管理分配资源和容器内部真实进程的运行 libcontainer 通过调用 libcontainer 来完成对容器的操作，加载容器配置container，继而创建真正的 Docker 容器。libcontainer 提供了访问内核中和容器相关的API，负责对容器进行具体操作 容器可以创建一个相对隔离的环境,就容器技术本身而言,其核心部分利用了内核的虚拟化技术 容器基础技术 Docker是一个给予Linux操作系统下Namespace和Cgroups和UnionFS的虚拟化工具 Linux NameSpace 实现各种资源隔离功能的技术为Linux Namespace，可以隔离一系列的系统资源 Namespace在基于chroot扩展升级的基础上,可以分别将一些资源隔离起来,限制每个进程能够访问的资源 PID Namespace：保障进程隔离，每个容器都以 PID=1 的 init 进程来启动 User Namespace：用于隔离容器中 UID、GID 以及根目录等 UTS Namespace：保障每个容器都有独立的主机名或域名 Mount Namespace: 保障每个容器都有独立的目录挂载路径 NET Namespace：保障每个容器有独立的网络栈、socket 和网卡设备 IPC Namespace：保障每个容器进程 IPC 通信隔离 Cgroup Namespace：保障容器容器中看到的 cgroup 视图，像宿主机一样以根形式来呈现，同时让容器内使用 cgroup 变得更安全 7类Namespace主要使用3种系统调用函数,就是和进程有关的调用函数 clone：创建新进程，根据传入上面的不同 NameSpace 类型，来创建不同的NameSpace 进行隔离，同样的，对应的子进程也会被包含到这些 Namespace 中 int clone(int (*child_func)(void *), void *child_stac, int flags, void *arg); flags就是标志用来描述你需要从父进程继承哪些资源，这里flags参数为将要创建的NameSpace类型 unshare：将进程移出某个指定类型的 Namespace，并加入到新创建的 NameSpace中， 容器中 NameSpace 也是通过 unshare 系统调用创建的 int unshare(int flags); flags同上 setns：将进程加入到 Namespace 中 int setns(int fd, int nstype); fd： 加入的NameSpace，指向/proc/[pid]/ns/目录里相应NameSpace对应的文件,nstype：NameSpace类型 几种Namespace 都是为了隔离容器的运行环境，此外，NameSpace 是和进程息息相关的，NameSpace 将全局共享的资源划分为多组进程间共享的资源，当一个NameSpace 下的进程全部退出，NameSpace 也会被销毁 Linux Cgroups Linux Cgroups（Control Groups）主要负责对指定的一组进程做资源限制，同时可以统计其资源使用。具体包括 CPU、内存、存储、I/O、网络等资源 Cgrpups 的核心概念，分别是 Task (任务)、Control Groups（控制组 ）、subsystem（子系统）、hierarchy（层级数） Task: 任务，在 Cgroup 中，任务同样是一个进程 Control Groups：控制组，Cgroups 的一组进程，并可以在这个 Cgroups 通过参数，将一组进程和一组 linux subsystem 关联起来 subsystem：子系统，是一组资源控制模块，subsystem 作用于 hierarchy 的 Cgroup 节点，并控制节点中进程的资源占用 hierarchy：层级树 Cgroups，将 Cgroup 通过树状结构串起来，通过虚拟文件系统的方式暴露给用户 容器中常用的 Cgroup 驱动 Cgroupfs 驱动：需要限制 CPU 或内存使用时，直接把容器进程的 PID 写入相应的 CPU 或内存的 cgroup systemdcgroup 驱动：提供 cgroup 管理，所有的 cgroup 写操作需要通过 systemd 的接口来完成，不能手动修改 1234567891011121314151617181920212223242526272829303132333435363738394041# 实验# 新建cgroup挂载文件# 新建一个 Cgroup，名为 cgroup-cosmos，先创建一个 hierarchy，再进行挂载代码mkdir cgroup-cosmossudo mount -t cgroup -o none,name=cgroup-cosmos cgroup-cosmos cgroup-cosmos/ll ./cgroup-cosmos# 创建子group(名为cgroup-cosmos-a)cd cgroup-cosmosmkdir cgroup-cosmos-atree# 在 Cgroup 中添加、移动进程# 将当前的进程 ID 写入对应的cgroup 文件即可echo $$ // 583cat /proc/583/cgroup# 将终端进程移动到 cgroup-cosmos-acd cgroup-cosmos-ash -c &quot;echo $$ &gt;&gt; tasks&quot;# 限制 Cgroup 中进程的资源# 查看hierarchy的subsystem，为/sys/fs/cgroup/memory/mount | grep memorycd /sys/fs/cgroup/memory/sudo mkdir cosmos-limit-memorycd cosmos-limit-memoryls# 先启动一个未限制的进程stress --vm-bytes 200m --vm-keep -m 1# 设置最大内存，并且将进程移动到当前 Cgroup 中，在此运行一个进程# 操作以后，就可以通过 top 命令看到已经将 stress 的最大内存限制到 100m 了# 设置最大内存占用sh -c &quot;echo &quot;100m&quot; &gt; memory.limit_in_bytes&quot;# 移动到这个cgroup内sh -c &quot;echo $$ &gt;&gt; tasks&quot;# 再启动一个机型stress --vm-bytes 200m --vm-keep -m 1top","categories":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/categories/Basic/"}],"tags":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/tags/Basic/"}]},{"title":"C++Primer","slug":"计算机基础知识/C++Primer","date":"2022-03-31T08:52:28.000Z","updated":"2023-04-09T13:36:47.123Z","comments":true,"path":"2022/03/31/计算机基础知识/C++Primer/","link":"","permalink":"http://jay1060950003.github.io/2022/03/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/C++Primer/","excerpt":"引言 C++ Primer的学习笔记","text":"引言 C++ Primer的学习笔记 1 开始 1.2 初始输入输出 iostream库为IO库,其中包含两个基本类型istream和ostream,分别表示输入流和输出流 一个流就是一个字符序列,是从IO设备读出或写入IO设备的 标准输入输出对象 cin标准输入 cout标准输出 cerr输出警告和错误信息,标准错误 clog输出程序运行时的一般性信息 向流中写入数据 输出运算符&lt;&lt; 接受两个运算对象,左边为ostream对象,右边为要打印的值 std::endl为操纵符：结束当前行,并将与设备关联的缓冲区中的内容刷到设备中 缓冲刷新操作可以保证到目前为止程序所产生的所有输出真正写入输出流中,而不是仅停留在内存中等待写入流 从流中读取数据 输入运算符&gt;&gt; 2 变量和基本类型 2.1 基本内置类型 类型 含义 最小尺寸 bool 布尔类型 未定义 char 字符 8位 wchar_t 宽字符16 位 char16_t unicode字符16 位 char32_t unicode字符32 位 short 短整型16 位 int 整型16 位 long 长整型32 位 long long 长整型64 位 float 单精度浮点数 6位有效数字 double 双精度浮点数 10位有效数字 long double 扩展精度浮点数 10位有效数字 C++规定,一个int至少和一个short一样大,一个long至少和一个int一样大,一个long long至少和一个long一样大 long long在C++11中新定义 一个字节为8bit,一个字32或64bit 带符号类型和无符号类型 int,short,long和long long都是带符号的,在类型名前添加unsigned就可以得到无符号类型 char,signed,unsigned char：char,signed并不一样 类型转换 赋给带符号类型一个超出表示范围的值时,结果是未定的 切勿混用带符号类型和无符号类型 字面值常量 以0开头的整数表示八进制数,以0x开头的整数表示十六进制数 浮点数字面值表现位一个小数或以科学计数法表示的指数,其中指数部分用E标识,默认的浮点型字面值为double 单引号括起来的单个字符称为char型字面值,双括号括起来的零个或多个字符则构成字符串型字面值 字符串字面值实际上是由常量字符构成的数组,在末尾处有’\\0’ 转义字符：以反斜线作为开始 泛化的转义序列,其形式是\\x后紧跟1个或多个十六进制,或者紧跟八进制数字,其中数字部分表示的是字符对应的数值 指定字面值的类型：添加前缀和后缀可以改变整型、浮点型和字符型字面值的默认类型 如果后缀中有U,则该字面值属于无符号类型 如果后缀中有L,则字面值的类型至少是long 如果后缀中有LL,则字面值的类型将是long long和unsigned long long 中的一种 nullptr是指针字面值 2.2 变量 C++是一种静态类型语言,其含义是在编译阶段检查类型 何为对象：对象是指一块能存储数据并具有某种类型的内部空间 C++中,初始化和赋值为两个概念 C++11,引入列表初始化：用花括号来初始化变量 默认初始化：内置类型的变量未被显式初始化,值由定义的位置决定,定义于任何函数体之外的变量被初始化为0 定义在函数体内部的内部的内置类型变量将不被初始化 一个未被初始化的内置类型变量的值是未被定义的 一些类要求每个对象都显式初始化,如果创建了一个该类的对象而未对其做明确的初始化操作,将引发错误 分离式编译 C++将声明和定义区分开,声明使得名字为程序所致,定义负责创建实体 变量声明规定了变量的类型和名字,同时申请存储空间 声明变量而不定义,需要在变量名前添加extern,而且不要显式初始化变量 extern:标示变量或者函数的定义在别的文件中,提示编译器遇到此变量和函数时在其他模块中寻找其定义 在函数体内部,尝试初始化一个由extern关键字标记的变量将会引发错误 任何显式初始化的声明为定义 变量只能被定义一次,但可以声明多次,变量的定义必须出现在且只能出现在一个文件中,而其他用到该变量的文件必须对其进行声明,却绝对不能重复定义 标识符 C++的标识符由字母、数字和下画线组成,其中必须以字母或下画线开头 标识符的长度没有限制,但是对大小写字母敏感 12345678910// 定义变量并初始化int units_sold = 0;int units_sold = &#123;0&#125;;int units_sold&#123;0&#125;;int units_sold(0);// 声明变量而不定义extern int i;// 声明并定义jint j; 2.3 复合类型 2.3.1 引用 引用为对象起了另一个名字,引用类型引用另外一种类型,通过将声明符携程&amp;d的形式来定义引用类型,其中d是声明的变量名 一般在初始化变量时,初始值会被拷贝到新建的对象中,然而定义引用时,程序会把引用和它的初始值绑定在一起,而不是将初始值拷贝给引用 引用必须初始化(引用无法令引用重新绑定到另外一个对象) 一旦初始化完成,引用将和它的初始值对象一直绑定在一起 定义了一个引用之后,对其进行的所有操作都是在与之绑定的对象上进行的 2.3.2 指针 与引用类似,指针也实现了对其他对象的间接访问 指针与引用相比又有很多不同点 指针本身就是一个对象,允许对指针赋值和拷贝,而且在指针的生命周期内它可以先后指向几个不同的对象 指针无须在定义时赋初值。和其他内置类型一样,在块作用域内定义的指针如果没有被初始化,也将拥有一个不确定的值 定义指针类型的方法将声明写出*d的形式,其中d式变量名 在声明语句中指针的类型实际上被用于指定它所指向对象的类型,二者必须匹配。如果指针指向了一个其他类型的对象,对该对象的操作将发生错误 获取对象的地址,需要使用取地址符&amp; 指针值的4种状态 指向一个对象 指向紧邻对象所占空间的下一个位置 空指针 无效指针 试图拷贝或以其他方式访问无效指针的值都将引发错误 指针访问对象,需要使用解引用符*访问对象 对指针解引用会得出所指的对象,若给解引用的结果赋值,实际上也就是给指针所指的对象赋值 解引用操作只适用于指向了某个对象的有效指针 空指针 C++11引入的新方法,使用nullptr初始化指针 nullptr是一种特殊类型的字面值,可以转换成任意其他类型的指针类型 NULL的预处理变量来给指针赋值,其值为0,定义在cstdlib中 赋值和指针 指针和引用都能提供对其他对象的间接访问,在具体实现细节上二者有很大不同,其中最重要的一点就是引用本身并非一个对象 一旦定义了引用,就无法令其再绑定到另外的对象,之后每次使用这个引用都是访问它最初绑定的那个对象 指针和它存放的地址之间就没有这种限制了。和其他任何变量(只要不是引用)一样,给指针赋值就是令它存放一个新的地址,从而指向一个新的对象 任何非0指针对应的条件值都是true void* 指针 特殊的指针类型,可以存放任意对象的地址 利用void*指针能做的事儿比较有限：拿它和别的指针比较、作为函数的输入或输出,或者赋给另外一个void*指针 不能直接操作void*指针所指的对象 以void*的视角来看内存空间也就仅仅是内存空间,没办法访问内存空间中所存的对象 2.3.3 理解复合类型 定义包括一个基本数据类型和一组声明符 定义多个变量时,基本数据类型是基本数据类型而非基本类型*,*仅仅是修饰了变量名而已 将*或&amp;与变量名连在一起 指向指针的指针 **表示指向指针的指针 解引用指向指针的指针会得到一个指针 两次解引用指向指针的指针会得到最原始的对象 指向指针的引用 引用本身不是一个对象,不能定义指向引用的指针,但指针是对象,所以存在对指针的引用 *&amp;r,理解时最简单的办法是从右向左阅读r的定义;离变量名最近的符号(此例中是&amp;r的符号&amp;)对变量的类型有最直接的影响,因此r是一个引用;声明符的其余部分用以确定r引用的类型是什么,此例中的符号*说明r引用的是一个指针;声明的基本数据类型部分指出r引用的是一个int指针 12345678910111213141516171819int *p; //定义指向int型对象的指针int ival = 42;int *p = &amp;ival; //p存放ival的地址,p式指向变量ival的指针int* p1,p2; //p1为一个指向int的指针,p2为int类型int **pp = &amp;p; //pp1表示指向一个int指针的指针int i = 42;int *p;int *&amp;r = p; //r是对指针p的引用r = &amp;i; //r引用了一个指针,因此给r赋值&amp;i就是令p指向i*r = 0; //解引用r得到i,也就是p指向的对象,将i的值改为0//要理解r的类型到底是什么,最简单的办法是从右向左阅读r的定义//离变量名最近的符号(此例中是&amp;r的符号&amp;)对变量的类型有最直接的影响,因此r是一个引用//声明符的其余部分用以确定r引用的类型是什么,此例中的符号＊说明r引用的是一个指针//最后,声明的基本数据类型部分指出r引用的是一个int指针 2.4 const限定符 const限定符对变量的类型加以限制可以防止程序改变变量的值 const变量一旦创建其值就不能再改变,故const变量必须初始化 默认状态下,const对象仅在文件内有效 编译器在编译过程中将变量全部替换成对应的值 当多个文件中出现了同名的const变量时,在不同文件中分别定义了独立的变量 文件共享const变量时,对const变量的声明和定义都添加extern关键字 2.4.1 const引用(常量引用) 将引用绑定在const对象上,是对常量的引用 const引用与普通引用的不同：对常量的引用不能被用于修改它绑定的对象 引用的类型必须与其所引用对象的类型一致 在初始化常量引用时允许用任意表达式作为初始值,只要其结果可以转换成引用的类型即可 常量引用一个非const的对象：不允许通过常量引用修改对象的值 2.4.2 const和指针 const指针(常量指针)：指向常量的指针,不可以修改其所指向对象的值 常量指针为底层指针,表示指针指向的是常量 常量只可以使用指向常量的指针存放常量的地址 常量指针可以指向其他对象,但不可以通过常量指针修改对象的值 常量指针必须初始化,一旦初始化完成,指针不可以改变 指针常量：把*放在const关键字之前说明指针是一个常量,即不变的是指针本身的值而非指向的那个值 指针常量为顶层const,指针本身就是常量 指针本身是一个常量并不意味着不能通过指针修改其所指对象的值,能否这样做完全依赖于所指对象的类型 注意区别指针常量和常量指针 2.4.3 顶层const和底层const 顶层const表示任意的对象是常量 底层const表示指向常量 顶层const拷贝时,顶层const不受影响 底层const拷贝时 拷入和拷出时的对象必须具有相同的底层const 或两个对象的数据类型必须可以转换 2.4.4 constexpr和常量表达式 常量表达式是指指不会改变并且在编译过程中就可以得到计算结果的表达式 C++11中,允许变量声明为constexpr类型,以便编译器验证变量的值是否是常量表达式 新标准允许定义一种特殊的constexpr函数(以使得编译时就可以计算其结果,可以用constexpr函数去初始化constexpr变量) 声明为constexpr的变量一定是一个常量,而且必须用常量表达式初始化 指针和引用定义成constexpr,constexpr指针初始化值必须是nullptr或0 指针和constexpr 在constexpr声明中定义了一个指针,限定符constexpr仅对指针有效,与指针所指的对象无关 1234567891011121314151617181920212223242526272829303132int i = 42;int &amp;r1 = i;const int &amp;r2 = i; //常量引用,但不可以通过其改变i的值r1 = 0;r2 = 0; //错误;r2为常量引用const double pi = 3.14;double *ptr = &amp;pi; //ptr为普通指针const double *cptr = &amp;pi; //指向常量的指针const double *const cptr = &amp;pi; //cptr是一个指向常量对象的常量指针int *const ptri = &amp;i; //ptri是一个指向int的常量指针int i = 0;int *const p1 = &amp;i; //顶层const,不可以改变p1的值const int ci = 42; //顶层const,不可以改变const int *p2 = &amp;ci; //底层const,可以改变p2的值const int *const p3 = p2; //左边的底层const,右边的顶层consti = ci; p2 = p3; //p2,p3所指向的对象类型相同,p3顶层const部分不影响int *p = p3; //错误,p不包含底层const含义p2 = p3; //正确p2 = &amp;i; //正确,int*可以转换成const int*int &amp;r = ci; //错误const int &amp;r2 = i; //正确//p3既是顶层const也是底层const//拷贝p3时可以不在乎它是一个顶层const,但是必须清楚它指向的对象得是一个常量const int *p = nullptr; // 为一个指向整型常量的指针constexpr int *q = nullptr; // 为一个指向整数的常量指针 2.5 处理类型 2.5.1 类型别名 类型别名是一个名字,是某种类型的同义词 传统方法：使用typedef C++11中使用别名声明,这种方法用关键字using作为别名声明的开始,其后紧跟着别名和等号,其作用是把等号左侧的名字规定成等号右侧类型的别名 类型别名和类型的名字等价 指针,常量和类型别名 在使用类型别名的声明语句时,不可以将别名替换成原来的样子,应将声明部分看成一个整体 2.5.2 auto类型说明符 在C++11中,引入auto修饰符,可以让编译器分析表达式所属的类型,推算变量的类型 auto定义的变量必须给初始值 ==当引用被用作初始值时,真正参与初始化的其实时引用对象的值 auto一般会忽略顶层const,保留底层const,需要顶层const时需要明确指出 ==设置一个类型为auto的引用,初始化中的顶层const属性会保留 ==一条语句中定义多个变量,&amp;,*只从属于某个声明符,而非基本数据类型的一部分 2.5.3 decltype类型指示符 C++11引入的第二种类型说明符,选择并返回操作数的数据类型 decltype处理顶层const和引用的方式与auto不同,若decltype使用的表达式是一个变量,则返回该变量的类型(包括顶层const和引用在内) 引用从来都是作为其所指对象的同义词出现,但在decltype中例外 如果decltype使用的表达式不是一个变量,则decltype返回表达式结果对应的类型 如果表达式内同是解引用操作,则decltype将得到引用类型 如果decltype使用的是一个不加括号的变量,则得到的结果就是该变量的类型 如果给变量加上了一层或多层括号,编译器就会把它当成是一个表达式,得到引用类型(变量是一种可以作为赋值语句左值的特殊表达式) 12345678910111213141516171819202122232425262728typedef char *pstring;const pstring cstr = 0; //cstr是指向char的常量指针const pstring *ps; //ps是一个指针,其对象是指向char的常量指针int i = 0, &amp;r = i;auto a = r; //a为int类型const int ci = i, &amp;cr = ci;auto b = ci; //b整型(ci的顶层const属性被忽略)auto c = cr; //c整型auto d = &amp;i;auto e = &amp;ci; //指向整型常量的指针const auto f = c; // const int auto &amp;g = 42; //错误const auto &amp;j = 42; //正确,可以为常量引用绑定字面值decltype(f()) sum = x; //sum的类型就是函数f的返回类型int i = 42,*p = &amp;i, &amp;r = i;decltype(r+0) b; // intdecltype(*p) c; //错误,c时int&amp;,必须初始化// r是一个引用,因此结果为引用类型// 但向让结果类型r是所指向的类型,需要使用表达式decltype((i)) d; //d,int&amp;必须初始化decltype(i) e; //int 2.6 自定义数据结构 12345678910111213// 结构体的定义Struct 结构体名&#123; 成员变量; 成员函数;&#125;;// 头文件保护符#ifdef 头文件#define 头文件// ...// 头文件内容// ...#endif 3 字符串,向量和数组 3.1 命名空间的using声明 using声明可以使用命名空间中的成员 每个名字都需要独立的using声明 头文件不应包含using声明 12// using声明using namespace::name; 3.2 标准库类型string 标准库类型string表示可变长字符序列,包含在string头文件中 定义和初始化string对象 使用=初始化变量,执行拷贝初始化,不使用=进行直接初始化 string操作的注意事项 getline函数的参数是一个输入流和一个string对象,函数从给定的输入流中读入内容,直到遇到换行符为止(注意换行符也被读进来了) &gt;&gt;不会保留输入时的空白符,遇空白符停止 string::size_type类型 所有用于存放string类的size函数返回值的变量,都是string::size_type类型的 在C++11中,允许编译器通过auto或者decltype来推断变量的类型 避免因为符号数和无符号数产生意外的结果 C++11引入范围for语句 遍历给定序列中的每个元素并对序列中的每个值执行某种操作 for(declaration:expression) expression部分是一个对象,用于表示一个序列;declaration部分负责定义一个变量,该变量将被用于访问序列中的基础元素;每次迭代,declaration部分的变量会被初始化为expression部分的下一个元素值 auto c可作为declaration部分 string的操作 解释 os&lt;&lt;s 将s写出到输出流os中,返回os is&gt;&gt;s 从is中读取字符串赋给s,字符串以空白分隔,返回is getline(is,s) 从is中读取一行赋给s,返回is s.empty() s为空返回true s.size() 返回s中字符的个数 s[n] 返回s中第n个字符的引用 s1+s2 返回s1,s2连接后的结果 s1=s2 s2的副本替换s1中原来的字符 s1==s2 完全一样,则相等 &lt;,&lt;=,&gt;,&gt;= 对字典序进行比较 cctype头文件中的标准库函数操作 解释 isalnum© 当c为字母或数字时为真 isalpha© 当c为字母时为真 iscntrl© 当c为控制字符时为真 isdigit© 当c为数字时为真 isgraph© 当c不是空格但可打印时为真 islower© 当c是小写字母时为真 isprint© 当c是可打印字符时为真(c为空格或具有可视形式) ispunct© 当c是标点符号时为真 isspace© 当c是空白时为真 issupper© 当c是大写字母时为真 isxdigit© 当c是十六进制数字时为真 tolower© 输出小写字母 toupper© 输出大写字母 1234567891011121314151617181920212223242526272829303132#include&lt;string&gt;using std::string;string s1; //默认初始化string s2 = s1; // 拷贝初始化string s2(s1); // 拷贝初始化string s3 = &quot;hiya&quot;; //拷贝初始化string s3(&quot;hiya&quot;); //直接初始化string s4(10,&#x27;c&#x27;); //cccccccccc// 读写string对象int main()&#123; string s; cin&gt;&gt;s; cout&lt;&lt;s&lt;&lt;endl; return 0;&#125;// 读写数量未知的stringint main()&#123; string word; while(cin&gt;&gt;word) cout&lt;&lt;word&lt;&lt;endl; return 0;&#125;// auto推断auto len = line.size(); //len string::size_type// 范围forfor(declaration:expression) statement 3.3 标准库类型vector 标准库类型vector表示对象的集合,其中所有对象的类型都相同,常被称为容器 集合中每个对象都有一个与之对应的索引,索引用于访问对象 vector属于类模板 编译器根据模板创建类或函数的过程称为实例化,在模板名后跟着一对尖括号,在括号内放上信息,即可创建模板实例类 vector能容纳绝大多数类型的对象作为其元素,但引用不属于对象,不存在包含引用的vector 定义和初始化vector对象 定义一个空vector,然后当运行时获取到元素的值后再逐一添加(在程序运行时高效地往vector对象中添加元素) 在定义对象时指定元素的初始值 C++11中可以使用列表初始化,用花括号括起来的元素值赋值给vector对象 用圆括号初始化指定的一般为数量,用花括号初始化的为初始化列表 向vector对象中添加元素 使用push_back向vector对象添加元素,将值作为尾元素压入vector中 vector对象(以及string对象)的下标运算符可用于访问已存在的元素,而不能用于添加元素 添加元素后再分配内存空间,声明定义只是开辟内存头 vector对象可以高效地增长,可以快速添加元素 如果循环体内部包含有向vector对象添加元素的语句,则不能使用范围for循环 定义vector对象的方法 解释 vector&lt;T&gt; v1 v1是一个空vector,建在元素是T类型 vector&lt;T&gt; v2(v1) v2中包含有v1所有元素的副本 vector&lt;T&gt; v2=v1 v2中包含有v1所有元素的副本 vector&lt;T&gt; v3(n,val) v3中包含n个val vector&lt;T&gt; v4(n) v4中包含n个重复地执行力值初始化的对象 vector&lt;T&gt; v5{a,b,c…} v5中包含初始化个数的元素,每个元素被赋予相同的初始值 vector&lt;T&gt; v5={a,b,c…} v5中包含初始化个数的元素,每个元素被赋予相同的初始值 vector对象地其他操作 解释 v.empty() v为空返回true v.size() 返回v中字符的个数 v.push_back() 向v中添加元素 v[n] 返回v中第n个字符的引用 v1=v2 v2的副本替换v1中原来的字符 v1={a,b,c…} 拷贝替换 v1==v2 完全一样,则相等 &lt;,&lt;=,&gt;,&gt;= 对字典序进行比较 1234567#include&lt;vector&gt;usind std::vector;vector&lt;int&gt; ivec;// 添加元素ivec.push_back(1); //向ivec中添加元素 3.4 迭代器介绍 标准库容器可以使用迭代器,迭代器类似指针类型,提供了对对象的间接访问 使用迭代器可以访问某个元素,迭代器也能从一个元素移动到另一个元素;有效的迭代器指向某个元素或容器尾元素的下一个位置 使用迭代器 有迭代器的类型同时拥有返回迭代器的成员,这些类型拥有begin和end成员 begin成员负责指向第一个元素的迭代器 end成员负责指向尾元素的下一个位置,指示的是容器一个不存在的尾后元素,迭代器称为尾后迭代器 由编译器决定迭代器的类型,一般使用auto关键字定义变量 若容器为空,begin和end返回的是一个迭代器,都是尾后迭代器 和指针类似,可通过解引用迭代器来获取它所指示的元素 begin和end返回的具体类型由对象是否是常量决定 如果对象是常量,begin和end返回const_iterator 如果对象不是常量,返回iterator 拥有迭代器的标准库类型使用iterator和const_iterator来表示迭代器类型 const_iterator为常量,可以读取但不能修改它所指向的元素值 C++11中引入cbegin和cend获得const_iterator C++语言定义了箭头运算符-&gt;, 箭头运算符把解引用和成员访问两个操作结合在一起,it-&gt;mem等价于(*it).mem 迭代器运算符 解释 *iter 返回迭代器iter所指元素 iter-&gt;mem 解引用iter并获取该元素的名为mem的成员,等价于(*iter).mem ++iter 指示容器的下一个元素 –iter 指示容器的上一个元素 iter1 == iter2 判断两个迭代器是否相等 iter1 != iter2 判断两个迭代器是否相等 迭代器支持的运算符 解释 iter+n 迭代器向前移动n个元素 iter-n 迭代器向后移动n个元素 iter+=n 复合赋值语句 iter-=n 复合赋值语句 iter1-iter2 计算两个迭代器之间的距离 1234567auto b = v.begin(),e=v.end();//拥有迭代器的标准库类型使用iterator和const_iterator来表示迭代器类型vector&lt;int&gt;::iterator it; //it可以读写vector&lt;int&gt;的元素string::iterator it; //it可以读写String的元素vector&lt;int&gt;::const_iterator it; //it可以读vector&lt;int&gt;的元素,但不可以写string::const_iterator it; //it可以读String的元素 3.5 数组 数组与vector的区别 与vector相似的地方是,数组也是存放类型相同的对象的容器,这些对象本身没有名字,需要通过其所在位置访问 与vector不同的地方是,数组的大小确定不变,不能随意向数组中增加元素 定义和初始化数组 数组为复合类型,默认情况下,数组的元素被默认初始化 定义数组的时候必须指定数组的类型,不允许用auto关键字由初始值的列表推断类型 数组的元素应为对象,不存在引用的数组 不能将数组的内容拷贝给其他数组作为其初始值,也不能用数组为其他数组赋值 访问数组元素 可使用范围for语句 使用数组下标时,通常定义为size_t类型,该类型在cstddef头文件中,是一种机器相关的无符号类型 复杂的数组声明 指针数组：存放指针的数组 数组指针：数组的指针及数组的引用 要想理解数组声明的含义,最好的办法是从数组的名字开始按照由内向外的顺序阅读 复合类型的理解规则：从右到左,从内到外 12345678910111213141516171819unsigned cnt = 42;constexpr unsigned sz = 42; //常量表达式int arr[10];int *parr[sz]; //含有42个整型指针的数组string bad[cnt]; //cnt不是常量表达式,错误string strs[get_size()]; //get_size()为常量表达式时正确int ial[sz] = &#123;0,1,2&#125;;int a2[] = &#123;0,1,2&#125;;int a3[5] = &#123;0,1,2&#125;; //a3[] = &#123;1,2,3,0,0&#125;char a1[] = &#123;&#x27;c&#x27;,&#x27;+&#x27;,&#x27;+&#x27;&#125;; //列表初始化,没有空字符char a1[] = &#123;&#x27;c&#x27;,&#x27;+&#x27;,&#x27;+&#x27;,&#x27;\\0&#x27;&#125;; //列表初始化,含有显式空字符char a1[] = &quot;C++&quot;; //列表初始化,含有隐式空字符,表示字符串结束的空字符 size(a1)=4int *ptrs[10]; //ptrs是含有10个整型指针的数组,指针数组int (*Parray)[10] = $arr; //Parry指向一个含有10个整数的数组,数组指针int (&amp;arrRef)[10] = arr; //arrRef引用一个含有10个整数的数组int *(&amp;arrRef)[10] = ptrs; //arrRef是一个引用,引用一个指针数组,该数组包含10个指针 3.5.3 指针和数组 使用数组时编译器一般会将数组转换为指针 对数组使用下标运算符得到该数组指定位置的元素 对数组元素使用取地址符能得到指向该元素的指针 数组名为一个指向数组首地址的指针 当使用数组作为一个auto变量的初始值时,推断得到的类型是指针而非数组 使用decltype关键字时不会发生转换 指针作为迭代器 若得到尾后指针,使用时容易出错 C++11新标准引入了两个名为begin和end的函数,可得到指向元素的首指针和尾元素下一个位置的指针,定义在iterator头文件中 指针可执行所有迭代器运算,包括解引用、递增、比较、与整数相加、两个指针相减等,用在指针和用在迭代器上意义完全一致 两指针相减时,得到ptrdiff_t的标准库类型,与size_t一样,是一种定义在cstddef头文件中的机器相关的类型 因为差值可能为负值,所以ptrdiff_t是一种带符号类型 两个指针指向同一个数组的元素,或者指向该数组的尾元素的下一位置,可利用关系运算符进行比较,否则不可以比较 对数组执行下标运算其实是对指向数组元素的指针执行下标运算 只要指针指向的是数组中的元素(或者数组中尾元素的下一位置),都可以执行下标运算 标准库类型限定使用的下标必须是无符号类型,而内置的下标运算可以是有符号类型 内置的下标运算符可以处理负值,结果地址必须指向原来的指针所指同一数组中的元素 12345678910111213string nums = &#123;&quot;one&quot;,&quot;two&quot;,&quot;three&quot;&#125;string *p = &amp;nums[0];string *p2 = nums; //等价于*p2=&amp;num[0]int ia[] = &#123;0,2,3,4,5,6&#125;;auto ia2(ia); //ia2为一个整型指针,指向ia的第一个元素decltype(ia) ia3=&#123;0,1,2&#125;; //ia3为一个整型数组int *p = &amp;ia[2]; //p指向索引为2的元素int j = p[1]; //相当于*(p+1),ia[3]int k = p[-2]; //p[-2]是ia[0]表示的元素 3.5.4 C风格字符串 C风格的字符串为char数组,并以空字符(‘\\0’)结束 一般利用指针来操作这些字符串 cstring头文件中,C风格字符串的函数 解释 strlen(p) 返回p的长度,空字符不计算在内 strcmp(p1,p2) 比较相等性,&lt;返回正值 strcat(p1,p2) p2附加在p1后,返回p1 strcpy(p1,p2) p2拷贝给p1,返回p1 3.5.5 与旧代码的接口 string的c_str成员函数：将string转换为c风格的字符串 函数的返回结果是一个指针,该指针指向一个以空字符结束的字符数组,而这个数组所存的数据恰好与那个string对象的一样 指针的类型是const char*,从而确保我们不会改变字符数组的内容 不允许使用一个数组为另一个内置类型的数组赋初值,也不允许使用vector对象初始化数组 允许使用数组来初始化vector对象 需指明要拷贝区域的首元素地址和尾后地址 尽量使用标准库类型而非数组 123int int_arr[] = &#123;0,1,2,3,4,5&#125;;vector&lt;int&gt; ivec(begin(int_arr),end(int_arr));vector&lt;int&gt; ivec(int_arr+1,int_arr+4); //拷贝3个元素,int_arr[1]~[3] 3.6 多维数组 多维数组初始化时,使用花括号进行初始化,可嵌套使用花括号 可使用范围for语句处理多维数组 使用范围for语句处理多维数组,除了最内层的循环外,其他所有循环的控制变量都应该是引用类型 定义多维数组的指针时,多维数组其实是数组的数组 使用auto或者decltype能尽可能地避免在数组前面加上一个指针类型 123456// 输出is中的每个元素的值,ia为二维数组,每个内层数组各占一行ia[3][4]for(auto p = ia;p!=ia+3;++p)&#123; for(auto q = *p;q!=*p+4;++q) cout&lt;&lt;*q&lt;&lt;&#x27; &#x27;; cout&lt;&lt;endl;&#125; 4 表达式 4.1 基础 重载运算符：当运算符作用与类类型的运算对象时,可以自定其含义 定义重载运算符时,其包括的运算对象的类型和返回值的类型都是由运算符定义的;但运算对象的个数,运算符的有限集和结合律都是无法改变的 左值和右值 左值可以位于赋值语句的左侧,右值则不能 当一个对象被用作右值的时候,用的是对象的值(内容) 当对象被用作左值的时候,用的是对象的身份(在内存中的位置) 在需要右值的地方可以用左值来代替,但是不能把右值当成左值(也就是位置)使用 当一个左值被当成右值使用时,实际使用的是它的内容(值) 使用关键字decltype时,左值和右值也有所不同 如果表达式的求值结果是左值,decltype作用于该表达式得到一个引用类型 4.2 算数运算符 算数运算符包括 + 加 - 减 * 乘 / 除 % 取余 C++11中,规定商一律向0取整(即直接切除小数部分) 4.3 逻辑和关系运算符 逻辑和关系运算符包括 逻辑非 ! 小于 &lt; 大于 &gt; 小于等于 &lt;= 大于等于 &gt;= 相等 == 不相等 != 逻辑与 &amp;&amp; 逻辑或 || 短路求值:逻辑与运算符和逻辑或运算符都是先求左侧运算对象的值再求右侧运算对象的值,当且仅当左侧运算对象无法确定表达式的结果时才会计算右侧运算对象的值 对于逻辑与运算符来说,当且仅当左侧运算对象为真时才对右侧运算对象求值 对于逻辑或运算符来说,当且仅当左侧运算对象为假时才对右侧运算对象求值 4.4 赋值运算符 赋值运算符的左侧运算对象必须是一个可修改的左值 C++11允许使用花括号括起来的初始值列表跳转至列表初始化作为赋值语句的右侧运算对象 赋值运算符的优先级低于关系运算符的优先级 4.5 递增和递减运算符 前置版本++v 首先将运算对象加1(或减1),然后将改变后的对象作为求值结果 后置版本 将运算对象加1(或减1),但是求值结果是运算对象改变之前那个值的副本 除非必须,否则不用递增递减运算符的后置版本 后置递增运算符的优先级高于解引用运算符 4.6 成员访问运算符 点运算符和箭头运算符都可以访问成员 点运算符获取类对象的一个成员 箭头运算符与点运算符有关,表达式ptr-&gt;mem等价于(*ptr).mem 箭头运算符作用于一个指针类型的运算对象,结果是一个左值 点运算符分成两种情况： 如果成员所属的对象是左值,那么结果是左值; 反之,如果成员所属的对象是右值,那么结果是右值 1234string s1 = &quot;a string&quot;, *p = &amp;s1;auto n = s1.size(); //运行string对象s1的size成员n = (*p).size(); //运行p所指对象的size成员n = p-size(); 4.7 条件运算符 条件运算符 cond?expr1:expr2; 其中cond是判断条件的表达式,而expr1和expr2是两个类型相同或可能转换为某个公共类型的表达式 条件运算符的执行过程是：首先求cond的值,如果条件为真对expr1求值并返回该值,否则对expr2求值并返回该值 条件运算的嵌套最好别超过两到三层 4.8 位运算符 位运算符作用于整数类型的运算对象,并把运算对象看成是二进制位的集合 一种名为bitset的标准库类型也可以表示任意大小的二进制位集合 位运算符包括 位求反 ` 左移 &lt;&lt; 右移 &gt;&gt; 位与 &amp; 位异或 ^ 位或 | 强烈建议仅将位运算符用于处理无符号类型 4.9 sizeof运算符 sizeof运算符返回一条表达式或一个类型名字所占的字节数 sizeof运算符满足右结合律,其所得的值是一个size_t类型,是一个常量表达式 形式1：sizeof(type) 形式2：sizeof expr sizeof返回的是表达式结果类型的大小,sizeof并不实际计算其运算对象的值 执行sizeof运算能得到整个数组的大小,可以用数组的大小除以单个元素的大小得到数组中元素的个数 123// 返回数组中的元素数量constexpr size_t sz = sizeof(ia)/sizeof(*ia);int arr2[sz]; 4.10 逗号运算符 逗号运算符含有两个运算对象,按照从左向右的顺序依次求值 对于逗号运算符来说,首先对左侧的表达式求值,然后将求值结果丢弃掉。逗号运算符真正的结果是右侧表达式的值。如果右侧运算对象是左值,那么最终的求值结果也是左值 4.11 类型转换 隐式转换 在大多数表达式中,比int类型小的整型值首先提升为较大的整数类型 在条件中,非布尔值转换成布尔类型 初始化过程中,初始值转换成变量的类型;在赋值语句中,右侧运算对象转换成左侧运算对象的类型 如果算术运算或关系运算的运算对象有多种类型,需要转换成同一种类型 函数调用时也会发生类型转换 算术转换：把一种算术类型转换成另外一种算术类型,其中运算符的运算对象将转换成最宽的类型 数组转换成指针：在大多数用到数组的表达式中,数组自动转换成指向数组首元素的指针 指针的转换 常量整数值0或者字面值nullptr能转换成任意指针类型 指向任意非常量的指针能转换成void* 指向任意对象的指针能转换成const void* 在有继承关系的类型间还有另外一种指针转换的方式 转换成布尔类型 存在一种从算术类型或指针类型向布尔类型自动转换的机制。如果指针或算术类型的值为0,转换结果是false;否则转换结果是true 转换成常量 允许将指向非常量类型的指针转换成指向相应的常量类型的指针,对于引用也是这样。也就是说,如果T是一种类型,就能将指向T的指针或引用分别转换成指向const T的指针或引用 类类型定义的转换 4.11.3 显式转换 显式转换为强制类型转换 命名的强制类型转换 cast-name&lt;type&gt;(expression); type是转换的目标类型而expression是要转换的值 如果type是引用类型,则结果是左值 cast-name是static_cast、dynamic_cast、const_cast和reinterpret_cast中的一种 static_cast 任何具有明确定义的类型转换,只要不包含底层const,都可以使用static_cast static_cast可以将一个较大的算术类型赋值给较小的类型 static_cast对于编译器无法自动执行的类型转换也非常有用 把指针存放在void*中,并且使用static_cast将其强制转换回原来的类型时,应该确保指针的值保持不变;强制转换的结果将与原始的地址值相等 对右值引用的特许规则:虽然不能隐式地将一个左值转换成右值引用,但static_cast可以显式地将一个左值转换成一个右值 const_cast “去掉const性质”：将常量对象转换成非常量对象的行为 只有const_cast能改变表达式的常量属性,使用其他形式的命名强制类型转换改变表达式的常量属性都将引发编译器错误 reinterpret_cat 为运算对象的位模式提供较低层次上的重新解释 12345void * p = &amp;d;double *dp = static_cast&lt;double*&gt;(p);int *ip;char *pc = reinterpret_cast&lt;char*&gt;(ip); 5 语句 5.3 条件语句 C++语言提供了两种按条件执行的语句 一种是if语句,它根据条件决定控制流 另外一种是switch语句,它计算一个整型表达式的值,然后根据这个值从几条执行路径中选择一条 悬垂else 当一个if语句嵌套在另一个if语句内部时,很可能if分支会多于else分支 C++规定else与离它最近的尚未匹配的if匹配 switch-case-default 5.4 迭代语句 迭代语句通常称为循环,它重复执行操作直到满足某个条件才停下来 while和for语句在执行循环体之前检查条件 do while语句先执行循环体,然后再检查条件 范围for语句for(declaration : expression) statement expression表示的必须是一个序列 declaration定义一个变量,序列中的每个元素都得能转换成该变量的类型;确保类型相容最简单的办法是使用auto类型说明符 需要对序列中的元素执行写操作,循环变量必须声明成引用类型 每次迭代都会重新定义循环控制变量,并将其初始化成序列中的下一个值,之后才会执行statement 5.5 跳转语句 C++语言提供了4种跳转语句：break,continue,goto和return break语句负责终止离它最近的while、do while、for或switch语句,并从这些语句之后的第一条语句开始继续执行 break语句只能出现在迭代语句或者switch语句内部 continue语句终止最近的循环中的当前迭代并立即开始下一次迭代 continue语句只能出现在for、while和do while循环的内部,或者嵌套在此类循环里的语句或块的内部 goto语句的作用是从goto语句无条件跳转到同一函数内的另一条语句 不要在程序中使用goto语句,因为它使得程序既难理解又难修改 goto label;其中,label是用于标识一条语句的标示符 带标签语句是一种特殊的语句,语句之前有一个标示符以及一个冒号: return 5.6 try语句块和异常处理 C++的异常处理包括 throw表达式,异常检查部分使用throw表达式表示遇到了无法处理的问题 try语句块,异常处理部分使用try语句块处理异常,try-catch语句块 一套异常类,用于在throw表达式和相关的catch子句之间传递异常的具体信息 5.6.1 throw表达式 throw表达式包含关键字throw和紧随其后的一个表达式,其中表达式的类型就是抛出的异常类型 123if(item1.isbn() != item2.isbn()) throw runtime_error(&quot;Data must refer to same ISBN&quot;); // throw表达式cout &lt;&lt; item1 + item2 &lt;&lt; endl; 5.6.2 try语句块 try语句块内声明的变量在块外部无法访问,特别是在catch子句内也无法访问 12345678// try语句块通用语法结构try&#123; program-statements&#125;catch(exception-declaration)&#123; handler-statements&#125;catch(exception-declaration)&#123; handler-statements&#125; 5.6.3 标准异常 C++标准库定义了异常类 exception头文件定义了最通用的异常类exception;只报告异常的发生,不提供任何额外信息 stdexcept头文件定义了几种常用的异常类,详细信息在表5.1中列出 new头文件定义了bad_alloc异常类型 type_info头文件定义了bad_cast异常类型 标准库异常类只定义了几种运算,包括创建或拷贝异常类型的对象,以及为异常类型的对象赋值 只能以默认初始化的方式初始化exception、bad_alloc和bad_cast对象,不允许为这些对象提供初始值 其他异常类型不允许使用默认初始化的方式：应该使用string对象或者C风格字符串初始化这些类型的对象;当创建此类对象时,必须提供初始值,该初始值含有错误相关的信息 异常类型只定义了一个名为what的成员函数,该函数没有任何参数,目的是提供关于异常的一些文本信息,返回值是一个指向C风格字符串的const char* &lt;stdexcept&gt;定义的异常类 解释 exception 最常见的问题 runtime_error 只有在运行时才能检测出的问题 range_error 运行时错误：生成的结果超出了有意义的值域范围 overflow_error 运行时错误：计算上溢 underflow_error 运行时错误：计算下溢 logic_error 程序逻辑错误 domain_error 逻辑错误：参数对应的结果值不存在 invalid_error 逻辑错误：无效参数 length_error 逻辑错误：试图创建一个超出该类型最大长度的对象 out_of_range 逻辑错误：使用一个超出有效范围的值 6 函数 6.1 函数基础 典型的函数包括：返回类型,函数名字,由0个或多个形参组成的列表以及函数体 通过调用运算符来执行函数,调用运算符的形式是一对圆括号,作用于一个表达式,该表达式是函数或者指向函数的指针 实参和形参 实参是形参的初始值 实参的类型必须与形参类型匹配 任意两个形参都不能同名,而且函数最外层作用域中的局部变量也不能使用与函数形参一样的名字 是否设置未命名的形参并不影响调用时提供的实参数量 即使某个形参不被函数使用,也必须为它提供一个实参 函数的返回类型不能是数组或函数类型,但可以是指向数组或函数的指针 6.1.1 局部对象 形参和函数体内部定义的变量称为局部变量 对函数而言是局部的,仅在函数的作用域内可见,同时局部变量会隐藏在外层作用域中同名的其他所有声明 存在于块执行器件的对象称为自动对象,当块的执行结束后,块中创建的自动对象的值就为未定义的 形参是一种自动对象,函数开始时为形参申请存储空间,函数终止,形参被销毁 局部静态对象 static类型：局部变量的生命周期贯穿函数调用及之后的时间 局部静态对象在程序执行路径第一次经过对象定义语句时初始化,并且直到程序终止才被销毁,在此期间即使对象所在函数结束执行也不会对它有影响 6.1.2 函数声明 函数声明与函数定义类似,唯一的区别就是函数声明无需函数体,使用一个分号代替 函数的三要素(返回类型,函数名,形参类型)描述了函数接口,说明了调用该函数所需的全部信息 函数声明也叫做函数原型 建议在头文件中进行函数声明 含有函数声明的头文件应该被包含到定义函数的源文件中 6.1.3 分离式编译 分离式遍历-链接形成可执行文件 6.2 参数传递 当形参是引用类型,对应的实参被引用传递或函数被传引用调用 当实参的值被拷贝给形参时,形参和实参是两个相互独立的对象,实参被值传递或函数被传值调用 6.2.1 传值参数 初始化一个非引用类型变量时,初始值被拷贝给变量 对变量的改动不会影响初始值 函数对形参的所有操作都不会影响实参 指针参数 指针的行为和其他非引用类型一样 当执行指针拷贝操作时,拷贝的是指针的值,拷贝之后,两个指针是不同的指针 可以使用指针修改它所指向的对象的值(指针可以间接访问所指的对象) 在C++中,建议使用引用类型的形参代替指针访问函数外部的对象 6.2.2 传引用参数 引用的操纵实际上是作用在引用所引的对象上 通过使用引用形参,允许函数改变一个或多个实参的值 使用引用可以避免拷贝 函数无需修改引用形参的值,最好将其声明为常量引用 传递引用形参可以帮助返回额外信息 123456789101112131415161718int n = 0, i = 42;int &amp;r = n;//传递指针void reset(int *ip)&#123; *ip = 0; //改变了指针ip所指对象的值 ip = 0; //改变了ip的局部拷贝,实参未被改变&#125;reset(&amp;i); //改变i的值,而非i的地址//传递引用void reset(int &amp;i) //i是传递给reset函数的对象的另一个名字&#123; i = 0;&#125;int j = 42;reset(j); //传引用,j的值会发生改变 6.2.3 const形参和实参 顶层const和底层const 形参是const时,若为顶层const,初始化时会忽略顶层const属性 底层const可以使用非常量进行初始化,反之不成立 C++允许用字面值初始化常量引用 尽量使用常量引用 把函数不会改变的形参定义成普通的引用会给函数的调用者产生误导,即函数可以修改他的实参值 使用引用而非常量引用也会极大地限制函数所能接受的实参类型,不能把const对象,字面值或需要类型转换的对象传递给普通的引用形参 函数嵌套调用时,假如其他函数(正确地)将它们的形参定义成常量引用,那么内层函数(普通引用)无法正常使用 6.2.4 数组形参 数组的特殊性 不允许拷贝数组 使用数组时会将其转换成指针 数组进行传递时,传递的是指向数组首元素的指针,不可以进行值传递 可以将形参携程类似数组的形式 数组是以指针的形式传递给函数的,但需要指明数组的确切尺寸 使用标记指定数组长度 使用标准库规范,传递指向数组首元素和尾后元素的指针 显式传递一个表示数组大小的形参 数组形参和const 当函数不需要对数组元素执行写操作时,数组形参应该是指向const的指针,只有需要改变元素值是才定义为非常量的指针 数组引用形参 形参可以是数组的引用,引用形参绑定到对应的数组上 传递多维数组 处理的是数组的数组,首元素本身就是一个数组,指针就是一个指向数组的指针 数组第二维(以及后面所有维度)的大小都是数组类型的一部分,不能省略 1234567891011// const int ia[]等价于const int* iavoid print(const int ia[], size_t size)// 形参为数组引用,维度是类型的一部分void print(int (&amp;arr)[10])// 二维数组// matrix指向数组的首元素,该数组的元素是由10个整数构成的数组void print(int (*matrix)[10],int rowSize)// 等价于void print(int matrix[][10], int rowSize) 6.2.5 main:处理命令行选项 main函数传递实参可以通过命令行选项通过两个形参传递给main函数 int main(int argv, char *argv[]) 第一个形参argc表示数组中字符串的数量 第二个形参argv是一个数组,它的元素是指向C风格字符串的指针 6.2.6 含有可变形参的函数 编写处理不同数量实参的函数,两种方法 如果实参类型相同,传递一个名为initializer_list的标准库类型 如果实参的类型不同,编写可变参数模板函数 利用省略符,传递可变数量的实参,一般只用于与C函数交互的接口程序 使用initializer_list类型的形参表示函数的实参数量未知但是全部实参的类型都相同 initializer_list是一种标准库类型,用于表示某种特定类型的值的数组 initializer_list类型定义在同名的头文件中 和vector一样,initializer_list也是一种模板类型 定义initializer_list对象时,必须说明列表中所含元素的类型 和vector不一样的是,initializer_list对象中的元素永远是常量值,无法改变initializer_list对象中元素的值 省略符形参 为了C++程序访问某些特殊的C代码而设置 省略符形参应该仅仅用于C和C++通用的类型 特别应该注意的是,大多数类类型的对象在传递给省略符形参时都无法正确拷贝 省略符形参只出现在形参列表的最后一个位置 initializer_list提供的操作 解释 initializer_list&lt;T&gt; lst; 默认初始化;T类型元素的空列表 initializer_list&lt;T&gt; lst{a,b,c…}; lst的元素数量和初始值一样多;lst元素是对应初始值的副本 lst2(lst) 拷贝或赋值一个initializer_list对象不会拷贝列表中的元素;拷贝后,原始列表和副本共享元素 lst2=lst 拷贝或赋值一个initializer_list对象不会拷贝列表中的元素;拷贝后,原始列表和副本共享元素 lst.size() 列表中的元素数量 lst.begin() 首元素的指针 lst.end() 尾元素下一位置的指针 12345678910initializer_list&lt;string&gt; ls;initializer_list&lt;int&gt; li;void error_msg(initializer_list&lt;string&gt; il)&#123; for(auto beg = il.begin();beg != il.end();++beg) cout &lt;&lt; *beg &lt;&lt; &quot; &quot;; cout &lt;&lt; endl;&#125;void foo(parm_list, ...) //省略符形参 6.3 返回类型和return语句 6.3.1 无返回值函数 没有返回值的return语句只能用在返回类型是void的函数中 返回void的函数不要求非得有return语句(会隐式地执行return) 6.3.2 有返回值的函数 return语句提供了函数的结果 只要函数的返回类型不是void,则该函数内的每条return语句必须返回一个值 return语句返回值的类型必须与函数的返回类型相同,或者能隐式地转换成函数的返回类型 值是如何被返回的 返回一个值的方式和初始化一个变量或形参的方式完全一样：返回的值用于初始化调用点的一个临时量,该临时量就是函数调用的结果 若函数返回引用,则该引用仅是它所引对象的一个别名 不要返回局部变量的引用或指针 函数完成后,局部变量所占的存储空间被释放,随之指针和引用不再有效 引用返回左值 调用一个返回引用的函数得到左值,其他返回类型得到右值 可以像使用其他左值那样来使用返回引用的函数的调用,特别是,我们能为返回类型是非常量引用的函数的结果赋值 列表初始化返回值 C++11规定,函数可以返回花括号包围的值的列表 类似于其他返回结果,此处的列表也用来对表示函数返回的临时量进行初始化 如果列表为空,临时量执行值初始化;否则,返回的值由函数的返回类型决定 主函数main的返回值 允许main函数没有return语句直接结束,编译器会隐式插入一条返回0的return语句 12345678910111213141516171819char &amp;get_val(string &amp;str,string::size_type ix)&#123; return str[ix];&#125;int main()&#123; string s(&quot;a value&quot;); get_val(s,0) = &#x27;A&#x27;; //将s[0]值改为A &#125;// 返回值是引用,因此调用是个左值,和其他左值一样它也能出现在赋值运算符的左侧vector&lt;string&gt; process()&#123; //.. if(expected.empty()) return &#123;&#125;; else if(expected == actual) return &#123;&quot;functionX&quot;,&quot;okay&quot;&#125;; else return &#123;&quot;functionX&quot;,expected, actual&#125;;&#125; 6.3.3 返回数组指针 声明一个返回数组指针的函数 定义一个返回数组指针的函数,数组的维度必须跟在函数名字之后 函数的形参列表也跟在函数名字后面且形参列表应该先于数组的维度 Type (*function(parameter_list))[dimension] 尾置返回类型 在C++11中引入尾置返回类型 任何函数的定义都能使用尾置返回,但是这种形式对于返回类型比较复杂的函数最有效 尾置返回类型跟在形参列表后面并以一个-&gt;符号开头 为了表示函数真正的返回类型跟在形参列表之后,在本应该出现返回类型的地方放置一个auto 使用decltype 知道函数返回的指针指向哪个数组就可以使用decltype关键字声明返回类型 decltype并不负责把数组类型转换成对应的指针,结果是个数组 要想返回指针还必须在函数声明时加一个*符号 12345678910// 尾置返回类型// 返回一个指针,该指针指向含有10个整数的数组auto func(int) -&gt; int (*)[10];int odd[] = &#123;1,3,5,7,9&#125;;int even[] = &#123;0,2,4,6,8&#125;;decltype(odd) *arrPtr(int i)&#123; return (i%2):&amp;odd:&amp;even;&#125; 6.4 函数重载 重载函数：同一个作用域内的几个函数名字相同但形参列表不同的函数 main函数不能重载 定义重载函数 重载函数在形参数量或形参类型上不同 不允许两个参数除了返回类型外其他所有要素都相同 重载和const形参 顶层const不影响传入函数的对象 一个拥有顶层const的形参无法和另一个没有顶层const的形参区分开 形参是某种类型的指针或引用,指向的是常量对象和指向非常量对象的函数可以重载,此时的const是底层的 const_cast和重载 const_cast在重载函数的情景中最有用const_cast 函数匹配：把函数调用与一组重载函数中的某一个关联起来。编译器首先将调用的实参与重载集合中每一个函数的形参进行比较,然后根据比较的结果决定到底调用哪个函数 在内层作用域中声明名字,将隐藏外层作用域中声明的同名实体 在不同的作用域中无法重载函数名 123456789const string &amp;shorterString(const string &amp;s1, const string &amp;s2)&#123; return s1.size() &lt;= s2.size() ? s1 : s2;&#125;string &amp;shorterString(string &amp;s1, string &amp;s2)&#123; auto &amp;r = shorterString(const_cast&lt;const string&amp;&gt;(s1), const_cast&lt;const string&amp;&gt;(s2)); return const_cast&lt;string&amp;&gt;(r);&#125; 6.5 特殊用途语言特性 6.5.1 默认实参 调用含有默认实参的函数时,可以包含该实参,也可以省略该实参 默认实参初始化 局部变量不能作为默认实参 只要表达式的类型能转换成形参所需的类型,该表达式就能作为默认实参 函数的后续声明只能为之前那些没有默认值的形参添加默认实参,而且该形参右侧的所有形参必须都有默认值 用作默认实参的名字在函数声明所在的作用域内解析,名字的求值过程发生在函数调用时 6.5.2 内联函数和constexpr函数 内联函数：通常就是将它在每个调用点上内联地展开消除在运行时的开销 在返回类型前面加关键字inline就可以声明为内联函数 一般来说,内联机制用于优化规模较小、流程直接、频繁调用的函数 constexpr函数是指能用于常量表达式的函数 定义constexpr函数：函数的返回类型及所有形参的类型都得是字面值类型,而且函数体中必须有且只有一条return语句 执行该初始化任务时,编译器把对constexpr函数的调用替换成其结果值 为了能在编译过程中随时展开,constexpr函数被隐式地指定为内联函数 constexpr函数体内也可以包含其他语句,只要这些语句在运行时不执行任何操作就行 例如,constexpr函数中可以有空语句、类型别名以及using声明 constexpr函数不一定返回常量表达式 内联函数和constexpr函数经常放在头文件中 1234567// 内联版本inline const string &amp;shorterString(const string &amp;s1, const string &amp;s2)&#123; return s1.size() &lt;= s2.size() ? s1 : s2;&#125;constexpr int new_sz()&#123;return 42;&#125;constexpr int foo = new_sz; //正确 6.5.3 调试帮助 屏蔽调试代码的方法 assert NDEBUG assert预处理宏 assert是一种预处理宏(预处理变量),类似于内联函数,定义在cassert文件中 预处理名字由预处理器而非编译器管理,可以直接使用预处理名字而无须提供using声明 assert宏使用一个表达式作为它的条件: assert(expr); 首先对expr求值,如果表达式为假,assert输出信息并终止程序的执行;为真,assert什么也不做 assert宏常用于检查“不能发生”的条件 NDEBUG assert的行为依赖于一个名为NDEBUG的预处理变量的状态 定义NDEBUG能避免检查各种条件所需的运行时开销,当然此时根本就不会执行运行时检查 可以把assert当成调试程序的一种辅助手段 预处理器定义了对于程序调试很有用的名字 _ FILE _ 存放文件名的字符串字面值 _ LINE _ 存放当前行号的整型字面值 _ TIME _ 存放文件编译时间的字符串字面值 _ DATE _ 存放文件编译日期的字符串字面值 _ func _当前调试的函数的名字 1234567891011// 使用#define语句定义NDEBUG从而关闭调试状态$ CC -D NDEBUG main.c// 等价于在main.c文件的一开始写#define NDEBUG// 可以使用NDEBUG编写自己的条件调试代码// 如果NDEBUG未定义,将执行#ifndef和#endif之间的代码;如果定义了NDEBUG,这些代码将被忽略掉void print(const int ia[], size_t size)&#123; #ifndef NDEBUG cerr &lt;&lt; __func__ &lt;&lt; size &lt;&lt; endl; #endif&#125; 6.6 函数匹配 函数匹配步骤 第一步是选定本次调用对应的重载函数集,集合中的函数称为候选函数 候选函数具备两个特征：一是与被调用的函数同名,二是其声明在调用点可见 第二步考察本次调用提供的实参,然后从候选函数中选出能被这组实参调用的函数,这些新选出的函数称为可行函数 可行函数也有两个特征：一是其形参数量与本次调用提供的实参数量相等,二是每个实参的类型与对应的形参类型相同,或者能转换成形参的类型 如果函数含有默认实参,则在调用该函数时传入的实参数量可能少于它实际使用的实参数量 第三步是从可行函数中选择与本次调用最匹配的函数 如果有且只有一个函数满足下列条件,则匹配成功： 该函数每个实参的匹配都不劣于其他可行函数需要的匹配 至少有一个实参的匹配优于其他可行函数提供的匹配 6.6.1 实参类型转换 为了确定最佳匹配,编译器将实参类型到形参类型的转换划分成几个等级,具体排序如下所示： 精确匹配,包括以下情况： 实参类型和形参类型相同。 实参从数组类型或函数类型转换成对应的指针类型 向实参添加顶层const或者从实参中删除顶层const。 通过const转换实现的匹配 通过类型提升实现的匹配 通过算术类型转换或指针转换实现的匹配 6.7 函数指针 函数指针指向的是函数而非对象 函数指针指向某种特定类型,函数的类型由它的返回类型和形参类型共同决定,与函数名无关 声明函数指针：在函数声明中,只需要用指针替换函数名即可 12345// 定义pf函数指针bool (*pf)(const string &amp;, const string &amp;); //未初始化// *pf两端的括号必不可少// 如果不写这对括号,则pf是一个返回值为bool指针的函数bool *pf(const string &amp;, const string &amp;); //未初始化 使用函数指针 把函数名作为一个值使用时,该函数自动地转换成指针 直接使用指向函数的指针调用该函数,无须提前解引用指针 可以为函数指针赋一个nullptr或者值为0的整型常量表达式,表示该指针没有指向任何一个函数 重载函数指针：如果定义了指向重载函数的指针,编译器通过指针类型决定选用哪个函数,指针类型必须与重载函数中的某一个精确匹配 12345678910111213141516171819// pf函数指针pf = lengthCompare; //pf指向lengthCompare函数pf = &amp;lengthCompare; //等价赋值语句bool b1 = pf(&quot;hello&quot;,&quot;goodbye&quot;); //调用lengthCompare函数string::size_type sumLength(const string&amp;,const string&amp;);bool cstringCompare(const char*, const char*);pf = 0; //正确,不指向任何函数pf = sumLength; //错误,返回类型不匹配pf = cstringCompare; //错误,形参类型不匹配pf = lengthCompare; //正确// 重载函数指针void ff(int*);void ff(unsigned int);void (*pf1)(unsigned int) = ff; //pf1指向ff(unsigned) 函数指针形参 和数组类似,虽然不能定义函数类型的形参,但形参可以是指向函数的指针 形参看起来是函数类型,但实际上当作指针使用 直接把函数作为实参,会自动转换成指针 返回指向函数的指针 必须把返回类型写出指针形式,编译器不会自动地将函数返回类型当成对应的指针类型处理 要想声明一个返回函数指针的函数,最简单的办法是使用类型别名 和函数类型的形参不一样,返回类型不会自动地转换成指针;需要显式地将返回类型指定为指针 可以使用尾置返回类型的方式声明一个返回函数指针的函数 将auto和decltype用于函数指针类型 如果明确知道返回的函数是哪一个,就能使用decltype简化书写函数指针返回类型的过程 将decltype作用于某个函数时,返回函数类型而非指针类型 需要显式地加上*以表明我们需要返回指针,而非函数本身 12345678910111213141516171819202122void useBigger(const string &amp;s1, const string &amp;s2, bool pf(const string &amp;, const string &amp;));// 等价显式定义为指向函数的指针void useBigger(const string &amp;s1, const string &amp;s2, bool (*pf)(const string &amp;, const string &amp;));// 自动将函数转换为函数指针useBigger(s1,s2,lengthCompare);// 返回指向函数的指针using F = int(int *, int); //F是函数类型,不是指针using PF = (int*)(int *,int); //PF是指针类型PF f1(int); //正确;PF是指向函数的指针,f1返回指向函数的指针F *f1(int); //正确;显式指定返回类型是指向函数的指针//等价声明int (*f1(int))(int*,int);//照由内向外的顺序阅读这条声明语句：我们看到f1有形参列表,所以f1是个函数// f1前面有*,所以f1返回一个指针;进一步观察发现,指针的类型本身也包含形参列表,因此指针指向函数,该函数的返回类型是intauto f1(int) -&gt; int (*) (int*,int); 7 类 类的基本思想是数据抽象和封装 数据抽象是一种依赖于接口和实现分离的编程技术 类的接口包括用户所能执行的操作; 类的实现则包括类的数据成员,负责接口实现的函数体以及定义类所需的各种私有函数 封装实现了类的接口和实现的分离 封装后的类隐藏了它的实现细节 7.1 定义抽象数据类型 7.1.1 定义改进的类 成员函数的声明必须在类的内部,定义既可以在类的内部也可以在类的外部 定义在类内部的函数是隐式的inline函数 作为接口组成部分的非成员函数,定义和声明在类的外部 this参数 成员函数通过一个名为this的额外的隐式参数来访问调用它的哪个对象 this是一个常量指针,总是指向这个对象 在成员函数内部,可以直接使用调用该函数的对象的成员,而无须成员访问运算符, 因为this所指的正是这个对象,任何对类成员的直接访问都被看作this的隐式引用 引入const成员函数(常量成员函数) 默认情况下,this的类型是指向类类型非常量版本的指针常量 因此在默认情况下,不能把this绑定在常量对象上,不能在常量对象上调用普通的成员函数 修改为指向常量的指针常量,需要在参数列表后添加const关键词,表示this是指向常量的指针常量 常量对象,以及常量对象的引用或指针都只能调用常量成员函数 在类的外部定义成员函数,定义需要与声明匹配,类外部定义的成员的名字必须包含所属的类名,使用::作用符 定义返回this对象的函数 函数的返回类型为类,return语句返回*this 1234567891011121314151617181920212223242526// 常量成员函数std::string isbn() const&#123; return bookNo;&#125;// 等价于std::string Sales_data::isbn(const Sales_data *const this)&#123; return this-&gt;isbn;&#125;// 定义返回this对象的函数Sales_data&amp; Sales_data::combine(const Sales_data &amp;rhs)&#123; units_sold += rhs.units_dold; revenue += tho.revenue; return *this;&#125;total.combine(trans); // 更新total的值// total的地址被绑定到隐式的this参数上,而rhs绑定到了trans上。// 效果等同于求total.units_sold和trans.unit_sold的和,然后把结果保存到total.units_sold中// 无须使用隐式的this指针访问函数调用者的某个具体成员,而是需要把调用函数的对象当成一个整体来访问：return *this;// 其中,return语句解引用this指针以获得执行该函数的对象,调用返回total的引用 7.1.3 定义类相关的非成员函数 如果函数在概念上属于类但是不定义在类中,则它一般应与类声明(而非定义)在同一个头文件内 在这种方式下,用户使用接口的任何部分都只需要引入一个文件 7.1.4 构造函数 构造函数：初始化类对象的数据成员,无论何时只要类的对象被创建,就会执行函数 构造函数的名字和类名相同,但构造函数没有返回类型 构造函数不能声明为const,直到构造函数完成初始化过程,对象才能真正取得其常量属性,构造函数在const对象的构造过程中可以向其写值 合成的默认构造函数 类通过一个特殊的构造函数来控制默认初始化过程 如果存在类内的初始值,用它来初始化成员,否则默认初始化该成员 不能合成默认构造函数的情况 类没有声明任何构造函数,编译器会自动合成默认构造函数 类包含有内置类型或复合类型的成员,则只有当这些成员全都被赋予了类内的初始值,这个类才适合使用默认的构造函数 =default 在C++11中,需要默认的行为,可以在参数列表后写上 =default 来要求编译器生成构造函数 =default 既可以和声明一起出现在类的内部(默认构造函数为内联函数),可以作为定义出现在类外部 构造函数初始化列表 构造函数冒号后的部分为构造初始化列表,构造函数初始值是成员名字的一个列表,每个名字后面紧跟着括号括起来的成员初始值,不同成员的初始化通过逗号分隔开 负责新创建的对象的一个或几个数据成员赋初值 类的外部定义构造函数：使用 类名::类名 的结构 7.1.5 拷贝,赋值和析构 编译器可以合成拷贝,赋值和析构函数,但生成的版本可能无法正常工作 7.2 访问控制与封装 使用访问说明符加强类的封装性 定义在public说明符之后的成员在整个程序内可被访问 public成员定义类的接口 定义在private说明符之后的成员可被类的成员函数防备,但不能在使用类的代码访问 private部分封装了类的实现细节 使用class或struct关键字 使用class关键字定义类,成员默认是private的 使用struct关键字定义类,成员默认是public的 7.2.1 友元 友元：类可以允许其他类或者函数访问它的非共有成员,方法是令其他类或函数成为它的友元 只需要增加一条以friend关键字开始的函数声明语句即可 友元声明只能出现在类定义的内部,但类出现的具体位置不限 友元不是类的成员也不受它所在区域访问控制级别的约束,最好再类定义开始或结束前的位置声明友元 封装的好处 确保用户代码不会无意间破坏封装对象的状态 被封装的类的具体实现细节可以随时改变,而无须调整用户级别的代码 防止由于用户的原因造成数据被破坏 友元的声明 如果希望类的用户能够调用某个友元函数,那么就必须在友元声明之外再专门对函数进行一次声明 为了使友元对类的用户可见,通常把友元的声明与类本身放置在同一个头文件中(类的外部) 需要调用的友元函数,在类的外部需再次声明 7.3 类的其他特性 7.3.1 类成员再探 类内部的成员函数自动是inline的 可以在类内部把inline显式声明,但不推荐;最好在类外部定义的地方声明inline 成员函数可以被重载 可变数据成员 使用mutable关键字 一个可变数据成员永远不会是const,即使是const对象的成员 一个const成员函数可以改变一个可变成员的值 在C++11中将默认值声明成类内初始值,可以在默认初始化时拥有默认初始值 类内初始值必须使用=的初始化形式或者花括号括起来的直接初始化形式 12345678910111213class Screen&#123; public: void some_member() const; private: mutable size_t access_ctr; //即使在const对象内也能被修改&#125;void Screen::some_member() const&#123; ++access_ctr;&#125;// 尽管some_member是一个const成员函数,它仍然能够改变access_ctr的值// 该成员是个可变成员,因此任何成员函数,包括const函数在内都能改变它的值 7.3.2 返回*this的成员函数 定义返回this对象的函数 从const成员函数返回*this 一个const成员函数如果以引用的形式返回*this,那返回类型将是常量引用 函数声明中返回的是const类型的类引用 基于const的重载 区分成员函数是否是const可以对函数进行重载 非常量版本的函数对常量对象是不可用的,需要在一个常量对象上调用const成员函数;但可以在非常量对象上调用const成员函数,但建议显式匹配 7.3.3 类类型 每个类定义了唯一的类型,即使两个类的成员列表完全一致,也是不同的类型 可以把类名作为类型的名字使用,从而直接指向类类型 或者,也可以把类名跟在关键字class或struct后面 类的声明：声明类而暂时不定义 class 类名; 声明称为前向声明,向程序中引入类,但声明类之后类是一个不完全类型,不清楚包括哪些成员 7.3.4 友元再探 类之间的友元关系 友元类的成员函数可以访问此类包括非公有成员在内的所有成员 友元关系不存在传递性,每个类负责控制自己的友元类或友元函数 令成员函数作为友元 当把一个成员函数声明为友元时,必须知名成员函数属于哪个类 函数重载和友元 一个类想把一组重载函数声明为它的友元,需要对这组函数中的每一个分别声明 友元声明和作用域 类和非成员函数的声明不是必须在友元声明之前 在类的内部定义该函数,必须在类的外部提供相应的声明从而使得函数可见 即使仅仅是用声明友元的类的成员调用该友元函数,它也必须是被声明过的 1234567891011121314151617181920class Screen&#123; // windos_mgr::clear必须在Screen类之前被声明 friend void Window_mgr::clear(ScreenIndex); // Screen类的剩余部分&#125;// 必须按照如下方式设计程序：// · 首先定义Window_mgr类,其中声明clear函数,但是不能定义它。在clear使用Screen的成员之前必须先声明Screen// · 接下来定义Screen,包括对于clear的友元声明// · 最后定义clear,此时它才可以使用Screen的成员struct X&#123; friend void f()&#123;&#125; X()&#123;f();&#125; void g(); void h();&#125;void X::g()&#123;return f();&#125; //错误f()未声明void f();void X::h()&#123;return f();&#125; //正确 7.4 类的作用域 在类的作用域之外,普通的数据和函数成员只能由对象,引用或指针使用成员访问运算符进行访问 对于类类型成员使用作用域运算符::来访问 当成员函数定义在类的外部时,返回类型中使用的名字都位于类的作用域之外时,返回类型必须指明它是哪个类的成员 7.4.1 名字查找与类的作用域 内层作用域可以重新定义外层作用域中的名字,即使该名字已经在内层作用域中使用过 在类中,如果成员使用了外层作用域中的某个名字,而该名字代表一种类型,则类不能在之后重新定义该名字 在类中,成员函数中定义的成员会隐藏类中的同名成员,但可以使用类名或this指针强制访问成员 12345678910111213141516171819202122232425262728293031323334353637typedef double Money;class Accout&#123; public: Money balance()&#123; return bal; &#125; private: typedef double Money; //错误,不能重新定义&#125;class Screen&#123; public: typedef std::string::size_type pos; void dummy_fcn(pos height)&#123; cursor = width * height; //是那个参数 &#125; private: pos cursor = 0; pos height = 0, width = 0;&#125;// 不建议的写法,成员函数中的名字不应该隐藏同名的成员void Screen::dummy_fcn(pos height)&#123; cursor = width * this-&gt;height; //成员height // 或 cursor = width * Screen::height; &#125;// 建议的写法：不要把成员名字作为参数或其他局部变量使用void Screen::dummy_fcn(pos ht)&#123; cursor = width * height; //成员height&#125;// 不建议的写法,不应该隐藏外层作用域中可能用到的名字void Screen::dummy_fcn(pos height)&#123; cursor = width * ::height; //全局的height&#125; 7.5 构造函数再探 7.5.1 构造函数初始值列表 初始化const或引用类型的唯一机会就是通过构造函数初始值 如果成员是const,引用,或者属于某种未提供默认构造函数的类类型,我们必须通过构造函数初始值列表为这些成员提供初值 建议：使用构造函数初始值 在很多类中,初始化和赋值的区别事关底层效率问题：前者直接初始化数据成员,后者则先初始化再赋值 除了效率问题外更重要的是,一些数据成员必须被初始化 构造函数初始值列表中初始值的前后位置关系不会影响实际的初始化顺序 但一个成员是用于另一个成员初始化时,位置关系较为重要 最好令构造函数初始值的顺序与成员声明的顺序保持一致。而且若可能的话,尽量避免使用某些成员初始化其他成员 123456789101112class ConstRef&#123; public: ConstRef(int ii); private: int i; const int ci; int &amp;ri;&#125;// 构造函数体一开始执行,初始化就完成了// 显式初始化引用和const成员ConstRef::ConstRef(int ii): i(ii), ci(ii), ri(i)&#123;&#125; 7.5.2 委托构造函数 C++11中扩展了构造函数初始值的功能,可以定义委托构造函数 委托构造函数使用它所属类的其他构造函数执行自己的初始化过程,它把自己的一些职责委托给了其他构造函数 委托构造函数具有成员初始化列表和一个函数体,成员初始化列表只有类名本身一个入口 成员初始值:类名后面紧跟着圆括号形成的参数列表,参数列表必须和类中另外一个构造函数匹配 先执行该构造函数的函数体代码再执行被委托构造函数的函数体 123456789class Sales_data&#123; public: Sales_data(std::string s, unsigned cnt, double price): bookNo(s), units_sold(cnt), revenue(cnt*price)&#123;&#125; // 其他构造函数委托给另一个构造函数 Sales_data() : Sales_data(&quot;&quot;,0,0)&#123;&#125; Sales_data(std::string s) : Sales_data(s,0,0)&#123;&#125; Sales_data(std::istream &amp;is) : Sales_data&#123;read(is,*this);&#125;&#125;; 7.5.3 默认构造函数的作用 当对象被默认初始化或值初始化时自动执行默认构造函数 默认初始化在以下情况下发生： 当我们在块作用域内不使用任何初始值定义一个非静态变量或者数组时 当一个类本身含有类类型的成员且使用合成的默认构造函数 当类类型的成员没有在构造函数初始值列表中显式地初始化时显式初始化 值初始化在以下情况下发生 在数组初始化的过程中如果我们提供的初始值数量少于数组的大小时 当我们不使用初始值定义一个局部静态变量时,局部对象 当我们通过书写形如T( )的表达式显式地请求值初始化时,其中T是类型名(vector的一个构造函数只接受一个实参用于说明vector大小,它就是使用一个这种形式的实参来对它的元素初始化器进行值初始化) 7.5.4 隐式的类类型转换 类定义隐式转换规则:如果构造函数只接受一个实参,则它实际上定义了转换为此类类型的隐式转换机制,这种构造函数称作转换构造函数 在需要该类对象的地方,可以使用其他可转换的对象类型作为替代 只允许一步类型转换,编译器指挥自动地执行一步类型转换 可以将构造函数声明为explicit抑制构造函数定义的隐式转换 explicit只对一个实参的构造函数有效 explicit构造函数只能用于直接初始化 发生隐式转换的一种情况是当执行拷贝形式(=)的初始化时 以直接初始化的形式可以使用explicit构造函数抑制自动转换 123456789101112string null_book = &quot;9-999-99999-9&quot;;// 构造一个临时的Sales_data对象item.combine(null_book);// 错误,两步转换item.combine(&quot;9-999-99999-9&quot;);// 正确item.combine(string(&quot;9-999-99999-9&quot;));// 显式构造item.combine(Sales_data(null_book));item.combine(static_cast&lt;Sales_data&gt;(cin)); 7.5.5 聚合类 聚合类使得用户可以直接访问其成员,并且具有特殊的初始化语法形式 当一个类满足如下条件时,为聚合的： 所有成员都是public的 没有定义任何构造函数 没有类内初始值,参考 没有基类,也没有virtual函数 可以使用花括号的成员初始值列表初始化聚合类的数据成员 初始值的列表必须和声明的顺序一致 初始值列表中的元素个数少于类的成员数量,靠后的成员被值初始化 123456struct Data&#123; int ival; string s;&#125;;Data vall = &#123;0, &quot;Anna&#125;; 7.5.6 字面值常量类 constexpr,其中提到constexpr函数的参数和返回值都必须是字面值类型 字面值类型的类可能含有constexpr函数成员 成员必须符合constexpr函数的所有要求,是隐式const的 数据成员都是字面值类型的聚合类是字面值常量类 如果一个类不是聚合类,但符合下述要求,则也是一个字面值常量类： 数据成员都必须是字面值类型 类必须至少含有一个constexpr构造函数 如果一个数据成员含有类内初始值,则内置类型成员的初始值必须是一条常量表达式;或者如果成员属于某种类类型,则初始值必须使用成员自己的constexpr构造函数 类必须使用析构函数的默认定义 constexpr构造函数 字面值常量类的构造函数可以是constexpr函数 constexpr构造函数可以声明成=default的形式(或者是删除函数的形式) 否则,constexpr构造函数就必须既符合构造函数的要求(意味着不能包含返回语句),又符合constexpr函数的要求(意味着它能拥有的唯一可执行语句就是返回语句 由上述可知,constexpr构造函数体一般来说应该是空的 constexpr构造函数必须初始化所有数据成员,初始值或者使用constexpr构造函数,或者是一条常量表达式 constexpr构造函数用于生成constexpr对象以及constexpr函数的参数或返回类型 12345678910111213141516171819202122232425// 字面值常量类class Debug&#123; public: constexpr Debug(bool b = true): hw(b),io(b),other(b)&#123;&#125; constexpr Debug(bool h, bool i, bool o): hw(h),io(i),other(o)&#123;&#125; constexpr bool any()&#123;return hw||io||other;&#125; void set_io(bool b)&#123;io=b;&#125; void set_hw(bool b)&#123;hw=b;&#125; void set_other(bool b)&#123;hw=b;&#125; private: bool hw; bool io; bool other;&#125;// constexpr构造函数用于生成constexpr对象以及constexpr函数的参数或返回类型constexpr Debug io_sub(false,true,false); //调试io// 等价于if(io_sub.any()) cerr &lt;&lt; &quot;print error&quot; &lt;&lt;endl;constexpr Debug prod(false); //无调试// 等价于if(prod.any()) cerr &lt;&lt; &quot;print error&quot; &lt;&lt;endl; 7.6 类的静态成员 声明静态成员 声明成员为static使得其与类关联在一起 可以是public或private,可以是常量,引用,指针,类类型等 类的静态成员存在于任何对象之外,对象中不包含任何与静态数据成员有关的数据 静态成员函数不会与任何对象绑定在一起,不包含this指针 静态成员函数不能声明称const,且不能在静态成员函数中使用this指针 通过**作用域运算符::**访问静态成员,可以使用类的对象,引用或指针来访问静态成员。 成员函数不用通过作用域运算符就可以直接访问静态成员 定义静态成员 可以在类的内部或外部定义静态成员函数 在类的外部定义静态成员时,不能重复static关键字,该static关键字只能出现在类内部的声明中 静态数据成员不属于类的任何一个对象,不是由类的构造函数初始化的,因此需要在类的外部定义和初始化每个静态成员,静态数据只能定义一次,且存在于程序的整个声明周期 静态成员的类内初始化 通常情况下,类的静态成员不应该在类的内部初始化 然而,可以为静态成员提供const整数类型的类内初始值,不过要求静态成员必须是字面值常量类型的constexpr 即使一个常量静态数据成员在类内部被初始化了,通常情况下也应该在类的外部定义一下该成员 静态数据可以作为默认实参,非静态数据成员不能作为默认实参,因为它的值本身属于对象的一部分 12345678910111213141516// 定义并初始化一个静态成员double Account::interestRate = initRate();// 该对象是类Account的静态成员,其类型是double// 从类名开始,这条定义语句的剩余部分就都位于类的作用域之内了// 因此,可以直接使用initRate函数// 注意,虽然initRate是私有的,也能用它初始化interestRate// 静态成员的类内初始化class Account&#123; public: static double rate() &#123;return interestRate;&#125; static void rate(double); private: static constexpr int period = 30; //常量表达式 double daily_tbl[period];&#125; 8 IO库 io库的基础设施 istream ostream cin cout cerr &gt;&gt; &lt;&lt; getline() 8.1 IO类 IO库类型和头文件 类型 iostream istream,wistream从流读取数据 ostream,wistream向流写入数据 iostream,wiostream读写流 fstream ifstream,wifstream从文件读取数据 ofstream,wofstream向文件写入数据 fstream,wfstream读写文件 sstream istringstream,wistringstream从string读取数据 ostringstream,wostringstream向string写入数据 stringstream,wstringstream读写string 宽字符版本的类型和函数的名字以w开始 wcin,wcout和wcerr对应cin,cout,cerr IO类型间的关系 概念上,设备类型和字符大小都不会影响要执行的IO操作 标准库使我们可以忽略不同类型的流之间的差异,是通过继承机制实现的 8.1.1 IO对象无拷贝或赋值 不能拷贝或对IO对象赋值,因此不能将形参或返回类型设置为流类型 进行IO操作的函数通常以引用方式传递和返回流,读写一个IO对象会改变其状态,传递和返回引用不能是const 8.1.2 条件状态 IO库条件状态 - strm::iostate strm是一种IO类型,iostate是一种机器相关的类型,提供了表达条件状态的完整功能 strm::badbit 指出流已崩溃 strm::failbit 指出一个IO操作失败 strm::eofbit 指出流到达了文件结束 strm::goodbit 指出流未处于错误状态 s.eof() 若流s的eofbit置位,则返回true s.fail() 若流s的failbit或badbit置位,则返回true s.bad() 若流s的badbit置位,则返回true s.good() 若流s处于有效状态,则返回true s.clear() 若流s中所有条件状态位复位,将流的状态设置位有效,返回void s.clear(flags) 根据给定的flags标志位,将流s中对应条件状态位复位。flags的类型位strm::iostate。返回void s.setstate(flags) 根据给定的flags标志位,将流s中对应条件状态位置位。flags的类型位strm::iostate。返回void s.rdstate() 返回流s的当前条件状态,返回类型位strm::iostate IO库定义了一个与机器无关的iostate类型,提供了表达流状态的完整功能,这个类型作为一个位集合使用 IO库定义了4个iostate类型的constexpr值,表示特定的位状态 badbit表示系统级错误,通常情况下,一旦badbit被置位,流就无法再使用了 在发生可恢复错误后,failbit被置位,通常是可以修正的,流还可以继续使用 如果到达文件结束位置,eofbit和failbit都会被置位 goodbit的值为0,表示流未发生错误 管理条件状态 流对象的rdstate成员返回一个iostate值,对应流的当前状态 123456789// 记住cin当前状态// clear不接受参数的版本清除(复位)所有错误标志位auto old_state = cin.rdstate();cin.clear();process_input(cin); //使用cincin.setstate(old_state); //置位会原有状态// 带参数的clear版本接受一个iostate值,表示流的新状态// 复位failbit和badbit,其他位保持不变cin.clear(cin.rdstate &amp; ~cin.failbit &amp; ~cin.badbit); 8.1.3 管理输出缓冲 每个输出流都管理一个缓冲区,用来保存程序读写的数据 导致缓冲刷新的原因 程序正常结束,作为main函数的return操作的一部分,缓冲刷新被执行 缓冲区满时,需要刷新缓冲,而后新的数据才能继续写入缓冲区 可以使用操纵符如endl来显式刷新缓冲区 在每个输出操作之后,可以用操纵符unitbuf设置流的内部状态,来清空缓冲区 默认情况下,对cerr是设置unitbuf的,因此写到cerr的内容都是立即刷新的 一个输出流可能被关联到另一个流。在这种情况下,当读写被关联的流时,关联到的流的缓冲区会被刷新 默认情况下,cin和cerr都关联到cout。因此,读cin或写cerr都会导致cout的缓冲区被刷新 刷新输出缓冲区 endl IO库中的flush和ends flush刷新缓冲区,但不输出任何额外的字符 ends向缓冲区插入一个空字符,然后刷新缓冲区 unitbu操作符 可控制不每次输出操作后都刷新缓冲区 nounitbu重置流,使其恢复正常使用 程序崩溃,输出缓冲区不会被刷新 关联输入和输出 当一个输入流被关联到一个输出流时,任何试图从输入流读取数据的操作都会先刷新关联的输出流 标准库将cout和cin关联在一起 tie有两个重载的版本 不带参数：返回指向输出流的指针(如果本对象当前关联到一个输出流,则返回的就是指向这个流的指针,如果对象未关联到流,则返回空指针) 接受一个指向ostream的指针：将自己关联到此ostream( x.tie(&amp;o)将x关联到输出流o) 123456789101112cout&lt;&lt;&quot;hi&quot;&lt;&lt;endl;cout&lt;&lt;&quot;hi&quot;&lt;&lt;flush;cout&lt;&lt;&quot;hi&quot;&lt;&lt;ends;cout &lt;&lt; unitbuf;cout &lt;&lt; nounitbuf;cin.tie(&amp;cout);ostream *old_tie = cin.tie(nullptr);cin.tie(&amp;cerr);cin.tie(old_tie); 8.2 文件输入输出 头文件fstream定义了三个类型来支持文件IO： ifstream从一个给定文件读取数据 ofstream向一个给定文件写入数据 fstream可以读写给定文件 使用IO运算符读写文件,可以用getline从一个ifstream读取数据 fstream特有的操作 - fstream fstrm 创建一个未绑定的文件流。fstream时头文件fstream中定义的一个类型 fstream fstrm(s) 创建一个未绑定的文件流,并打开名为s的文件 fstream fstrm(s,mode) 创建一个未绑定的文件流,以mode打开名为s的文件 fstrm.open(s) 打开名为s的文件,并将文件与fstrm绑定 fstrm.close() 关闭于fstrm绑定的文件,返回void fstrm.is_open() 返回一个bool值,指出与fstrm关联的文件是否成功打开且尚未关闭 8.2.1 使用文件流对象 想要读写一个文件时,可以定义一个文件流对象,并将对象与文件关联起来,每个文件流类都定义了一个名为open的成员函数,完成一些系统相关的操作,用来定位给定的文件,并视情况打开为读或写模式 用fstream代替iostream&amp; 在要求使用基类型对象的地方,可以用继承类型的对象来替代 接受一个iostream类型引用(或指针)参数的函数,可以用一个对应的fstream(或sstream)类型来调用 如果有一个函数接受一个ostream&amp;参数,在调用这个函数时,可以传递给它一个ofstream对象,对istream&amp;和ifstream也是类似的 成员函数open和close 定义一个文件流对下昂,随后可以调用open将文件关联起来(调用open失败,failbit会被置位) 自动析构：当一个fstream对象被销毁时,close会自动被调用 1234567891011121314151617181920212223242526272829ifstream in(ifile); //构建一个ifstream并代开给定文件ofstream out; //输出文件流未关联到任何文件ifstream input(argv[1]); //打开销售记录文件ofstream output(argv[2]);Sales_data total;if(read(input,total))&#123; Sales_data trans; while(read(input,trans))&#123; if(total.isbn()==trans.isbn()) total.combine(trans); else&#123; print(output,total)&lt;&lt;endl; total = trans; &#125; &#125; print(out,total) &lt;&lt;endl;&#125; else cerr&lt;&lt;&quot;No data?!&quot;&lt;&lt;endl;// open文件流ifstream in(ifile);ofstream out;out.open(ifile + &quot;.copy&quot;);if(out) //检测open是否成功in.close;in.open(ifile + &quot;2&quot;); 8.2.2 文件模式 文件模式 - in 以读方式打开 out 以写方式打开 app 每次写操作前均定位到文件末尾 ate 打开文件后立即定位到文件末尾 trunc 截断文件 binary 以二进制方式进行IO 只可以对ofstream或fstream对象设定out模式 只可以对ifstream或fstream对象设定in模式 只有当out也被设定时才可设定trunc模式 只要trunc没被设定,就可以设定app模式。在app模式下,即使没有显式指定out模式,文件也总是以输出方式被打开 默认情况下,即使我们没有指定trunc,以out模式打开的文件也会被截断。为了保留以out模式打开的文件的内容,我们必须同时指定app模式,这样只会将数据追加写到文件末尾;或者同时指定in模式,即打开文件同时进行读写操作 ate和binary模式可用于任何类型的文件流对象,且可以与其他任何文件模式组合使用 每个文件流类型都定义了一个默认的文件模式,当我们未指定文件模式时,就使用此默认模 与ifstream关联的文件默认以in模式打开 与ofstream关联的文件默认以out模式打开 与fstream关联的文件默认以in和out模式打开 在每次打开文件时,都要设置文件模式,可能是显式地设置,也可能是隐式地设置。当程序未指定模式时,就使用默认值 8.3 string流 istringstream从string读取数据 ostringstream向string写入数据 stringstream既可从string读数据也可向string写数据 stringstream特有地操作 - sstream strm; strm是一个未绑定的stringstream对象。sstream是头文件sstream中定义的一个类型 sstream strm(s); strm是一个sstream对象。保存string s的一个拷贝。此构造函数时explicit的 strm.str() 返回strm所保存的string的拷贝 strm.str(s) 将string s拷贝strm中。返回void 使用istringstream：当某些工作是对整行文本进行处理,而其他一些工作是处理行内的单个单词时,通常可以使用istringstream 使用ostringstream：当逐步构造输出,希望最后一起打印时,ostringstream是很有用的 9 序容器 顺序容器为程序员提供了控制元素存储和访问顺序的能力 9.1 顺序容器概述 顺序容器类型 - vector 可变大小数组。支持快速随机访问。在尾部之外的位置插入或删除元素会很慢 deque 双端队列。支持快速随机访问。在头尾位置插入/删除速度很快 list 双向链表。只支持双向顺序访问。在list中任何位置进行插入/删除操作速度都很快 forward_list 单向链表。只支持单向顺序访问。在链表任何位置进行插入/删除操作速度很快 array 固定大小数组。支持快速随机访问。不能添加或删除元素 string 与vector相似的容器,但专门用于保存字符。随机访问快。在尾部插入/删除速度快 除了固定大小的array外,其他容器都提供高效,灵活的内存管理 可以添加和删除元素,扩张和收缩容器的大小 string和vector将元素保存在连续的内存空间中 可以由元素的下标来计算其地址是非常快速的,两个容器的中间位置添加和删除元素会非常耗时 list和forward_list两个容器的设计目的是令容器任何位置的添加和删除都很快捷,但不支持元素的随机访问(为了访问元素只能遍历整个容器),其额外内存开销也很大 deque中间的位置添加或删除元素的代价很高,但在两端添加或删除元素很快,与list和forward_list添加删除元素的速度相当 C++11中新添加的类型,forward_list和array 与内置数组类似,array对象的大小是固定的 array不支持添加和删除元素以及改变容器大小的操作 forward_list的设计目标是达到与最好的手写的单向链表数据结构相当的性能 因此forward_list没有size操作,因为保存或计算其大小就会比手写链表多出额外的开销 对其他容器而言,size保证是一个快速的常量时间的操作 选择容器的基本原则 除非你有很好的理由选择其他容器,否则应使用vector 如果程序有很多小的元素,且空间的额外开销很重要,则不要使用list或forward_list 如果程序要求随机访问元素,应使用vector或deque 如果程序要求在容器的中间插入或删除元素,应使用list或forward_list 如果程序需要在头尾位置插入或删除元素,但不会在中间位置进行插入或删除操作,则使用deque 如果程序只有在读取输入时才需要在容器中间位置插入元素,随后需要随机访问元素,则 首先,确定是否真的需要在容器中间位置添加元素。当处理输入数据时,通常可以很容易地向vector追加数据,然后再调用标准库的sort函数来重排容器中的元素,从而避免在中间位置添加元素 如果必须在中间位置插入元素,考虑在输入阶段使用list,一旦输入完成,将list中的内容拷贝到一个vector中 9.2 容器库概览 每个容器都定义在一个头文件中,文件名与类型名相同,容器均为模板类 对容器可保存的元素类型的限制 顺序容器可以保存任意类型的元素,特别是,可以定义一个容器,其元素类型是另一个容器 可以为不支持特定操作需求的类型定义容器(但只能使用那些没有特殊需求的容器操作) 容器操作 - 类型别名 - iterator 此容器类型的迭代器类型 const_iterator 可以读取元素,但不能修改元素的迭代器类型 size_type 无符号整数类型,足够保存此种容器类型最大可能容器的大小 difference_type 带符号整数类型,足够保存两个迭代器之间的距离 value_type 元素类型 reference 元素的左值类型,与value_type&amp;含义相同 const_reference 元素的const左值类型,与const value_type&amp;含义相同 构造函数 - C c 默认构造函数,构造空容器 C c1(c2) 构造c2的拷贝c1 C c(b,e) 构造c,将迭代器b和e指定的范围内的元素拷贝到c C c{a,b,c…} 列表初始化c 赋值与swap - c1=c2 将c1中的元素替换成c2中元素 c1={…} 将c1中的元素替换成列表中元素 a.swap(b) 交换a和b的元素 swap(a,b) 交换a和b的元素 大小 - c.size() c中的元素数目(不支持forward_list) c.max_size() c中可保存的最大元素数目 c.empty() c保存了元素返回false 添加/删除元素(不适用于array) - c.insert(args) 将args中的元素拷贝进c c.emplace(inits) 使用inits构造c中的一个元素 c.erase(args) 删除args指定的元素 c.clear() 删除c中的所有元素 关系运算符 - ==,!= 所有容器都支持相等运算符 &lt;,&gt;=,&lt;=,&gt;= 关系运算符(无序容器不支持) 获取迭代器 - c.begin() c.end() 返回迭代器 c.cbegin() c.cend() 返回const_iterator 反向容器的额外成员(不支持forward_list - reverse_iterator 逆序寻址元素的迭代器 const_reverse_iterator 不能修改元素的逆序迭代器 c.rbegin() c.rend() 返回reverse_iterator c.crbegin() c.crend() 返回const_reverse_iterator 9.2.1 迭代器 与容器一样,迭代器有公共的接口：迭代器提供的操作的实现方式都是相同的 forward_list迭代器不支持递减运算符 迭代器范围 一个迭代器范围由一对迭代器表示,两个迭代器分别指向同一容器中的元素(begin,first)或者尾元素(end,last,尾元素的下一个元素)之间的元素 元素范围为左闭合区间 构成范围的迭代器的要求 两个迭代器begin和end构成一个迭代器 指向同一容器的元素,或者是容器最后一个元素之后的位置,且可以通过递增begin到达end 9.2.3 begin和end成员 begin和end操作生成指向容器第一个元素和尾元素之后位置的迭代器,形成一个包含容器内所有元素的迭代器范围 带r的反向迭代器 带c的返回const迭代器的版本 C++11新引入的,用于支持auto与begin和end函数相结合 当不需要写访问时,应该使用cbegin和cend 9.2.4 容器定义和初始化 容器定义和初始化 - C c 默认构造函数,构造空容器,若C是array,则c中元素按默认方式初始化 C c1(c2) 构造c2的拷贝c1 C c1 = c2 相同的容器类型,且保存的是相同的元素类型;对于array还应具有相同的大小 C c{a,b,c…} 列表初始化c C c = {a,b,c…} 列表初始化c C c(b,e) 构造c,将迭代器b和e指定的范围内的元素拷贝到c 只有顺序容器(不包括array)的构造函数才可以接受大小参数 - C seq(n) seq包含n个元素,这些元素进行值初始化;此构造函数是explicit C seq(n,t) seq包含n个初始值为t的元素 将一个容器初始化为另一个容器的拷贝 可以直接拷贝整个容器 两个容器的类型及其元素类型必须匹配 拷贝由一个迭代器对指定元素范围 新容器和原容器中元素类型可以不同,只要能将拷贝元素转换为要初始化的容器的元素类型即可 构造函数接受两个迭代器参数,为第一个元素和尾元素之后的元素 列表初始化 C++11中可以对容器进行列表初始化,显式指定容器中每个元素的值 与顺序容器大小相关的构造函数 接受一个容器大小和一个可选的元素初始值 只有顺序容器的构造函数才接受大小参数,关联容器并不支持 标准库array由固定大小 定义array时不仅要指定元素类型,也要指定大小 不支持普通的容器构造函数,一个默认构造的array非空,包含于大小一样多的默认初始化的元素 123456789101112list&lt;string&gt; authors = &#123;&quot;Milton&quot;,&quot;Shakespeare&quot;,&quot;Austen&quot;&#125;;vector&lt;const char*&gt; articles = &#123;&quot;a&quot;,&quot;an&quot;,&quot;the&quot;&#125;;list&lt;string&gt; list2(authors); //正确deque&lt;string&gt; authList(authors); //错误,容器类型不匹配forward_list&lt;string&gt; words(articles.begin(),articles.end()); //正确,可以将const char*元素转换为string//拷贝元素,直到(不包括)it指向的元素deque&lt;string&gt; authList(authors.begin(),it);array&lt;int,42&gt; //保存42个int的数组array&lt;int,10&gt;::size_type i; //数组类型包括元素类型和大小 9.2.5 赋值和swap 赋值与swap - c1=c2 将c1中的元素替换成c2中元素 c1={…} 将c1中的元素替换成列表中元素 a.swap(b) 交换a和b的元素 swap(a,b) 交换a和b的元素 assign操作不适用于关联容器和array - seq.assign(b,e) 将seq中的元素替换为迭代器b和e所表示的范围中的元素 seq.assign(il) 将seq中的元素替换为初始化列表il中的元素 seq.assign(n,t) 将seq中的元素替换为n个值为t的元素 赋值相关操作会导致指向坐标容器内部的迭代器,引用和指针失效 swap会将容器内容交换,不会导致指向容器的迭代器,引用和指针失效(容器类型为array和string除外) 使用assign(仅顺序容器) 允许从一个不同但相容的类型赋值,或者从容器的一个子序列赋值 由于其旧元素被替换,因此传递给assign的迭代器不能指向调用assign的容器 使用swap 除array外,swap不对任何元素进行拷贝、删除或插入操作,因此可以保证在常数时间内完成 9.2.7 关系运算符 每个容器类型都支持相等运算符 除了无序关联容器外的所有容器都支持关系运算符 比较两个容器实际上是进行元素的逐对比较 如果两个容器具有相同大小且所有元素都两两对应相等,则这两个容器相等;否则两个容器不等 如果两个容器大小不同,但较小容器中每个元素都等于较大容器中的对应元素,则较小容器小于较大容器 如果两个容器都不是另一个容器的前缀子序列,则它们的比较结果取决于第一个不相等的元素的比较结果 只有当其元素类型也定义了相应的比较运算符时,才可以使用关系运算符来比较两个容器 容器的相等运算符实际上是使用元素的==运算符实现比较的,而其他关系运算符是使用元素的&lt;运算符 9.3 顺序容器操作 9.3.1 向顺序容器添加元素 除array外,所有的标准库容器提供灵活的内存管理,在运行时可以动态添加或删除元素来改变容器大小 forward_list有自己版本的insert和emplace forward_list不支持push_back和emplace_back vector和string不支持push_front和emplace_front 向顺序容器添加元素的操作 - c.push_back(t) 在c的尾部创建一个值为t或由args创建的元素 c.emplace_back(t) 在c的尾部创建一个值为t或由args创建的元素 c.push_front(t) 在c的头部创建一个值为t或由args创建的元素 c.emplace_front(t) 在c的头部创建一个值为t或由args创建的元素 c.insert(p,t) 在迭代器p指向的元素之前创建一个值为t的元素。返回指向新添加元素的迭代器 c.emplace(p,args) 在迭代器p指向的元素之前创建一个值为t的元素。返回指向新添加元素的迭代器 c.insert(p,n,t) 在迭代器p指向的元素之前创建n个值为t的元素。返回指向新添加的第一个元素的迭代器 c.insert(p,b,e) 将迭代器b和e指定的范围内的元素插入到迭代器p指向的元素之前 c.insert(p,il) il是一个花括号包围的元素值列表。将这些给定值插入到迭代器p指向的元素之前。返回指向新添加的第一个元素的迭代器;若列表为空,则返回p 向一个vector,string或deque插入元素会使所有指向容器的迭代器,引用和指针失效 使用push_back 除了array和forward_list之外,每个顺序容器都支持push_back 当用一个对象来初始化容器时,或将一个对象插入到容器中时,实际上放入到容器中的是对象值的一个拷贝,而不是对象本身 使用push_front list,forward_list和deque还支持push_front,将元素插入到容器头部 deque提供了随机访问元素的能力,且支持push_front,但vector具有随机访问的能力不支持push_front,插入元素非常耗时 在容器特定位置添加元素：insert成员,vector、deque、list和string都支持insert成员,但vector、deque和string插入元素耗时 插入范围内元素：insert带参数的版本 使用emplace操作 emplace_front、emplace和emplace_back,这些操作构造而不是拷贝元素,分别对应push_front、insert和push_back,允许将元素放置在容器头部、一个指定位置之前或容器尾部 当调用push或insert成员函数时,将元素类型的对象传递给它们,这些对象被拷贝到容器中 而当调用一个emplace成员函数时,则是将参数传递给元素类型的构造函数,emplace成员使用这些参数在容器管理的内存空间中直接构造元素(传递给emplace函数的参数必须和构造函数相匹配) 123456// 在c的末尾构造一个Sales_data对象// 使用三个参数的Sales_data构造函数c.emplace_back(&quot;978-0590353403&quot;,25,15.99);// 创建一个临时的对象传递给push_backc.push_back(Sales_data(&quot;978-0590353403&quot;,25,15.99)); 9.3.2 访问元素 包括array在内的每个顺序容器都有一个front成员函数,而除forward_list之外的所有顺序容器都有一个back成员函数,分别返回首元素和尾元素的引用 间接的方法：通过解引用begin返回的迭代器来获取首元素的引用,以及通过递减然后解引用end返回的迭代器来获得尾元素的引用 at和下标操作只适用于string,vector,deque和array back不适用于forward_list 在顺序容器中访问元素的操作 - c.back() 返回c中尾元素的引用。若c为空,函数行为未定义 c.front() 返回c中首元素的引用。若c为空,函数行为未定义 c[n] 返回c中下标未n的元素的引用 c.at(n) 返回下标未n的元素引用 访问成员函数返回的是引用：在容器中访问元素的成员函数返回的都是引用 如果容器是一个const对象,则返回值是const的引用 如果使用auto变量来保存函数的返回值,使用此变量来改变元素的值,应将变量定义为引用类型 安全的随机访问：使用at函数,类似下标运算符,若下标越界则抛出out_of_range异常 9.3.3 删除元素 forward_list由特殊版本的erase forward_list不支持pop_back;vector和string不支持pop_front 删除deque中除首尾位置之外的任何元素都会使所有迭代器,引用和指针失效 指向vector或string中删除点之后位置的迭代器,引用和指针都会失效 删除元素的成员函数并不检查其参数,在删除之前必须确保它们使存在的 顺序容器的删除操作 - c.pop_back() 删除c中尾元素 c.pop_front() 删除c中首元素 c.erase(p) 删除迭代器p所指的元素,返回一个指向被删元素之后元素的迭代器,若p指向尾元素,则返回尾后迭代器 c.erase(b,e) 删除迭代器b和e所指范围内的元素 c.clear() 删除c中的所有元素,返回void 9.3.4 特殊的forward_list操作 在forward_list中插入或删除元素的操作 - lst.before_begin() 返回指向链表首元素之前不存在的元素的迭代器。此迭代器不能解引用 lst.cbefore_begin() - lst.insert_after(p,t) 在迭代器p之后的位置插入元素。t是一个对象 lst.insert_after(p,n,t) 在迭代器p之后的位置插入元素。t是一个对象,n是数量 lst.insert_after(p,b,e) b,e表示范围的一对迭代器 lst.insert_after(p,il) il是一个花括号列表 emplace_after(p,args) 使用args在p指定的位置之后创建一个元素 lst.erase_after(p) 删除p指向的位置之后的元素 lst.erase_after(b,e) 删除b之后直到e之间的元素 9.3.5 改变容器大小 resize来增大或缩小容器(array不支持resize) 如果当前大小大于所要求的大小,容器后部的元素会被删除 如果当前大小小于新大小,会将新元素添加到容器后部 顺序容器大小操作 - c.resize(n) 调整c的大小为n个元素 c.resize(n,t) 调整c的大小为n个元素,任何新添加的元素都初始化为值t 9.3.6 容器操作可能是迭代器失效 向容器中添加元素和从容器中删除元素的操作可能会使指向容器元素的指针、引用或迭代器失效。一个失效的指针、引用或迭代器将不再表示任何元素。使用失效的指针、引用或迭代器是一种严重的程序设计错误,很可能引起与使用未初始化指针一样的问题 在向容器添加元素后： 如果容器是vector或string,且存储空间被重新分配,则指向容器的迭代器、指针和引用都会失效。如果存储空间未重新分配,指向插入位置之前的元素的迭代器、指针和引用仍有效,但指向插入位置之后元素的迭代器、指针和引用将会失效 对于deque,插入到除首尾位置之外的任何位置都会导致迭代器、指针和引用失效。如果在首尾位置添加元素,迭代器会失效,但指向存在的元素的引用和指针不会失效 对于list和forward_list,指向容器的迭代器(包括尾后迭代器和首前迭代器)、指针和引用仍有效。 当我们从一个容器中删除元素后,指向被删除元素的迭代器、指针和引用会失效,这应该不会令人惊讶。毕竟,这些元素都已经被销毁了。当我们删除一个元素后： 对于list和forward_list,指向容器其他位置的迭代器(包括尾后迭代器和首前迭代器)、引用和指针仍有效 对于deque,如果在首尾之外的任何位置删除元素,那么指向被删除元素外其他元素的迭代器、引用或指针也会失效。如果是删除deque的尾元素,则尾后迭代器也会失效,但其他迭代器、引用和指针不受影响;如果是删除首元素,这些也不会受影响 对于vector和string,指向被删元素之前元素的迭代器、引用和指针仍有效。注意：当我们删除元素时,尾后迭代器总是会失效 不要保存end返回的迭代器 9.4 vector对象是如何增长的 vector和string的实现通常会分配比新的空间需求更大的内存空间,容器预留了这些文件作为备用,用来保存更多的新元素 这种策略比每次添加新元素时重新分配内存空间高效,实际性能表现的足够好 管理容器的成员函数 vector和string类型提供了一些成员函数,允许我们与它的实现中内存分配部分互动 capacity操作告诉我们容器在不扩张内存空间的情况下可以容纳多少个元素 reserve操作允许我们通知容器它应该准备保存多少个元素 shrink_to_fit只适用于vector,string和deque capacity和reserve只适用于vector和string reserve并不改变容器中元素的数量,它仅影响vector预先分配多大的内存空间 如果需求大小大于当前容量,reserve至少分配与需求一样大的内存空间(可能更大) 如果需求大小小于或等于当前容量,reserve什么也不做(且容器不会退回内存空间) 在C++11中,可以调用shrink_to_fit来要求deque、vector或string退回不需要的内存空间 此函数指出不再需要任何多余的内存空间 但具体的实现可以选择忽略此请求(调用shrink_to_fit也并不保证一定退回内存空间) 容器大小管理操作 - c.shrink_to_fit() 将capacity()减少为于size()相同大小 c.capacity() 不重新分配内存空间的话,c可以保存多少元素 c.reserve(n) 分配至少能容纳n个元素的内存空间 capacity和size size：指它已经保存的元素的数目 capacity：在不分配新的内存空间的前提下最多可以保存多少元素 每个vector实现都可以选择自己的内存分配策略 但必须遵守的一条原则：只有当迫不得已时才可以分配新的内存空间 只有在执行insert操作时size与capacity相等,或者调用resize或reserve时给定的大小超过当前capacity,vector才可能重新分配内存空间 虽然不同的实现可以采用不同的分配策略,但所有实现都应遵循一个原则： 确保用push_back向vector添加元素的操作有高效率 从技术角度说,就是通过在一个初始为空的vector上调用n次push_back来创建一个n个元素的vector,所花费的时间不能超过n的常数倍 9.5 额外的string操作 9.5.1 构造string的其他方法 容器定义和初始化方法 string支持的其他构造函数 - string s(cp,n) s是cp指向的数组中前n个字符的拷贝,此数组至少应该包括n个字符 string s(s2,pos2) s是string s2从下标pos2开始的字符的拷贝 string s(s2,pos2,len2) s是string s2从下标pos2开始len2个字符的拷贝 构造函数接受一个string或一个const char*参数 传递一个string时可以给定一个下标来指出从哪里开始拷贝 传递const char*时指针指向的数组必须以空字符结尾,拷贝操作时遇到空字符时停止 传递构造函数一个计数值,数组就不必以空字符结尾 substr操作 s.substr(pos,n) 返回一个string,包含s中从pos开始的n个字符的拷贝。pos的默认值为0.n的默认值为s.size()-pos,即拷贝从pos开始的所有字符 9.5.2 改变string的其他方法 修改string的操作 - s.insert(pos,args) 在pos之前插入args指定的字符(pos可以是下标或一个迭代器),接受下标的版本返回一个指向s的引用;接受迭代器的版本返回指向第一个插入字符的迭代器 s.erase(pos,len) 删除从位置pos开始的len个字符。若len被省略则删除所有字符。返回一个指向s的引用 s.assign(args) 将s中的字符替换args指定的字符。返回一个指向s的引用 s.append(args) 将args追加到s,返回一个指向s的引用 s.replace(range,args) 删除s中范围range内的字符,替换为args指定的字符。range或者是一个下标和一个长度,或者是一对指向s的迭代器。返回一个指向s的引用 args可以是下列形式之一; append和assign可以使用所有形式 str不能与s相同,迭代器版本b和e不能指向e - str 字符串str str,pos,len str中从pos开始最多len个字 cp,len 从cp指向的字符数组的前len个字符 cp cp指向的以空字符结尾的字符数组 n,c n个字符c b,e 迭代器b和e指定的范围内的字符 初始化列表 花括号包围的,以逗号分隔的字符列表 9.5.3 string搜索操作 每个搜索操作都返回一个string::size_type值,表示匹配发生位置的下标 如果搜索失败,则返回一个名为string::npos的static成员 标准库将npos定义为一个const string::size_type类型,并初始化为值-1 由于npos是一个unsigned类型,此初始值意味着npos等于任何string最大的可能大小 string搜索操作 - s.find(args) 查找s中args第一次出现的位置 s.rfind(args) 查找s中args最后一次出现的位置 s.find_first_of(args) 查找s中args中任何一个字符第一次出现的位置 s.find_last_of(args) 查找s中args中任何一个字符最后一次出现的位置 s.find_first_not_of(args) 查找s中第一个不在args中的字符 s.find_last_not_of(args) 查找s中最后一个不在args中的字符 args可以是下列形式之一 - c,pos 从s中位置pos开始查找字符c。pos默认值为0 s2,pos 从s中位置pos开始查找字符串s2。pos默认值为0 cp,pos 从s中位置pos开始查找指针cp指向的以空字符结尾的C风格字符串。pos默认值为0 cp,pos,n 从s中位置pos开始查找指针cp指向的数组的前n个字符。pos默认值为0 123456string::size_type pos = 0;// 每步循环查找name中下一个数while((pos=name.find_first_of(numbers,pos))!=string::npos)&#123; cout&lt;&lt;pos&lt;&lt;name[pos]&lt;&lt;endl; ++pos;&#125; 9.5.4 compare函数 s.compare的几种参数形式 - s2 比较s和s2 pos1,n1,s2 将s中从pos1开始的n1个字符与s2进行比较 pos1,n1,s2,pos2,n2 将s中从pos1开始的n1个字符与s2中从pos2开始的n2个字符进行比较 cp 比较s与cp指向的以空字符结尾的字符串数组 pos1,n1,cp 将s中从pos1开始n1的字符与cp指向的以空字符结尾的字符数组进行比较 pos1,n1,cp,n2 将s中从pos1开始n1的字符与cp指向的地址开始的n2个字符进行比较 9.5.5 数值转换 如果string不能转换为一个数值,这些函数抛出一个invalid_argument异常 如果转换得到的数值无法用任何类型来表示,则抛出一个out_of_range异常 string和数值之间的转换 - to_string 一组重载函数,返回数值val的string表示 stoi(s,p,b) 返回s的起始子串(表示整数内容),返回值类型为int stol(s,p,b) 返回s的起始子串(表示整数内容),返回值类型为long stoul(s,p,b) 返回s的起始子串(表示整数内容),返回值类型为unsigned long stoll(s,p,b) 返回s的起始子串(表示整数内容),返回值类型为long long stoull(s,p,b) 返回s的起始子串(表示整数内容),返回值类型为unsigned long long stof(s,p) 返回s的起始子串(表示浮点数内容)的数值,返回值类型为float stod(s,p) 返回s的起始子串(表示浮点数内容)的数值,返回值类型为double stold(s,p) 返回s的起始子串(表示浮点数内容)的数值,返回值类型为long double 9.6 容器适配器 顺序容器适配器：stack,queue和priority_queue 适配器是标准库中一个通用概念(容器,迭代器和函数都有适配器) 一个内容适配器接受一个已有的容器类型,使其行为看起来像一种不同的类型 所有容器适配器都支持的操作和类型 - to_string 一组重载函数,返回数值val的string表示 value_type 元素类型 container_type 实现适配器的底层容器类型 A a 创建一个名为a的空适配器 A a© 创建一个名为a的适配器,带有容器c的一个拷贝 关系运算符 运算符返回底层容器的比较结果 a.empty() 若a包含任何元素,返回false a.size() 返回a中的元素数目 swap(a,b) 交换a和b的内容,a和b必须由相同类型,包括底层容器类型也必须相同 a.swap(b) 交换a和b的内容,a和b必须由相同类型,包括底层容器类型也必须相同 定义一个适配器：默认构造函数创建一个空对象,接受一个容器的构造函数拷贝该容器来初始化适配器 默认情况下,stack和queue是基于deque实现的,priority_queue是在vector之上实现的 对于一个给定的适配器,可以使用哪些容器是有限制的 所有适配器都要求容器具有添加和删除元素的能力(适配器不能构造在array上) 类似的,也不能用forward_list来构造适配器,因为所有适配器都要求容器具有添加、删除以及访问尾元素的能力 stack只要求push_back、pop_back和back操作,因此可以使用除array和forward_list之外的任何容器类型来构造stack queue适配器要求back、push_back、front和push_front,因此它可以构造于list或deque之上,但不能基于vector构造 priority_queue除了front、push_back和pop_back操作之外还要求随机访问能力,因此它可以构造于vector或deque之上,但不能基于list构造 123456stack&lt;int&gt; stk(deq); //从deq拷贝元素到stk// 在vector上实现的空栈stack&lt;string,vector&lt;string&gt;&gt; str_stk;// str_stk2在vector上实现,初始化时保存svec的拷贝stack&lt;string,vector&lt;string&gt;&gt; str_stk2(svec); 栈适配器 stack类型定义在stack头文件中 栈默认基于deque实现,也可以在list或vector上实现的 未列出的栈操作 - s.pop() 删除栈顶元素,但不返回该元素值 s.push(item) 创建一个新元素压入栈顶,该元素通过拷贝或移动item而来 s.emplace(args) 创建一个新元素压入栈顶,该元素由args构造 s.top() 返回栈顶元素,但不将元素弹出栈 12345678910stack&lt;int&gt; intStack;// 填满栈for(size_t ix = 0;ix!=10;++ix) intStack.push(ix); //intStack保存0到9十个数while(!intStack.empty())&#123; int value = intStack.top(); // 使用栈顶值的代码 intStack.pop(); //弹出栈顶元素,继续循环&#125; 队列适配器 queue和priority_queue适配器定义在queue头文件中 标准库queue使用一种先进先出(FIFO)的存储和访问策略 priority_queue允许我们为队列中的元素建立优先级。新加入的元素会排在所有优先级比它低的已有元素之前 queue默认基于deque实现,priority_queue默认基于vector实现 queue也可以用list或vector实现,priority_queue可以用deque实现 未列出的queue和priority_queue操作 - q.pop() 返回queue的首元素或priority_queue的最高优先级的元素 q.front() 返回首元素或尾元素,但不删除此元素 q.back() 只适用于queue q.top() 返回最高优先级元素,但不删除该元素 - 只适用于priority_queue s.push(item) 在queue末尾或priority_queue中恰当的位置创建一个元素,其值为item s.emplace(args) 在queue末尾或priority_queue中恰当的位置创建一个元素,其值由args构造 10 泛型算法 10.1 概述 大多数的算法都定义在头文件algorithm中,还在头文件numeric中定义了一组数值泛型算法 一般情况下,算法不直接操作容器,而是遍历由两个迭代器指定的一个元素范围来进行操作(通常情况下,算法遍历范围,对其中每个元素进行一些处理) 迭代器令算符不依赖于容器,但算法依赖于元素类型的操作 算法永远不会执行容器的操作： 泛型算法本身不会执行容器的操作,它们只会运行于迭代器之上,执行迭代器的操作 泛型算法运行于迭代器之上而不会执行容器操作的特性带来了一个令人惊讶但非常必要的编程假定：算法永远不会改变底层容器的大小 算法可能改变容器中保存的元素的值,也可能在容器内移动元素,但永远不会直接添加或删除元素 10.2 初始泛型算法 10.2.1 只读算法 一些算法只会读取输入范围内的元素,而不改变元素 对于读取而不改变元素的算法,通常最好使用cbegin()和cend(),但若需要使用算法返回迭代器来改变元素的值,需要使用begin()和end()的结果作为参数 10.2.2 写容器元素的算法 一些算法将新值赋予序列中的元素,使用这些算法时,必须注意确保序列原大小至少不小于要求算法写入的元素数目 算法不会执行容器操作,因此自身不可能改变大小 12345// 算法fill接受一对迭代器表示一个范围,还接受一个值作为第三个参数// fill将给定的这个值赋予输入序列的每个元素fill(vec.begin(),vec.end(),0) //将每个元素重置为0// 将容器的一个子序列设置为10fill(vec.begin(),vec.begin()+vec.size()/2,10); 迭代器参数 一些算法从两个序列中读取元素。构成这两个序列的元素可以来自于不同类型的容器 操作两个序列的算法之间的区别在于如何传递第二个序列 如equal,接受三个迭代器,前两个表示第一个序列的范围,第三个表示第二个序列的首元素 用一个单一的迭代器表示第二个序列的算法都是假定第二个序列至少与第一个一样长,确保算法不会试图访问第二个序列中不存在的元素 其他算法接受四个迭代器,前两个表示第一个序列的元素范围,后两个表示第二个序列的范围 算法不检查写操作 一些算法接受一个迭代器来指出一个单独的目的位置,算法将新值赋予一个序列的元素,该序列从目的位置迭代器指向的元素开始 向目的位置迭代器写入数据的算法假定目的位置足够大,能容纳要写入的元素 12345678910111213// 可以用fill_n将一个新值赋予vector中的元素vector&lt;int&gt; vec; //空vector// 使用vec,赋予它不同值fill_n(vec.begin(), vec.size(), 0); //将所有元素重置为0// 函数fill_n假定写入指定个元素是安全的fill_n(dest, n, val)// fill_n假定dest指向一个元素,而从dest开始的序列至少包含n个元素// 在空容器上调用fill_nvector&lt;int&gt; vec; //空向量// 灾难：修改vec中的10个不存在元素fill_n(vec.begin(), 10, 0); 介绍back_inserter 一种保证算法有足够元素空间来容纳数据的方法是使用插入迭代器 插入迭代器是一种向容器中添加元素的迭代器,通常情况通过一个插入迭代器赋值时,一个与赋值号右侧值相等的元素被添加到容器中 iterator函数中back_insert函数：接受一个指向容器的引用,返回一个与该容器绑定的插入迭代器 通过此迭代器赋值时,赋值运算符会调用push_back将一个具有给定值的元素添加到容器中 1234567vector&lt;int&gt; vec; //空向量auto it = back_insert(vec);*it = 42;// 使用back_insert创建迭代器,作为算法的目的位置来使用vector&lt;int&gt; vec; //空向量fill_n(back_insert(vec),10,0); //添加10个元素到vec 拷贝算法 是另一个向目的位置迭代器指向的输出序列中的元素写入数据的算法 接受三个迭代器：前两个表示一个输入范围,第三个表示目的序列的起始位置;将输入范围内的元素拷贝到目的系列中 copy算法 replace算法：读入一个序列,并将其中所有等于给定值的元素都改为另一个值,接收4个参数,前两个是迭代器,表示输入序列,后两个一个是搜索的值,另一个是新值 replace_copy：保留原序列不变,需要支持额外的第三个迭代器参数,指出保存后序列的位置 10.2.3 重排容器元素的算法 sort算法：重排输入序列中的元素,利用元素类型的&lt;运算符来实现排序 unique算法：重排输入序列,将相邻的重复项消除,并返回一个指向不重复值范围末尾的迭代器 erase算法：删除无用元素 10.3 定制操作 很多算法会比较输入序列的元素：默认情况下,这类算法使用元素类型的&lt;或==运算符完成比较; 10.3.1 向算法传递函数 按长度重排vector,将使用sort的重载版本,接收三个参数,此参数是一个谓词 谓词：是一个可调用的表达式,其返回结果是一个能用作条件的值 接收谓词参数的算法对输入序列中的元素调用谓词,因此元素类型必须能转换为谓词的参数类型 接收二元谓词的sort版本用谓词代替&lt;来比较元素 stable_sort算法：保持等长元素间的字典序,重排输入序列中的元素 1234567// 比较函数,用来按长度排序单词bool isShorter(const string &amp;s1, const string &amp;s2)&#123; return s1.size() &lt; s2.size();&#125;// 按长度由短至长排序sort(words.begin(),words.end(),isShorter); 10.3.2 lambda表达式 可以向一个算法传递任何类别的可调用对象 对于一个对象或一个表达式,如果可以对其调用运算符,则称它为可调用的,e为一个可调用表达式,则可编写e(args),其中args是一个逗号分割的一个或多个参数列表 ==可调用对象：函数,函数指针,重载了函数调用运算符的类,lambda表达式 lambda表达式：表示一个可调用单元源代码,可理解为一个未命名的内联函数(具有返回类,参数列表和函数体),可定义在函数内部 lambda表达式的形式:[capture list](parameter list) -&gt; return type{function body} capture list是一个lambda所在函数中定义的局部变量的列表; 可以忽略参数列表和返回类型,但必须永远包含捕获列表和函数体 忽略参数列表等价于一个空参数列表,若忽略返回类型,lambda根据函数体中的代码推断出返回类型;若函数体只是一个return语句,则返回类型从返回表达式的类型推断而来 向lambda传递参数 调用lambda时给定的实参会被用来初始化lambda的形参,但不能带默认参数(因此lambda调用的实参数目永远与形参数目相等) 空捕获列表表示lambda不使用它所在函数中的任何局部变量 使用捕获列表 捕获列表指引lambda在其内部包含访问局部变量所需的信息 一个lambda通过将局部变量包含在其捕获列表中指出将会使用这些变量 一个lambda只有在其捕获列表中捕获一个它所在函数中的局部变量,才能在函数体中使用该变量 捕获列表只用于局部非static变量,lambda可以直接使用局部static变量和它所在函数之外声明的名字 for_each算法 使用for_each接收一个可调用对象,并将输入序列中每个元素调用此对象 12345678stable_sort(words.begin(),words.end(), [](const string &amp;a, const string &amp;b) &#123;return a.size() &lt; b.size();&#125;)[sz](const string &amp;a) &#123;return a.size() &gt;= sz;&#125;for_each(wc,words.end(), [](const string &amp;s) &#123;cout &lt;&lt; s &lt;&lt; &quot; &quot;;&#125;)cout &lt;&lt; endl; 10.3.3 lambda捕获和返回 当定义一个lambda时,编译器生成一个与lambda对应的新的类类型 当向一个函数传递一个lambda时,同时定义了一个新类型和该类型的一个对象：传递的参数就是此编译器生成的类类型的未命名对象(当使用auto定义一个用lambda初始化的变量时,定义了一个从lambda生成的类型的对象) 默认情况下,从lambda生成的类都包含一个对应该lambda所捕获的变量的数据成员 值捕获 被捕获的变量的值是在lambda创建时拷贝,而不是调用时拷贝 引用捕获 一个以引用方式捕获的变量与其他任何类型的引用的行为类似 在lambda函数体内使用此变量时,实际上使用的是引用所绑定的对象 采用引用方式捕获一个变量,就必须确保被引用的对象在lambda执行的时候是存在的 建议：尽量保持lambda的变量捕获简单 捕获一个普通变量,如int、string或其他非指针类型,通常可以采用简单的值捕获方式。在此情况下,只需关注变量在捕获时是否有所需的值就可以了 如果捕获一个指针或迭代器,或采用引用捕获方式,就必须确保在lambda执行时,绑定到迭代器、指针或引用的对象仍然存在。而且,需要保证对象具有预期的值 隐式捕获 让编译器根据lambda体中的代码来推断要使用变量 应在捕获列表中写一个&amp;或= &amp;告诉编译器采用捕获引用方式 =表示采用值捕获方式 混合使用隐式捕获和显式捕获时,捕获列表中的第一个元素必须是一个&amp;或=(指定了默认捕获方式为引用或值),且显式捕获和隐式捕获必须采用不同的方式 可变lambda 默认情况下,对于一个值被拷贝的变量,lambda不会改变其值,若希望能改变一个被捕获的变量的值,必须在参数列表首加上关键字mutable 可变lambda能省略参数列表 引用可以修改依赖于此引用指向的是一个const类型还是非const类型 指定lambda返回类型 为一个lambda定义返回类型时,必须使用尾置返回类型(跳转尾置返回类型) 1234567891011121314151617181920212223242526272829void fcn1()&#123; size_t v1 = 42; auto f = [v1] &#123;return v1;&#125;; v1 = 0; auto j = f(); //j值为42 // 由于被捕获变量的值是在lambda创建时拷贝,因此随后对其修改不会影响到lambda内对应的值&#125;void fcn2()&#123; size_t v1 = 42; auto f = [&amp;v1] &#123;return v1;&#125;; v1 = 0; auto j = f(); //j值为0&#125;wc = find_if(words.begin(),words.end(), [=](const string &amp;s) &#123;return s.size() &gt;= sz;&#125;)// 可变lambdavoid fcn3()&#123; size_t v1 = 42; auto f = [v1]() mutable &#123;return ++v1;&#125;; v1 = 0; auto j = f(); //j值为43&#125;transform(vi.begin(),vi.end(),vi.begin(), [](int i) -&gt; int &#123;if(i&lt;0) return -i; else return i;&#125;); 10.3.4 参数绑定 对于捕获局部变量的地方,建议使用lambda 标准库bind函数： 定义在头文件functional中 可将bind函数看作一个通用的函数适配器,接受一个可调用对象,生成一个新的可调用对象来适应原对象的参数列表 调用的一般形式：auto newCallable = bind(callable,arg_list); 其中,newCallable本身是一个可调用对象,arg_list是一个逗号分隔的参数列表,对应给定的callable的参数 当调用newCallable时,newCallable会调用callable,并传递给它arg_list中的参数。arg_list中的参数可能包含形如_n的名字,其中n是一个整数。这些参数是“占位符”,表示newCallable的参数,占据了传递给newCallable的参数的“位置”。数值n表示生成的可调用对象中参数的位置：_1为newCallable的第一个参数,_2为第二个参数,依此类推 使用placeholders名字 定义在头文件functional中 名字_n都定义在一个名为placeholders的命名空间中,而这个命名空间本身定义在std命名空间中 为了使用这些名字,两个命名空间都要写上 用bind重排参数顺序 绑定引用 默认情况下,bind的不是占位符的参数被拷贝进bind返回的可调用对象中,但有时对有些绑定的参数希望以引用方式传递或时要绑定的参数的类型无法拷贝 ref和cref定义在functional中 ref函数：返回一个对象,包含给定的引用,此对象是可以拷贝的 cref函数：生成一个保存const引用的类 1234567891011121314151617181920212223242526272829303132333435bool check_size(const string &amp;s, string::size_type sz)&#123; return s.size() &gt;= sz;&#125;// 将使用bind生成一个调用check_size的对象auto check6 = bind(check_size,_1,6);// 此bind调用只有一个占位符,表示check6只接受单一参数string s = &quot;hello&quot;;bool bl = check6(s);// 替换示例auto wc = find_if(words.begin(),words.end() [sz](const string &amp;a));// 替换auto wc = find_if(words.begin(),words.end() bind(check_size,_1,sz));// 此bind调用生成一个可调用对象,将check_size的第二个参数绑定到sz的值// 当find_if对words中的string调用这个对象时,这些对象会调用check_size,将给定的string和sz传递给它// 使用_1using std::placeholders::_1;// 或声明全部placeholdersusing namespace std::placeholders;// 由短到长排序sort(words.begin(),words.end(),isShorter);// 由长到短排序sort(words.begin(),words.end(),bind(isShorter,_2,_1));ostream &amp;print(ostream &amp;os, const string &amp;s, char c)&#123; return os&lt;&lt;s&lt;&lt;c;&#125;for_each(words.begin(),words.end(), bind(print,ref(os),_1,&#x27; &#x27;)); 10.4 再探迭代器 迭代器的四种类型： 插入迭代器：迭代器被绑定到一个容器上,可用来向容器插入元素 流迭代器：迭代器被绑定到输入或输出流上,可用来遍历所关联的IO流 反向迭代器：迭代器向后而不是向前移动。除了forward_list之外的标准库容器都有反向迭代器 移动迭代器：专用的迭代器不是拷贝其中的元素,而是移动它们 10.4.1 插入迭代器 插入迭代器是一种迭代器适配器,接受一个容器,生成一个迭代器,能实现向给定容器添加元素 通过插入迭代器进行赋值时,该迭代器调用容器操作来向给定容器的指定尾置插入一个元素 插入迭代器操作 it=t 在it指定的当前位置插入值t *it,it,it 插入器的三种类型,差异在于元素插入的位置 back_inserter 创建一个使用push_back的迭代器 front_inserter 创建一个使用push_front的迭代器 当调用front_inserter©时,得到一个插入迭代器,接下来会调用push_front 当每个元素被插入到容器c中时,它变为c的新的首元素 因此,front_inserter生成的迭代器会将插入的元素序列的顺序颠倒过来,而inserter和back_inserter则不会 inserter 创建一个使用insert的迭代器(接受第二个参数,指向给定容器的迭代器,元素将被插入到给定迭代器表示的元素之前) 只有在容器支持push_front的情况下,才可以使用front_inserter。类似的,只有在容器支持push_back的情况下,才能使用back_inserter 12345678910111213*it = val;//等效代码it = c.insert(it,val);++it;//front_insertlist&lt;int&gt;lst = &#123;1,2,3,4&#125;;list&lt;int&gt; lst2,lst3;// 拷贝完成后lst2包含 4 3 2 1 copy(lst.cbegin(),lst.cend(),front_inserter(lst2));// 拷贝完成后lst3包含 1 2 3 4 copy(lst.cbegin(),lst.cend(),insert(lst3,lst3.begin()) 10.4.2 iostream迭代器 标准库定义了用于IO类型对象的迭代器 istream_iterator读取输入流,ostream_iterator向一个输出流写数据 迭代器将对应的流当作一个特定类型的元素序列来处理,通过使用流迭代器,可以用泛型算法从流对象读取数据以及向其写入数据 istream_iterator操作 当创建一个流迭代器时,必须指定迭代器将要读写的对象类型 一个istream_iterator使用&gt;&gt;读取流 创建一个istream_iterator时,可以将它绑定到一个流 还可以默认初始化迭代器,创建一个可以当作尾后值使用的迭代器 使用算法操作流迭代器：由于算法使用迭代器操作处理数据,而流迭代器又至少支持某些迭代器操作,因此至少可以用某些算法来操作流迭代器 istream_iterator允许使用懒惰求值： 当讲istream_iterator绑定到一个流时,标准库并不保证迭代器立即从流读取数据 具体实现可以推迟从流中读取数据,直到使用迭代器时才真正读取(该操作办证第一次解引用迭代器之前,从流中读取数据的操作已经完成) istream_iterator操作 - istream_iterator&lt;T&gt; in(is) in从输入流is读取类型为T的值 istream_iterator&lt;T&gt; end 读取类型为T的值的istream_iterator迭代器,表示尾后位置 in1 == in2 in1和in2必须读取相同类型;如果它们都是尾后迭代器,或绑定到相同的输入,则两者相等 *in 返回从流中的读取的值 in-&gt;men 返回从流中的读取的值 in,in 使用元素类型所定义的&gt;&gt;运算符从输入流中读取下一个值(前置版本返回一致指向递增后迭代器的引用,后置版本返回旧值) 12345678910111213141516171819202122istream_iterator&lt;int&gt; int_it(cin); //从cin读取intistream_iterator&lt;int&gt; int_eof; //尾后迭代器ifstream in(&quot;afile&quot;);istream_iterator&lt;string&gt; str_in(in);// 用istream_iterator从标准输入读取数据,存入vectoristream_iterator&lt;int&gt; in_iter(cin);istream_iterator&lt;int&gt; eof;while(in_iter != eof) vec.push_back(*in_iter++);// 重写istream_iterator&lt;int&gt; in_iter(cin),eof;vector&lt;int&gt; vec(in_in_iter,eof);// 用一对表示元素范围的迭代器来构造vec// 两个迭代器是istream_iterator,这意味着元素范围是通过从关联的流中读取数据获得的// 这个构造函数从cin中读取数据,直至遇到文件尾或者遇到一个不是int的数据为止// 从流中读取的数据被用来构造vec// 利用一对istream_iterator调用accumulateistream_iterator&lt;int&gt; in(cin),eof;cout&lt;&lt;accumulate(in,eof,0)&lt;&lt;endl; ostream_iterator操作 可以对任何具有输出运算符(&lt;&lt;)的类型定义ostream_iterator 创建一个ostream_iterator时,可以提供第二参数,在输出每个元素后都会打印此字符串 ostream_iterator操作 - ostream_iterator&lt;T&gt; out(os) out将类型为T的值写出到输出流os中 ostream_iterator&lt;T&gt; out(os,d) out将类型为T的值写出到输出流os中,每个值后面都输出一个d。d指向一个空字符结尾的字符数组 out = val 用&lt;&lt;运算符将val写入到out所绑定的ostream中 *out,out,out 不对out做任何事情。每个运算符都返回out 1234567891011121314ostream_iterator&lt;int&gt; out_iter(cout,&quot; &quot;);for(auto e:vec) *out_iter++ = e; //赋值语句实际上将元素写到coutcout &lt;&lt; endl;// 运算符*和++实际上对ostream_iterator对象不做任何事情,因此忽略它们对我们的程序没有任何影响// 但是,推荐第一种形式。在这种写法中,流迭代器的使用与其他迭代器的使用保持一致for(auto e:vec) out_iter = e; //赋值语句实际上将元素写到coutcout &lt;&lt; endl;// 可以调用copycopy(vec.begin(),vec.end(),out_iter); 使用流迭代器处理类类型 可以为任何定义了输入运算符的类型创建istream_iterator,可以为任何定义了输出运算符的类型创建ostream_iterator 10.4.3 反向迭代器 反向迭代器就是在容器中从尾元素向首元素反向移动的迭代器 对于反向迭代器,递增,递减操作的含义会颠倒过来 递增一个反向迭代器(++it)会移动到前一个元素 递减一个迭代器(–it)会移动到下一个元素 除了forward_list或一个流迭代器之外,其他容器都支持反向迭代器 除了forward_list之外,标准容器上的其他迭代器都既支持递增运算又支持递减运算 流迭代器不支持递减运算,因为不可能在一个流中反向移动 可以通过调用rbegin、rend、crbegin和crend成员函数来获得反向迭代器 这些成员函数返回指向容器尾元素和首元素之前一个位置的迭代器 与普通迭代器一样,反向迭代器也有const和非const版本 10.5 泛型算法结构 迭代器类别 - 输入迭代器 只读,不写;单遍扫描,只能递增 输出迭代器 只写,不读;单遍扫描,只能递增 前向迭代器 可读写;多遍扫描,只能递增 双向迭代器 可读写;多遍扫描,可递增递减 随机访问迭代器 可读写;多遍扫描,支持全部迭代器运算 10.5.1 5类迭代器 输入迭代器：可以读取序列中的元素 用于比较两个迭代器的相等和不相等运算符(==、！=) 用于推进迭代器的前置和后置递增运算(++) 用于读取元素的解引用运算符(*);解引用只会出现在赋值运算符的右侧 箭头运算符(-&gt;),等价于(*it).member,即,解引用迭代器,并提取对象的成员 输入迭代器只用于顺序访问 对于一个输入迭代器,*it++保证是有效的,但递增它可能导致所有其他指向流的迭代器失效。其结果就是,不能保证输入迭代器的状态可以保存下来并用来访问元素 输出迭代器：可以看作输入迭代器功能上的补集——只写而不读元素 用于推进迭代器的前置和后置递增运算(++) 解引用运算符(*),只出现在赋值运算符的左侧(向一个已经解引用的输出迭代器赋值,就是将值写入它所指向的元素) 前向迭代器：可以读写元素。这类迭代器只能在序列中沿一个方向移动。前向迭代器支持所有输入和输出迭代器的操作,而且可以多次读写同一个元素。因此,我们可以保存前向迭代器的状态,使用前向迭代器的算法可以对序列进行多遍扫描。 双向迭代器：可以正向/反向读写序列中的元素。除了支持所有前向迭代器的操作之外,双向迭代器还支持前置和后置递减运算符(–) 随机访问迭代器：提供在常量时间内访问序列中任意元素的能力 用于比较两个迭代器相对位置的关系运算符(&lt;、&lt;=、&gt;和&gt;=) 迭代器和一个整数值的加减运算(+、+=、-和-=),计算结果是迭代器在序列中前进(或后退)给定整数个元素后的位置 用于两个迭代器上的减法运算符(-),得到两个迭代器的距离 下标运算符(iter[n]),与*(iter[n])等价 10.5.3 算法命名规范 一些算法使用重载形式传递一个谓词 接受谓词参数来代替&lt;或==运算符的算法,以及那些不接受额外参数的算法,通常都是重载的函数 函数的一个版本用元素类型的运算符来比较元素 另一个版本接受一个额外谓词参数,来代替&lt;或== _if版本的算法 接受一个元素值的算法通常有另一个不同名的(不是重载的)版本,该版本接受一个谓词代替元素值 接受谓词参数的算法都有附加的_if前缀 区分拷贝元素的版本和不拷贝的版本 1234567891011121314unique(beg,end); //使用==运算符比较元素unique(beg,end,comp); //使用comp比较元素find(beg,end,val); //查找输入范围中val第一次出现的位置find_if(beg,end,pred); //查找第一个令pred为真的元素// 两个算法提供了命名上差异的版本,而非重载版本,因为两个版本的算法都接受相同数目的参数// 因此可能产生重载歧义,虽然很罕见,但为了避免任何可能的歧义,标准库选择提供不同名字的版本而不是重载// 从v1中删除奇数元素remove_if(v1.begin(),v1.end() [](int i) &#123;return i%2;&#125;);// 将偶数元素从v1拷贝到v2;v1不变remove_if(v1.begin(),v1.end(),back_inserter(v2), [](int i) &#123;return i%2;&#125;); 10.6 特定容器算法 对于list和forward_list,应该优先使用成员函数版本的算法而不是通用算法 链表特有的操作会改变容器 多数链表特有的算法都与其通用版本很相似,但不完全相同 链表特有版本与通用版本间的一个至关重要的区别是链表版本会改变底层的容器 类似的,merge和splice会销毁其参数 list和forward_list成员函数版本的算法(返回void) - lst.merge(lst2) 将来自lst2的元素合并如lst lst.merge(lst2,comp) 元素将从lst2中删除(在合并之后,lst2变成空) lst.remove(val) 调用erase删除掉与给定值相等或令一元谓词为真的每个元素 lst.remove_if(pred) 调用erase删除掉与给定值相等或令一元谓词为真的每个元素 lst.reverse() 反转lst中元素的顺序 lst.sort() 使用&lt;或给定比较操作排序元素 lst.sort(comp) 使用&lt;或给定比较操作排序元素 lst.unique() 调用erase删除同一值得连续拷贝.第一个版本使用=,第二个版本使用给定的二元谓词 lst.unique(pred) 调用erase删除同一值得连续拷贝.第一个版本使用=,第二个版本使用给定的二元谓词 11 关联容器 关联容器中的元素时按关键字来保存和访问的,支持高效的关键字查找和访问 两个主要的关联容器：map和set map中的元素是一些关键字-值对：关键字起到索引的作用,值则表示与索引相关联的数据 set中每个元素只包含一个关键字;set支持高效的关键字查询操作(检查一个给定关键字是否在set中) 头文件 类型map和multimap定义在头文件map中 set和multiset定义在头文件set中 无序容器则定义在头文件unordered_map和unordered_set中 关联容器类型 - 按关键字有序保存元素 - map 关联数组;保存关键字-值对 set 关键字即值 multimap 关键字可重复出现的map multiset 关键字可重复出现的set 无序集合 - unordered_map 用哈希函数组织的map unordered_set 用哈希函数组织的set unordered_multimap 哈希组织的map,关键字可重复出现 unordered_multiset 哈希组织的set,关键字可重复出现 11.1 使用关联容器 123456789101112131415161718// 使用关联数组进行单词计数// 统计每个单词在输入中出现的次数map&lt;string,size_t&gt; word_count;string word;while(cin&gt;&gt;word) ++word_count[word];for(const auto &amp;w:word_count)cout&lt;&lt;w.first&lt;&lt;&quot; occurs &quot;&lt;&lt;w.second&lt;&lt;((w.second &gt;1)? &quot;times&quot; : &quot; time&quot;)&lt;&lt;endl;// 统计输入中每个单词出现的次数// 可忽略部分单词map&lt;string,size_t&gt; word_count;set&lt;string&gt; exclude = &#123;&quot;The&quot;,&quot;But&quot;&#125;;string word;while(cin&gt;&gt;word) if(exclude.find(word) == exclude.end() ) ++word_count[word]; 11.2 关联容器概述 关联容器支持普通容器操作,但不支持顺序容器的位置相关的操作 关联容器中元素时根据关键字存储的,这些操作对关联容器没有意义,而且关联容器不支持构造函数或插入操作这些接受一个元素值和一个数量值得操作 11.2.1 定义关联容器 每个关联容器都定义一个默认构造函数,创建了一个指定类型的空容器 定义map,必须既指明关键字类型又指明值类型 初始化时,必须提供关键字类型和值类型{key,value} 定义set,只需指明关键字类型 元素类型就是关键字类型 初始化multimap和multiset 允许多个元素具有相同的关键字 123456789// 将创建一个名为ivec的保存int的vector,它包含20个元素：0到9每个整数有两个拷贝// 将使用此vector初始化一个set和一个multisetvector&lt;int&gt; ivec;for(vector&lt;int&gt;::size_type i= 0;i!=10;++i)&#123; ivec.push_back(i); ivec.push_back(i);&#125;set&lt;int&gt; iset(ivec.cbegin(), ivec.cend());multiset&lt;int&gt; miset(ivec.cbegin,ivec.cend()); 11.2.2 关键字类型的要求 关键容器对其关键字类型有一定限制 对于有序容器map,multimap,set,multiset,关键字类型必须定义元素比较的方法 默认情况下,标准库使用关键字类型的&lt;运算符比较两个关键字 有序容器的关键字类型 可以向算法提供自定义的比较操作,也可以提供自定义的操作代替关键字上的&lt;运算符 所提供的操作必须在关键字类型上定义一个严格弱序(可看作小于等于) 使用关键字类型的比较函数 用来组织一个容器中元素的操作的类型也是该容器类型的一部分 为了指定使用自定义的操作,必须在定义关联容器类型时提供此操作的类型 在尖括号中出现的每个类型,就仅仅是一个类型而已 当创建一个容器(对象)时,才会以构造函数参数的形式提供真正的比较操作(其类型必须与在尖括号中指定的类型相吻合) 为了使用自定义的操作,在定义multiset时必须提供两个类型：关键字类型,以及比较操作类型(函数指针类型) 1234567// 严格弱序函数bool compareIsbn(const Sales_data % lhs, const Sales_data &amp;rhs)&#123; return lhs.isbn() &lt; rhs.isbn();&#125;multiset&lt;Sales_data,decltype(compareIsbn)*&gt; bookstore(compareIsbn);// 用compareIsbn来初始化bookstore对象,这表示当我们向bookstore添加元素时,通过调用compareIsbn来为这些元素排序 11.2.3 pair类型 pair的标准库类型,定义在头文件utility中 一个pair保存两个数据成员(创建时需要提供两个类型名) 与其他标准库类型不同,pair的数据成员是public的,两个成员分别命名为first和second 12345pair&lt;string,string&gt; anon;pair&lt;string,size_t&gt; word_count;pair&lt;string,vector&lt;int&gt;&gt; line;pair&lt;string,string&gt; author&#123;&quot;James&quot;,&quot;Joyce&quot;&#125;; pair上的操作 - pair&lt;T1,T2&gt; p; p是pair,对两个成员进行了值初始化 pair&lt;T1,T2&gt; p(v1,v2); p是pair,对两个成员v1,v2进行了值初始化 pair&lt;T1,T2&gt; p={v1,v2}; 同上 make_pair(v1,v2); 返回一个用v1和v2初始化的pair p.first 返回p的first数据成员 p.second 返回p的second数据成员 p1 relop p2 关系运算符(relop为关系运算符)运算 p1 == p2 相等性判断 p1 != p2 相等性判断 11.3 关联容器操作 关联容器额外的类型别名 - key_type 此容器类型的关键字类型 mapped_type 每个关键字关联的类型,只适用于map value_type 对于set与key_type相同;对于map为pair&lt;const key_type,mapped_type&gt; 11.3.1 关联容器迭代器 解引用一个关联容器迭代器时,得到一个类型为容器的value_type的值的引用 一个map的value_type是一个pair,我们可以改变pair的值,但不能改变关键字成员的值 set的迭代器是const的：虽然set类型同时定义了iterator和const_iterator类型,但两种类型都只允许只读访问set中的元素 遍历关联容器：map和set类型都支持begin和end操作,可以用这些函数获取迭代器,然后用迭代器来遍历容器 关联容器和算法： 通常不对关联容器使用泛型算法 关键词是const意味着不能将关联容器传递给修改或重排容器元素的算法 关联容器只可用于只读取元素的算法 12345678910auto map_it = word_cout.begin();map_it-&gt;first = &quot;new key&quot;; //错误,关键字是const++map_it-&gt;second; //可通过迭代器改变元素set&lt;int&gt; iset = &#123;0,1,2,3,4,5,6,7,8,9&#125;;set&lt;int&gt;::iterator set_it = iset.begin();if(set_it != iset.end())&#123; *set_it = 42; //错误,set中关键字只读 cout &lt;&lt; *set_it &lt;&lt;endl; //正确,可以读关键字&#125; 11.3.2 添加元素 关联容器的insert成员向容器中添加一个元素或元素范围 insert有两个版本,分别接受一对迭代器,或是一个初始化器列表 向map添加元素 元素类型是pair,可以在insert的参数列表中创建一个pair 关联容器insert操作 - c.insert(v) v是value_type类型的对象 c.emplace(args) 构造一个元素 c.insert(b,e) b,e是迭代器,表示一个c::value_type类型值的范围 c.insert(il) il是花括号列表 c.insert(p,v) 将迭代器p作为指示从哪里开始搜索新元素应存储的位置 c.insert(p,args) 将迭代器p作为指示从哪里开始搜索新元素应存储的位置 检测insert的返回值 对于map和set,只有当元素的关键字不在c中才插入元素,函数返回一个pair,包含一个迭代器,指向具有指定关键字的元素,以及一个指示插入是否成功的bool值 若关键字已在容器中,bool部分为false 对于multimap和multiset,总会插入给定元素,并返回一个指向新元素的迭代器 1234567891011121314151617// 统计每个单词在输入中出现次数的繁琐方法map&lt;string,size_t&gt; word_count;string sord;while(cin&gt;&gt;word)&#123; auto ret = word_cout.insert(&#123;word,1&#125;); if(!ref.second) ++ret.first-&gt;second;&#125;//ret 保存insert返回的值,是一个pair// ret.first是pair的第一个成员,是一个map迭代器,指向具有给定关键字的元素// ret.first-&gt; 解引用此迭代器,提取map中的元素,元素也是一个pair// ret.first-&gt;second map中元素的值部分// ++ret.first-&gt;second 递增此值// ret的实际类型pair&lt;map&lt;string,size_t&gt;::iterator,bool&gt; 11.3.3 删除元素 从关联容器删除元素 - c.erase(k) 从c中删除每个关键字为k的元素.返回一个size_type值(指出删除元素的数量) c.erase(p) 从c中删除迭代器p指定的元素.p必须指向c中的一个真实元素。返回一个指向p之后元素的迭代器 c.erase(b,e) 删除迭代器对b和e所表示的范围中的元素,返回e 11.3.4 map的下标操作 map和unordered_map容器提供了下标运算符和一个对应的at函数 不能对一个multimap或一个unordered_multimap进行下标操作,因为这些容器中可能有多个值与一个关键字相关联 map下标运算符接受一个索引,获取与此关键字相关联的值 但如果关键字并不在map中,会为它创建一个元素并插入到map中,关联值将进行值初始化 set类型不支持下标,因为set中没有与关键字相关联的“值” map和unordered_map的下标操作 - c[k] 返回关键字为k的元素;若k不在c中,添加元素并进行初始化 c.at(k) 访问关键字为k的元素,带参数检查,若不存在,则抛出一个out_of_range异常 当对一个map进行下标操作时,会获得一个mapped_type对象 当解引用一个map迭代器时,会得到一个value_type对象 11.3.5 访问元素 关心一个特定元素是否已在容器中,find函数是最佳选择 对于允许重复关键字的容器,count还会统计有多少个元素有相同的关键字 对map使用find代替下标操作 在multimap或multiset中查找元素：如果一个multimap或multiset中有多个元素具有给定关键字,则这些元素在容器中会相邻存储 不同的面向迭代器查找元素： 用lower_bound和upper_bound来解决此问题 两个操作都接受一个关键字,返回一个迭代器 如果关键字在容器中,lower_bound返回的迭代器将指向第一个具有给定关键字的元素,而upper_bound返回的迭代器则指向最后一个匹配给定关键字的元素之后的位置 如果元素不在multimap中,则lower_bound和upper_bound会返回相等的迭代器 如果lower_bound和upper_bound返回相同的迭代器,则给定关键字不在容器中 equal_range函数 函数接受一个关键字,返回一个迭代器pair 若关键字存在,则第一个迭代器指向第一个与关键字匹配的元素,第二个迭代器指向最后一个匹配元素之后的位置 若未找到匹配元素,则两个迭代器都指向关键字可以插入的位置 在一个关联容器中查找元素的操作 - - lower_bound和upper_bound不适用于无序容器 - 下标和at操作只适用于非const的map和unordered_map c.find(k) 返回一个迭代器,指向第一个关键字为k的元素;若无k,则返回尾后迭代器 c.count(k) 返回关键字等于k的数量 c.lower_bound(k) 返回一个迭代器,指向第一个关键字不小于k的元素 c.upper_bound(k) 返回一个迭代器,指向第一个关键字大于k的元素 c.equal_range(k) 返回一个迭代器pair,表示关键字等于k的元素的范围;若不存在,两个成员为c.end() 11.4 无序容器 新标准定义了4个无序关联容器,使用哈希函数和关键字类型的==运算符 使用无序容器 除了哈希管理操作之外,无序容器还提供了与有序容器相同的操作(find,insert等) 用于map和set的操作也能用于unordered_map和unordered_set 通常可用一个无序容器替换对应的有序容器 1234567// 用unordered_map重写单词计数程序unordered_map&lt;string,size_t&gt; word_count;string word;while(cin&gt;&gt;word) ++word_count[word];for(const auto &amp;w:word_count) cout&lt;&lt;w.first&lt;&lt;&quot; occurs &quot; &lt;&lt; w.second &lt;&lt; ((w.second &gt;1)? &quot; times&quot;:&quot; time&quot;)&lt;&lt;endl; 管理桶 无序容器在存储上组织为一组桶(使用一个哈希函数将元素映射到桶),每个桶保存零个或多个元素 为了访问一个元素,容器首先计算元素的哈希值,它指出应该搜索哪个桶,容器将具有一个特定哈希值的所有元素都保存在相同的桶中,如果容器允许重复关键字,所有具有相同关键字的元素也都会在同一个桶中 因此,无序容器的性能依赖于哈希函数的质量和桶的数量和大小 对于相同的参数,哈希函数必须总是产生相同的结果。理想情况下,哈希函数还能将每个特定的值映射到唯一的桶。但是,将不同关键字的元素映射到相同的桶也是允许的 无序容器管理操作 - 桶接口 - c.bucket_count() 正在使用桶的数目 c.max_bucket_count() 容器能容纳最多的桶的数量 c.bucket_size(n) 第n个桶中有多少个元素 c.bucket(k) 关键字为k的元素在哪个桶中 桶迭代 - local_iterator 可以用来访问桶中元素的迭代器类型 const_local_iterator 桶迭代器的const版本 c.begin(n),c.end(n) 桶n的首元素迭代器和尾后迭代器 c.cbegin(n),c.cend(n) 返回const_local_iterator 哈希策略 - c.load_factor 每个桶的平均元素数量,返回float值 c.max_load_factor c试图维护的平均桶大小,返回float值。c会在需要时添加新的桶,以使得load_factor&lt;=max_load_factor&gt; c.rehash(n) 重组存储,使得bucket_count&gt;=n,且bucket_count&gt;size/max_load_factor c.reserve(n) 重组存储,使得c可以保存n个元素且不必rehash 无序容器对关键字类型的要求 默认情况下,无序容器使用关键字类型的==运算符来比较元素,它们还使用一个hash&lt;key_type&gt;类型的对象来生成每个元素的哈希值 标准库为内置类型(包括指针)提供了hash模板,还为一些标准库类型,包括string和智能指针类型定义了hash 因此,可以直接定义关键字是内置类型(包括指针类型)、string还是智能指针类型的无序容器 12345678910111213size_t hasher(const Sales_data &amp;sd)&#123; return hash&lt;string&gt;() (sd.isbn());&#125;bool eqOp(const Sales_data &amp;lhs, const Sales_data &amp;rhs)&#123; return lhs.isbn() == rhs.isbn();&#125;// 我们的hasher函数使用一个标准库hash类型对象来计算ISBN成员的哈希值,该hash类型建立在string类型之上// 类似的,eqOp函数通过比较ISBN号来比较两个Sales_datausing SD_multiset = unordered_multiset&lt;Sales_data,dacltype(hasher)*,decltype(eqOp)*&gt;;// 参数使桶大小,哈希函数指针和相等性判断运算符指针SD_multiset bookstore(42,hasher,eqOp); 12 动态内存 目前为止只使用过静态内存或栈内存(分配在静态或栈内存中的对象由编译器自动创建和销毁) 静态内存用来保存局部static对象,类static数据成员以及定义在任何函数之外的变量 栈内存用来保存定义在函数内的非static对象 对于栈对象,仅在其定义的程序块运行时才存在 static对象在使用之前分配,在程序结束时销毁 除了静态内存和栈内存,每个程序还拥有一个内存池。这部分内存被称作自由空间或堆 程序用堆来存储动态分配的对象 12.1 动态内存与智能指针 在C++中,动态内存使通过一对运算符来完成的： new,在动态内存中位对象分配空间并返回一个指向该对象的指针,可以选择对对象进行初始化 delete,接受一个动态对象的指针,销毁该对象,并释放与之关联的内存 在新标准中,提供两种智能指针来管理动态对象,与普通指针的区别是可以自动释放所指向的对象 在memory头文件中 shared_ptr：允许多个对象指向同一个对象 unique_ptr：独占所指向的对象 weak_ptr：伴随类,弱引用,指向shared_ptr所管理的对象 12.1.1 shared_ptr类 智能指针是模板,创建时必须提供额外的信息(指针可以指向的类型,在&lt;&gt;内给出类型) 默认初始化的智能指针中保存着一个空指针 解引用一个智能指针返回它所指向的对象 12345shared_ptr&lt;string&gt; p1;shared_ptr&lt;list&lt;int&gt;&gt; p2;if(p1 &amp;&amp; p1-&gt;empty()) *p1 = &quot;hi&quot;; shared_ptr和unique_ptr都支持的操作 - shared_ptr&lt;T&gt; sp 空智能指针,可以指向类型为T的对象 unique_ptr&lt;T&gt; up 空智能指针,可以指向类型为T的对象 p 将p用作一个条件判断,若p指向一个对象,则为true *p 解引用p,获得它所指向的对象 p-&gt;mem 等价于(*p).mem p.get() 返回p中保存的指针 swap(p,q) 交换p和q中的指针 p.swap(q) 交换p和q中的指针 shared_ptr独有的操作 - make_shared&lt;T&gt;(args) 返回一个shared_ptr,指向一个动态分配的类型为T的对象,使用args初始化此对象 shared_ptr&lt;T&gt;p(q) p是返回shared_ptr的拷贝;此操作会递增q中的计数器;q中的指针必须能转换成T* p=q 所保存的指针必须能相互转换;此操作会递减p的引用计数,递增q的引用计数 p.unique() 若p.use_count()为1,返回true p.use_count() 返回与p共享对象的智能指针数量(用于调试) make_shared函数 最安全的分配和使用动态内存的方法：调用make_shared函数 此函数在动态内存中分配一个对象并初始化,返回指向此对象的shared_ptr 类似顺序容器的emplace成员,make_shared用其参数来构造给定类型的对象 可以使用auto定义一个对象保存make_shared的结果 shared_ptr的拷贝和赋值 当进行拷贝或赋值操作时,每个shared_ptr会记录有多少个其他shared_ptr指向相同的对象 每个shared_ptr都有一个关联的计数器,通常称其为引用计数,拷贝shared_ptr,计数器都会递增 12345678910111213shared_ptr&lt;int&gt; p3 = make_shared&lt;int&gt;(42);shared_ptr&lt;string&gt; p3 = make_shared&lt;string&gt;(10,&#x27;9&#x27;);auto p6 = make_shared&lt;vector&lt;string&gt;&gt;();auto p = make_shared&lt;int&gt;(42);auto q(p); //p和q指向相同对象,此对象有两个引用者auto r = make_shared&lt;int&gt;(42);r = q; //递增r所指向的对象的引用计数;// 递减r原来指向对象的引用计数;// r原来指向的对象已经没有引用者,会自动释放 shared_ptr自动销毁所管理的对象以及相关联的内存 当指向一个对象的最后一个shared_ptr被销毁时,shared_ptr类会自动销毁此对象 通过析构函数完成销毁工作,析构函数一般用来释放对象所分配的资源 shared_ptr的析构函数会递减所指向的对象的引用计数 当动态对象不再被使用时,shared_ptr类会自动释放动态对象 由于在最后一个shared_ptr销毁前内存都不会释放,保证shared_ptr在无用之后不再保留非常重要 如果将shared_ptr存放于一个容器中,而后不再需要全部元素,而只使用其中一部分,要记得用erase删除不再需要的那些元素 1234567891011121314// factory返回一个shared_ptr,指向一个动态分配的对象shared_ptr&lt;Foo&gt; facory(T arg)&#123; return make_shared&lt;Foo&gt;(arg);&#125;void use_factory(T arg)&#123; shared_ptr&lt;Foo&gt; p = factory(arg);&#125;//p离开作用域,所指向的内存会被自动释放掉void use_factory(T arg)&#123; shared_ptr&lt;Foo&gt; p = factory(arg); // 使用p return p; //当返回p时,引用计数进行了递增操作&#125;//p离开了作用域,但它指向的内存不会被释放掉 使用了动态生存期的资源的类 程序使用动态内存出现三种原因之一： 程序不知道自己需要使用多少对象 程序不知道所需对象的准确类型 程序需要在多个对象间共享数据 一般而言,如果两个对象共享底层数据,当某个对象被销毁,不能单方面地销毁底层数据 使用动态内存的一个常见原因是允许多个对象共享相同的类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445class StrBlob&#123; public: typedef std::vector&lt;std::string&gt;::size_type size_type; StrBlob(); StrBlob(std::initializer_list&lt;std::string&gt; il); size_type size() const &#123;return data-&gt;size();&#125; bool empty() const &#123;return data-&gt;empty();&#125; void push_back(const std::string &amp;t) &#123;data-&gt;push_back(t);&#125; void pop_back(); std::string&amp; front(); std::string&amp; back(); private: std::shared_ptr&lt;str::vector&lt;std::string&gt;&gt; data; void check(size_type i, const std::string &amp;msg) const;&#125;;StrBlob::StrBlob(): data(make_shared&lt;vector&lt;string&gt;&gt;) &#123;&#125;strBlob::StrBolb(initializer_list&lt;string&gt; il): data(make_shared&lt;vector&lt;string&gt;&gt;()) &#123;&#125;void StrBlob::check(size_type i, const string &amp;msg) const&#123; if(i &gt;= data-&gt;size()) throw out_of_range(msg);&#125;string&amp; StrBlob::front()&#123; check(0,&quot;front on empty StrBlob&quot;); return data-&gt;front();&#125;string&amp; StrBlob::back()&#123; check(0,&quot;back on empty StrBlob&quot;); return data-&gt;back();&#125;string&amp; StrBlob::pop_bakc()&#123; check(0,&quot;pop_back on empty StrBlob&quot;); return data-&gt;pop_back();&#125;// 类似Sales_data类,StrBlob使用默认版本的拷贝、赋值和销毁成员函数来对此类型的对象进行这些操作// 默认情况下,这些操作拷贝、赋值和销毁类的数据成员// StrBlob类只有一个数据成员,它是shared_ptr类型// 因此,当我们拷贝、赋值或销毁一个StrBlob对象时,它的shared_ptr成员会被拷贝、赋值或销毁 12.1.2 直接管理内存 运算符new分配内存,delete释放nre分配的内存 使用new动态分配和初始化对象 在自由空间分配的内存是无名的,因此new无法为其分配的对象命名,而是返回一个指向该对象的指针 默认情况下,动态分配的对象是默认初始化的,意味着内置类型或组合类型的对象的值是未定义的,而类类型对象将用默认构造进行初始化 可以使用直接初始化方式来初始化动态分配的对象,或使用列表初始化(使用花括号) 可以对动态分配的对象进行值初始化(在类型名之后跟一对空括号) 如果使用括号包围的仅有单一初始化器,可以使用auto推断元素类型 动态分配的const对象 动态分配的const对象必须进行初始化(定义了默认构造函数的类类型,可以隐式初始化) 内存耗尽 一旦一个程序用光了所有的可用内存,new表达式会报错,抛出bad_alloc异常 定位new：允许向new传递额外的参数,(传递nothrow意图不能抛出异常,返回空指针) nothrow和bad_alloc定义在new头文件中 1234567891011121314151617int *pi = new int;string *ps = new string;int *pi = new int(1024);string *ps = new string(10,&#x27;9&#x27;);vector&lt;int&gt; *pv = new vector&lt;int&gt;&#123;0,1,2,3,4,5,6,7,8,9&#125;;string *ps = new string(); //值初始化为空auto p1 = new auto(obj);auto p2 = new auto&#123;a,b,c&#125;; //错误,括号中只能由单个初始化器const int *pci = new const int(1024)const string *pcs = new const string;int *p1 = new int;int *p2 = new (nothrow) int; //分配失败,new返回空指针 释放动态内存 使用delete表达式来讲动态内存归还给系统 两个动作：销毁给定指针指向的对象,释放对应的内存 delete表达式接受一个指针,指向要释放的对象 指针和delete delete必须指向动态分配的内存或空指针(释放一块非new分配的内存,该行为未定义) const对象的值不能被修改,但本身是可以被销毁的 动态对象的生存期直到被释放时为止 由shared_ptr管理的内存在最后一个shared_ptr销毁时会被自动释放 通过内置指针类型来管理的内存,直到被显式释放之前它都是存在的 返回动态内存的指针的函数需要记得释放内存 当一个指针离开其作用域时,它所指向的对象什么都不会发生;如果这个指针指向的时动态内存,内存将不会被自动释放 小心：动态内存的管理非常容易出错 使用new和delete管理动态内存存在三个常见问题： 忘记delete内存 使用已经释放掉的对象 同一块内存释放两次 delete之后重置指针值 delete一个指针后,指针为空悬指针 不再使用该指针：在指针即将离开其作用域之前释放它所关联的内存 需要使用该指针：将指针赋值为nullptr,指明指针不再指向任何对象 多个指针指向相同内存,delete一个指针后,另一个指针需要置为nullptr 123456789101112131415161718192021222324252627delete p;// 释放const对象const int *pci = new const int(1024);delete pci;// factory返回一个指针,指向一个动态分配的对象Foo* factory(T arg)&#123; return new Foo(arg); //调用者负责释放此内存&#125;void use_factory(T arg)&#123; Foo *p = factory(arg); //使用p但不delete&#125; //p离开作用域,但所指向的内存没有释放// 记得释放内存void use_factory(T arg)&#123; Foo *p = factory(arg); //使用p delete p;&#125;int *p(new int(42));auto q = p;delete p;p = nullptr; 12.1.3 shared_ptr和new结合使用 接受指针参数的智能指针构造函数是explicit的 不能将一个内置指针隐式转换为一个智能指针,必须使用直接初始化形式来初始化一个智能指针 不能进行内置指针到智能指针间的隐式转换 默认情况下,一个用来初始化智能指针的普通指针必须指向动态内存,因为智能指针默认使用delete释放它所关联的对象 可以将智能指针绑定到一个指向其他类型的资源的指针上,但是为了这样做,必须提供自己的操作来替代delete 123456789101112131415// 可以用new返回的指针来初始化智能指针shared_ptr&lt;double&gt; p1;shared_ptr&lt;int&gt; p2(new int(42));// 不能将一个内置指针隐式转换为一个智能指针,必须使用直接初始化形式来初始化一个智能指针shared_ptr&lt;int&gt; p1 = new int(1024); //错误：必须使用直接初始化形式shared_ptr&lt;int&gt; p2(new int(1024)); //正确：使用直接初始化形式shared_ptr&lt;int&gt; clone(int p)&#123; return new int(p); //错误,存在隐式转换&#125;shared_ptr&lt;int&gt; clone(int p)&#123; return shared_ptr&lt;int&gt;(new int(p));&#125; 定义和改变shared_ptr的其他方法 - shared_ptr&lt;T&gt; p(q) p管理内置指针q所指向的对象;q必须指向new分配的内存,且能转换为T*类型 shared_ptr&lt;T&gt; p(u) p从unique_ptr u那里接管了对象的所有权,将u置为空 shared_ptr&lt;T&gt; p(q,d) p接管了内置指针q所指向的对象的所有权。q必须能转换为T*类型。p将使用可调用对象d来代替delete shared_ptr&lt;T&gt; p(p2,d) p时shared_ptr p2的拷贝,唯一的区别时p将用可调用对象d来代替delete p.reset() 若p是唯一指向其对象的shared_ptr,reset会释放此对象 p.reset(q) 若传递了可选的参数内置指针q,会令p指向q,否则会将p置为空 p.reset(q,d) 若传递了参数d,将会调用d而不是delete来释放q 不要混合使用普通指针和智能指针 shared_ptr可以协调对象的析构,但仅限于其自身的拷贝之间(推荐make_shared而不是new的原因) 在分配对象的同时就将shared_ptr与之绑定,从而避免无意中将同一块内存绑定到多个独立创建的shared_ptr上 将一个shared_ptr绑定到一个普通指针时,就将内存的管理责任交给了这个shared_ptr 一旦这样做了,就不应该再使用内置指针来访问shared_ptr所指向的内存了 使用一个内置指针来访问一个智能指针所负责的对象是很危险的,因为无法知道对象何时会被销毁 不要使用get初始化另一个智能指针或为智能指针赋值 智能指针类型定义了一个get函数,返回一个内置指针,指向智能指针管理的对象 使用场景：需要向不支持使用智能指针的代码传递指针 使用get返回的指针不能delete 用reset将新的指针赋予一个shared_ptr: 与赋值类似,reset会更新引用计数,如果需要的话,会释放p指向的对象 reset成员经常与unique一起使用,来控制多个shared_ptr共享的对象 123456789101112131415161718192021222324252627282930313233343536373839// 在函数被调用时ptr被创建并初始化void process(shared_ptr&lt;int&gt; ptr)&#123; //使用ptr&#125; //ptr离开作用域,被销毁// process的参数是传值方式传递// 拷贝一个shared_ptr会递增其引用计数,因此,在process运行过程中,引用计数值至少为2// 当process结束时,ptr的引用计数会递减,但不会变为0// 因此,当局部变量ptr被销毁时,ptr指向的内存不会被释放shared_ptr&lt;int&gt; p(new int(42)); //引用计数为1process(p); //拷贝p会递增它的引用计数;在process中引用计数值为2int i = *p; //正确;引用计数值为1// 虽然不能传递给process一个内置指针,但可以传递给它一个(临时的)shared_ptr,这个shared_ptr是用一个内置指针显式构造的// 虽然不能传递给process一个内置指针,但可以传递给它一个(临时的)shared_ptr,这个shared_ptr是用一个内置指针显式构造的int *x(new int(1024));process(x); //错误：不能将int*转换为一个shared_ptr&lt;int&gt;process(shared_ptr&lt;int&gt;(x)); //合法的,但内存会被释放int j = *x; //未定义的：x是一个空悬指针// 将一个临时shared_ptr传递给process// 当这个调用所在的表达式结束时,这个临时对象就被销毁了// 但x继续指向(已经释放的)内存,从而变成一个空悬指针// 将另一个智能指针绑定到get返回的指针上是错误的shared_ptr&lt;int&gt; p(new int(42));int *q = p.get();&#123; // 新程序块 shared_ptr&lt;int&gt;(q);&#125;//程序块结束,q被销毁,它指向的内存被释放int foo = *p; //未定义：p指向的内存已被释放p = new int(1024); //错误：不能将一个指针赋予shared_ptrp.reset(new int(1024)); //正确：p指向一个新对象// 在改变底层对象之前,我们检查自己是否是当前对象仅有的用户。如果不是,在改变之前要制作一份新的拷贝if(!p.unique())p.reset(new string(*p));*p += newVal; 12.1.4 智能指针和异常 可以使用智能指针确保资源被释放 如果使用智能指针,即使程序块过早结束,智能指针类也能确保在内存不再需要时将其释放 使用自定义的释放操作 删除器函数必须能够完成对shared_ptr中保存的指针进行释放的操作 正确使用智能指针,必须坚持一些基本规范： 不使用相同的内置指针值初始化(或reset)多个智能指针 不delete get()返回的指针 不使用get()初始化或reset另一个智能指针 如果使用get()返回的指针,记住当最后一个对应的智能指针销毁后,指针就变为无效了 如果使用智能指针管理的资源不是new分配的内存,记住传递给它一个删除器 12345678910111213141516171819202122// 网络库代码(示例)struct destination;struct connection;connection connect(destination*);void disconnect(connect);void f(destination &amp;d)&#123; //获得一个连接 connection c = connect(&amp;d);// 使用连接 // 如果在f推出之 前忘记调用disconnect,就无法关闭c&#125;// 释放操作,删除器void end_connection(connection *p) &#123;disconnect(*p);&#125;void f(destination &amp;d)&#123; //获得一个连接 connection c = connect(&amp;d); shared_ptr&lt;connection&gt; p(&amp;c,end_connection)// 使用连接 // 如果在f推出之 前忘记调用disconnect,就无法关闭c&#125; 12.1.5 unique_ptr 一个unique_ptr拥有它所指向的对象 与shared_ptr不同,某个时刻只能有一个unique_ptr指向一个给定对象 当unique_ptr被销毁时,它所指向的对象也被销毁 当定义一个unique_ptr时,需要将其绑定到一个new返回的指针上 类似shared_ptr,初始化unique_ptr必须采用直接初始化形式 unique_ptr不支持普通的拷贝或赋值操作 可调用release或reset将指针的所有权转移 release成员返回unique_ptr当前保存的指针并将其置为空 release返回的指针通常被用来初始化另一个智能指针或给另一个智能指针赋值 调用release会切断unique_ptr和它原来管理的对象间的联系 reset成员接受一个可选的指针参数,令unique_ptr重新指向给定的指针 传递unique_ptr参数和返回unique_ptr 可以拷贝或赋值一个将要被销毁的unique_ptr auto_ptr(标准库的较早版本,具有unique_ptr的部分特性,但不是全部) 不能在容器中保存auto_ptr,也不能从函数中返回auto_ptr 虽然auto_ptr仍是标准库的一部分,但编写程序时应该使用unique_ptr 向unique_ptr传递删除器 重载一个unique_ptr中默认的删除器 必须在尖括号中unique_ptr指向类型之后提供删除器类型 在创建或reset一个这种unique_ptr类型的对象时,必须提供一个指定类型的可调用对象(删除器) unique_ptr操作 - unique_ptr&lt;T&gt; u1 空unique_ptr,可以指向类型为T的对象。u1会使用delete来释放它的指针 unique_ptr&lt;T,D&gt; u2 u2会使用一个类型为D的可调用对象来释放它的指针 unique_ptr&lt;T,D&gt; u(d) 空unique_ptr,指向类型为T的对象,用类型为D的对象d代替delete u=nullptr 释放u指向的对象,将u置为空 u.release() u放弃对指针的控制权,返回指针,并将u置为空 u.reset() 释放u指向的对象 u.reset(q) 如果提供了内置指针q,令u指向这个对象 u.reset(nullptr) 如果提供了内置指针q,令u指向这个对象 123456789101112unique_ptr&lt;int&gt; p2(new int(42));unique_ptr&lt;string&gt; p1(new string(&quot;Stegosaurus&quot;));// 从函数返回一个unique_ptrunique_ptr&lt;int&gt; clone(int p)&#123; return unique_ptr&lt;int&gt;(new int(p));&#125;// p指向一个类型为objT的对象,并使用一个类型为delT的对象释放objT对象// 调用一个名为fcn的delT类型对象unique_ptr&lt;objT,delT&gt; p(new objT,fcn) 12.1.6 weak_ptr weak_ptr是一种不控制所指向对象生存期的智能指针,它指向由一个shared_ptr管理的对象 将一个weak_ptr绑定到一个shared_ptr不会改变shared_ptr的引用计数 一旦最后一个指向对象的shared_ptr被销毁,对象就会被释放(即使有weak_ptr指向对象) 由于对象可能不存在,不能使用weak_ptr直接访问对象,而必须调用lock 此函数检查weak_ptr指向的对象是否仍存在 如果存在,lock返回一个指向共享对象的shared_ptr weak_ptr操作 - weak_ptr&lt;T&gt; w 空weak_ptr,可以指向类型为T的对象 weak_ptr&lt;T&gt; w(sp) 与shared_ptr sp指向相同对象的weak_ptr w = p p可以是一个shared_ptr或一个weak_ptr。w与p共享对象 w.reset() 将w置为空 w.use_count() 与w共享对象的shared_ptr的数量 w.expired() 若w.use_count为0,返回true w.lock() 若expired为true,返回一个空shared_ptr;否则返回一个指向w的对象的shared_ptr 12.2 动态数组 C++语言和标准库提供了两种一次分配一个对象数组的方法 C++语言定义了另一种new表达式语法,可以分配并初始化一个对象数组 标准库中包含一个名为allocator的类,允许我们将分配和初始化分离 12.2.1 new和数组 为了new分配一个对象数组,需要在类型名之后跟一对方括号,在其中指明要分配的对象的数目 new分配一个数组时,得到的是一个数组元素类型的指针 分配的内存不是一个数组类型,不能对动态数组调用begin和end,不能用范围for语句 初始化动态分配对象的数组 可以对数组中的元素进行值初始化,在大小后跟着一对空括号 不能在括号中给出初始化器,意味着不能用auto分配数组 可以使用元素初始化器的花括号列表 使用new[0]时：动态数组正确,对于零长度的数组来说,此指针就像尾后指针一样,但指针不能解引用 释放动态数组 特殊形式的delete：在指针前加一个空方括号 如果在delete一个数组指针时忘记了方括号,或者在delete一个单一对象的指针时使用了方括号,编译器很可能不会给出警告。程序可能在执行过程中在没有任何警告的情况下行为异常 智能指针和动态数组 可以管理new分配的数组的unique_ptr版本,必须在对象类型后面跟一对空方括号 当一个unique_ptr指向一个数组时,不能使用点和箭头成员运算符(毕竟unique_ptr指向的是一个数组而不是单个对象),可以使用下标访问成员 使用shared_ptr管理一个动态数组,必须提供自定义的删除器 shared_ptr不直接支持动态数组管理这一特性会影响访问数组中的元素 为了访问数组中的元素,必须用get获取一个内置指针,然后用它来访问数组元素 指向数组的unique_ptr - unique_ptr&lt;T[]&gt; u u可以指向一个动态分配的数组 unique_ptr&lt;T[]&gt; u(p) u可以指向内置指针p所指向的动态分配的数组;p必须能转换成类型T* u[i] 返回u拥有的数组中位置i处的对象 123456789101112131415161718int *pia = new int[get_size()];int *pia = new int[10](); //10个值初始化为0的intint *pia1 = new int[10]&#123;0,1,2,3,4,5,6,7,8,9&#125;;delete [] pa;unique_ptr&lt;int[]&gt; up(new int[10]);up.release(); //自动用delete[]销毁其指针//为了使用shared_ptr,必须提供删除器shared_ptr&lt;int&gt; sp(new int[10],[](int *p) &#123;delete[] p;&#125;);sp.reset(); //使用提供的lambda释放数组// 使用get获取一个内置指针for(size_t i = 0; i!=10;++i)&#123; *(sp.get()+i) = i;&#125; 12.2.2 allocator类 new灵活性上的限制：希望将内存分配和对象初始化组合在一起 allocator类 在头文件memory中 帮助将内存分配和对象构造分离开,提供类型感知的内存分配方法,分配的内存时原始的,未构造的 必须指明allocator可以分配的对象类型(当一个allocator对象分配内存时,会根据给定的对象类型来确定恰当的内存大小和对齐位置) allocator类及其算法 - allocator&lt;T[]&gt; a 定义了一个名为a的allocator对象,可为类型T的对象分配内存 a.allocator(n) 分配一段原始的,未构造的内存,保存n个类型为T的对象 a.deallocator(p,n) 释放从T*指针p中地址开始的内存;p必须是一个先前有allocate返回的指针,且n必须是p创建时所要求的大小;在调用之前必须对这块内存中的对象调用destory a.construct(p,args) p必须时一个类型为T*的指针,指向一块原始内存;arg被传递给类型为T的构造函数,用来在p指向的内存中构造一个对象 a.destroy(p) 对p指向的对象执行析构函数 allocator分配未构造的内存 construct成员函数接受一个指针和额外参数,初始化构造对象(额外参数必须时与构造的对象的类型相匹配的合法初始化器) 一旦元素被销毁后,就可以重新使用这部分内存来保存其他对象,也可以将其归还给系统 释放内存通过调用deallocate来完成 1234567891011121314allocator&lt;string&gt; alloc; //可以分配string的allocator对象auto const p = alloc.allocate(n); //分配n个未初始化的stringauto q = p; //q指向最后构造的元素之后的位置alloc.construct(q++); //*q为空字符串alloc.construct(q++,10,&#x27;c&#x27;); //*q为ccccccccccalloc.construct(q++,&quot;hi&quot;); //*q为hi// 销毁对象while(q != p) alloc.destroy(--q); //释放真正构造的string// 释放内存alloc.deallocate(p,n); allocator算法 - uninitialized_copy(b,e,b2) 从迭代器b和e指出的输入范围中拷贝元素到迭代器b2指定的未构造的原始内存中 uninitialized_copy_n(b,n,b2) 从迭代器b指向的元素开始,拷贝n个元素到b2开始的内存 uninitialized_fill(b,e,t) 在迭代器b和e指定的原始内存范围中创建对象,对象的值均为t的拷贝 uninitialized_fill_n(b,n,t) 在迭代器b指向的内存地址开始创建n个对象 13 拷贝控制 一个类通过定义5种特殊的成员函数来控制显式地或隐式地指定在此类型地的对象拷贝,移动或销毁时做什么 拷贝构造函数 拷贝赋值运算符 移动构造函数 移动赋值运算符 析构函数 拷贝和移动构造函数定义了当用同类型的另一个对象初始化本对象时做什么 拷贝和移动赋值运算符定义了将一个对象赋予同类型的另一个对象时做什么 析构函数定义了当此类型对象销毁时做什么 13.1 拷贝,赋值与销毁 13.1.1 拷贝构造函数 拷贝构造函数：构造函数的第一个参数是自身的引用,且任何额外参数都有默认值 拷贝构造函数通常不应该是explicit的 合成拷贝构造函数 即使定义了其他构造函数,编译器也会合成一个拷贝构造函数 对某些类,合成拷贝构造函数用来阻止拷贝该类类型的对象 一般情况,合成的拷贝构造函数会将其参数的成员逐个拷贝到正在创建的对象中(拷贝每个非static成员) 对于类类型,会使用其拷贝构造函数拷贝 内置类型的成员则直接拷贝 拷贝初始化 使用直接初始化,实际上是要求编译器使用普通的函数匹配来选择与提供的参数最匹配的构造函数 使用拷贝初始化,要求编译器将右侧运算对象拷贝到正在创建的对象中(必要时还要进行类型转换) 如果一个类由一个移动构造函数,则拷贝初始化有时候会使用移动构造函数而非拷贝构造函数完成 拷贝初始化在用=定义变量时会发生 将一个对象作为实参传递给一个非引用类型的形参会发生 从一个返回类型为非引用类型的函数返回一个对象会发生 用花括号列表初始化一个数组中的元素或一个聚合类中的成员会发生 参数和返回值 在函数调用过程中,具体非引用类型的参数要进行拷贝初始化 当一个函数具有非引用的返回类型时,返回值会被用来初始化调用方的结果 拷贝构造函数用来初始化非引用类类型参数(若其参数不是引用类型则调用不成功) 拷贝初始化的限制：若初始化过程需要通过一个explicit的构造函数来进行类型转换,使用拷贝初始化还是直接初始化就都可以 123456789101112131415161718192021class Sales_data&#123; public: Sales_data(const Sales_data&amp;); private: std::string bookNo; int units_sold = 0; double revenue = 0.0;&#125;Sales_data::Sales_data(const Sakes_data&amp; orig): bookNo(orig.bookNo),units_sold(orig.units_sold),revenue(orig.revenue) &#123;&#125;string dots(10,&#x27; &#x27;); //直接初始化string s(dots); //直接初始化string s2 = dots; //拷贝初始化string null_book = &quot;9-999-99999-9&quot;; //拷贝初始化string nines = string(100,&#x27;9&#x27;); //拷贝初始化vector&lt;int&gt; v1(10);vector&lt;int&gt; v2 = 10; //错误,接收大小参数的构造函数是explicit 13.1.2 拷贝赋值运算符 类控制其对象如何让赋值 类未定义拷贝赋值运算符时,编译器会合成拷贝赋值运算符 重载赋值运算符 重载运算符本质上时函数,其名字由operator关键字后接表示要定义的运算符的符号组成 重载赋值运算符就是operator=的函数 重载运算符的参数必须表示运算符的运算对象,某些运算符必须定义为成员函数 若运算符时一个成员函数,其左侧运算符对象就绑定到隐式的this参数 为了与内置类型的赋值保持一致,赋值运算符通常返回一个指向其左侧运算对象的引用 合成拷贝赋值运算符 类似拷贝构造函数,对于某些类,合成拷贝赋值运算符用来禁止该类型对象的赋值 拷贝赋值运算符会将右侧运算对象的每个非static成员赋给左侧运算对象对象的成员 1234567891011121314// 拷贝赋值运算符class Foo&#123; public: Foo&amp; operator=(const Foo&amp;); //赋值运算符&#125;// 等价于合成拷贝赋值运算符Sales_data&amp; Sales_data::operator=(const Sakes_data&amp; orig)&#123; bookNo = orig.bookNo; units_sold = orig.units_sold; revenue = orig.revenue; return *this;&#125; 13.1.3 析构函数 析构函数释放对象使用的资源,并销毁对象的非static数据成员 析构函数是类的成员函数,名字由波浪号接类名构成,没有返回值也不接受参数 析构函数,首先执行函数体,然后销毁成员,成员按初始化顺序销毁使用 隐式销毁一个内置指针类型的成员不会delete它所指向的对象 智能指针成员在析构时会被自动销毁 当一个对象的引用或指针离开作用域时,析构函数不会执行 合成析构函数：合成函数用来阻止该类型的对象被销毁,如果不是这种情况,合成析构函数的函数体为空 13.1.4 三/五法则 三个基本操作可以控制类的拷贝操作：拷贝构造函数,拷贝赋值运算符,析构函数 新标准中,可以定义移动构造函数和移动赋值运算符 需要析构函数的类也需要拷贝和赋值操作 需要拷贝构造函数的类也需要拷贝赋值运算符,反之亦然 13.1.5 使用=default 可以通过将拷贝控制成员定义为=default来显式地要求编译器生成合成地版本 在类内用=default修饰成员的声明时,合成的函数将隐式地声明为内联的 只能对具有合成版本的成员函数使用=default(即,默认构造函数或拷贝控制成员) 如果不希望合成的成员是内联函数,应该只对成员的类外定义使用=default 123456789class Sales_data&#123; public: // 拷贝控制成员;使用default Sales_data() = default; Sales_data(const Sales_data&amp;) = default; Sales_data&amp; operator=(const Sales_data&amp;); ~Sales_data() = default;&#125;Sales_data&amp; Sales_data::operator=(const Sales_data&amp;) = default; 13.1.6 阻止拷贝 对于拷贝构造函数和拷贝赋值运算符没有意义地类,定义时必须采用某种机制阻止拷贝或赋值 新标准下,可以通过将拷贝构造函数和拷贝赋值运算符定义为删除的函数来阻止拷贝 删除的函数：虽然声明了,但不能以任何方式使用,在函数的参数列表后面加上=delete来指明希望定义为删除的 =delete必须出现在函数第一次声明时 析构函数不能是删除的函数(避免无法销毁此类型的对象) 删除了析构函数的类型编译器将不允许定义该类型的变量或创建该类的临时对象 合成的拷贝控制成员可能是删除的 如果一个类有数据成员不能默认构造、拷贝、复制或销毁,则对应的成员函数将被定义为删除的,编译器将这些合成的成员定义为删除的函数 一个成员由删除的或不可访问的析构函数会导致合成的默认和拷贝构造函数被定义为删除的 对于具有引用成员或无法默认构造的const成员的类,编译器不会为其合成默认构造函数 如果一个类有const成员,则不能使用合成的拷贝赋值运算符 对于有引用成员的类,合成拷贝赋值运算符被定义为删除的 将一个新值赋予一个引用成员,为这样的类合成拷贝赋值运算符,则赋值后,左侧运算对象仍然指向赋值前一样的对象,而不会与右侧运算对象指向相同的对象 private拷贝控制 在新标准之前,类是通过将其拷贝构造函数和拷贝赋值运算符声明为private阻止拷贝 现在不推荐使用 12345678910111213struct NoCopy&#123; NoCopy() = default(); NoCopy(const Nocopy&amp;) = delete; NoCopy&amp; operator=(const NoCopy&amp;) = delete; //阻止赋值&#125;struct NoDtor&#123; NoDtor() = default; ~NoDtor() = delete;&#125;NoDtor *p = new NoDtor(); //正确,但不能delete pdelete p; //错误,析构函数是删除的 13.2 拷贝控制和资源管理 管理类外资源的类必须定义拷贝控制成员 这种类需要通过析构函数来释放对象所分配的资源(一个类需要析构函数必须肯定需要拷贝构造函数和拷贝赋值运算符) 为了定义这些成员,首先必须确定此类型对象的拷贝语义,有两种选择：定义拷贝操作,使类的行为看起来像一个值或像一个指针 类的行为像一个值,意味着应该有自己的状态;拷贝一个像值的对象时,副本和原对象使完全独立的,改变副本不会对原对象产生任何影响 行为像指针的类则共享状态;拷贝一个类使,副本和原对象使用相同的底层数据;改变副本会改变原对象,反之亦然 13.2.1 行为像值的类 为了提供类值得行为,对于类管理的资源,每个对象都应该拥有一份自己的拷贝 类值拷贝赋值运算符 赋值运算符通常组合了析构函数和构造函数的操作 赋值运算符会从右侧运算对象拷贝数据 赋值运算符会销毁左侧运算对象的资源 即使是将一个对象赋予它自身,也要能正确工作,一个好的方法是在销毁左侧运算对象资源之前拷贝右侧运算对象 1234567891011121314151617181920212223242526// 意味着对于ps指向string,每个HasPtr对象都必须有自己的拷贝// 为了实现类值,需要定义一个拷贝构造函数,析构函数,拷贝赋值运算符class HasPtr&#123; public: HasPtr(const std::string &amp;s = std::string()): ps(new std::string(s)),i(0)&#123;&#125; //对ps指向的string,每个HasPtr对象都有自己的拷贝 HasPtr(const HasPtr &amp;p): ps(new std::string(*p.ps)),i(p.i)&#123;&#125; HasPtr&amp; operator=(const HasPtr&amp;); ~HasPtr()&#123;delete ps;&#125; private: std::string *ps; int i;&#125;// 本例中,通过先拷贝右侧运算对象,可以处理自赋值情况,并且能保证在异常发生时代码安全// 完成拷贝后,释放左侧运算对象的资源,并更新指针指向新分配的stringHasPtr&amp; HasPtr::operator=(const HasPtr&amp; rhs)&#123; auto newp = new string(*rhs.ps); delete ps; ps = newp; i = rhs.i; return *this;&#125; 13.2.2 定义行为像指针的类 对于行为类似指针的类,需要定义拷贝构造函数和拷贝赋值运算符 类展现类似指针的行为的最好办法是使用shared_ptr来管理类中的资源 拷贝(或赋值)一个shared_ptr会拷贝(赋值)shared_ptr所指向的指针,shared_ptr类自己记录共享所指向对象的数量;没有用户使用对象时,shared_ptr类负责释放资源 直接管理资源,使用引用计数 引用计数的工作方式 除了初始化对象外,每个构造函数要创建一个引用计数,用来记录有多少个对象与正在创建的对象共享状态 构造函数不分配新的计数器,而是拷贝给定对象的数据成员 析构函数递减计数器,指出共享状态的用户减少一个 拷贝赋值运算符递减右侧运算对象的计数器,递减左侧运算对象的计数器 在动态内存中保存计数器 123456789101112131415161718192021222324252627282930313233// 定义一个使用引用计数的类class HasPtr&#123; public: HasPtr(const std::string &amp;s = std::string()): ps(new std::string(s)),i(0),use(new std::size_t(1)) &#123;&#125; HasPtr(const HasPtr &amp;p): ps(p.ps),i(p.i),use(p.use) &#123;++*use;&#125; HasPtr&amp; operator=(const HasPtr&amp;); ~HasPtr(); private: std::string *ps; int i; std::size_t *use; //用来记录有多少个对象共享*ps的成员&#125;HasPtr::~HasPtr()&#123; if(--*use == 0)&#123; delete ps; delete use; &#125;&#125;HasPtr&amp; HasPtr::operator=(const HasPtr&amp; rhs)&#123; ++*rhs.use; if(--*use == 0)&#123; delete ps; delete use; &#125; ps = rhs.ps; i = rhs.i; use = rhs.use; return *this;&#125; 13.3 交换操作 除了定义拷贝控制成员,管理资源的类还定义了一个swap的函数 swap函数应该调用swap,而不是std::swap 在赋值运算符中使用swap 定义swap的类通常用swap来定义赋值运算符,使用拷贝并交换的技术 使用拷贝和交换的赋值运算符自动就是异常安全的,且能正确处理自赋值 1234567891011121314151617class HasPtr&#123; // 将swap定义为friend,以便能访问HasPtr的(private的)数据成员 // 由于swap的存在就是为了优化代码,将其声明为inline函数 friend void swap(HasPtr&amp;, HasPtr&amp;);&#125;;inline void swap(HasPtr &amp;lhs,HasPtr &amp;rhs)&#123; using std::swap; swap(lhs.ps,rhs.ps); swap(lhs.i,rhs.i);&#125;// 注意rhs是按值传递的,意味着HasPtr的拷贝构造函数// 将右侧运算对象中的string拷贝到rhsHasPtr&amp; HasPtr::operator=(HasPtr rhs)&#123; swap(*this,rhs); //rhs现在指向本对象曾经使用的内存 return *this; // rhs被销毁,从而delete了rhs中的指针&#125; 13.5 *动态内存管理类 某些类需要在运行时分配可变大小的内存空间,可以使用标准库容器来保存它们的数据 某些类需要自己进行内存分配,这些类必须定义自己的拷贝控制成员来管理所分配的内存 将实现标准库vector类的一个简化版本,只针对于string,被命名为StrVec StrVec类的设计 在StrVec类中使用allocator类获得原始内存 使用destroy成员来销毁元素 alloc_n_copy会分配内存,并拷贝一个给定范围中的元素 free会销毁构造的元素并释放内存 chk_n_alloc保证StrVec至少有容纳一个新元素的空间 reallocate在内存用完时为StrVec分配新内存 使用construct 函数push_back调用chk_n_alloc确保空间容纳新元素 在重新分配内存的过程中移动而不是拷贝元素 移动拷贝函数 std::move;move的标准库函数,位于utility文件中 12345678910111213141516171819202122232425262728class StrVec&#123; public: StrVec(): //allocator成员进行默认初始化 elements(nullptr),first_free(nullptr),cap(nullptr)&#123;&#125; StrVec(const StrVec&amp;); //拷贝构造函数 StrVec &amp;operator=(const StrVec&amp;); //拷贝赋值运算符 ~StrVec(); //析构函数 void push_back(const std::string&amp;); //拷贝元素 size_t size() const &#123;return first_free - elements;&#125; size_t capacity() const &#123;return cap - elements;&#125; std::string *begin() const &#123;return elements;&#125; std::string *end() const &#123;return first_free;&#125; // ... private: Static std::allocator&lt;std::string&gt; alloc; //分配元素 void chk_n_alloc()&#123; if(size() == capacity()) reallocate(); &#125; // 工具函数,被拷贝构造函数,赋值运算符和析构函数所使用 std::pair&lt;std::string*,std::string*&gt; alloc_n_copy (const std::string*,const std::string*); void free(); void reallocate(); std::string *elements; std::string *first_free; std::string *cap;&#125; 13.6 对象移动 新标准的一个最主要特征是：可以移动而非拷贝对象的能力 标准库容器,string和shared_ptr类既支持移动也支持拷贝.IO类和unique_ptr类可以移动但不能拷贝 13.6.1 右值引用 左值与右值的介绍 为了支持移动操作,新标准引入了新的引用类型——右值引用 右值引用就是必须绑定到右值的引用,使用&amp;&amp;获得右值引用,且只能绑定到一个将要销毁的对象 左值引用不能将其绑定到要求转换的表达式,字面常量或返回右值的表达式 返回左值引用的函数,连同赋值,下标,解引用和前置递增运算符都是返回左值,可以用左值引用绑定 右值引用可以绑定到这类表达式上 返回非引用类型的函数,连通算数,关系,位以及后置递增运算符都生成右值,可以用const左值引用或右值绑定 左值持久,右值短暂 左值有持久的状态,而右值要么是字面常量,要么是表达式求值过程中创建的临时对象 变量是左值：变量可以看作只有一个运算对象而没有运算符的表达式 不能将一个右值引用绑定到一个右值引用类型的变量上 变量是左值,不能将一个右值引用直接绑定到一个变量(包括右值引用类型的变量)上 标准库move函数 可以显式地将一个左值转换位对应地右值引用 调用move就承诺：除了对左值赋值或销毁它之外,将不再使用它,且调用move之后,不能对移动后原对象地值做任何假设 可以销毁一个移后源对象,也可以赋予它新值,但不能使用一个移后源对象的 使用move的代码应该使用std：：move而不是move,可以避免潜在的名字冲突 1234int &amp;&amp;rr1 = 42;int &amp;&amp;rr2 = rr1; //错误：表达式rr1是左值int &amp;&amp;rr3 = std::move(rr1); 13.6.2 移动构造函数和移动赋值运算符 移动拷贝函数的第一个参数是该类类型的一个引用 该引用为一个右值引用 任何额外的参数都必须有默认实参 需要保证移后源对象处于销毁无害的状态,且一旦资源完成移动,源对象必须不再指向被移动的资源 动构造函数不分配任何新内存,而是接管给定的内存 接管内存后,将对象中的指针都置为nullptr noexcept 承诺函数不抛出异常的一种方法,在参数列表后指定noexcept 不抛出异常的移动构造函数和移动赋值运算符必须标记为noexcept 1234567// StrVec类定义移动构造函数StrVec::StrVec(StrVec &amp;&amp;s) noexcept //移动操作不应抛出任何异常 : elements(s.elements),first_free(s.first_free),cap(s.cap)&#123; // 对其运行析构函数是安全的 s.elements = s.first_free = s.cap = nullptr;&#125; 移动赋值运算符 移动赋值运算符执行于析构函数和移动构造函数相同的工作 以移动构造函数一样,若移动赋值运算符不跑出任何异常,就应该标记为noexcept 12345678910StrVec &amp;StrVec::operator=(StrVec &amp;&amp;rhs) noexcept&#123; if(this!=&amp;rhs)&#123; free(); elements = rhs.elements; first_free = rhs.first_free; cap = rhs.cap; rhs.elements = rhs.first_free = rhs.cap = nullptr; &#125; return *this;&#125; 移后源对象必须可析构 从一个对象移动数据并不会销毁此对象,但有时在移动操作完成后,源对象会被销毁 因此,当编写一个移动操作时,必须确保移后源对象进入一个可析构的状态 可通过将移后源对象的指针成员置为nullptr来实现的。 除了将移后源对象置为析构安全的状态之外,移动操作还必须保证对象仍然是有效的 一般来说,对象有效就是指可以安全地为其赋予新值或者可以安全地使用而不依赖其当前值 另一方面,移动操作对移后源对象中留下的值没有任何要求 因此程序不应该依赖于移后源对象中的数据 合成的移动操作 若一个类定义了拷贝构造函数,拷贝赋值运算符或析构函数,编译器就不会合成移动构造函数和移动赋值运算符 只有当一个类没有定义任何自己版本的拷贝控制成员,且类的每个非static数据成员都可以移动时,编译器才会为它合成移动构造函数或移动赋值运算符 编译器可以移动内置类型的成员 如果一个成员是类类型,且该类有对应的移动操作,编译器也能移动这个成员 移动操作永远不会隐式定义为删除的函数 可以显式要求生成=default的移动操作,且编译器不能移动所有成员,则编译器会将移动操作定义为删除的函数 移动构造函数被定义为删除的函数的条件是： 有类成员定义了自己的拷贝构造函数且未定义移动构造函数,或者是有类成员未定义自己的拷贝构造函数且编译器不能为其合成移动构造函数。移动赋值运算符的情况类似 如果有类成员的移动构造函数或移动赋值运算符被定义为删除的或是不可访问的,则类的移动构造函数或移动赋值运算符被定义为删除的 类似拷贝构造函数,如果类的析构函数被定义为删除的或不可访问的,则类的移动构造函数被定义为删除的 类似拷贝赋值运算符,如果有类成员是const的或是引用,则类的移动赋值运算符被定义为删除的 移动操作和合成的拷贝控制成员间还有最后一个相互作用关系：一个类是否定义了自己的移动操作对拷贝操作如何合成有影响。如果类定义了一个移动构造函数和/或一个移动赋值运算符,则该类的合成拷贝构造函数和拷贝赋值运算符会被定义为删除的,需要定义自己的拷贝操作 如果一个类有一个可用的拷贝构造函数而没有移动构造函数,则其对象是通过拷贝构造函数来“移动”的。拷贝赋值运算符和移动赋值运算符的情况类似。 拷贝并交换赋值运算符和移动操作 拷贝并交换赋值运算符：是函数匹配和移动操作间相互关系的一个很好的示例 所有五个拷贝控制成员应该看作一个整体：一般来说,如果一个类定义了任何一个拷贝操作,它就应该定义所有五个操作。如前所述,某些类必须定义拷贝构造函数、拷贝赋值运算符和析构函数才能正确工作 123456789101112131415class HasPtr&#123; public: //添加的移动构造函数 HasPtr(HasPtr &amp;&amp;p) noexcept :ps(p.ps),i(p.i)&#123;p.ps = 0;&#125; // 赋值运算符既是移动赋值运算符,也是拷贝赋值运算符 HasPtr&amp; operator=(HasPtr rhs)&#123; swap(*this,rhs); return *this; &#125;&#125;// 为类添加了一个移动构造函数,它接管了给定实参的值// 构造函数体将给定的HasPtr的指针置为0,从而确保销毁移后源对象是安全的hp = hp2; //hp2是左值使用拷贝构造函数拷贝hp = std::move(hp2); //移动构造函数移动hp2 移动迭代器 一个移动迭代器通过改变给定迭代器的解引用运算符的行为来适配此迭代器,移动迭代器的解引用运算符生成一个右值引用 调用标准库的make_move_iterator函数将一个普通迭代器转换为一个移动迭代器 建议：不要随意使用移动操作 由于一个移后源对象具有不确定的状态,对其调用std：：move是危险的 调用move时,必须绝对确认移后源对象没有其他用户 13.6.3 右值引用和成员函数 除了构造函数和赋值运算符之外,一个成员函数同时提供拷贝和移动版本,一个版本接收一个指向const的左值引用,第二个版本接收一个指向非const的右值引用 区分移动和拷贝的重载函数通常有一个版本接受一个const T&amp;,而另一个版本接受一个T&amp;&amp; push_bakc的标准库容器提供两个版本 12void push_back(const X&amp;); //拷贝,绑定到任意类型的Xvoid push_back(X&amp;&amp;); //移动,只能绑定到类型X的可修改的右值 右值和左值引用成员函数 在一个对象上调用成员函数,而不管该对象是一个左值还是右值 新标准中仍然允许向右值赋值,若希望阻止这种用法,希望强制左侧运算对象(即this指向的对象)是一个左值 this的左右值属性与定义const成员函数相同,即在参数列表后放置一个引用限定符 引用限定符可以是&amp;或&amp;&amp;,分别指出this可以指向一个左值或右值 类似const限定符,引用限定符只能用于(非static)成员函数,且必须同时出现在函数的声明和定义中 一个函数可以同时用const和引用限定。但引用限定符必须跟随在const限定符之后 1234567891011121314151617string s1 = &quot;a value&quot;,s2 = &quot;another&quot;;auto n = (s1+s2).find(&#x27;a&#x27;);s1 + s2 = &quot;wow&quot;; //正确,但应阻止这种用法class Foo&#123; public: Foo &amp;operator=(const Foo&amp;) &amp;; //只能向可修改的左值放置&#125;;Foo &amp;Foo::operator=(const Foo &amp;rhs) &amp;&#123; //do something works; return *this;&#125;class Foo&#123; Foo anotherMem() const &amp;; //正确,const限定符在前&#125; 重载和引用函数 可以综合引用限定符和const来区分一个成员函数的重载版本 当定义const成员函数时,可以定义两个版本,唯一的差别是一个版本有const限定而另一个没有 引用限定的函数则不一样：如果定义两个或两个以上具有相同名字和相同参数列表的成员函数,就必须对所有函数都加上引用限定符,或者所有都不加 如果一个成员函数有引用限定符,则具有相同参数列表的所有版本都必须有引用限定符 14 重载运算与类型转换 14.1 基本概念 重载的运算符具有特殊名字的函数：名字由operator和其后要定义的运算符号共同组成,也包含返回类型,参数列表以及函数体 如果运算符函数是成员函数,则第一个左侧运算对象绑定到隐式的this指针上(成员运算符函数的显式参数数量比运算符的运算对象总数少一个) 对于一个运算符函数来说,它或者是类的成员,或者至少含有一个类类型的参数,意味着当运算符作用于内置类型的运算对象时,无法改变该运算符的含义 不能被重载的运算符 :: .* . ? : 直接调用一个重载的运算符函数 将运算符作用于类型正确的实参,从而以这种简介调用重载的运算符函数 可以像调用普通函数一样直接调用运算符函数,先指定函数名字,然后再传入数量正确,类型适当的实参 可以显式调用成员运算符的函数：首先指定运算函数的对象的名字,然后使用点运算符访问希望调用的函数 某些运算符不应该被重载 某些运算符指定了运算对象求值的顺序,若重载则运算对象求值顺序的规则不发应用到重载的运算符上 特使是：逻辑与,逻辑或和逗号运算符 C++对逗号运算符和取地址运算符定义了特殊含义,一般不会被重载 使用于内置类型一致的含义 某些操作在逻辑上与运算符相关,则适合于定义成重载的运算符 重载运算符的返回类型通常情况下应该与其内置版本的返回类型兼容,逻辑运算符和关系运算符应该返回bool,算数运算符应该返回一个类类型的值,赋值运算符和复合赋值运算符应该返回左侧运算对象的引用 选择作为成员或者非成员 定义重载的运算符时,必须首先决定将其声明为类的成员函数还是声明为一个普通的非成员函数 赋值(=),下标([ ]),调用(( ))和成员访问箭头(-&gt;)运算符必须是成员 复合赋值运算符一般来说应该是成员,但并非必须,这一点与赋值运算符略有不同 改变对象状态的运算符或者与给定类型密切相关的运算符,如递增、递减和解引用运算符,通常应该是成员 具有对称性的运算符可能转换任意一端的运算对象,例如算术、相等性、关系和位运算符等,因此它们通常应该是普通的非成员函数 12345678910111213141516// 错误：不饿能为int重定义内置的运算符int operator+(int,int);// 一个非成员运算符函数的等价调用data1 + data2;operator+(data1,data2);// 调用非成员函数operator+,传入data1,data2作为实参data1 += data2;data1.operator+=(data2);string s = &quot;world&quot;;string t = s + &quot;!&quot;;string u = &quot;hi&quot; + s; //如果+时string的成员则产生错误// 如果operator+时string类的成员,则上面的第一个加法等价于s.operator+(&quot;!&quot;)// &quot;hi&quot;+s等价于&quot;hi&quot;.operator+(s) 14.2 输入和输出运算符 IO标准库分别使用&gt;&gt;和&lt;&lt;执行输入和输出操作 对两个运算符来说,IO库定义了用其读写内置类型的版本,而类需要自定义适合其对象的新版本以支持IO操作 14.2.1 重载输出运算符&lt;&lt; 通常情况下,输出运算符的第一个形参是一个非常量ostream对象的引用,之所以ostream是非常量是因为向流写入内容会改变其状态;而该形参是引用时因为无法直接复制一个ostream对象 第二个形参一般来说是一个常量的引用,该常量是我们想要打印的类类型,第二个形参是引用的原因是我们希望避免复制实参 为了与其他输出运算符保持一致,operator&lt;&lt;一般要返回它的ostream形参 输出运算符尽量减少格式化操作 用于内置类型的输出运算符不太考虑格式化操作,尤其不会打印换行符 如果运算符打印了换行符,则用户就无法在对象的同一行内接着打印一些描述性的文本,相反,令输出运算符尽量减少格式化操作可以使用户有权控制输出的细节 通常,输出运算符应该主要负责打印对象的内容而非控制格式,输出运算符不应该打印换行符 输入输出运算符必须使非成员函数 与iostream标准库兼容的输入输出运算符必须是普通的非成员函数,而不能是类的成员函数,否则左侧运算对象是类的一个对象 假设输入输出运算符是某个类的成员,则它们也必须是istream或ostream的成员,然而,这两个类属于标准库,并且无法给标准库中的类添加任何成员 如果希望为类自定义IO运算符,则必须将其定义成非成员函数 12345678// Sales_data的输出运算符ostream&amp; operator&lt;&lt;(ostream &amp;os, const Sales_data &amp;item)&#123; os &lt;&lt; item.isbn() &lt;&lt;&quot; &quot; &lt;&lt; item.units_sold &lt;&lt;&quot; &quot;&lt;&lt; item.revenus &lt;&lt; &quot; &quot; &lt;&lt; item.avg_price(); return os;&#125;Sales_data data;data&lt;&lt;cout; //如果operator&lt;&lt;是Sales_data的成员 14.2.2 重载输入运算符&gt;&gt; 输入运算符的第一个形参是运算符将要读取的流的引用,第二个形参是将要读入到的对象的引用,该运算符通常会返回某个给定流的引用 第二个形参之所以必须是非常量是因为输入运算符本身的目的就是将数据读入到这个对象中 输入运算符必须处理输入可能失败的情况,而输出运算符不需要 输入时的错误 当流含有错误类型的数据时读取操作可能会失败 当读取操作到达文件末尾或遇到输入流的其他错误时也会失败 通常将对象置于合法的状态,能略微保护使用者免于受到输入错误的影响,当读取操作发生错误时,输入运算符应该负责从错误中恢复 12345678910// Sales_data的输入运算符istream &amp;operator&gt;&gt;(istream &amp;is,Sales_data &amp;item)&#123; double price; is &gt;&gt; item.bookNo &gt;&gt; item.units_sold &gt;&gt;price; if(is) item.revenue = item.units_sold * price; else item = Sales_data(); return is;&#125; 14.3 算术和关系运算符 通常情况下,把算数和关系运算符定义成非成员函数以允许对左侧或右侧的运算对象进行转换 这些运算符一般不需要改变运算对象的状态,形参都是常量的引用 算数运算符通常会计算它的两个运算对象并得到一个新值,操作完成后返回该局部变量的副本作为其结果 如果类定义了算数运算符,则一般也会定义一个对应的复合赋值运算符 如果类同时定义了算数运算符和相关的复合赋值运算符,则通常情况下应该使用复合赋值来实现算术运算符 1234567// 最有效的方法是使用复合赋值来定义算数运算符// 假设两个对象指向同一本书Sales_data operator+(const Sales_data &amp;lhs, const Sales_data &amp;rhs)&#123; Sales_data sum = lhs; sum += rhs; return sum;&#125; 14.3.1 相等运算符 C++中的类通过定义相等运算符来检测两个对象是否相等 12345678bool operator==(const Sales_data &amp;lhs, const Sales_data &amp;rhs)&#123; return lhs.isbn() == rhs.isbn() &amp;&amp; lhs.units_sold == rhs.units_sold &amp;&amp; lhs.revenue == rhs.revenue;&#125;bool operator !=(const Sales_data &amp;lhs, const Sales_data &amp;rhs)&#123; return !(lhs == rhs);&#125; 设计准则： 如果一个类含有判断两个对象是否相等的操作,则它显然应该把函数定义成operator==而非一个普通的命名函数 如果类定义了operator==,则该运算符应该能判断一组给定的对象中是否含有重复数据 通常情况下,相等运算符应该具有传递性 如果类定义了operator==,则这个类也应该定义operator!= 相等运算符和不相等运算符中的一个应该把工作委托给另外一个,这意味着其中一个运算符应该负责实际比较对象的工作,而另一个运算符则只是调用那个真正工作的运算符 14.3.2 关系运算符 定义了相等运算符的类常常包含关系运算符,特别是,因为关联容器和一些算法要用到小于运算符,所以定义operator&lt;会比较有用 通常情况下关系运算符应该 定义顺序关系,令其与关联容器中对关键字的要求一致; 如果类同时含有运算符的话,则定义一种关系令其与保持一致 如果存在唯一一种逻辑可靠的&lt;定义,则应该考虑为这个类定义&lt;运算符 如果类同时还包含==,则当且仅当&lt;的定义和==产生的结果一致时才定义&lt;运算符 14.4 赋值运算符 拷贝赋值和移动赋值运算符可以把类的一个对象赋值给该类的另一个对象 类可以定义其他赋值运算符以使用别的类型作为右侧运算对象 和拷贝赋值及移动赋值运算符一样,其他重载的赋值运算符也必须先释放当前内存空间,再创建一个新空间 不同之处是运算符无须检查对象向自身的赋值 可以重载赋值运算符,不论形参的类型是什么,赋值运算符都必须定义为成员函数 复合赋值运算符 复合赋值运算符不非得是类的成员,但还是倾向于把包括复合赋值在内的所有赋值运算符都定义在类的内部 为了与内置类型的复合赋值保持一致,类中的复合赋值运算符也要返回其左侧运算对象的引用 赋值运算符必须定义成类的成员,复合赋值运算符也通常定义为类的成员(两类运算符都应该返回左侧运算对象的引用) 12345678910111213141516171819202122232425// 标准库vector定义了第三种赋值运算符,接受花括号内的元素列表作为参数vector&lt;string&gt; v;v = &#123;&quot;a&quot;,&quot;an&quot;,&quot;the&quot;&#125;;// 同样也可以把这个运算符添加到StrVec类中class StrVec&#123; public: StrVec &amp;operator=(std::initializer_list&lt;std::string&gt;);&#125;;// 为了与内置类型的赋值运算符保持一致,新的赋值运算符将返回其左侧运算对象的引用StrVec &amp;StrVec::operator=(initializer_list&lt;string&gt; il)&#123; auto data = alloc_n_copy(il.begin(),il.end()); free(); elements = data.first; first_free = cap = data.second; return *this;&#125;// Sales_data类中复合赋值运算符的定义Sales_data&amp; Sales_data::operator+=(const Sales_data &amp;rhs)&#123; units_sold += rhs.units_sold; revenue += rhs.revenue; return *this;&#125; 14.5 下标运算符 表示容器的类通常可以通过元素在容器中的位置访问元素,这些类一般会定义下标运算符operator[] 下标运算符必须是成员函数 下标运算符通常以所访问元素的引用作为返回值 最好定义下标运算符的常量版本和非常量版本,当作用于一个常量对象时,下标运算符返回常量引用确保不会给返回的对象赋值 1234567891011class StrVec&#123; public: std::string&amp; operator[](std::size_t n)&#123; return elements[n]; &#125; const std::string&amp; operator[](std::size_t n) const&#123; return elements[n]; &#125; private: std::string *elements; //指向数组首元素的指针&#125; 14.6 递增和递减运算符 对于内置类型来说,递增和递减运算符既有前置版本还有后置版本 应该为类定义两个版本递增和递减运算符 为了与内置版本保持一致前置运算符应该返回递增或递减后对象的引用 12345678910111213141516171819class StrBlobPtr&#123; public: StrBlobPtr&amp; operator++(); StrBlobPtr&amp; operator--();&#125;// 递增和递减运算符的工作机理非常相似// 前置版本：返回递增/递减对象的引用StrBlobPtr&amp; StrBlobPtr::operator++()&#123; check(curr,&quot;increment past end of StrBlobPtr&quot;); ++curr; return *this;&#125;StrBlobPtr&amp; StrBlobPtr::operator--()&#123; --curr; check(curr,&quot;decrement past begin of StrBlobPtr&quot;); return *this;&#125; 区分前置和后置运算符 要想同时定义前置和后置运算符,需要解决同一个符号的重载问题 后置版本接收一个额外的int类型的形参 当使用后置运算符时,编译器为形参提供了值为0的实参 形参的唯一作用就是区分前置版本和后置版本的函数,而不是真的在实现后置版本时参与运算 为了与内置版本保持一致,后置运算符应该返回对象的原值(递增或递减之前的值),返回的形式是一个值而非引用 显式地调用后置运算符 可以显式地调用一个重载的运算符,其效果与在表达式中以运算符号的形式使用它完全一样 1234567891011121314151617181920212223// 添加后置运算符class StrBlobPtr&#123; public: StrBlobPtr operator++(int); StrBlobPtr operator--(int);&#125;// 在递增对象之前需要首先记录对象的状态StrBlobStr StrBlobStr::operator++(int)&#123; StrBlobPtr ret = *this; ++*this; return ret;&#125;StrBlobStr StrBlobStr::operator--(int)&#123; StrBlobPtr ret = *this; --*this; return ret;&#125;// 用函数调用地方式调用后置版本StrBlobPtr p(a1);p.operator++(0);p.operator++(); 14.7 成员访问运算符 在迭代器类及智能指针类中常常用到解引用运算符和箭头运算符 箭头运算符必须是类的成员,解引用运算符通常也是类的成员 对箭头运算符返回值的限定 令operator*完成任何指定操作,可以让operator*返回一个固定值或打印对象的内容或其他 重载的箭头运算符必须返回类的指针或者自定义了箭头运算符的某个类的对象 1234567891011121314151617class StrBlobPtr&#123; public: std::string&amp; operator*() const&#123; auto p = check(curr,&quot;dereference past end&quot;); return (*p)[curr]; &#125; std::string* operator-&gt;() const&#123; return &amp; this-&gt;operator*(); &#125;&#125;// 解引用运算符首先检查curr是否仍在作用范围内,如果是,则返回curr所指元素的一个引用// 箭头运算符不执行任何自己的操作,而是调用解引用运算符并返回解引用结果元素的地址// 值得注意的是,我们将这两个运算符定义成了const成员,这是因为与递增和递减运算符不一样,获取一个元素并不会改变StrBlobPtr对象的状态// 同时,它们的返回值分别是非常量string的引用或指针,因为一个StrBlobPtr只能绑定到非常量的StrBlob对象(*point).mem; //point是一个内置的指针类型point.operator()-&gt;mem; //point是类的一个对象 14.8 函数调用运算符 如果类重载了函数调用运算符,可以像使用函数一样使用该类的对象 因为这样的类同时能存储状态,所以与普通函数相比更加灵活 函数调用运算符必须是成员函数 一个类可以定义多个不同版本的调用运算符,相互之间应该在参数数量或类型上有所区别 如果类定义了调用运算符,则该类的对象称作函数对象;因为可以调用这种对象,所以说这些对象的“行为像函数一样” 12345678910struct absInt&#123; int operator() (int val) const&#123; return val&lt;0? -val:val; &#125;&#125;// 定义了一种操作：函数调用运算符,它负责接受一个int类型的实参,然后返回该实参的绝对值int i = -42;absInt abdObj;int ui = absObj(i); //将i传递给absObj.operator() 含有状态的函数对象类 和其他类一样,函数对象除了operator()之外可以包含其他成员 函数对象类通常含有一些数据成员,成员被用于定制调用运算符中的操作 12345678910class PrintString&#123; public: PrintString(ostream &amp;o = cout, char c = &#x27; &#x27;): os(o),sep(c)&#123;&#125; void operator() (const string &amp;s) const &#123;os &lt;&lt; s &lt;&lt; seq;&#125; private: ostream &amp;os; char seq;&#125;// 类有一个构造函数,它接受一个输出流的引用以及一个用于分隔的字符,这两个形参的默认实参分别是cout和空格。之后的函数调用运算符使用这些成员协助其打印给定的string 14.8.1 lambda是函数对象 在lambda表达式产生的类中含有一个重载的函数调用运算符 123456789101112131415161718// 传递给stable_sort作为最后一个实参的lambda表达式// 根据单词长度第七进行排序,对于长度相同的字母按照字母表顺序排序stable sort(words.begin(),words.end()), [](const string &amp;a, const string &amp;b) &#123;return a.size() &lt; b.size();&#125;// 行为类似一个类的未命名对象class ShorterString&#123; public: bool operator() (const string &amp;s1, const string &amp;s2) const &#123;return s1.size() &lt; s2.size();&#125;&#125;;// 在默认情况下,由lambda产生的类当中的函数调用运算符是一个const成员函数。如果lambda被声明为可变的,则调用运算符就不是const的了// 用这个类代替lambdastable sort(words.begin(),words.end(),ShorterString());// 第三个实参是新构建的ShorterString对象,当stable_sort内部的代码每次比较两个string时就会“调用”这一对象,此时该对象将调用运算符的函数体,判断第一个string的大小小于第二个时返回true 表示lambda及相应捕获行为的类 当lambda表达式通过引用捕获变量时,需要确保lambda执行时引用所引用的对象确实存在 通过值捕获的变量被拷贝到lambda中 lambda产生的类必须为每个值捕获的变量建立对应的数据成员,同时创建构造函数,令其使用比获得变量的值来初始化数据成员 lambda表达式产生的类不含默认构造函数、赋值运算符及默认析构函数;它是否含有默认的拷贝/移动构造函数则通常要视捕获的数据成员类型而定 123456789101112131415// 找到第一个长度不小于给定值的string对象auto wc = find_if(words.begin(),words.end(), [sz](const string &amp;a)&#123;return a.size()&gt;=sz;&#125;);// lambda表达式产生的类将形成class SizeComp&#123; sizeComp(size_t n):sz(n)&#123;&#125; bool operator() (const string &amp;s) const &#123;return s.size() &gt;= sz;&#125; private: size_t sz;&#125;// 获得第一个指向满足条件元素的迭代器,该元素满足size() is &gt;= szauto wc = find_if(words.begin(),words.end(),SizeComp(sz)); 14.8.2 标准库定义的函数对象 标准库定义了一组表示算术运算符、关系运算符和逻辑运算符的类,每个类分别定义了一个执行命名操作的调用运算符 定义在functional头文件中 算术 关系 逻辑 plus&lt;Type&gt; equal_to&lt;Type&gt; logical_and&lt;Type&gt; minus&lt;Type&gt; no_equal_to&lt;Type&gt; logical_or&lt;Type&gt; multiplies&lt;Type&gt; greater&lt;Type&gt; logical_not&lt;Type&gt; divides&lt;Type&gt; greater_equal&lt;Type&gt; modulus&lt;Type&gt; less&lt;Type&gt; negate&lt;Type&gt; less_equal&lt;Type&gt; 14.8.3 可调用对象与function C++中可调用的对象 函数 函数指针 lambda表达式 bind创建的对象 重载了函数调用运算符的类 两个不同类型的可调用对象可以共享同一种调用形式 调用形式指明了调用返回类型以及传递给调用的实参类型 一种调用形式对应一个函数类型 不同类型可能具有相同的调用形式 对于几个可调用对象共享同一种调用形式的情况,有时希望把它们看成具有相同的类型 函数表：用于存储指向可调用对象的指针,当程序需要执行某个特定的操作时,从表中查找该调用函数 函数表可以使用map实现 1234567891011121314151617181920int(int, int)// 函数类型,接收两个int,返回一个int// 考虑下列不同类型的可调用对象int add(int i,int j)&#123;return i+j;&#125;auto mod = [](int i, int j)&#123;return i%j;&#125;// 函数对象类struct divide&#123; int operator()(int denominator,int divisor)&#123; return denominator/divisor; &#125;&#125;;// 共享一种调用形式int(int, int)// map实现函数表map&lt;string,int(*)(int,int)&gt; binops;binops.insert(&#123;&quot;+&quot;&#125;,add); //&#123;&quot;+&quot;,add&#125;是一个pair function的操作 - function&lt;T&gt; f; f是一个用来存储可调用对象的空function,这些可调用对象的调用形式应该与函数类型T相同 function&lt;T&gt; f(nullptr); 显式地构造一个空function function&lt;T&gt; f(obj); 在f中存储可调用对象obj的副本 f 将f作为条件;当f含有一个可调用对象时为真;否则为假 f(args) 调用f中的对象,参数是args 定义为function&lt;T&gt;的成员的类型 - result_type 该function类型的可调用对象返回的类型 argument_type 当T有一个或两个实参时定义的类型 first_argument_type 第一个实参类型 second_argument_type 第二个实参类型 function是一个模板,在创建时需要提供额外的信息 123456789101112131415// 调用形式function&lt;int(int,int)&gt;function&lt;int(int,int)&gt; f1 = add;function&lt;int(int,int)&gt; f2 = divide();function&lt;int(int,int)&gt; f3 = [](int i,int j)&#123;return i*j;&#125;// 重新定义mapmap&lt;string,function&lt;int(int,int)&gt;&gt; binops;map&lt;string,function&lt;int(int,int)&gt;&gt; binops = &#123; &#123;&quot;+&quot;,add&#125;, &#123;&quot;-&quot;,std::minus&lt;int&gt;()&#125;, &#123;&quot;/&quot;,devide()&#125;,&#125; 重载的函数与function 不能直接将重载函数的名字存入function类型的对象中 解决二义性的一条途径：存储函数指针而非函数的名字 第二条途经：使用lambda 新版本标准库中的function类与旧版本中的unary_function和binary_function没有关联,后两个类已经被更通用的bind函数替代了 1234int (*fp)(int,int) = add;binops.insert(&#123;&quot;+&quot;,fp&#125;);binops.insert(&#123;&quot;+&quot;,[](int a,int b)&#123;return add(a,b);&#125;&#125;); 14.9 重载,类型转换与运算符 跳转：由一个实参调用的非显式构造函数定义了一种隐式的类型转换,这种构造函数将实参类型的对象转换成类类型 可以定义对于类类型的类型转换,通过定义类型转换运算符可以做到,转换构造函数和类型转换运算符共同定义了类类型转换 14.9.1 类型转换运算符 类型转换运算符：类的一种特殊成员函数,负责将一个类类型的值转换成其他类型 一般形式:operator type() const 类型转换运算符既没有显式的返回类型,也没有形参,而且必须定义成类的成员函数 类型转换运算符通常不应该改变待转换对象的内容,因此类型转换运算符一般被定义成const成员 一个类型转换函数必须是类的成员函数;它不能声明返回类型,形参列表也必须为空。类型转换函数通常应该是const 类型转换运算符是隐式执行的,无法给这些函数传递实参,当然也就不能在类型转换运算符的定义中使用任何形参 同时,尽管类型转换函数不负责指定返回类型,但实际上每个类型转换函数都会返回一个对应类型的值 1234567891011121314151617181920212223242526// 定义含有类型转换运算符的类class SmallInt&#123; public: SmallInt(int i=0):val(i)&#123; if(i&lt;0||i&gt;255) throw std::out_of_range(&quot;Bad SmallInt value&quot;); &#125; operator int() const &#123;return val;&#125; private: std::size_t val;&#125;// 我们的SmallInt类既定义了向类类型的转换,也定义了从类类型向其他类型的转换// 其中,构造函数将算术类型的值转换成SmallInt对象,而类型转换运算符将SmallInt对象转换成intSmallInt si;si = 4;si +3; //首先将si隐式转换成int,然后执行整数加法class SamllInt;operator int(SmallInt&amp;); //错误,不是成员函数class SmallInt&#123; public: int operator int() const; //错误,制定了返回类型 operator int(int =0) const; //错误,参数列表不为空 operator int*() const &#123;return 42;&#125; //错误,42不是指针&#125; 显式的类型转化运算符：C++11新标准引入的 编译器不会将一个显式的类型转换运算符用于隐式类型转换 当表达式出现在下列位置时,显式的类型转换将被隐式地执行 if、while及do语句的条件部分 for语句头的条件表达式 逻辑非运算符(！)、逻辑或运算符(||)、逻辑与运算符(&amp;&amp;)的运算对象 条件运算符(？ ：)的条件表达式 在C++11新标准下,IO标准库通过定义一个向bool的显式类型转换实现向void*转换 向bool的类型转换通常用在条件部分,因此operator bool一般定义成explicit的 12345678910111213// 显式的类型转换class SmallInt&#123; public: ecplicit operator int() const &#123;return val;&#125;;&#125;;SmallInt si =3;si + 3; //错误发生了隐式转换// 无论我们什么时候在条件中使用流对象,都会使用为IO类型定义的operator bool。例如：while(std::cin&gt;&gt;value)// while语句的条件执行输入运算符,它负责将数据读入到value并返回cin。为了对条件求值,cin被istream operator bool类型转换函数隐式地执行了转换// 如果cin的条件状态是good,则该函数返回为真;否则该函数返回为假 14.9.2 避免有二义性的类型转换 如果类中包含一个或多个类型转换,则必须确保在类类型和目标之间只有唯一的转换方式 多重转换路径： 第一种情况是两个类提供相同的类型转换 第二种情况是定义了多个类型转换 1234567891011121314151617// 定义了两种将B转换成A的方法：一种使用B的类型转换运算符、另一种使用A的以B为参数的构造函数struct B;struct A&#123; A() = default; A(const B&amp;); //将B转换成A&#125;;struct B&#123; operator A() const&#125;;A f(const A&amp;);B b;A a = f(b); //二义性错误：含义是f(B::operator A())还是f(A::A(const B&amp;))// 需要显式调用A a1 = f(b.operator A());A a2 = f(A(b)); 以下的经验规则可能避免类型转换产生二义性有帮助： 不要令两个类执行相同的类型转换：如果Foo类有一个接受Bar类对象的构造函数,则不要在Bar类中再定义转换目标是Foo类的类型转换运算符 避免转换目标是内置算术类型的类型转换。特别是当你已经定义了一个转换成算术类型的类型转换时,接下来 不要再定义接受算术类型的重载运算符。如果用户需要使用这样的运算符,则类型转换操作将转换你的类型的对象,然后使用内置的运算符 不要定义转换到多种算术类型的类型转换。让标准类型转换完成向其他算术类型转换的工作 一言以蔽之：除了显式地向bool类型的转换之外,我们应该尽量避免定义类型转换函数并尽可能地限制那些“显然正确”的非显式构造函数 重载函数与转换构造函数：如果在调用重载函数时我们需要使用构造函数或者强制类型转换来改变实参的类型,则这通常意味着程序的设计存在不足。在调用重载函数时,如果需要额外的标准类型转换,则该转换的级别只有当所有可行函数都请求同一个用户定义的类型转换时才有用。如果所需的用户定义的类型转换不止一个,则该调用具有二义性 14.9.3 函数匹配与重载运算符 和普通函数调用不同,不能通过调用的形式来区分当前调用的是成员函数还是非成员函数 当使用重载运算符作用于类类型的运算对象时,候选函数中包含该运算符的普通非成员版本和内置版本。除此之外,如果左侧运算对象是类类型,则定义在该类中的运算符的重载版本也包含在候选函数内 当我们一个命名的函数时,具有该名字的成员函数和非成员函数不会彼此重载 因为用来调用命名函数的语法形式对于成员函数和非成员函数来说是不相同的 当通过类类型的对象(或者该对象的指针及引用)进行函数调用时,只考虑该类的成员函数 而当在表达式中使用重载的运算符时,无法判断正在使用的是成员函数还是非成员函数,因此二者都应该在考虑的范围内 如果对同一个类既提供了转换目标是算术类型的类型转换,也提供了重载的运算符,则将会遇到重载运算符与内置运算符的二义性问题 15 面向对象程序设计 15.1 OOP概述 面向对象程序设计基于三个基本概念：数据抽象、继承和动态绑定 通过数据抽象,可以将类的接口与实现分离 使用继承,可以定义相似的类型并对其相似关系建模 使用动态绑定,可以在一定程度上忽略相似类型的区别,以同一的方式使用它们的对象 继承 通过继承联系在一起的类构成一种层次关系 通常在层次关系的根部有一个基类,其他类直接或简介地从基类继承而来,继承得到的类称为派生类 基类负责定义层次关系中所有类共同拥有的成员,每个派生类定义各自特有的成员 C++语言中,基类将类型相关的函数与派生类不做改变直接继承的函数区分对待 对于某些函数,基类希望派生类各自定义适合自身的版本,此时基类将这些函数声明为虚函数 派生类必须使用类派生列表指出是由哪个基类继承而来 1234567891011class Quote&#123; public: std::string isbn() const; virtual double net_price(std::size_t n) const;&#125;;// 类派生列表的形式是：首先是一个冒号,后面紧跟以逗号分隔的基类列表,其中每个基类前面可以有访问说明符class Bulk_quote:public Quote&#123; public: double net_price(std::size_t) const override;&#125; 动态绑定 通过使用动态绑定,能用同一段代码分类处理两个类中的对象 在运行时选择函数的版本,动态绑定又称为运行时绑定 当使用基类的引用(或指针)调用一个虚函数时将发生动态绑定 123456789101112// 计算并打印销售给定数量的某种书籍所得的费用double print_total(ostream &amp;os,const Quote &amp;item, size_t n)&#123; // 根据传入item形参的对象类型调用Quote::net_price // 或者Bulk_quote::net_price double ret = item.net_price(n); os &lt;&lt; item.isbn() &lt;&lt; n &lt;&lt; ret &lt;&lt;endl; return ret;&#125;// basic的类型是Quote,bulk的类型是Bulk_quoteprint_total(cout,basic,20); //调用Quote的net_priceprint_total(cout,bulk,20); //调用Bulk_quote的net_price 15.2 定义基类和派生类 15.2.1 定义基类 12345678910111213141516// 基类的定义class Quote&#123; public: Quote() = default; Quote(const std::string &amp;book,double sales_price): bookNo(book),price(sales_price)&#123;&#125; std::string isbn() const &#123;return bookNo;&#125; virtual double net_price(std::size_t n) const&#123; return n * price; &#125; virtual ~Quote() = default; //对析构函数进行动态绑定 private: std::string bookNo; protected: double price = 0.0;&#125;; 基类都应该定义一个虚析构函数,即使该函数不执行任何操作 成员函数与继承 派生类可以继承其基类的成员,派生类需要对部分操作提供自己的新定义以覆盖(override)从基类继承来的旧定义 基类必须将两种成员函数分开： 一类是基类希望其派生类进行覆盖的函数(虚函数) 当使用指针或引用调用虚函数时,该调用被动态绑定(执行基类版本或派生类版本) 在成员函数语句之前加virtual使得函数执行动态绑定 任何构造函数之外的函数都可以是虚函数 virtual智能出现在类内部的声明语句中 一类是基类希望派生类直接继承而不要改变的函数 访问控制与继承：基类允许派生类访问基类的成员,但禁止其他用户访问,使用受保护的(protected)访问运算 15.2.2 定义派生类 派生类必须通过使用类派生列表明确指出是从哪个基类继承而来的 类派生列表的形式是,首先一个冒号,后面紧跟以逗号分割的基类列表,其中每个基类前都可以有三类访问说明符的一个public,protected,private 如果一个派生是公共的,则基类的公共成员也是派生类接口的组成部分 派生类中的虚函数 派生类经常覆盖它继承的虚函数,如果派生类没有覆盖其基类中的某个虚函数,则该虚函数的行为类似于其他的普通成员,派生类会直接继承其在基类中的版本 派生类可以在它覆盖的函数前使用virtual关键字,但不是非要这么做 C++11新标准允许派生类显式注明它在使用某个成员函数覆盖了它继承的虚函数 派生类对象及派生类向基类的类型转换 一个派生类对象包含多个组成部分：一个派生类对象包含多个组成部分,一个含有派生类自定义的非静态成员的子对象,以及一个与该派生类继承的基类对应的子对象 在一个对象中,继承自基类的部分和派生类自定义的部分不一定是连续存储的 派生类对象中含有与基类对应的组成部分,可以把派生类的对象当作基类对象来使用,而且也能将基类的指针或引用绑定到派生类对象中的基类部分 派生类到基类的类型转换,和其他类型转换一样,编译器会隐式地执行派生类到基类的转换 隐式特性意味着可以把派生类对象或派生类对象的引用用在需要基类引用的地方;同时可以把派生类对象的指针用在需要基类指针的地方 派生类构造函数：派生类可以访问基类的公共成员和受保护成员 继承与静态成员 基类定义了一个静态成员,则在整个继承中只存在该成员的唯一定义 若基类中的成员是private,派生类无权访问 被用作基类的类 一个类是基类,同时也可以是派生类 直接基类出现在派生列表中,而简介基类有派生类通过其直接基类继承而来 每个类都会继承直接基类的所有成员 防止继承的发生 在类名后跟final关键字可以防止继承发生 123456789101112131415161718class Bulk_quote:public Quote&#123; public: Bulk_quote() = default; Bulk_quote(const std::string&amp;, double,std::size_t,double); // 覆盖基类的函数版本以实现基于大量购买折扣政策 double net_price(dts::size_t) const override; private: std::size_t min_qty = 0; double discount = 0.0;&#125;Quote item; //基类对象Bulk_quote bulk; //派生类对象Quote *p = &amp;item; //p指向Quote对象p = &amp;bulk; //p指向bulk的Quote部分Quote &amp;r = bulk; //r绑定到bulk的Quote部分class NoDerived final(); //NoDerived不能作为基类 15.2.3 类型转换与继承 可以将基类的指针绑定到派生类对象上 当使用基类的引用时,实际上不清楚引用所绑定的真实类型,该对象可能是基类的对象,也可能是派生类的对象 和内置指针一样,智能指针类也支持派生类向基类的类型转换(可以将派生类对象的指针存储在一个基类的智能指针内) 静态类型与动态内存 当使用存在继承关系的类型时,必须将一个变量或其他表达式的静态类型与该表达式表示的对象的动态类型区分开 如果表达式既不是引用也不是指针,则它的动态类型永远与静态类型一致 基类的指针或引用的静态类型可能与其动态类型不一致 不存在从基类向派生类的隐式类型转换 之所以存在派生类向基类的类型转换时因为每个派生类对象都包含一个基类部分,而基类的引用或指针可以绑定到该基类部分上 一个基类的对象既可以以独立的形式存在,也可以作为派生类对象的一部分存在 如果基类对象不是派生类对象的一部分,则它只含有基类定义的成员 不存在从基类向派生类的自动类型转换 即使一个基类指针或引用绑定在一个派生类对象上,也不能执行从基类向派生类的转换 12345678910// 一个基类的对象可能是派生类对象的一部分,也可能不是// 不存在从基类向派生类的自动类型转换Quote base;Bulk_quote* bulkP = &amp;base; //错误,不能将基类转换成派生类Bulk_quote&amp; bulkP = base; //错误,不能将基类转换成派生类// 即使一个基类指针或引用绑定在一个派生类对象上,也不能执行从基类向派生类的转换Bulk_quote bulk;Quote *itemP = &amp;bulk;Bulk_quote *bulkP = itemP; //错误,不能将基类转换成派生类 在对象之间不存在类型转化 派生类向基类的自动类型转换只对指针或引用类型有效,在派生类类型和基类类型之间不存在这种转换 当用派生类对象为一个基类对象初始化或赋值时,只有该派生类对象中的基类部分会被拷贝,移动或赋值,它的派生类部分将被忽略掉 存在继承关系的类型之间的转换规则 从派生类向基类的类型转换只对指针或引用类型有效 基类向派生类不存在隐式类型转换 和任何其他成员一样,派生类向基类的类型转换也可能会由于访问数显而变得不可行 15.3 虚函数 使用基类的引用或指针调用一个虚成员函数时会执行动态绑定 必须为所有虚函数都提供定义 对虚函数的调用可能在运行时才被解析 当某个虚函数通过指针或引用调用时,编译器产生的代码直到运行时才能确定应该调用哪个版本的函数 被调用的函数是与绑定到指针或引用上的对象的动态类型相匹配的一个 动态绑定只有当通过指针或引用调用虚函数时才会发生 通过一个具有普通类型的表达式调用虚函数时,在编译时就能将调用的版本确认下来 C++的多态性 把具有继承关系的多个类型称为多态类型 引用或指针的静态类型与动态类型不同这一事实正是C++语言支持多态性的根本所在 当使用基类的引用或指针调用基类中定义的一个函数时,并不知道该函数真正作用的对象是什么类型,因为它可能是一个基类的对象也可能是一个派生类的对象。如果该函数是虚函数,则直到运行时才会决定到底执行哪个版本,判断的依据是引用或指针所绑定的对象的真实类型 另一方面,对非虚函数的调用在编译时进行绑定 类似的,通过对象进行的函数(虚函数或非虚函数)调用也在编译时绑定。对象的类型是确定不变的,无论如何都不可能令对象的动态类型与静态类型不一致。因此,通过对象进行的函数调用将在编译时绑定到该对象所属类中的函数版本上 派生类中的虚函数 当在派生类中覆盖了某个虚函数时,可以再一次使用virtual关键字指出该函数的性质(一旦被声明为虚函数,在所有的派生类中都是虚函数) 基类中的虚函数在派生类中隐含的也是一个虚函数,派生类覆盖了某个虚函数时,该函数在基类中的形参必须与派生类中的形参严格匹配 final和override说明符 在新标准中,使用override关键字说明派生类中的虚函数 某个函数指定为final,之后任何尝试覆盖该函数的操作都将引发错误 final和override说明符出现在形参列表以及尾置返回类型之后 虚函数与默认形参：虚函数也可以拥有默认实参 如果某次函数调用使用了默认实参,则该实参值由本次调用的静态类型决定 如果通过基类的引用或指针调用函数,则使用基类中定义的默认实参,即使实际运行的是派生类中的函数版本也是如此 回避虚函数机制 希望对虚函数的调用不要进行动态绑定,而是强迫执行虚函数的某个特定版本,可以使用作用域运算符 如果一个派生类虚函数需要调用它的基类版本,但是没有使用作用域作用符,则在运行时该调用将被解析为对派生类版本自身的调用,从而导致无限递归 12345678// 到底调用net_price的哪个版本完全依赖于运行时绑定到item的实参的实际(动态)类型Quote base(&quot;0-201-82470-1&quot;,50);print_total(cout,base,10); //调用Quote::net_priceBulk_total derived(&quot;0-201-82470-1&quot;,50,5,.19);print_total(cout,derived,10); //调用Bulk_quote::net_price// 回避虚函数机制double undiscounted = baseP-&gt;Quote::net_price(42); 15.4 抽象基类 纯虚函数 纯虚函数无需定义,通过在函数体的位置书写=0可以将一个虚函数说明为纯虚函数,=0智能出现在类内部的虚函数声明语句处 可以为纯虚函数提供定义,但函数体必须定义在类的外部(不能在类的内部为一个=0的函数提供函数体) 含有纯虚函数的类是抽象基类 抽象基类负责定义接口,而后续的其他类可以覆盖该接口 不能直接创建一个抽象基类的对象,可定义派生类的对象(前提是提前覆盖率纯虚函数) 派生类构造函数只初始化它的直接基类 12345678910111213141516171819class Dis_quote:public Quote&#123; public: Disc_quote() = default; Disc_quote(const std::string&amp; book,double price,std::size_t qty, double disc): Quote(book,price),quantity(qty),discount(disc)&#123;&#125; double net_price(std::size_t) const =0; protected: std::size_t quantity = 0; double discount = 0.0;&#125;class Bulk_quote:public Disc_quote&#123; public: Bulk_quote() = default; Bulk_quote(const std::string&amp; book,double price, std::size_t qty, double disc): Disc_quote(book,price,qty,disc)&#123;&#125; // 覆盖基类中的函数版本以实现一种新的折扣策略 double net_price(std::size_t) const override;&#125; 15.5 访问控制与继承 每个类分别控制自己的成员初始化过程,与之类似,每个类还分别控制其成员对于派生类是否可访问 受保护的成员 一个类使用protect关键字来声明那些希望与派生类分享但不想被其他公共访问使用的成员 protect说明符可以看作是public和private中和后的产物 和私有成员类似,受保护的成员对于类的用户来说是不可访问的 和公有成员类似,受保护的成员对于派生类的成员和友元来说是可访问的 派生类的成员或友元只能通过派生类对象来访问基类的受保护成员。派生类对于一个基类对象中的受保护成员没有任何访问特权 公有,私有和受保护继承 某个类对其继承而来的成员的访问权限受到两个因素影响 在基类中该成员的访问说明符 在派生类的派生列表中的访问说明符 派生访问说明符的目的是控制派生类用户(包括派生类的派生类)对于基类成员的访问权限 12345678910111213141516171819202122232425262728class Base&#123; protect: int prot_mem;&#125;;class Sneaky: public Base&#123; friend void clobber(Sneaky&amp;); //能访问Sneaky::prot_mem friend void clobber(Base&amp;); //不能访问Base::prot_mem int j;&#125;void clobber(Sneaky &amp;s) &#123;s.j = s.prot_mem = 0;&#125; //正确可以访问void clobber(Base &amp;b) &#123;b.prot_mem = 0;&#125; //错误,不能访问class Base&#123; public: void pub_mem() protected: int prot_mem; private: char priv_mem;&#125;;struct Pub_Derv : public Base&#123; int f() &#123;return prot_mem;&#125; char g() &#123;return priv_mem;&#125; //错误,不可访问&#125;struct Priv_Derv : private Base&#123; // private不影响派生类的访问权限 int f() &#123;return prot_mem;&#125;&#125; 派生类向基类转换的可访问性 派生类向基类的转换是否可访问由使用该转换的代码决定,同时派生类的派生访问说明符也会有影响 假定D继承自B 只有当D公有地继承B时,用户代码才能使用派生类向基类的转换;如果D继承B的方式是受保护的或者私有的,则用户代码不能使用该转换 不论D以什么方式继承B,D的成员函数和友元都能使用派生类向基类的转换;派生类向其直接基类的类型转换对于派生类的成员和友元来说永远是可访问的 如果D继承B的方式是公有的或者受保护的,则D的派生类的成员和友元可以使用D向B的类型转换;反之,如果D继承B的方式是私有的,则不能使用 对于代码中的某个给定节点来说,如果基类的公有成员是可访问的,则派生类向基类的类型转换也是可访问的,反之则不行 类的设计与受保护的成员 普通用户：编写的代码使用类的对象,这部分代码只能访问类的公有(接口)成员 实现者：负责编写类的成员和友元的代码,成员和友元既能访问类的公有部分,也能访问类的私有(实现)部分 派生类：基类把它希望派生类能够使用的部分声明成受保护的。普通用户不能访问受保护的成员,而派生类及其友元仍旧不能访问私有成员 和其他类一样,基类应该将其接口成员声明为公有的;同时将属于其实现的部分分成两组：一组可供派生类访问,另一组只能由基类及基类的友元访问。对于前者应该声明为受保护的,这样派生类就能在实现自己的功能时使用基类的这些操作和数据;对于后者应该声明为私有的 友元与继承 友元关系不能继承 基类的友元在访问派生类成员时不具有特殊性,类似的,派生类的友元也不能随意访问基类的成员 当一个类将另一个类声明为友元时,这种友元关系只对做出声明的类有效;对于原来的类,其友元的基类或派生类不具有特殊的访问能力 123456789101112131415161718class Base&#123; // 添加friend声明,其他成员与之前的版本一致 friend class Pal; //Pal在访问Base的派生类时不具有特殊性&#125;;class Pal&#123; public: int f(Base b) &#123;return b.prot_mem;&#125; //正确,Pal时Base的友元 int f2(Sneaky s) &#123;return s.j;&#125; //错误,Pal不是Sneaky的友元 // 对基类的访问权限由基类本身控制,即使对于派生类的基类部分也是如此 int f3(Sneaky s) &#123;return s_prot.mem;&#125; //正确,Pal是Base的友元 // Pal是Base的友元,所以Pal能够访问Base对象的成员,这种可访问性包括了Base对象内嵌在其派生类对象中的情况&#125;// D2对Base的protected和privated成员不具有特殊的访问能力class D2: public Pal&#123; public: int mem(Base b) &#123;return b.prot_mem;&#125; //错误：友元关系不能继承&#125; 改变个别成员的可访问性 需要改变派生类继承的某个名字的访问级别,通过使用using声明可达到这一目的 using声明语句中名字的访问权限由该using声明语句之前的访问说明符来决定 如果一条using声明语句出现在类的private部分,则该名字只能被类的成员和友元访问 如果using声明语句位于public部分,则类的所有用户都能访问它 如果using声明语句位于protected部分,则该名字对于成员、友元和派生类是可访问的 派生类只能为那些它可以访问的名字提供using声明 默认的继承保护机制 默认派生运算符也由定义派生类所用的关键字来决定 使用class关键字定义的派生类默认是私有继承的 使用struct关键字定义的派生类是公有继承的 建议显式声明 1234567891011121314class Base&#123; public: std::size_t size() const &#123;return n;&#125; protected: std::size_t n;&#125;class Derived: private Base&#123; public: // 保持对象尺寸相关的成员的访问级别 using Base::size; protected: using Base::n;&#125;// 使用using声明语句改变了这些成员的可访问性。改变之后,Derived的用户将可以使用size成员,而Derived的派生类将能使用n 15.6 继承中的类作用域 在编译时进行名字查找 一个对象,引用或指针的静态类型决定了该对象的哪些成员是可见的。即使静态类型与动态类型可能不一致,但是能使用哪些成员还是由静态类型决定的 12345678910111213// 给Disc_quote添加一个新成员,该成员返回一个存有最小(或最大)数量及折扣价格的pairclass Disc_quote:public Quote&#123; public: std::pair&lt;size_t, double&gt; discount_policy() const &#123; return &#123;quantity,discount&#125;;&#125;&#125;//只能通过Disc_quto及其派生类的对象,引用或指针使用discount_policyBulk_quote bulk;Bulk_quote *bulkP = &amp;bulk; //静态类型与动态类型一致Quote *itemP = &amp;bulk; //静态类型与动态类型不一致bulkP-&gt;discount_policy(); //正确:bulkP的类型是Bulk_quote*itemP-&gt;discount_policy(); //错误:itemP的类型是Quote* 名字冲突与继承 和其他作用域一致,派生类也能重用定义在其直接基类或间接基类中的名字,此时定义在内层作用域的名字将隐藏定义在外层作用域的名字 派生类的成员将隐藏同名的基类成员 通过作用域运算符来使用隐藏的成员 可以通过使用作用域运算符来使用一个被隐藏的基类成员 除了覆盖继承而来的虚函数之外,派生类最好不要宠用其他定义在基类中的名字 名字查找优先于类型检查： 定义派生类中的函数也不会重载其基类中的成员 如果派生类(即内层作用域)的成员与基类(即外层作用域)的某个成员同名,则派生类将在其作用域内隐藏该基类成员(即使派生类成员和基类成员的形参列表不一致,基类成员也仍然会被隐藏掉) 虚函数与作用域 假如基类与派生类的虚函数接受的实参不同,则无法通过基类的引用或指针调用派生类的虚函数 覆盖重载的函数 和其他函数一样,成员函数无论是否是虚函数都能被重载。派生类可以覆盖重载函数的0个或多个实例 如果派生类希望所有的重载版本对于它来说都是可见的,那么它就需要覆盖所有的版本,或者一个也不覆盖 一种好的解决方案是为重载的成员提供一条using声明语句,这样就无须覆盖基类中的每一个重载版本 using声明语句指定一个名字而不指定形参列表,所以一条基类成员函数的using声明语句就可以把该函数的所有重载实例添加到派生类作用域中。此时,派生类只需要定义其特有的函数就可以了,而无须为继承而来的其他函数重新定义 类内using声明的一般规则同样适用于重载函数的名字;基类函数的每个实例在派生类中都必须是可访问的。对派生类没有重新定义的重载版本的访问实际上是对using声明点的访问 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Base&#123; Base():mem(0)&#123;&#125; protected: int mem;&#125;struct Derived: Base&#123; Derived(int i):mem(i)&#123;&#125; int get_mem() &#123;return mem;&#125; // 使用隐藏的成员 int get_mem() &#123;return Base::mem;&#125; protected: int mem; //隐藏基类中的mem&#125;Derived d(42);d.get_mem(); //42class Base&#123; public: virtual int fcn();&#125;;class D1:public Base&#123; public: int fcn(int); //形参列表与Base中的fcn不一致 virtual void f2(); //是一个新的虚函数,在Base中不存在&#125;class D2:public D1&#123; public: int fcn(int); //是一个非虚函数,隐藏了D1::fcn(int) int fcn(); //覆盖了Base的虚函数fcn void f2(); //覆盖了D1的虚函数f2&#125;// 使用隐藏的虚函数的方法Base bobj;D1 d1obj;D2 d2obj;Base *bp1 = &amp;bobj,*bp2 = &amp;d1obj, *bp3 = &amp;d2obj;bp1-&gt;fcn(); //虚调用,将在运行时调用Base::fcnbp2-&gt;fcn(); //虚调用,将在运行时调用Base::fcnbp3-&gt;fcn(); //虚调用,将在运行时调用D2::fcnD1 *d1p = &amp;d1obj;D2 *d2p = &amp;d2obj;bp2-&gt;f2(); //错误,Base没有名为f2的成员d1p-&gt;f2(); //虚调用,将在运行时调用D1::f2()d2p-&gt;f2(); //虚调用,将在运行时调用D2::f2() 15.7 构造函数与拷贝控制 15.7.1 虚析构函数 继承关系对基类拷贝控制最直接的影响时基类通常应该定义一个虚析构函数,能动态分配继承体系中的对象 通过在基类中将析构函数定义成虚函数以确保执行正确的析构函数版本 虚析构函数的虚属性也会被继承 虚析构函数将阻止合成移动操作：如果一个类定义了析构函数,即使通过=default的形式使用了合成版本,编译器也不会为这个类使用合成移动操作 123456789class Quote&#123; public: virtual ~Quote() = default; //动态绑定析构函数&#125;Quote *itemP = new Quote;delete itemP; //调用Quote的析构函数itemP = new Bulk_quote;delete itemP; //调用Bulk_quote的析构函数 15.7.2 合成拷贝控制与继承 基类或派生类的合成拷贝控制成员的行为与其他合成的构造函数,赋值运算符或析构函数类似 对类本身的成员依次进行初始化,赋值或销毁的操作,此外合成的成员还负责使用直接基类中对应的操作对一个对象的直接基类部分进行初始化,赋值或销毁操作 对于派生类的析构函数来说,除了销毁派生类自己的成员外,还负责销毁派生类的直接基类 派生类中删除的拷贝控制与基类的关系 基类或派生类能出于同样的原因将其合成的默认构造函数或者任何一个拷贝控制成员定义成被删除的函数 某些定义基类的方式也可能导致派生类成员称为被删除的函数 如果基类中的默认构造函数、拷贝构造函数、拷贝赋值运算符或析构函数是被删除的函数或者不可访问,则派生类中对应的成员将是被删除的,原因是编译器不能使用基类成员来执行派生类对象基类部分的构造、赋值或销毁操作 如果在基类中有一个不可访问或删除掉的析构函数,则派生类中合成的默认和拷贝构造函数将是被删除的,因为编译器无法销毁派生类对象的基类部分 和过去一样,编译器将不会合成一个删除掉的移动操作。当我们使用=default请求一个移动操作时,如果基类中的对应操作是删除的或不可访问的,那么派生类中该函数将是被删除的,原因是派生类对象的基类部分不可移动。同样,如果基类的析构函数是删除的或不可访问的,则派生类的移动构造函数也将是被删除的 移动操作与继承 大多数基类都会定义一个虚析构函数,默认情况下,基类通常不含有合成的移动操作,而且在它的派生类中没有合成的移动操作 基类缺少移动操作会阻止派生类拥有自己的合成操作 一旦基类定义了自己的移动操作,那么必须同时显示地定义拷贝操作 15.7.3 派生类的拷贝控制成员 派生类的拷贝和移动构造函数在拷贝和移动自由成员的同时,也要拷贝和移动基类部分的成员 析构函数只负责销毁派生类自己分配的资源,派生类对象的基类部分是被自动销毁的 定义派生类的拷贝或移动拷贝函数 使用基类的构造函数初始化对象的基类部分 在默认情况下,基类默认构造函数初始化派生类对象的基类部分,如果需要拷贝或移动基类部分,则必须在派生类的构造函数初始化列表中显式地使用基类的拷贝或移动构造函数 派生类赋值运算符 派生类的赋值运算符必须显式的为其基类部分赋值 在构造函数和析构函数中调用虚函数 派生类对象的基类部分首先被构建,当执行基类的构造函数时,该对象的派生类部分还是未初始化的状态 为了处理该未完成状态,当构建一个对象时,需要把对象的类和构造函数的类看作是同一个;对虚函数的调用绑定正好符合这种把对象的类和构造函数的类看成同一个的要求; 如果构造函数或析构函数调用某个虚函数,应该执行与构造函数或析构函数所属类型对应的虚函数版本 12345678910111213141516171819class Base&#123;//....&#125;;class D:public Base&#123; public: D(const D&amp; d):Base(d) //拷贝基类成员 D(D&amp;&amp; d):Base(std::move(d)) //移动基类成员&#125;// 初始值Base(d)将一个D对象传递给基类构造函数// 尽管从道理上来说,Base可以包含一个参数类型为D的构造函数,但是在实际编程过程中通常不会这么做// 相反,Base(d)一般会匹配Base的拷贝构造函数。D类型的对象d将被绑定到该构造函数的Base&amp;形参上。Base的拷贝构造函数负责将d的基类部分拷贝给要创建的对象// 假如没有提供基类的初始值D(const D&amp; d) //成员初始值,但没有提供基类初始值// Base的默认构造函数将被用来初始化D对象的基类部分。假定D的构造函数从d中拷贝了派生类成员,则这个新构建的对象的配置将非常奇怪：它的Base成员被赋予了默认值,而D成员的值则是从其他对象拷贝得来的// Base::operator=(const BAse&amp;)不会被自动调用D &amp;D::operator=(const D &amp;rhs)&#123; Base::operatr=(rhs); //为其基类部分赋值 return *this;&#125; 15.7.4 继承的构造函数 派生类能重用其直接基类定义的构造函数 一个类只能继承其直接基类的构造函数,类不能继承默认,拷贝和移动构造函数,若派生类未定义这些构造函数,则编译器将合成 派生类继承基类构造函数使用using语句 继承的构造函数的特点 一个构造函数的using声明不会改变该构造函数的访问等级 一个using声明语句不能指定explicit或constexpr 若基类的构造函数时explicit或constexpr,则继承的构造函数仍保持相同属性 当一个基类构造函数含有默认实参,则实参不会被继承,派生类获得多个继承的构造函数,其中每个构造函数分别省略掉一个含有默认实参的形参 12345class Bulk_quote:public Disc_quote&#123; public: using Disc_quote::Disc_quote; //继承基类的构造函数 double new_price(std::size_t) const;&#125; 15.8 容器与继承 使用容器存放继承体系中的对象,必须使用间接存储的方式 因为不允许在容器中保存不同类型的元素,故不能将具有继承关系的多种类型的对象直接存放在容器中 在容器中放置(智能)指针而非对象 希望在容器中存放具有继承关系的对象时,实际上存放的通常是基类指针 指针的动态类型指向的可能是基类或者派生类 12345678910vector&lt;Quote&gt; basket;basket.push_back(Quote(&quot;0-201-82470-1&quot;,50));//正确,但只能把对象的Quote部分拷贝给basketbasket.push_back(Bulk_quote(&quot;0-201-82470-1&quot;,50,10,.25));//basket是Quote对象,向其中添加Bulk_quote对象是,派生类部分会被忽略vector&lt;shared_ptr&lt;Quote&gt;&gt; basket;basket.push_back(make_shared&lt;Quote&gt;(&quot;0-021-82470-1&quot;,50));basket.push_back(make_shared&lt;Bulk_quote&gt;(&quot;0-021-82470-1&quot;,50,10,.25)); 16 模板与泛型编程 16.1 定义模板 16.1.1 函数模板 定义一个通用的函数模板,而不是为每个类型都定义一个新函数 模板的定义以关键字template开始,后跟一个模板参数列表,这是一个逗号分割的一个或多个模板参数的列表,用&lt;&gt;包围起来 模板参数列表不能为空 模板参数表示在类或函数定义中用到的类型或值,使用模板时,(隐式地或显示地)指定模板实参 实例化函数模板 调用函数模板时,编译器用函数实参来推断模板实参(编译器使用实参的类型来确定绑定到模板参数T的类型) 编译器用推断出的模板参数来实例化一个特殊版本的函数 模板类型参数 可以将类型参数看作类型说明符 类型参数可以用来指定返回类型或函数的参数类型,以及在函数体内用于变量声明或类型转换 非类型模板参数 通过特定的类型名而非关键字class或typename来指定非类型参数 可以在模板中定义非类型参数,一个非类型参数表示一个值而非一个类型,非类型参数必须是常量表达式 一个非类型参数可以是一个整型,或者是一个指向对象或函数类型的指针或(左值)引用 绑定到非类型整型参数的实参必须是一个常量表达式 绑定到指针或引用非类型参数的实参必须具有静态的生存期 不能用一个普通(非static)局部变量或动态对象作为指针或引用非类型模板参数的实参 指针参数也可以用nullptr或一个值为0的常量表达式来实例化 inline和constexpr的函数模板 函数模板可以声明称inline和constexpr,说明符放在模板参数列表之后,返回类型之前 编写泛型代码的两个重要原则 模板中的函数参数是const的引用 函数体中的条件判断仅使用&lt;比较运算符 模板编译 只有当实例化出模板的一个特定版本时,编译器才会生成代码 函数模板和类模板成员函数的定义通常放在头文件中 1234567891011121314151617181920212223242526272829303132// compare的模板版本template&lt;typename T&gt;int compare(const T &amp;v1, const T &amp;v2)&#123; if (v1 &lt; v2) return -1; if (v2 &lt; v1) return 1; return 0;&#125;cout &lt;&lt; compare(1,0)&lt;&lt;endl; //T为intvector&lt;int&gt; vec1&#123;1,2,3&#125;;vector&lt;int&gt; vec2&#123;4,5,6&#125;;cout &lt;&lt; compare(vec1,vec2)&lt;&lt;endl; //T为vector&lt;int&gt;template&lt;typename T&gt; T foo(T* p)&#123; T tmp = *p; //... return tmp;&#125;// 错误,U前面必须假声class或typenametemplate&lt;typename T,U&gt; T calc(const T&amp;, const U&amp;);// 正确template&lt;typename T,class U&gt; T calc(const T&amp;, const U&amp;);template&lt;unsigned N, unsigned M&gt;int compare(onst char(&amp;p1)[N], const char (&amp;p2)[M])&#123; return strcmp(p1,p2);&#125;// 调用时会用字面常量的大小来代替N,Mtemplate&lt;typename T&gt; inline T min(const T&amp;,const T&amp;); 16.1.2 类模板 类模板是用来生成类的蓝图 与函数模板不同之处是,编译器不能为类模板推断模板参数类型 定义类模板 类似函数模板,类模板以关键字template开始,后跟模板参数列表 在类模板的定义中,将模板参数当作替身,代替使用模板时用户需要提供的类型或值 实例化类模板 使用类模板时,必须提供额外信息,额外信息是显式模板实参列表,其被绑定到模板参数使用模板实例化出特定的类 一个类模板的每个实例都形成一个独立的类,两个独立的类不会关联,且不会对其他任何实例类的成员有特殊访问权限 在模板作用域中引用模板类型 类模板用来实例化类型,而一个实例化的类型总是包含模板参数 一个类模板中的代码如果使用了另一个模板,通常不将一个实际类型的名字用作其模板实参。相反,通过将模板自己的参数当作被使用模板的实参 类模板的成员函数 既可以在类模板内部,也可以在类模板外部为其定义成员函数,且定义在类模板内的成员函数被隐式声明为内联函数 类模板的成员函数本身是一个函数,但类模板每个实例都有其自己版本的成员函数,因此类模板的成员函数具有和模板相同的模板参数 定义在类模板之外的成员函数就必须以关键字template开始,后接类模板参数列表 构造函数 与其他任何定义在类模板外的成员一样,构造函数的定义要以模板参数开始 类模板成员函数的实例化 默认情况下,一个类模板的成员函数只有当程序用到它时才能进行实例化 对于一个实例化的类模板,其成员只有在使用时才被实例化 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162template&lt;typename T&gt; class Blob&#123; public: typedef T value_type; typedef typename std::vector&lt;T&gt;::size_type size_type; Blob(); Blob(std::initializer&lt;T&gt; il); size_type size() const &#123;return data-&gt;size();&#125; bool empty() const &#123;return data-&gt;empty();&#125; void push_back(const T &amp;t) const &#123;data-&gt;push_back(t);&#125; void push_back(T &amp;&amp;t) const &#123;data-&gt;push_back(std::move(t));&#125; void pop_back; T&amp; back(); T&amp; operator[](size_type i); private: std::shared_ptr&lt;std::vector&lt;T&gt;&gt; data; void check(size_type i, const std::string &amp;msg) const;&#125;// data使用两个模板,vector和shared_ptrstd::shared_ptr&lt;std::vector&lt;T&gt;&gt; data;// 对于StrBlob的一个给定的成员函数ret-type StrBlob::member-name(parm-list);// 对应的Blob成员：template&lt;typename T&gt; ret-type Blob&lt;T&gt;::member-name(parm-list)// check成员,检查一个给定的索引template &lt;typename T&gt;void Blob&lt;T&gt;::check(size_type i, const std::string &amp;msg) const&#123; if(i&gt;=data-&gt;size()) throw std::out_of_range(msg);&#125;// 模板版本则返回一个引用,指向用来实例化Blob的类型template &lt;typename T&gt;T&amp; Blob&lt;T&gt;::back()&#123; check(0,&quot;back on empty Blob&quot;); return data-&gt;back();&#125;template &lt;typename T&gt;T&amp; Blob&lt;T&gt;::operator[](size_type i)&#123; check(i,&quot;subscipt out of range&quot;); return (*data)[i];&#125;// 模板版本则返回一个引用,指向用来实例化Blob的类型template &lt;typename T&gt;void Blob&lt;T&gt;::pop_back()&#123; check(0,&quot;pop_back on empty Blob&quot;); return data-&gt;pop_back();&#125;// 构造函数的定义要以模板参数开始template &lt;typename T&gt; Blob&lt;T&gt;::Blob() :data(std::make_shared&lt;std::vector&lt;T&gt;&gt;())&#123;&#125; 在类代码内简化模板类名的使用 使用一个类模板类型时,必须提供模板实参 在类模板自己的作用域中,可以使用模板名而不提供实参 处于一个类模板的作用域中时,编译器处理模板自身引用时就好像已经提供了与模板参数匹配的实参一样 在类模板外使用类模板名 在类模板外定义其成员时,必须记住,并不在类的作用域中,直到遇到类名才表示进入类的作用域 在一个类模板的作用域内,可以直接使用模板名而不必指定模板实参 类模板和友元 当一个类包含一个友元声明时,类与友元各自是否是模板相互无关 如果一个类模板包含一个非模板友元,则友元被授权可以访问所有模板实例;如果友元自身是模板,类可以授权给所有友元模板实例,也可以只授权给特定实例 一对一友好关系 类模板与另一个模板间友好关系的最常见形式是建立对应实例及其友元间的友好关系 通用和特定的模板友好关系 一个类也可以将另一个模板的每个实例都声明为自己的友元或限定特定的实例为友元 为了让所有实例称为友元,友元声明中必须使用与类模板本身不同的模板参数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 若试图访问一个不存在的元素,BlobPtr抛出一个异常template&lt;typename T&gt; class BlobPtr&#123; public: BlobPtr() : curr(0) &#123;&#125; BlobPtr(Blob&lt;T&gt; &amp;a, size_t sz = 0): wptr(a.data),curr(sz) &#123;&#125; T&amp; operator*() const &#123; auto p = check(curr, &quot;deference past end&quot;); return (*p)[curr]; &#125; // 处于一个类模板的作用域中时,编译器处理模板自身引用时就好像已经提供了与模板参数匹配的实参一样 // 等效于BlobPtr&lt;T&gt;&amp; operator++(); BlobPtr&amp; operator++(); BlobPtr&amp; operator--(); private: std::shared_ptr&lt;std::vector&lt;T&gt;&gt; check(std::size_t, const std::string&amp;) const; std::weak_ptr&lt;std::vector&lt;T&gt;&gt; wptr; std::size_t curr;&#125;// 后置：递增/递减对象但返回原址template&lt;typename T&gt;BlobPtr&lt;T&gt; BlobPtr&lt;T&gt;::operator++(int)&#123; BlobPtr ret = *this; ++*this; return ret;&#125;// 在函数体内,已经进入类的作用域,在定义ret时无需重复模板参数// 不提供模板参数,则编译器将假定使用的类型与成员实例化所用类型一致// 一对一友好关系// 前置声明,在Blob中声明友元所需要的template&lt;typename&gt; class BlobPtr;template&lt;typename&gt; class Blob;template&lt;typename T&gt; bool operator==(const Blob&lt;T&gt;&amp;, const Blob&lt;T&gt;&amp;);template&lt;typename T&gt; class Blob&#123; // 每个Blob实例将访问权限授予用相同类型实例化的BlobPtr和相等运算符 friend class BlobPtr&lt;T&gt;; friend bool operator==&lt;T&gt; (const Blob&lt;T&gt;&amp;, const Blob&lt;T&gt;&amp;);&#125;// 友元的声明用Blob的模板形参作为自己的模板实参// 友好关系被限定在用相同实例化的Blob和BlobPtr相等的运算符中Blob&lt;char&gt; ca;Blob&lt;int&gt; ia;// BlobPtr&lt;char&gt;的成员可以访问ca的非public部分// 但ca对ia没有特殊访问权限// 通用和特定的模板友好关系// 前置声明,在将模板的一个特定实例声明为友元时会用到template&lt;typename T&gt; class Pal;class C&#123; firend class Pal&lt;C&gt;; //用类C实例化的Pal时C的一个友元 template &lt;typename T&gt; friend class Pal2; //Pal2的所有实例都是C的友元,无需前置声明&#125;;template&lt;template T&gt; class C2&#123; friend class Pal&lt;T&gt;; //Pal的模板声明必须在作用域之内 template&lt;typename X&gt; friend class Pal2; //Pal2的所有实例都是C2每个实例的友元,无需前置声明 friend class Pal3; //Pal3是一个非模板类,它是C2所有实例的友元&#125; 令模板自己的类型参数成为友元 在新标准中,可以将模板类型参数声明为友元 模板类型别名 新标准允许为类模板定义一个类型别名 类模板的static成员 类模板可以声明static成员,static成员函数只有在使用时才会实例化 类模板的每个不同的实例都有其自己的static成员实例,类模板的相同类型的实例共享相同的成员实例 123456789101112131415161718192021222324// 模板参数类型声明为友元template&lt;typename Type&gt; class Bar&#123; friend Type; //...&#125;// 对于某个类型Foo,Foo将成为Bar&lt;Foo&gt;的友元// 使用typedef定义模板类型别名typedef Blob&lt;string&gt; StrBlob;// 使用using定义模板类型别名template&lt;typename T&gt; using twin = pair&lt;T,T&gt;;twin&lt;string&gt; authors;template&lt;typename T&gt; using partNo = pair&lt;T,unsigned&gt;;partNo&lt;string&gt; books; //pair&lt;string unsigned&gt;// 声明static成员template&lt;typename T&gt; class Foo&#123; public: static std::size_t count() &#123;return ctr;&#125; private: static std::size_t ctr;&#125;; 16.1.3 模板参数 模板参数的名字没有内在含义 模板参数名的可用范围时在其声明之后,至模板声明或定义结束之前 模板参数会隐藏外层作用域中声明的相同的名字,但在模板内部不能重用模板参数名 模板声明 与函数参数相同,声明中的模板参数的名字不必与定义中相同 使用类的类型成员 使用一个模板类型参数的类型参数,就必须显式告诉编译器该名字是一个类型 通过使用关键字typename来实现,不能使用class 默认模板实参 在新标准中,可以为类模板和函数提供默认模板实参 模板默认实参与类模板 无论何时使用一个类模板,都必须在模板名之后接上尖括号,尖括号指出类必须从一个模板实例化而来 特别是,如果一个类模板为其所有模板参数都提供了默认实参,且希望使用这些默认实参,就必须在模板名之后跟一个空尖括号对 1234567891011121314151617181920212223242526272829303132333435template&lt;typename T&gt; int compare(const T&amp;, const T&amp;);template&lt;typename T&gt; class Blob;// 声明但不定义compare和Blobtemplate&lt;typename T&gt; T calc(const T&amp;, const T&amp;);template&lt;typename U&gt; U calc(const U&amp;, const U&amp;);// 模板的定义template&lt;typename Type&gt; Type clac(const Type&amp; a, const Type&amp; b) &#123;//...&#125;// 使用类的类型成员template&lt;typename T&gt;typename T::value_type top(const T&amp; c)&#123; if(!c.empty()) return c.back(); else return typename T::value_type();&#125;// 重写comparetemplate&lt;typename T, typename F = less&lt;T&gt;&gt;int compare(const T &amp;v1, const T &amp;v2, F f = F())&#123; if(f(v1,v2)) return -1; if(f(v2,v1)) return 1; return 0;&#125;// 调用该模板时,可以自定义比较操作template&lt;class T = int&gt; class Numbers&#123; public: Numbers(T v = 0):val(v)&#123;&#125; private: T val;&#125;;Numbers&lt;long double&gt; lots_of_precision;Numbers&lt;&gt; average_precision; //&lt;&gt;表示希望使用默认类型 16.1.4 成员模板 一个类可以包含本身是模板的成员函数,这种成员成为成员模板 成员模板不能是虚函数 普通(非模板)类的成员函数 类模板的成员模板 可以为类模板定义成员模板,类和成员各自有自己独立的模板参数 与类模板的普通成员函数不同,成员模板是函数模板 在类模板外定义一个成员模板时,必须同时为类模板和成员模板提供模板参数列表,类模板的参数列表在前,成员模板参数列表在后 实例化与成员模板 为了实例化一个类模板的成员模板,必须同时提供类和函数模板的实参 123456789101112131415161718192021222324252627282930313233343536// 作为普通类包含成员模板的例子,定义一个类,类似unique_ptr所使用的默认删除器类型// 类似默认删除器,类将包含一个重载的函数调用运算符,它接受一个指针并对此指针执行delete// 与默认删除器不同,类还将在删除器被执行时打印一条信息。由于希望删除器适用于任何类型,所以将调用运算符定义为一个模板// 函数对象类,对给定指针执行deleteclass DebugDelete&#123; public: DebugDelete(std::ostream &amp;s = std::cerr): os(s) &#123; &#125; // 与任何函数模板相同,T的类型由编译器推断 template&lt;typename T&gt; void operator()(T *p) const &#123; os &lt;&lt; &quot;deleting unique_ptr&quot; &lt;&lt; std::endl; delete p; &#125; private: std::osream &amp;os;&#125;double *p = new double;DebugDelete d;d(p); //调用DebugDelete::operator()(double*),释放pint* ip = new int;DebugDelete()(ip); //在一个临时DebugDelete对象上调用operator()(int*)// 将DebugDelete用作unique_ptr的删除器// 为了重载unique_ptr的删除器,在尖括号内给出删除器类型,并提供一个这种类型的对象给unique_ptr的构造函数// 销毁p指向的对象unique_ptr&lt;int, DebugDelete&gt; p(new int, DebugDelete());// 类模板的成员模板template &lt;typename T&gt; class Blob&#123; template &lt;typename It&gt; Blob(It b, It e);&#125;template&lt;typename T&gt; template&lt;typename It&gt; Blob&lt;T&gt;::Blob(It b,Ite ): data(std::make_shared&lt;std::vector&lt;T&gt;&gt;(b,e)) &#123;&#125; 16.1.5 控制实例化 当模板被使用时才会进行实例化,这意味着相同的实例可能出现在多个对象文件中,独立编译的源文件使用了相同的模板,模板参数相同时会有多个模板的实例 可以使用显式实例化来避免多余的开销 将一个实例化声明为extern表示承诺在程序其他位置有该实例化的一个非extern声明,但必须只有一个定义 对于每个实例化声明,在程序中某个位置必须有其显式的实例化定义 123456extern template declaration; //实例化声明template declaration; //实例化定义// declaration是一个类或函数声明,其中所有模板参数已被替换成模板实参extern template class Blob&lt;string&gt;;template int compare(const int&amp;, const int&amp;); 16.2 模板实参推断 从函数实参来确定模板实参的过程称为模板实参推断 16.2.1 类型转换与模板类型参数 与非模板函数一样,在一次调用中传递给函数模板的实参被用来初始化函数的形参 如果函数形参的类型使用了模板类型参数,则采用特殊的初始化规则 顶层const无论在形参中还是实参中,都会被忽略 在其他类型转换中,能在调用中应用于函数模板的包括： const转换：可以将一个非const对象的引用传递给一个const的引用 数组和函数指针转换：若函数形参不是引用类型,则可以对数组或函数类型的实参引用正常的指针转换 将实参传递给模板类型的函数形参是,能自动应用类型转换的只有const转换及数组或函数到指针的转换 123456789101112// 考虑函数fobj和fref的调用// fobj函数拷贝它的参数,而fref的参数是引用类型template&lt;typename T&gt; T fobj(T, T); //实参被拷贝template&lt;typename T&gt; T fref(const T&amp;, const T&amp;);string s1(&quot;a value&quot;);const string s2(&quot;another value&quot;);fobj(s1,s2); //调用fobj(string,string);const被呼呼额fref(s1,s2); //调用fobj(const string&amp;,const string&amp;); //将s1转换为const是允许的int a[10],b[42];fobj(a,b); //调用f(int*,int*)fref(a,b); //错误,数组类型不匹配 使用相同模板参数类型的函数形参 一个模板类型参数可以用作多个函数形参的类型 由于至允许有限的集中类型转换,因此传递给形参的实参必须具有相同的类型 若允许对函数实参进行正常的初始化,可以将函数模板定义成两个类型的参数 且必须定义能比较这些类型的&lt;运算符 正常类型转换应用于普通函数实参 函数模板可以有用普通类型定义的参数 不涉及模板类型参数的类型,这种函数实参不进行特殊处理,正常转换为对应形参的类型 1234567891011121314151617// compare函数接收两个const T&amp;参数,其实参类型必须具有相同类型compare(long, 1024); //不能实例化,参数类型不同// 若允许对函数实参进行正常的初始化,可以将函数模板定义成两个类型的参数template&lt;typename A, typename B&gt;int compare(const A&amp; v1, const B&amp; v2)&#123; if (v1&lt;v2) &#123; return -1; &#125; if (v2&lt;v1) &#123; return 1; &#125; return 1;&#125; 16.2.2 函数模板显式实参 当函数返回类型与参数列表中任何类型都不相同是,编译器无法推断出模板实参的类型 指定显式模板实参 在调用时必须提供一个显式模板实参：显式实参在尖括号中给出,位于函数名之后,实参列表之前 显式模板实参按由左至右的顺序与对应的模板参数匹配 正常类型转换应用于显式指定的实参 对于模板类型参数已经显式指定了的函数实参,也进行正常的类型转换 12345// 编译器无法推断template&lt;typename T1, typename T2, typename T3&gt; T1 sum(T2, T3);// 提供显式模板实参,显式指明T1,但T2,T3由实参类型推断auto val3 = sum&lt;long long&gt;(i,lng); 16.2.3 尾置返回类型与类型转换 显式模板实参表示模板函数的返回类型是很有效的,但在其他情况下,要求显式指定模板实参会添加额外的负担 使用尾置返回类型,由于尾置返回类型出现在参数列表之后,可以使用函数的参数 进行类型转换的标准库模板类 对于传递的参数的类型,但直到唯一可以使用的操作是迭代器操作,但所有迭代器操作都不会生成元素,只能使用元素的引用 为了获得元素类型,使用标准库的类型转换模板 定义在头文件type_traits中,通常用于所谓的模板源程序设计 1234567891011121314151617181920212223242526272829303132// 编写一个函数,接受表示序列的一对迭代器和返回序列中一个元素的引用template &lt;typename It&gt;??? &amp;fcn(It beg, It end)&#123; //处理序列 return *beg;&#125;// 并不知道返回结果的类型,但知道所需类型是所处理的序列的元素类型vector&lt;int&gt; vi = &#123;1,2,3,4,5&#125;;Blob&lt;string&gt; ca = &#123;&quot;hi&quot;,&quot;bye&quot;&#125;;auto &amp;i = fcn(vi.begin(),vi.end()); //应该返回int&amp;auto &amp;s = fcn(ca.begin(),ca.end()); //应该返回string&amp;// 尾置返回允许在参数列表之后声明返回类型template &lt;typename It&gt;auto &amp;fcn(It beg, It end) -&gt; decltype(*beg)&#123; //处理序列 return *beg;&#125;// 使用remove_reference来获得元素类型remove_reference&lt;decltype(*beg)&gt;::type// 组合使用template &lt;typename It&gt;auto &amp;fcn(It beg, It end) -&gt; typename remove_reference&lt;decltype(*beg)&gt;::type&#123; //处理序列 return *beg;&#125;// type是一个类的成员,而该类依赖于一个模板参数,必须在返回类型的声明中使用typename来告知编译器,type表示一个类型 对Mod&lt;T&gt;,其中Mod为 T为 Mod&lt;T&gt;::type为 remove_reference X&amp;或X&amp;&amp;,否则 X,否则为T add_const X&amp;,const X,或函数,否则 T,否则为const T add_lvalue_reference X&amp;,X&amp;&amp;,否则 T,X&amp;,否则为T&amp; add_rvalue_reference X&amp;或X&amp;&amp;,否则 T,否则为T&amp;&amp; remove_pointer X*,否则 X,否则为T add_pointer X&amp;或X&amp;&amp;,否则 X*,否则为T* make_signed unsigned X,否则 X,否则为T make_unsigned 带符号类型,否则 unsigned X,否则为T remove_extent X[n],否则 X,否则为T remove_all_extent X[n1][n2],否则 X,否则为T 16.2.4 函数指针和实参推断 用一个函数模板初始化一个函数指针或为一个函数指针赋值时,编译器使用指针的类型来推断模板实参 12345678910111213// 假定有一个函数指针,指向的函数返回int,接受两个参数,每个参数都是指向const int的引用// 可以使用该指针指向compare的一个实例template&lt;typename T&gt; int compare(const T&amp;, const T&amp;);// pf1指向实例int compare(const int&amp;,const int&amp;)int (*pf1)(const int&amp;,const int&amp;) = compare;// 如果不能从函数指针类型确定模板实参,则产生错误// func的重载版本：每个版本接受不同的函数指针类型void func(int(*) (const string&amp;, const string&amp;));void func(int(*) (const int&amp;, const int&amp;));func(compare); //错误,使用混乱func(compare&lt;int&gt;); //传递compare(const int&amp;, const int&amp;) 16.2.5 模板实参推断和引用 从左值引用函数参数推断类型 当一个函数参数是模板类型参数的普通(左值)引用时,只能传递一个左值,实参可以时const类型,也可以不是 如果实参是const的,则T将被推断称const类型 如果函数参数的类型是const T&amp;,正常可以传递任何类型的实参(对象,临时对象或字面值) 当函数参数本身是const时,T的类型推断结果不会是一个const类型 从右值引用函数参数推断类型 函数参数时右值引用时,可以传递右值,类型推断推断的应为右值 引用折叠和右值引用参数 例外规则,允许非正常的绑定 第一条是：当将一个左值传递给函数的右值引用参数,且此右值引用指向模板类型参数时,编译器推断模板类型参数为实参的左值引用类型 如果间接创建一个引用的引用,则引用形成折叠：引用会折叠称一个普通的左值引用类型 只有右值引用的右值引用会折叠称右值引用 引用折叠只能应用于间接创建的引用的引用,如类型别名或模板参数 若函数参数是指向模板参数类型的右值引用,则可以传递任意类型的实参;若将左值传递,则函数实参被实例化成一个普通的左值引用 右值引用常用于两种情况：模板转发其实参或模板被重载 虽然不能隐式地将一个左值转换为右值引用,但可以用static_cast显式地将一个左值转换为一个右值引用 123456789101112131415161718192021template &lt;typename T&gt; void f1(T&amp;); //实参必须时一个左值f1(i); //i是int,则T为intf1(ci); //i是const int,则T为const intf1(5); //错误,传递的实参必须是左值template &lt;typename T&gt; void f2(const T&amp;); //可以接受右值f2(i); //i是int,则T为const intf2(ci); //i是const int,则T为intf2(5); //T为inttemplate &lt;typename T&gt; void f3(T&amp;&amp;);f3(42); //T为intf3(i); //实参为左值,T为int&amp;f3(ci); //实参为左值,T为const int&amp;// 编写接受右值引用参数的模板函数template&lt;typename T&gt; void f3(T&amp;&amp; val)&#123; T t = val; t = fcn(t); if(val == t)&#123;//...&#125;&#125; 16.2.7 转发 某些函数需要将其一个或多个实参连同类型不变地转发给其他函数 需要保持被转发实参的所有性质,包括实参类型是否是const以及实参是左值还是右值 定义能保持类型信息的函数参数 通过将一个函数参数定义为一个指向模板类型参数的右值引用,可以保持其对应实参的所有类型信息 使用引用参数,使得可以保持const属性,因为在引用类型中的const是底层的 将函数参数定义为T1&amp;&amp;和T2&amp;&amp;,通过引用折叠就可以保持翻转实参的左值/右值属性 如果一个函数参数是指向模板类型参数的右值引用(如T&amp;&amp;),它对应的实参的const属性和左值/右值属性将得到保持 在调用中使用std::forward保持类型信息 使用名为forward的新标准库设施来传递flip2的参数,能保俶原始实参的类型 定义在utility中,必须通过显式模板实参来调用,forward返回该显式实参类型的右值引用 使用forward传递那些定义为模板类型参数的右值引用的函数参数 通过其返回类型上的引用折叠,forward可以保持给定实参的左值/右值属性 123456789101112131415161718192021222324252627282930313233343536373839// 接受一个可调用对象和另外两个参数的模板// 对翻转的参数调用给定的可调用对象// flip1是一个不完整的实现：顶层const和引用丢失了template&lt;typename F, typename T1, typename T2&gt;void flip1(F f, T1 t1, T2 t2)&#123; f(t2,t1);&#125;// 调用一个接受引用参数的函数时会出现问题void f(int v1, int &amp;v2)&#123; cout&lt;&lt;v1&lt;&lt;&quot; &quot;&lt;&lt; ++v2&lt;&lt;endl; // 改变了绑定到v2的值&#125;f(42,i); //f改变了实参iflip1(f,j,42); //通过flip1调用f不会改变j// 问题在于j被传递给flip1的参数t1,此参数是一个普通的,非引用类型的int,而非int&amp;// 被实例化为void flip1(void(*fcn)(int,int&amp;),int t1,int t2);// 定义能保持类型信息的函数参数template&lt;typename F, typename T1, typename T2&gt;void flip2(F f, T1 &amp;&amp;t1, T2 &amp;&amp;t2)&#123; f(t2,t1);&#125;// 解决一半问题,但不能接受右值引用参数的函数void g(int &amp;&amp;i,int&amp; j)&#123; cout&lt;&lt;i&lt;&lt;&quot; &quot;&lt;&lt; j&lt;&lt;endl;&#125;// 试图通过flip2调用g,则参数t2将被传递给g的右值引用参数。即使传递一个右值给flip2flip2(g,i,42); //错误,不能从一个左值实例化int&amp;&amp;// 函数参数与其他任何变量一样,都是左值表达式// 因此,flip2中对g的调用将传递给g的右值引用参数一个左值// forward可以保持给定实参的左值/右值属性template&lt;typename F, typename T1, typename T2&gt;void flip(F f, T1 &amp;&amp;t1, T2 &amp;&amp;t2)&#123; f(std::forward&lt;T2&gt;(t2),std::forward&lt;T1&gt;(t1));&#125; 16.3 重载与模板 函数模板可以被另一个模板或一个普通非模板函数重载(名字相同的函数必须具有不同数量或类型的参数) 当有多个重载模板对一个调用提供同样好的匹配时,应选择最特例化的版本 对于一个调用,如果一个非函数模板与一个函数模板提供同样好的匹配,则选择非模板版本 123456789101112131415161718192021222324252627282930313233343536373839// 编写重载模板// 打印任何不能处理的类型template &lt;typename T&gt; string debug_rep(const T &amp;t)&#123; ostringstream ret; ret&lt;&lt;t; return ret.str();&#125;// 此函数可以用来生成一个对象对应的string表示,该对象可以是任意具备输出运算符的类型// 定义打印指针的debug_rep版本// 打印指针的值,后跟指针指向的对象// 不能用于char*// IO库为char*值定义了一个&lt;&lt;版本。此&lt;&lt;版本假定指针表示一个空字符结尾的字符数组,并打印数组的内容而非地址值template&lt;typename T&gt; string debug_rep(T *p)&#123; ostringstream ret; ret &lt;&lt;&quot;pointer: &quot;&lt;&lt;p; if(p) ret&lt;&lt; &quot; &quot; &lt;&lt;debug_rep(*p); else ret&lt;&lt; &quot; null pointer&quot;; return ret.str; //返回ret绑定的string的一个副本&#125;// 以下调用const string *sp = &amp;s;// 两个模板都是可行的,而且两个都是精确匹配：// debug_rep(const string*&amp;),由第一个版本的debug_rep实例化而来,T被绑定到string*// debug_rep(const string*),由第二个版本的debug_rep实例化而来,T被绑定到const string// 解析为debug_rep()T*),即第二个版本// 设计这条规则的原因是,没有它,将无法对一个const的指针调用指针版本的debug_rep// 问题在于模板debug_rep(const T&amp;)本质上可以用于任何类型,包括指针类型。此模板比debug_rep(T*)更通用,后者只能用于指针类型。没有这条规则,传递const的指针的调用永远是有歧义的// C语言风格字符串指针和字符串字面常量cout &lt;&lt;debug_rep(&quot;hi world!&quot;)&lt;&lt;endl; //调用debug_rep(T*)// 对给定实参来说,两个模板都提供精确匹配// 第二个模板需要进行一次(许可的)数组到指针的转换,而对于函数匹配来说,这种转换被认为是精确匹配// 非模板版本是可行的,但需要进行一次用户定义的类型转换,因此它没有精确匹配那么好,所以两个模板成为可能调用的函数。与之前一样,T*版本更加特例化,编译器会选择它 16.4 可变参数模板 一个可变参数模板就是一个接受可变数目参数的模板函数或模板类 可变数目的参数被称为参数包 存在两种参数包：模板参数包,表示零个或多个模板参数;函数参数包,表示零个或多个函数模板 用省略号来指出一个模板参数或函数参数表示一个包 在一个模板参数列表中class…或typename…指出接下来的参数表示零个或多个类型的列表; 一个类型名后面跟一个省略号表示零个或多个给定类型的非类型参数列表 在函数参数列表中,如果一个参数的类型是一个模板参数包,则此参数也是一个函数参数包 sizeof运算符 需要直到包中有多少元素时,可以使用sizeof…运算符,sizeof…返回一个常量表达式,且不会对其实参求值 12345678// Args是一个模板参数包,rest是一个函数参数包template&lt;typename T, typename...Args&gt;void foo(const T &amp;t, const Args &amp;...rest);template&lt;typename ...Args&gt; void g(Args ...args)&#123; cout &lt;&lt; sizeof...(Args) &lt;&lt;endl; cout &lt;&lt; sizeof...(args) &lt;&lt;endl;&#125; 16.4.1 编写可变参数函数模板 可变参数函数通常是递归的 第一步调用处理包中的第一个实参,然后用剩余实参调用自身 当定义可变参数版本的函数时,非可变参数版本的声明必须在作用域中。否则可变参数版本会无限递归 123456789101112// 用来终止递归并打印最后一个元素的函数// 此函数必须在可变参数模板的print定义之前声明template&lt;typename T&gt;ostream &amp;print(ostream &amp;os, const T &amp;t)&#123; return os &lt;&lt; t; //包中最后一个元素之后不打印分隔符&#125;// 包中除了最后一个元素之外的其他元素都会调用这个版本的printtemplate &lt;typename T, typename ...Args&gt;ostream &amp;print(ostream &amp;os, const T &amp;t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; &quot;, &quot;; return print(os,rest); //递归调用,打印其他实参&#125; 16.4.2 包扩展 对于一个参数包,除了获取其大小外,对它唯一能做的是扩展 当扩展一个包是,还需要提供用于每个扩展元素的模式 扩展一个包就是将它分解为构成的元素,对每个元素应用模式,获得扩展后的列表 在模式右边放一个省略号来触发扩展操作 扩展中的模式会独立地应用于包中的每个元素 12345678910111213141516171819// 对print做扩展操作template &lt;typename T, typename ...Args&gt;ostream &amp;print(ostream &amp;os, const T &amp;t, const Args&amp;... rest) //扩展Args&#123; os &lt;&lt; t &lt;&lt; &quot;, &quot;; return print(os,rest...); //扩展rest&#125;// 在print调用中对每个实参调用debug_reptemplate &lt;typename ...Args&gt;ostream &amp;errorMsg(ostream &amp;os, const Args&amp;... rest)&#123; return print(os,debug_rep(rest)...);&#125;// 问题在于debug_rep调用中扩展了rest,等价于print(cerr,debug_rep(fcnName,code.num(),otherData,&quot;otherData&quot;,item));// 试图用了一个五个实参的列表来调用debug_rep,但并不存在与此调用匹配的debug_rep版本// debug_rep函数不是可变参数的,且没有哪个debg_rep接受五个参数 16.4.3 转发参数包 组合使用可变参数模板与forward机制来编写函数,实现将其实参不变地传递给其他函数 12345678910111213141516171819202122232425262728293031323334353637383940// 将为StrVec类添加一个emplace_back成员// 标准库容器的emplace_back成员是一个可变参数成员模板,它用其实参在容器管理的内存空间中直接构造一个元素// 保持类型信息是一个两阶段的过程// 首先为了保持实参中的类型信息,必须将emplace_back的函数定义为模板类型参数的右值引用class StrVec&#123;public: template&lt;class... Args&gt; void emplace_back(Args&amp;&amp;...);&#125;// 模板参数包扩展中的模式是&amp;&amp;,意味着每个函数参数将是一个指向其对应实参的右值引用// 当emplace_back将实参传递给constrct时,必须使用forward来保持实参的原始类型template&lt;class... Args&gt;inlinevoid StrVec::emplace_back(Args&amp;&amp;... args)&#123; chk_n_alloc(); //如果需要的话重新分配StrVec内存空间 alloc.construct(first_free++, std::forward&lt;Args&gt;(args)...);&#125;// 假定svec是一个StrVec,如果调用svec.emplace_back(10,&#x27;c&#x27;); //将cccccccccc添加新的尾元素// construct调用中的模式会扩展出std::forward&lt;int&gt;(10),std::forward&lt;char&gt;(c)// 如果用右值调用emplace_back,则construct会得到一个右值svec.emplace_back(s1+s2);// 传递右值std::forward&lt;string&gt;(string(&quot;the end&quot;))// forward&lt;string&gt;的结果类型是string&amp;&amp;,因此construct将得到一个右值引用实参// construct会继续将此实参传递给string的移动构造函数来创建新元素// 转发和可变参数模板// func有零个或多个参数,每个参数都是一个模板参数类型的右值引用template&lt;typename... Args&gt;void fun(Args&amp;&amp;... args) //将Args扩展为一个右值引用&#123; // work的实参即扩展Args又扩展args work(std::forward&lt;Args&gt;(args)...);&#125;// 由于fun的参数是右值引用,因此可以传递给它任意类型的实参// 由于使用std：：forward传递这些实参,因此它们的所有类型信息在调用work时都会得到保持 16.5 模板特例化 编写单一模板,使之对任何可能的模板实参都是最合适的,都能实例化 在某些情况下,通用模板的定义对特定类型是不适合的：通用定义可能编译失败或做得不正确 当不能使用模板版本时,可定义类或函数模板得一个特例化版本 定义函数模板特例化 特例化一个函数模板时,必须为原模版中每个模板参数都提供实参 为了指出正在实例化一个模板,应该使用关键字template后跟一对空尖括号,空尖括号指出将为原模版的所有模板参数提供实参 函数重载与模板特例化 特例化的本质是实例化一个模板,而非重载它。特例化不影响函数匹配 将一个特殊的函数定义为一个特例化版本还是一个独立的非模板函数,会影响到函数匹配, 函数匹配会选择疼特例化的版本 当一个非模板函数提供与函数模板同样匹配好的情况下,编译器会选择非模板版本 类模板特例化 可以特例化类模板,必须在原模版定义所在的命名空间中特例化 类模板部分特例化 可指定一部分而非所有模板参数,或是参数的一部分而非全部特性 一个类模板的部分特例化本身是一个模板,使用时用户必须为哪些在特例化版本中为指定的模板参数提供实参 只能特例化类模板,不能部分特例化函数模板 特例化成员而不是类：可以只特例化成员函数而不是特例化整个模板 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// compare函数的例子// 第一个版本：可以比较任意两个类型template&lt;typename T&gt; int cmpare(const T&amp;, const T&amp;);// 第二个版本：处理字符串字面常量template&lt;size_t N, size_t M&gt; int cmpare(const char (&amp;)[N], const char (&amp;)[M]);// 只有当传递compare一个字符串字面常量或一个数组时,编译器才会调用接受两个非类型模板参数的模板const char *p1 = &quot;hi&quot;,*p2 = &quot;mom&quot;;compare(p1, p2); //调用第一个模板compare(&quot;hi&quot;,&quot;mom&quot;); //调用第二个模板// 无法将一个指针转换为一个数组的引用// 为了处理字符指针,可以为第一个版本的compare定义一个模板特例化版本// 一个特例化版本就是模板的一个独立地定义,在其中一个或多个模板被指定为特定的类型// compare的特殊版本,处理字符数组的指针template&lt;&gt;int compare(const char* const &amp;p1, const char* const &amp;p2)&#123; return strcmp(p1,p2);&#125;// 当定义一个特殊化版本时,函数参数类型必须与一个先前声明的模板中对应的类型匹配// 希望定义此函数的一个特例化版本,其中T为const char*// 函数要求一个指向此类型const版本的引用。一个指针类型的const版本是一个常量指针而不是指向const类型的指针// 需要在特例化版本中使用的类型是const char * const &amp;,即一个指向const char的const指针的引用// 打开std命名空间,以便特例化std::hashnamespace std&#123; &#125; //关闭std命名空间;注意右花括号之后没有分号// 打开std命名空间,以便特例化std::hashnamespace std&#123; template &lt;&gt; //特例化版本,模板参数为Sales_data struct hash&lt;Sales_data&gt;&#123; typedef size_t resule_type; typedef Sales_data argument_type; size_t operator() (const Sales_data&amp; s) const; &#125;; size_t hash&lt;Sales_data&gt;::operator() (const Sales_data&amp; s) const &#123; return hash&lt;string&gt;() (s.bookNo) ^ hash&lt;unsigned&gt;() (s.units_sold) ^ hash&lt;double&gt;() (s.revenue); &#125;&#125; //关闭std命名空间;注意右花括号之后没有分号template &lt;class T&gt; class std::hash; //友元声明所需要的class Sales_data&#123; friend class std::hash&lt;Sales_data&gt;;&#125;// 指出特殊实例hash&lt;Sales_data&gt;是Sales_data的友元// 由于此实例定义在std命名空间中,必须在友元声明中使用std::hash// 特例化成员template &lt;typename T&gt; struct Foo&#123; Foo(const T &amp;t = T()) : mem(t)&#123;&#125; void Bar() &#123;//...&#125; T mem;&#125;;template&lt;&gt; //正在特例化模板void Foo&lt;int&gt;::Bar()&#123; // 特例化Foo&lt;int&gt;的成员Bar // 进行应用于int的特例化处理&#125; 17 标准库特殊设施 17.1 tuple类型 tuple类似pair的模板,一个tuple可以有任意数量的成员,每个确定的tuple类型的成员数目是固定的,但一个tuple类型的成员数目可以与另一个tuple类型不同 当希望将一些数据组合成成单一对象,但不想重新定义一个数据结构来表示数据时,tuple为较好的选择 定义在tuple头文件中 tuple支持的操作 - tuple&lt;T1,T2,…,Tn&gt; t t为n个不同成员类型的tuple tuple&lt;T1,T2,…,Tn&gt; t(v1,v2,…vn) t为n个不同成员类型初始化了的tuple,次构造函数时explicit make_tuple(v1,v2,…vn) 返回一个初始值初始化的tuple t1 == t2 当两个tuple具有相同数量的成员且成员对应相等时,两个相等 t1 != t2 当两个tuple具有相同数量的成员且成员对应相等时,两个相等 t1 relop t2 关系运算符,使用字典序进行 get&lt;i&gt;(t) 返回t第i个成员的引用,若t是一个左值,结果为左值,否则为右值 tuple_size&lt;tupleType&gt;::value 一个类模板,通过tuple类型初始化 tuple_element&lt;i,tupleType&gt;::type 一个类模板,通过一个整型常量和一个tuple类型来初始化,有一个type的成员,表示给定tuple类型中指定成员的类型 17.1.1 定义和初始化tuple 定义tuple时,需要指出每个成员的类型 构造函数是explicit,必须使用直接初始化语法 12345678tuple&lt;size_t,size_t,size_t&gt; threeD;tuple&lt;string, vector&lt;double&gt;, int, list&lt;int&gt;&gt; = someVal(&quot;constants&quot;,&#123;3.14,2.718&#125;,42,&#123;0,1,2,3,4,5&#125;)// 直接初始化tuple&lt;size_t,size_t,size_t&gt; threeD&#123;1,2,3&#125;;// make_tupleauto item = make_tuple(&quot;0-99-78345-X&quot;,3,20.00); 访问tuple成员 使用get标准库函数模板,并指定显式模板实参(传递tuple对象,返回指定成员的引用) 尖括号的值必须是整型常量表达式 ==不知道tuple准确的类型细节时,使用辅助类进行查询 123456auto book = get&lt;0&gt;(item);get&lt;2&gt;(item) *= 0.8;typedef decltype(item) trans; //trans是item的类型size_t sz = tuple_size&lt;trans&gt;::value; //返回trans类型对象中成员的数量tuple_element&lt;1,trans&gt;::type cnt = get&lt;1&gt;(item); 17.1.2 使用tuple返回多个值 最常见的用途是从一个函数返回多个值 1234567891011121314151617181920212223242526272829303132// matches有三个成员：一家书店的索引和两个指向书店vector中元素的迭代器typedef tuple&lt;vector&lt;Sales_data&gt;::size_type, vector&lt;Sales_data&gt;::const_iterator, vector&lt;Sales_data&gt;::const_iterator&gt; matches;// files保存每家书店的销售记录// findBook返回一个vector,每家销售了给定书籍的书店在其中都有一项vector&lt;matches&gt;findBook(const vector&lt;vector&lt;Sales_data&gt;&gt; &amp;files, const string &amp;book)&#123; vector&lt;matches&gt; ret; for(auto it = files.cbegin();it!=files.cend();++it)&#123; auto found = equal_range(it-&gt;cbegin(),it-&gt;cend(),book,compareIsbn); if(found.first != found.second) ret.push_back(make_tuple(it - files.cbegin(),found.first,found.second)); &#125; return ret;&#125;// equal_range的标准库算法:前两个实参是表示输入序列的迭代器(参见10.1节,第336页),第三个参数是一个值。默认情况下,equal_range使用&lt;运算符来比较元素,Sales_data没有&lt;运算符,则需要传递函数指针// 返回迭代器表示pair表示元素范围// 打印汇总销售信息void reportResults(istream &amp;in, ostream &amp;os, const vector&lt;vector&lt;Sales_data&gt;&gt; &amp;files)&#123; string s; while(in&gt;&gt;s)&#123; auto trans = findBook(files,s); if(trans.empty())&#123; cout &lt;&lt; s &lt;&lt; &quot; not found in any stores&quot; &lt;&lt; endl; continue; &#125; for(const auto &amp;store : trans) os &lt;&lt; &quot;store &quot; &lt;&lt; get&lt;0&gt;(store) &lt;&lt; &quot; sales: &quot;&lt;&lt; accumualte(get&lt;1&gt;(store),get&lt;2&gt;(store),Sales_data(s))&lt;&lt;endl; &#125;&#125; 17.2 bitset类型 bitset类,可以使位运算更加容易,且能处理超过最长整数类型大小的位集合 定义在bitset头文件中 17.2.1 定义和初始化bitset 初始化bitset的方法 - bitset&lt;n&gt; b; b有n位,每一位均为0,此构造函数时constexpr bitset&lt;n&gt; b(u); b有unsigned long long值u的低n位的拷贝 bitset&lt;n&gt; b(s,pos,m,zero,one); b是string s从pos开始m个字符的拷贝;s只能包含字符zero或one bitset&lt;n&gt; b(cp,pos,m,zero,one); 同上,cp指向字符数组中拷贝字符 - 接受一个string或字符指针的构造函数时explicit 12345678910// unsigned初始化bitset&lt;13&gt; bitvec1(oxbeef); // string初始化bitset&lt;32&gt; bitvec2(&quot;1100&quot;);// string的子串进行初始化string str(&quot;111111110000000011001101&quot;);bitset&lt;32&gt; bitset5(str,5,4);bitset&lt;32&gt; bitset5(str,str.size()-4); 17.2.2 bitset操作 bitset操作 - b.any() b中是否含有置位的二进制位 b.all() b中所有位都置位了吗 b.none() b中不存在置位的二进制位吗 b.count() b中置位的位数 b.size() b中的位数,constexpr函数 b.test(pos) 判断pos位是否置位 b.set(pos,v) 将pos处的位设置位bool值v b.set() 将b中所有位置位 b.reset(pos) 将位置pos处的位复位 b.reset() 将b中所有的位复位 b.flip(pos) 改变pos处的位状态 b.flip() 改变每一位的状态 b[pos] 访问b中位置pos处的位 b.to_ulong() 返回一个unsigned long或unsigned long long值,其位模式与b相同 b.to_ullong() 返回一个unsigned long或unsigned long long值,其位模式与b相同 b.to_string(zero,one) 返回一个string,表示b中的位模式,zero和one的默认值分为0和1表示b中的0和1 os &lt;&lt; b 将b中二进制位打印为字符1或0,打印到流os is &gt;&gt; b 从is读取字符并存入b 17.4 正则表达式 是一种描述字符序列的方法,是一种强大的计算工具 使用C++正则表达式库(RE库),定义在头文件regex中,包含多个组件 正则表达式库组件 - regex 表示有一个正则表达式的类 regex_match 将一个字符序列与一个正则表达式匹配 regex_search 寻找第一个与正则表达式匹配的子序列 regex_replace 使用给定格式替换一个正则表达式 sregex_iterator 迭代器适配器,使用regex_search遍历一个string中所有匹配的子串 smatch 容器类,保存在string中的搜索结果 ssub_match string中匹配的子串表达式的结果 regex类表示一个正则表达式 函数regex_match和regexsearch确定了一个给定字符序列与一个给定regex是否匹配 regex_search和regex_match的参数 (seq,m,r,mft) /(seq,r,mft) 在字符序列seq中查找regex对象r中的正则表达式,seq可以是一个string,表示范围的一对迭代器以及一个指向空字符结尾的字符数组的指针,m是一个match对象,用来报讯匹配结果的相关细节,m和seq必须具有兼容的类型 mft是一个可选的regex_constants::match_flag_type值 17.3.1 使用正则表达式库 12345678910111213// 查找拼写规则,i除非在c之后,否则必须在e之前// 查找不在字符c之后的字符串eistring pattern(&quot;[^c]ei&quot;);// 包含pattern的整个单词pattern = &quot;[[:alpha:]]*&quot; + pattern + &quot;[[:alpha:]]*&quot;;regex r(pattern); //构造一个用于查找模式的regexsmatch result; //定义一个对象保存搜索结果// 定义一个string保存与模式匹配和不匹配的文本string test_str = &quot;receipt friend theif receive&quot;;// 用r在test_str中查找与pattern匹配的子串if(regex_search(test_str,result,r)) cout &lt;&lt; result.str() &lt;&lt; endl; regex(和wregex)选项 - regex r(re) re时一个正则表达式 regex r(re,f) re时一个正则表达式,f是指出对象如何处理的标志 r1 = re 将r1中的正则表达式替换成re r1.assign(re,f) 与=效果相同 r1.mark_count() r中子表达式的数目 r1.flags() 返回r的标志集 定义regex时指定的标志 定义在regex和regex_constans::syntax_option_type中 icase 在匹配过程中忽略大小写 nosubs 不保存匹配的子表达式 optimize 执行速度有限 ECMAScript 使用ECMAScipt指定的语法 basic 使用POSIX基本的正则表达式语法 extened 使用POSIX扩展的正则表达式语法 awk 使用POSIX版本的awk正则表达式语法 grep 使用POSIX版本的grep正则表达式语法 egrep 使用POSIX版本的egrep正则表达式语法 指定或使用正则表达式时的错误 正则表达式是在运行时,当一个regex对象被初始化或被赋予了一个新模式时,才会被编译 正则表达式在运行时解析是否正确 错误时,抛出regex_error的异常,what操作描述什么错误,code成员返回错误类型对应的数值编码 正则表达式库类 - 输入类型 使用正则表达式类 string regex,smatch,ssub_match和sregex_iterator const char* regex,cmatch,csub_match和cregex_iterator wstring wregex,wsmatch,wssub_match和wsregex_iterator const wchar_t* wregex,wcmatch,wcsub_match和wcregex_iterator 17.3.2 匹配与Regex迭代器类型 sregex_iterator操作 同样适用cregex_iterator,wsregex_iterator,wcregex_iterator sregex_iterator 一个sregex_iterator,遍历迭代器b和e表示的string it(b,e,r) 调用sregex_search(b,e,r)将it定位到输入中第一个匹配的位置 sregex_iterator end; 尾后迭代器 *it 返回一个smatch的对象的引用或指向stmatch对象的指针 it-&gt; 返回一个smatch的对象的引用或指向stmatch对象的指针 ++it 前置返回递增后迭代器 it++ 后置返回旧值 it1==it2 相等比较 it1!=it2 相等比较 当将一个sregex_iterator绑定到一个string和一个regex对象时,迭代器自动定位到给定string中第一个匹配位置 即,sregex_iterator构造函数对给定string和regex调用regex_search 当解引用迭代器时,会得到一个对应最近一次搜索结果的smatch对象 当递增迭代器时,它调用regex_search在输入string中查找下一个匹配 smatch操作 - m.ready() 若已经通过调用regex_search或regex_match设置了m,则返回true m.size() 匹配失败返回0,否则返回最近一次匹配的正则表达式中子表达式的数目 m.empty() 若m.size()为0,返回true m.prefix() ssub_match对象,表示当前匹配之前的序列 m.suffix() ssub_match对象,表示当前匹配之后的序列 m.format() - m.length(n) 第n个匹配的子表达式的大小 m.position(n) 第n个子表达式距离序列开始的距离 m.str(n) 第n个子表达式匹配的string m[n] 对应第n个子表达式的ssub_match地想 m.begin(),m.end() 迭代器 m.cbegin(),m.cend() 迭代器 17.3.3 使用子表达式 正则表达式中的模式通常包含一个或多个子表达式 一个子表达式是模式的一部分,本身也具有意义。正则表达式语法通常用括号表示子表达式 123456789101112131415161718192021222324252627// 电话号码匹配string phone = &quot;(\\\\()?(\\\\d&#123;3&#125;)(\\\\))?([-.])?(\\\\d&#123;3&#125;)([-.]?)(\\\\d&#123;4&#125;)&quot;;// 逐个剥离(括号包围的)子表达式：1.(\\\\()？表示区号部分可选的左括号;2.(\\\\d&#123;3&#125;)表示区号;3.(\\\\))？表示区号部分可选的右括号;4.([-.])？表示区号部分可选的分隔符;5.(\\\\d&#123;3&#125;)表示号码的下三位数字;6.([-.])？表示可选的分隔符;7.(\\\\d&#123;4&#125;)表示号码的最后四位数字regex r(phone);smatch m;string s;while(getline(cin,s))&#123; for(sregex_iterator it(s.begin(),s.end(),r),end_it;it!end_it;++it) if(valid(*it)) cout &lt;&lt; &quot;valid: &quot; &lt;&lt; it-&gt;str() &lt;&lt; endl; else cout &lt;&lt; &quot;not valid: &quot; &lt;&lt; it-&gt;str() &lt;&lt; endl;&#125;// pattern有七个子表达式,每个smatch对象会包含八个ssub_match元素。位置[0]的元素表示整个匹配;元素[1]…[7]表示每个对应的子表达式// 已经有一个完整的匹配,但不知道每个可选的子表达式是否是匹配的一部分// 如果一个子表达式是完整匹配的一部分,则其对应的ssub_match对象的matched成员为true// 在一个合法的电话号码中,区号要么是完整括号包围的,要么完全没有括号。因此,valid要做什么工作依赖于号码是否以一个括号开始bool valid(const smatch&amp; m)&#123; // 如果区号前有一个左括号 if(m[1].matched) // 则区号后必须有一个右括号,之后紧跟剩余号码或一个空格 return m[3].matched &amp;&amp; (m[4].matched == 0 || m[4].str() == &quot; &quot;); else return !m[3].matched &amp;&amp; m[4].str() == m[6].str();&#125; 17.3.4 使用regex_replace 希望在输入序列中查找并替换一个正则表达式时,使用regex_replace 接受一个输入序列,一个regex对象,和一个输出形式的字符串 正则表达式替换操作 - m.format(dest,fmt,mft) 使用格式字符串 fmt 生成格式化输出,匹配在m中,可选的match_flag_type标志在mft中.第一个版本写入迭代器dest指向的目的位置并接受fmt参数,可以是string,也可以是表示字符数组中范围的一对指针 m.format(fmt,mft) 第二个版本返回string,保存输出,并接受fmt参数,可以是 一个string, 也可以是指向空字符结尾的字符数组的指针.mft的默认值为format_default regex_replace(dest,seq,r,fmt,mft) 遍历seq,用regex_search查找与regex对象r匹配的子串 regex_replace(seq,r,fmt,mft) 遍历seq,用regex_search查找与regex对象r匹配的子串 匹配标志 定义在regex_constans::match_flag_type中 match_default 等价于format_default match_not_bol 不将首字符作为行首处理 match_not_eol 不将尾字符作为行首处理 match_not_bow 不将首字符作为单词首处理 match_not_eow 不将尾字符作为单词首处理 match_any 如果存在对于一个匹配,则可以返回任意一个匹配 match_not_null 不匹配任何空字符 match_continuous 匹配必须从输入的首字符开始 match_prev_avail 输入序列包含第一个匹配之前的内容 format_default 用ECMAScript规则替换字符串 format_sed 用POSIX sed规则替换字符串 format_no_copy 不输出输入序列中未匹配的部分 format_first_only 只替换子表达式的第一次出现 17.4 随机数 头文件random中的随机数库通过一组协作式的类来解决随机数的范围,类型或分布问题 引入随机数引擎类和随机数分布类 一个引擎类可以生成unsigned随机数序列,一个分布类使用一个引擎类生成指定类型的在给定范围内的服从特定概率分布的随机数 C++中应该使用default_random_engine类和恰当的分布类对象 17.4.1 随机数引擎和分布 随机数引擎时函数对象类,定义了一个调用运算符,不接受参数返回一个随机unsigned整数 每次程序运行都会生成不同的随机结果,可以通过种子来实现 种子时一个数值,引擎可以利用它从序列中一个新位置重新开始生成随机数 创建种子的两种方式 在创建引擎对象时提供种子 调用引擎的seed成员 随机数引擎操作 - Engine e 默认构造函数,使用该引擎类型默认的种子 Engine e(s); 使用整数值s作为种子 e.seed(s); 使用种子s重置引擎的状态 e.min(); 引擎可生成的最小值 e.max(); 引擎可生成的最大值 Engine::result_type 此引擎生成的unsigned整数类型 e.discard(u) 此引擎推进u步;u的类型尾unsigned long long 12345678910111213141516171819202122default_random_engine e; //生成随机无符号数for(size_t i = 0;i&lt;10;++i) cout &lt;&lt; e() &lt;&lt; &quot; &quot;;// 生成0到9之间均匀分布的随机数uniform_int_distribution&lt;unsigned&gt; u(0,9);default_random_engine e;for(size_t i = 0;i&lt;10;++i&gt;) cout &lt;&lt; u(e) &lt;&lt; &quot; &quot;;default_random_engine e1; //默认种子default_random_engine e2(2147483646); //使用给定的种子// e3和e4将生成相同的序列,使用相同的种子default_random_engine e3;e3.seed(32767);default_random_engine e4(32767);for(size_t i = 0; i!=100;++i)&#123; if(e1() == e2) cout &lt;&lt; i&lt;&lt;endl; if(e3() == e4) cout &lt;&lt; i&lt;&lt;endl;&#125; 17.4.2 其他随机数分布 分布类型的操作 - Dist d 默认构造函数,分布类型的构造函数时explicit d(e) 使用相同的e连续调用d扽话,会根据d的分布式类型生成一个随机数序列;e随机数引擎对象 d.min() 最小值 d.max() 最大值 d.reset() 重建d的状态 一个分布不接受模板参数,即bernoulli_distribution,因为它是一个普通类,而非模板 此分布总是返回一个bool值。它返回true的概率是一个常数,此概率的默认值是0.5 由于引擎返回相同的随机数序列,所以必须在循环外声明引擎对象 否则,每步循环都会创建一个新引擎,从而每步循环都会生成相同的值 类似的,分布对象也要保持状态,因此也应该在循环外定义 12// 定义0-1的随机均匀分布uniform_real_distribution&lt;double&gt; u(0,1); 17.5 IO库再探 17.5.1 格式化输入与输出 格式状态控制格式化的某些方面,如整数值是几进制,浮点值得精度,一个输出元素的宽度 操纵符来修改流的格式状态 一个操纵符是一个函数或是一个对象,会影响流的状态,并能用作输入或输出运算符的运算对象 当操纵符改变流的格式状态时,通常改变后的状态对所有后续IO都生效 改变布尔值的格式 boolalpha操纵符覆盖格式,输出true和false noboolalpha取消cout格式状态的改变 指定整数值的进制 使用hex,oct和dec将其改成十六进制,八进制或十进制输出 浮点数不受影响 在输出中指出进制 需要打印八进制或十六进制,使用showbase操纵符,遵循与整数常量中指定进制相同的规范 使用noshowbase恢复,不再显示整数值的进制 控制浮点数格式 三种格式： 以多高精度(多少个数字)打印浮点值 数值是打印为十六进制、定点十进制还是科学记数法形式 对于没有小数部分的浮点值是否打印小数点 默认情况下是六位数精度打印, 指定打印精度 可调用IO对象的precision成员或使用setprecision操纵符改变精度 定义在iomanip中 precision成员是重载的,接受一个int值将其设为精度,并返回旧精度,不接受参数返回当前精度值 setprecision接受一个参数,用来设置精度 指定浮点数计数法 scientific改变流的状态使用科学计数法 fixed改变流的状态使用定点十进制 新标准库中的函数 hexfloat强制浮点数使用十六进制 defaultfloat恢复至默认状态 精度值控制的是小数点后的数字位数,默认情况下控制的是数字总位数 打印小数点 showpoint操纵符强制打印小数点 noshowpoint恢复默认行为 输出补白 setw 指定下一个数字或字符串值得最小空间 left 表示左对齐输出 right 表示右对齐输出(默认格式 internal 控制负号符号得位置 setfill 允许指定一个字符代替默认的空格来补白输出 定义在iomanip中的操纵符 setfill(ch) 用ch填充空白 setprecision(n) 将浮点精度设置为n setw(w) 读或写值得宽度为w个字符 setbase(b) 将整数输出为b进制 控制输入格式 noskipws 输入序列读取空白符,而不是跳过 skipws 恢复 17.5.2 未格式化的输入/输出操作 低层操作,支持未格式化IO,允许将流仿作一个无解释的字节序列处理 三种方法退回字符,有着细微的差别： peek返回输入流中下一个字符的副本,但不会将它从流中删除,peek返回的值仍然留在流中 unget使得输入流向后移动,从而最后读取的值又回到流中。即使不知道最后从流中读取什么值,仍然可以调用unget putback是更特殊版本的unget：它退回从流中读取的最后一个值,但它接受一个参数,此参数必须与最后读取的值相同 函数peek和无参的get版本都以int类型从输入流返回一个字符 函数返回一个int的原因是：可以返回文件尾标记,使用char范围中的每个值来表示一个真实字符,因此,取值范围中没有额外的值可以用来表示文件尾 返回int的函数将它们要返回的字符先转换为unsigned char,然后再将结果提升到int。因此,即使字符集中有字符映射到负值,这些操作返回的int也是正值。而标准库使用负值表示文件尾可以保证与任何合法字符的值都不同 头文件cstdio定义了一个名为EOF的const,可以用它来检测从get返回的值是否是文件尾,而不必记忆表示文件尾的实际数值 get将分隔符留作istream中的下一个字符,而getline则读取并丢弃分隔符 无论哪个函数都不会将分隔符保存在sink中 确定读取了多少个字符 某些操作从输入读取未知个数的字节。可以调用gcount来确定最后一个未格式化输入操作读取了多少个字符。应该在任何后续未格式化输入操作之前调用gcount 特别是,将字符退回流的单字符操作也属于未格式化输入操作。如果在调用gcount之前调用了peek、unget或putback,则gcount的返回值为0 单字节低层IO操作 - is.get(ch) 从istream is读取下一个字节存入字符ch中返回is os.put(ch) 将字符ch输出到ostream os,返回os is.get() 将is的下一个字节作为int返回 is.putback(ch) 将字符ch放回is,返回is is.unget() 将is向后移动一个字节,返回is is.peek() 将下一个字节作为int返回,但不从流中删除 多字节低层IO操作 - is.get(sink,size,delim) 从is中读取最多size个字节,保存在起始地址为sink的字符数组中,若读取到字符delim或读取了size个字节或文件尾时停止,若遇到了delim,则将其留在输入流中,不读取出来存入sink is.getline(sink,size,delim) 与get相似,但会读取并舍弃delim is.read(sink,size) 读取最多size个字节,存入字符数组sink中,返回is is.gcount() 返回上一个未格式化读取操作从is读取的字节数 os.write(source, size) 将字符数组source中size个字节写入os,返回os is.ignore(size, delim) 读取并忽略最多size个字符,包括delim 17.5.3 流随机访问 为了支持随机访问,提供了两个函数,一个函数通过将标记seek到一个给定位置来重定位它;另一个函数tell我们标记的当前位置 从逻辑上讲,只能对istream和派生自istream的类型ifstream和istringstream使用g版本,同样只能对ostream和派生自ostream的类型ofstream和ostringstream使用p版本;一个iostream、fstream或stringstream既能读又能写关联的流,因此对这些类型的对象既能使用g版本又能使用p版本 由于只有单一的标记,因此只要在读写操作间切换,就必须进行seek操作来重定位标记 seek和tell函数 - tellg() 返回一个输入流标记的当前位置 tellp() 返回一个输出流标记的当前位置 seekg(pos) 在输入流将标记重新定位到给定的绝对位置,pos通常是前一个tellg或tellp返回的值 seekp(pos) 在输出流将标记重新定位到给定的绝对位置,pos通常是前一个tellg或tellp返回的值 seekg(off, from) 在一个输入流中将标记当味道from之前或之后off个字符 seekp(off, from) 在一个输出流中将标记当味道from之前或之后off个字符 18 用于大型程序的工具 18.1 异常处理 18.1.1 抛出异常 C++语言中，通过抛出一条表达式来引发一个异常 被抛出的表达式的类型以及当前的调用链共同决定了哪段处理代码被用来处理该异常 被选中的处理代码是在调用链中与对象类型匹配的最近的处理代码 栈展开 栈展开过程： 当抛出一个异常后，程序暂停当前函数的执行过程并立即开始寻找与异常匹配的catch子句。当throw出现在一个try语句块内时，检查与该try块关联的catch子句 如果找到了匹配的catch，就使用该catch处理异常 如果这一步没找到匹配的catch且该try语句嵌套在其他try块中，则继续检查与外层try匹配的catch子句 如果还是找不到匹配的catch，则退出当前的函数，在调用当前函数的外层函数中继续寻找 栈展开过程沿着嵌套函数的调用链不断查找，直到找到了与异常匹配的catch子句为止；或者没有皮皮额的catch语句，程序调用标准库函数terminate，终止程序执行 栈展开过程中对象被自动销毁 在栈展开过程中退出了某个块，编译器将负责确保在这个块中创建的对象能被正常地销毁 如果异常发生在构造函数中，则需要确保已构造地成员能被正常地销毁 析构函数与异常 若使用类来控制资源地分配，就能确保无论函数正常结束还是异常时，资源都能被正确释放 析构函数不应该抛出自身不能处理地异常 析构函数需要执行某个可能抛出异常地操作，则操作应该被放置在一个try语句块中，并且在析构函数内部得到处理 在栈展开的过程中，运行类类型的局部对象的析构函数 析构函数自动执行，不应该抛出异常。一旦析构函数抛出异常，且析构函数自身没能捕捉到该异常，则程序将被终止 异常对象 异常对象位于编译器管理的空间中，当异常处理完毕后，异常对象被销毁 抛出一条表达式时，该表达式的静态编译时类型决定了异常对象的类型 如果一条throw表达式解引用一个基类指针，而该指针实际指向的是派生类对象，则抛出的对象将被切掉一部分，只有基类部分被抛出 18.1.2 捕获异常 当进入一个catch语句之后，通过异常对象初始化异常声明中的参数，通过异常初始化异常声明中的参数 和函数的参数类似，若catch的参数类型是非引用类型，则该参数是异常对象的一个副本，在catch语句内改变该参数实际上改变的是局部副本而非异常对象本身 如果catch的参数是基类类型，可以使用其派生类类型的异常对象对其进行初始化 若catch的参数是非引用，则异常对象将被且一部分 异常声明的静态类型将决定catch语句所能执行的操作，若catch的参数是基类类型，则catch无法使用派生类特有的任何成员 查找匹配的处理代码 搜寻catch语句时，找到的catch语句是第一个异常匹配的语句 当程序使用具有继承关系的多个异常时必须对catch语句的顺序进行组织和管理，使得派生类异常的处理代码出现在基类异常的处理代码之前 在匹配时允许的转换 允许从非常量向常量的类型转换，也就是说，一条非常量对象的throw语句可以匹配一个接受常量引用的catch语句 允许从派生类向基类的类型转换 数组被转换成指向数组（元素）类型的指针，函数被转换成指向该函数类型的指针 应该把继承链最底层的类放在前面，而将继承链最顶端的类放在后面 重新抛出 一条catch语句通过重新抛出的操作将异常传递给另一个catch语句 重新抛出使用throw语句，但不包含任何表达式 一个重新抛出语句并不指定新的表达式，而是将当前异常对象沿调用链向上传递 捕获所有异常的处理代码 一次性捕获所有异常，使用省略号作为异常声明，这样的处理代码称为捕获所有异常的代码(catch…) 一条捕获所有异常的语句可以与任意类型的异常匹配 如果catch(…)与其他几个catch语句一起出现，则catch(…)必须在最后的位置 出现在捕获所有异常语句后面的catch语句将永远不会被匹配 12345678void mainp()&#123; try&#123; &#125;catch(...)&#123; // 处理异常的某些特殊操作 throw; &#125;&#125; 18.1.3 函数try语句块与构造函数 构造函数在进入其函数体之前首先初始化列表，在初始化列表抛出异常时构造函数体内的try语句块未生效 构造函数体内的catch语句无法处理构造函数初始化列表抛出的异常 将构造函数写成函数try语句块 函数try语句块使得一组catch语句既能处理构造函数体，也能处理构造函数的初始化过程 12345template&lt;typename T&gt;Blob&lt;T&gt;::Blob(std::initializer_list&lt;T&gt; il) try: data(std::make_shared&lt;std::vector&lt;T&gt;&gt; il)&#123; //空函数体 &#125;catch(const std::bad_alloc &amp;e) &#123;handle_out_of_memory(e);&#125; 18.1.4 noexcept异常说明 通过提供noexcept说明指定某个函数不会抛出异常 关键字noexcept紧跟在函数的参数列表后面，表示函数不会抛出异常 违反异常说明 编译器并不会在编译时检查noexcept说明 实际上若一个函数说明了noexcept的同时又含有throw语句也能顺利编译 noexcept可接受一个可选的实参，该实参必须转换成bool类型，若为true函数不会抛出异常 noexcept运算符 noexcept运算符是一个一元运算符，它的返回值是一个bool类型的右值常量表达式，用于表示给定的表达式是否会抛出异常 不会对其运算对象求值 异常说明与指针，虚函数和拷贝控制 函数指针及该指针所指的函数必须具有一致的异常说明 虚函数承诺了不会抛出异常，则派生的虚函数也必须不能抛出任何异常 若基类的虚函数允许抛出异常，则派生类的对应函数既可以抛出异常，也可以不允许抛出异常 1234noexcept(recoup(i)); //若recoup不跑出异常结果为truenoexcept(e);// 当e调用的所有函数都做了不抛出说明且e本身不含有throw语句时，表达式为true 18.1.5 异常类层次 exception bad_cast runtime_error overflow_error underflow_error range_error logic_error domain_error invalid_argument out_of_range length_error bad_alloc 18.2 命名空间 命名空间为了防止名字冲突而提供了可控的机制，分割了全局命名空间，其中每个命名空间是一个作用域 18.2.1 命名空间的定义 命名空间的定义包含 首先是关键字namespace 随后是命名空间的名字 在命名空间后市一系列由花括号括起来的声明和定义 命名空间后无需分号 每一个命名空间都是一个作用域 命名空间中每个名字必须表示该空间的唯一实体 定义在某个命名空间中的名字可以被该命名空间内的其他成员直接访问，也可以被这些成员内嵌作用域中的任何单位访问 位于命名空间之外的代码必须使用作用域说明符(::)指出所用的名字属于哪个命名空间 命名空间的定义可以不连续的特性 使得可以将几个独立的接口和实现文件组成一个命名空间 命名空间的管理 命名空间的一部分成员的作用是定义类，以及声明作为类接口的函数及对象，则这些成员应该置于头文件中，这些头文件将被包含在使用了这些成员的文件中 命名空间成员的定义部分则置于另外的源文件中 定义命名空间成员 命名空间之外定义的成员必须使用含有前缀的名字 模板特例化 模板特例化必须定义在原始模板所属的空间 只要在命名空间中声明了特例化，就能在命名空间外部定义 全局命名空间 全局命名空间为隐式的方式声明的，全局作用域中定义的名字被隐式地添加到全局命名空间中 嵌套的命名空间：是定义在其他命名空间中的命名空间 调用时嵌套调用 内联命名空间 内联命名空间中的名字可被外层命名空间直接使用 无须在内联命名空间的名字前添加表示该命名空间的前缀，通过外层命名空间的名字就可以直接访问它 关键字inline必须出现在命名空间第一次定义的地方，后续再打开命名空间时可不写inline 应用程序的代码在一次发布和另一次发布之间发生了改变时，常常会用到内联命名空间 未命名的命名空间 namespace后紧跟着花括号的一系列声明 未命名的命名空间中定义的变量拥有静态声明周期：再第一次使用前创建，并且直到程序结束才销毁 未命名的命名空间不能跨越文件 未命名的命名空间中定义的名字的作用域与该命名空间所在的作用域相同 如果未命名的命名空间定义在文件的最外层作用域中，则该命名空间中的名字一定要与全局作用域中的名字有所区别 未命名的命名空间可以嵌套在其他命名空间中，使用外层命名空间的名字来访问 可使用未命名的命名空间代替文件中的静态声明 12345678910111213141516namespace cplusplus_pimer&#123; class Sales_data&#123;//...&#125;; Sales_data operator+(const Sales_data&amp;,const Sales_data&amp;); class Query(//...); class Query_base&#123;//..&#125;&#125;// 声明模板特例化namespace std&#123; template&lt;&gt; struct hash&lt;Sales_data&gt;&#125;// 在std中添加了模板特例化声明后，就可以在命名空间的外部定义template&lt;&gt; struct std::hash&lt;Sales_data&gt;&#123;&#125; 18.2.2 使用命名空间成员 命名空间的别名以关键字nameapace开始，后接别名，=，命名空间原来的名字和分号 using声明 有效范围从using声明的地方开始，一直到using声明所在的作用域结束为止 头文件与using声明 头文件如果在其顶层作用域中含有using指示或using声明，则会将名字注入到所有包含了该头文件的文件中 18.2.3 类，命名空间与作用域 对命名空间内部名字的查找遵循常规的查找规则：即由内向外依次查找每个外层作用域。外层作用域也可能是一个或多个嵌套的命名空间，直到最外层的全局命名空间查找过程终止 查找与std::move和std::forward 通常情况下，如果在应用程序中定义了一个标准库中已有的名字，则将出现以下两种情况中的一种：要么根据一般的重载规则确定某次调用应该执行函数的哪个版本；要么应用程序根本就不会执行函数的标准库版本 在函数模板中，右值引用形参可以匹配任何类型。如果应用程序也定义了一个接受单一形参的move函数，则不管该形参是什么类型，应用程序的move函数都将与标准库的版本冲突。forward函数也是如此 友元声明与实参相关的查找 当类声明了一个友元时，该友元声明并没有使得友元本身可见。然而，一个另外的未声明的类或函数如果第一次出现在友元声明中，则认为它是最近的外层命名空间的成员 12345678910111213namespace A&#123; class C&#123; friend void f2(); //除非另有声明，否则不会被找到 friend void f(const C&amp;); //根据实参相关的查找规则可被找到 &#125;&#125;int main()&#123; A::C cobj; f(cobj); //通过再A::C中的友元声明找到 f2(cobj); //错误，未声明&#125;// 因为f接受一个类类型的实参，而且f在C所属的命名空间进行了隐式的声明，所以f能被找到。相反，因为f2没有形参，所以它无法被找到 18.2.4 重载与命名空间 与实参相关的查找与重载 对于接受类类型实参的函数来说，其名字查找将在实参类所属的命名空间中进行 这条规则对于如何确定候选函数集同样也有影响：将在每个实参类（以及实参类的基类）所属的命名空间中搜寻候选函数；在这些命名空间中所有与被调用函数同名的函数都将被添加到候选集当中，即使其中某些函数在调用语句处不可见也是如此 重载与using声明 using声明语句声明的是一个名字，而非一个特定的函数 一个using声明囊括了重载函数的所有版本以确保不违反命名空间的接口。库的作者为某项任务提供了好几个不同的函数，允许用户选择性地忽略重载函数中的一部分但不是全部有可能导致意想不到的程序行为 一个using声明引入的函数将重载该声明语句所属作用域中已有的其他同名函数 如果using声明出现在局部作用域中，则引入的名字将隐藏外层作用域的相关声明 如果using声明所在的作用域中已经有一个函数与新引入的函数同名且形参列表相同，则该using声明将引发错误 除此之外，using声明将为引入的名字添加额外的重载实例，并最终扩充候选函数集的规模 重载与using指示 using指示将命名空间的成员提升到外层作用域中，如果命名空间的某个函数与该命名空间所属作用域的函数同名，则命名空间的函数将被添加到重载集合中 跨越多个using指示的重载 如果存在多个using指示，则来自每个命名空间的名字都会成为候选函数集的一部分 18.3 多重继承与虚继承 多重继承：从多个直接基类中产生派生类的能力 继承了所有父类的属性 18.3.1 多重继承 在派生类的派生列表中可以包含多个基类 每个基类包含一个可选的说明符，若忽略，则class为private，struct为public 多继承的派生列表只能包含已经被定义过的类，而且类不能是final的 在某个给定的派生列表中，同一个基类只能出现一次 多重继承的派生类从每个基类中继承状态 派生类构造函数初始化所有基类 构造一个派生类对象将同时构造并初始化它的所有基类子对象 多重继承的派生类的构造函数初始值只能初始化它的直接基类 继承的构造函数与多重继承 允许派生类从一个或几个基类中继承构造函数，但从不能从多个基类继承相同的构造函数，需为这个类自定义构造函数 多重继承的派生类的拷贝与移动操作 多重继承的派生类如果定义了自己的拷贝/赋值构造函数和赋值运算符，则必须在完整的对象上执行拷贝、移动或赋值操作 只有当派生类使用的是合成版本的拷贝、移动或赋值成员时，才会自动对其基类部分执行这些操作 在合成的拷贝控制成员中，每个基类分别使用自己的对应成员隐式地完成构造、赋值或销毁等工作 123class Bear: public ZooAnimal&#123; lass Panda:public Bear, public Endangered&#123;//....&#125;;&#125; 18.3.2 类型转换与多个基类 可以使用可访问基类的指针或引用直接指向派生类的对象 基于指针类型或引用类型的查找 对象，指针和引用的静态类型决定了能使用哪些成员 18.3.3 多重继承下的类作用域 当一个类拥有多个基类时，有可能出现派生类从两个或更多基类中继承了同名成员的情况。此时，不加前缀限定符直接使用该名字将引发二义 18.3.4 虚继承 实际上派生类可以多次继承同一类，派生类可以通过它的两个直接基类分别继承同一个简介积累，也可以直接继承某个基类，然后通过某一个基类再一次间接继承该类 在默认情况下，派生类中含有继承链上每个类对应的子部分 如果某个类在派生过程中出现了多次，则派生类中将包含该类的多个子对象 虚继承机制：令某个类做出声明，承诺愿意共享它的基类，其中共享的基类子对象称为虚基类 无论虚基类在继承体系中出现多少次，在派生类中都只含有唯一一个共享的虚基类 虚派生只影响从指定了虚基类的派生类中进一步派生出的类，不影响派生类本身 使用虚基类 指定虚基类的方式是在派生列表中添加virtual virtual说明符表示在后续的派生类当中共享虚基类的同一份实例 虚基类成员的可见性 在每个共享的虚基类中只有唯一一个共享的子对象，所以该基类的成员可以被直接访问 123456789// 关键字public和virtual的顺序随意class Raccon : public virtual ZooAnimalclass Bear : virtual public ZooAnimal// 某个类指定了虚基类，该类的派生按常规方式进行class Panda:public Bear,public Raccoon,public Endangered&#123; //...&#125;// Panda通过Raccoon和Bear继承了ZooAnimal，因为Raccoon和Bear继承ZooAnimal的方式都是虚继承，所以在Panda中只有一个ZooAnimal基类部分 18.3.5 构造函数与虚继承 在虚派生中，虚基类是最低层的派生类初始化的 虚继承的对象的构造方式 含有虚基类的对象的构造顺序与一般的顺序稍有区别：首先使用提供给最低层派生类构造函数的初始值初始化该对象的虚基类子部分，接下来按照直接基类在派生列表中出现的次序依次对其进行初始化 虚基类总是先于非虚基类的构造 构造函数与析构函数的次序 一个类可以由多个虚基类，虚的子对象按照在派生列表中出现的顺序从左向右一次构造 19 特殊工具与技术 19.1 控制内存分配 重载new运算符和delete运算符控制内存分配的过程 19.1.1 重载new和delete 使用new表达式的实际操作 new盗用了operator new的标准库函数，分配一块足够大的原始的未命名的内存空间一遍存储特定类型的对象 编译器运行相应的构造函数构造这些对象，并传入初始值 对象被分配了空间并构造完成，返回一个指向该对象的指针 使用delete的实际操作 对指向的对象或数组执行对象的析构函数 编译器调用operator delete的标准库函数释放内存空间 当自定义了全局的operator new函数和operator delete函数后，我们就担负起了控制动态内存分配的职责。这两个函数必须是正确的：因为它们是程序整个处理过程中至关重要的一部分 operator new接口和operator delete接口 可自定义上面函数版本的任意一个，前提是自定义的版本必须位于全局作用域或类作用域中 使用上面的运算符函数定义成类的成员时时隐式静态的，无需显示声明为static 因为operator new用在对象构造之前而operator delete用在对象销毁之后，所以这两个成员(new和delete)必须是静态的，而且它们不能操纵类的任何数据成员 想要自定义operator new函数，则可以为它定义额外的形参 此时用到这些自定义函数的new表达式必须使用new的定位形式将实参传给新增的形参 malloc和free函数 C++从C中继承了这些函数，并将其定义在cstdlib头文件中 malloc函数接受一个表示待分配字节数的size_t,返回指向分配空间的指针或者返回0以表示分配失败 free函数接受一个void*，是malloc返回的指针的副本，free将相关内存返回给系统 1234567891011121314151617181920212223242526// 标准库中的重载版本// 可能会抛出异常void *operator new(size_t); //分配一个对象void *operator new[](size_t); //分配一个数组void *operator delete(void*) noexcept; //释放一个对象void *operator delete[](void*) noexcept; //释放一个数组// 承诺不会抛出异常void *operator new(size_t,nothrow_t&amp;) noexcept; //分配一个对象void *operator new[](size_t,nothrow_t&amp;) noexcept; //分配一个数组void *operator delete(void*, nothrow_t&amp;) noexcept; //释放一个对象void *operator delete[](void*, nothrow_t&amp;) noexcept; //释放一个数组void *operator new(size_t, void*); //不允许重新定义这个版本// 该版本只供标准库使用，不能被用户重新定义// 定义operator new和operator delete的简单方式void *operator new(size_t size)&#123; if(void *mem = malloc(size)) return mem; else throw bad_alloc();&#125;void operator delete(void *mem) noexcept&#123; free(mem);&#125; 19.1.2 定位new表达式 与allocator不同的是，对于operator new分配的内存空间来说无法使用construct函数构造对象 应该使用new的定位new形式构造对象，为分配函数提供了额外的信息 定位new允许在一个特定的，预先分配的内存地址上构造对象 定位new与allocator的construct成员相似，但一个重要区别 传给construct的指针必须指向同一个allocator对象分配的空间，但是传给定位new的指针无需指向operator new分配的内存 显式的析构函数调用 定位new与使用allocate类似一样，对析构函数的显式调用也与使用destroy类似 既可以通过对象调用析构函数，也可以通过对象的指针或引用调用析构函数 和调用destroy类似，调用析构函数可以清除给定的对象但是不会释放该对象所在的空间 需要的话可以重新使用该空间 调用析构函数会销毁对象，但是不会释放内存 12345678910// 定位new的形式new (place_address) typenew (place_address) type (initializers)new (place_address) type [size]new (place_address) type [size] &#123; braced initializer list&#125;// place_address必须是一个指针，同时在initializers中提供一个以逗号分割的初始值列表，该初始值列表用于构造新分配的对象string *sp = new string(&quot;a value&quot;);sp-&gt;~string(); 19.2 运行时类型识别 运行时类型识别的功能由两个运算符实现 typeid运算符用于返回表达式的类型 dynamic_cast运算符用于将基类的指针或引用安全地转换成派生类的指针或引用 将两个运算符用于某种类型的指针或引用，并且该类型含有虚函数是，运算符将使用指针或引用所绑定对象的动态类型 两个运算符特别适用的情况 想使用基类对象的指针或引用执行某个派生类操作并且该操作不是虚函数 一般来说，只要有可能应该尽量使用虚函数 当操作被定义成虚函数时，编译器将根据对象的动态类型自动地选择正确的函数版本 假设我们使用虚函数，则可以使用一个RTTI运算符 另一方面，与虚成员函数相比，使用RTTI运算符蕴含着更多潜在的风险：程序员必须清楚地知道转换的目标类型并且必须检查类型转换是否被成功执行 19.2.1 dynamic_cast运算符 12345678910111213141516// dynamic_cast运算符的使用形式dynamic_cast&lt;type*&gt;(e)dynamic_cast&lt;type&amp;&gt;(e)dynamic_cast&lt;type&amp;&amp;&gt;(e)// 其中，type必须是一个类类型，并且通常情况下该类型应该含有虚函数// e的类型必须符合以下三个条件中的任意一个：// e的类型是目标type的公有派生类、e的类型是目标type的公有基类或者e的类型就是目标type的类型// 如果符合，则类型转换可以成功。否则，转换失败// 假定Base类至少含有一个虚函数，Derived是Base的公有派生类// 如果有一个指向Base的指针bp，则可以在运行时将它转换成指向Derived的指针if(Derived *dp = dynamic_cast&lt;Derived*&gt;(bp))&#123; //使用dp指向的Derived对象&#125;else&#123; //bp指向一个Base对象 //使用bp指向的Base对象&#125; 19.2.2 typeid运算符 typeid表达式的形式是typeid(e)，其中e可以是任意表达式或类型的名字 typeid操作的结果是一个常量对象的引用，该对象的类型是标准库类型type_info或者type_info的公有派生类型 定义在typeinfo头文件 可以作用于任意类型的表达式，顶层const被忽略 当typeid作用于引用返回该引用所引对象的类型 当typeid作用于数组或函数时，并不会执行向指针的标准类型转换 当运算对象不属于类类型或者是一个不包含任何虚函数的类时，typeid运算符指示的是运算对象的静态类型 当typeid作用于指针时(而非指针所指的对象)，返回的结果是该指针的静态编译时类型 typeid是否需要运行时检查决定了表达式是否会被求值 只有当类型含有虚函数时，编译器才会对表达式求值。反之，如果类型不含有虚函数，则typeid返回表达式的静态类型;编译器无须对表达式求值也能知道表达式的静态类型 如果表达式的动态类型可能与静态类型不同，则必须在运行时对表达式求值以确定返回的类型 这条规则适用于typeid(*p)的情况。如果指针p所指的类型不含有虚函数，则p不必非得是一个有效的指针。否则，*p将在运行时求值，此时p必须是一个有效的指针 如果p是一个空指针，则typeid(*p)将抛出一个名为bad_typeid的异常 12345678910Derived *dp = new Derived;Base *bp = dp; //两个指针都指向Derived对象if(typeid(*bp)==typeid(*dp))&#123; //bp和dp指向同一类型的对象&#125;// 检查运行时类型是否是某种指定的类型if(typeid(*bp) == typeid(Derived))&#123; //bp实际指向Derived对象&#125; 19.2.3 使用RTTI 在某些情况下RTTI非常有用 比如想为具有继承关系的类实现相等运算符时，对于两个对象来说，如果它们的类型相同并且对应的数据成员取值相同，则说这两个对象是相等的 在类的继承体系中，每个派生类负责添加自己的数据成员，因此派生类的相等运算符必须把派生类的新成员考虑进来 定义比较操作 如果参与比较的两个对象类型不同，则比较结果为false 例如，如果试图比较一个基类对象和一个派生类对象，则==运算符应该返回false 基于上述推论，可以使用RTTI解决问题了 定义的相等运算符的形参是基类的引用，然后使用typeid检查两个运算对象的类型是否一致 如果运算对象的类型不一致，则==返回false；类型一致才调用equal函数。每个类定义的equal函数负责比较类型自己的成员。这些运算符接受Base&amp;形参，但是在进行比较操作前先把运算对象转换成运算符所属的类类型 123456789101112131415161718192021222324252627282930313233343536// 定义两个示例类class Base&#123; friend bool operator==(const Base&amp;, const Base&amp;); public: //Base的接口成员 protected: virtual bool equal(const Base&amp;) const; //Base的数据成员和其他用于实现的成员&#125;;class Derived: public Base&#123; public: //Derived的其他接口成员 protected: bool equal(const Base&amp;) const; // Derived的数据成员和其他用于实现的成员&#125;;// 定义整体相等运算符bool operator==(const Base &amp;lhs, const Base &amp;rhs)&#123; //如果typeid不相同,返回false;否则虚调用equal return typeid(lhs) == typeid(rhs) &amp;&amp; lhs.equal(rhs);&#125;// 虚equal函数// 继承体系中的每个类必须定义自己的equal函数// 派生类的所有函数要做的第一件事都是相同的，那就是将实参的类型转换为派生类类型bool Derived::equal(const Base &amp;rhs) const&#123; //清除这两个类型是相等的，所以转换过程不会抛出异常 auto r = dynamic_cast&lt;const Derivd&amp;&gt;(rhs); // 执行比较两个Derived对象的操作并返回结果&#125;// 基类equal函数bool Base::equal(const Base &amp;rhs) const&#123; //执行比较Base对象的操作&#125; 19.2.4 type_info类 type_info的操作 - t1 == t2 如果type_info对象t1和t2表示同一种类型，返回true t1 != t2 如果type_info对象t1和t2表示不同类型，返回true t.name() 返回C风格字符串，表示类型名字的可打印形式。类似名字的生成方式因系统而异 t1.before(t2) 返回一个bool值，表示t1是否位于t2之前。before所采用的顺序关系是依赖于编译器 19.3 枚举类型 枚举类型将一组整型常量组织在一起 和类一样，每个枚举类型定义了一种新的类型，枚举属于字面值常量类型 限定作用域的枚举类型：首先是关键字enum class随后是枚举类型名字以及花括号括起来的以逗号分割的枚举成员，最后是一个分号 不限定作用域的枚举类型：省略class 枚举成员 在限定作用域的枚举类型中，枚举成员的名字遵循常规的作用域准则，并且在枚举类型的作用域外是不可访问的 在不限定作用域的枚举类型中，枚举成员的作用域与枚举类型本身的作用域相同 默认情况下，枚举值从0开始，依次加1 初始化enum对象或者为enum对象赋值，必须使用该类型的一个枚举成员或者该类型的另一个对象 一个不限定作用域的枚举类型的对象或枚举成员自动地转换成整型 指定enum的大小 实际上enum是由某种整数类型表示的 在enum后面加上冒号以及想要在enum中使用的类型 枚举类型的前置声明 可以提前声明enum，enum的前置声明必须指定其成员的大小 形参匹配与枚举类型 要想初始化一个enum对象，必须使用该enum类型的另一个对象或者它的一个枚举成员 即使某个整型值恰好与枚举成员的值相等也不能作为函数的enum实参使用 尽管不能直接将整型值传给enum形参，但是可以将一个不限定作用域的枚举类型的对象或枚举成员传给整型形参 1234567891011121314151617181920212223242526272829// 定义限定作用域的枚举类型enum class open_modes &#123;input, output, append&#125;;// 定义不限定作用域的枚举类型enum color &#123;red, yellow, green&#125;;enum class intTypes&#123; charTyp = 8,shortTyp = 16, intTyp = 16, longTyp = 32, long_longTyp = 64&#125;;constexpr intTypes charbits = intTypes::charTyp;// 初始化enum对象或者为enum对象赋值，必须使用该类型的一个枚举成员或者该类型的另一个对象om = open_mode::input; //input是open_modes的一个枚举成员// 不限定作用域的枚举类型intValues的前置声明enum intValues : unsigned long long; //不限定作用于的必须指定成员类型enum class open_modes; //限定作用域的枚举类型可以使用默认成员类型int// 不限定作用域的枚举类型，潜在类型因机器而已enum Tokens &#123;INLINE = 18,VIRTUAL = 129&#125;;void ff(Tokens);void ff(int);int main()&#123; Tokens curTok = INLINE; ff(128); ff(INLINE); ff(curTok); return 0;&#125; 19.4 类成员指针 成员指针是指可以指向类的非静态成员的指针 一般情况下，指针指向一个对象，但是成员指针指示的是类的成员，而非类的对象 类的静态成员不属于任何对象，因此无须特殊的指向静态成员的指针，指向静态成员的指针与普通指针没有什么区别 初始化这样的指针时，令其指向类的某个成员，但是不指定该对象所属的对象，直到使用成员指针时，才提供成员所属的对象 123456789101112// Screen类class Screen&#123; public: typedef std::string::size_type pos; char get_curosor() const &#123; return contents[cursor];&#125; char get() const; char get(pos ht, pos wd) const; private: std::string contents; pos cursor; pos height, width;&#125; 19.4.1 数据成员函数 和其他指针一样，在声明成员指针时可以使用*来表示当前声明对象的名字是一个指针，成员指针必须包含成员所属的类 在*之前添加classname::以表示当前定义的指针可以指向classname的成员 初始化一个成员指针时，需要指定所指向的成员 新标准中声明成员指针简答的方法是使用auto或decltype 使用数据成员指针 当初始化一个成员指针或为成员指针赋值时，该指针并没有指向任何数据 成员指针指定了成员而非该成员所属的对象，只有当解引用成员指针时我们才提供对象的信息 与成员访问运算符.和-&gt;类似，也有两种成员指针访问运算符：.*和-&gt;*，这两个运算符使得我们可以解引用指针并获得该对象的成员 返回数据成员指针的函数 常规的访问控制规则对成员指针同样有效 因为数据成员一般情况下是私有的，所以通常不直接获得数据成员的指针 123456789const string Screen::*pdata;pdata = &amp;Screen::contents;auto pdata = &amp;Screen::contents;Screen myScreen, *pScreen = &amp;myScreen;auto s = myScreen.*pdata;s = pScreen-&gt;*pdata; 19.4.2 成员函数指针 和指向数据成员的指针一样，使用classname::*的形式声明一个指向成员函数的指针 类似于任何其他函数指针，指向成员函数的指针也需要指定目标函数的返回类型和形参列表 如果成员函数是const成员或者引用成员，则必须将const限定符或引用限定符包含进来 和普通函数指针不同的是，在成员函数和指向该成员的指针之间不存在自动转换规则 使用成员函数指针 和使用指向数据成员的指针一样，使用. *或者-&gt;*运算符作用于指向成员函数的指针，以调用类的成员函数 使用成员指针的别名 使用类型别名或typedef可以让成员指针更容易理解 和其他函数指针类似，可以将指向成员函数的指针作为某个函数的返回类型或形参类型 其中，指向成员的指针形参也可以拥有默认实参 成员指针函数表 对于普通函数指针和指向成员函数的指针来说，一种常见的用法是将其存入一个函数表当中。如果一个类含有几个相同类型的成员，则这样一张表可以帮助我们从这些成员中选择一个 19.4.3 将成员函数用作可调用对象 要想通过一个指向成员函数的指针进行函数调用，必须首先利用.*运算符或-&gt;*运算符将该指针绑定到特定的对象上 因此与普通的函数指针不同，成员指针不是一个可调用对象，这样的指针不支持函数调用运算符 因为成员指针不是可调用对象，所以不能直接将一个指向成员函数的指针传递给算法 使用function生成一个可调用对象 从指向成员函数的指针获取可调用对象的一种方法是使用标准库模板function 使用function必须提供成员的调用形式 使用mem_fn可以让编译器负责推断成员的类型，可以从成员指针生成一个可调用对象 mem_fn可根据成员指针的类型推断出可调用对象的类型，而无需用户显式地指定 使用bind生成一个可调用对象 出于完整性的考虑使用bind从成员函数生成一个可调用对象 和function类似的地方是，当使用bind时，必须将函数中用于表示执行对象的隐式形参转换成显式的 和mem_fn类似的地方是，bind生成的可调用对象的第一个实参既可以是string的指针，也可以是string的引用 19.5 嵌套类 一个类定义在另一个类的内部，前者称为嵌套类或嵌套类型 嵌套类常用于定义作为实现部分的类 嵌套类是一个独立的类，与外层类基本没什么关系 特别是，外层类的对象和嵌套类的对象是相互独立的 在嵌套类的对象中不包含任何外层类定义的成员 类似的，在外层类的对象中也不包含任何嵌套类定义的成员 嵌套类中成员的种类与非嵌套类是一样的 和其他类类似，嵌套类也使用访问限定符来控制外界对其成员的访问权限 外层类对嵌套类的成员没有特殊的访问权限，同样，嵌套类对外层类的成员也没有特殊的访问权限 嵌套类在其外层类中定义了一个类型成员 和其他成员类似，该类型的访问权限由外层类决定 位于外层类public部分的嵌套类实际上定义了一种可以随处访问的类型 位于外层类protected部分的嵌套类定义的类型只能被外层类及其友元和派生类访问 位于外层类private部分的嵌套类定义的类型只能被外层类的成员和友元访问 在外层类之外定义一个嵌套类 在嵌套类在其外层类之外完成真正的定义之前，它都是一个不完全类型 定义嵌套类的成员 为其定义构造函数，必须指明QueryResult是嵌套在TextQuery的作用域之内的 具体的做法是使用外层类的名字限定嵌套类的名字 嵌套类作用域中的名字查找规则 名字查找的一般规则在嵌套类中同样适用 嵌套类本身是一个嵌套作用域，所以还必须查找嵌套类的外层作用域 可以说明为什么我们不在QueryResult的嵌套版本中定义line_no 原来的QueryResult类定义了该成员，从而使其成员可以避免使用TextQuery：：line_no的形式。然而QueryResult的嵌套类版本本身就是定义在TextQuery中的，所以我们不需要再使用typedef。嵌套的QueryResult无须说明line_no属于TextQuery就可以直接使用它 嵌套类是其外层类的一个类型成员，外层类的成员可以像使用任何其他类型成员一样使用嵌套类的名字 嵌套类和外层类型是相互独立的 尽管嵌套类定义在其外层类的作用域中，但是外层类的对象和嵌套类的对象没有任何关系 嵌套类的对象只包含嵌套类定义的成员；同样，外层类的对象只包含外层类定义的成员，在外层类对象中不会有任何嵌套类的成员 123456789101112131415161718192021// 声明嵌套类class TextQuery&#123; public: class QueryResult; //嵌套类稍后定义&#125;;// 在外层类之外定义一个嵌套类// QueryResult的定义class TextQuery::QueryResult&#123; // 在类的作用域内，不必对QueryResult形参进行限定 friend std::ostream&amp; print(std::ostream&amp;, const QueryResult&amp;); public: QueryResult(std::string,std::shared_ptr&lt;std::set&lt;line_no&gt;&gt;,std::shared_ptr&lt;std::vector&lt;std::string&gt;&gt;)；&#125;;TextQuery::QueryResult::QueryResult(string s,shhared_ptr&lt;set&lt;line_no&gt;&gt; p, shared_ptr&lt;vector&lt;string&gt;&gt; f): sought(s),lines(p),file(f)&#123;&#125;// 嵌套类的静态成员定义int textQuery::QueryResult::static_mem = 1024; 19.6 union:一种节省空间的类 联合是一种特殊的类，可以有多个数据成员，但在任意时刻只有一个数据成员可以有值 当给union的某个成员赋值之后，该union的其他成员就变成未定义的状态了 分配给一个union对象的存储空间至少要能容纳它的最大的数据成员 union不能含有引用类型的成员，可以为成员指定public,protect和private等保护标记 默认情况下，union的成员都是共有的 union不能继承自其他类，也不能作为基类使用，不能含有虚函数 匿名union是一个未命名的union，并且在右花括号和分号之间没有任何声明 在匿名union的定义所在的作用域内该union的成员都是可以直接访问的 含有类类型成员的union 当union包含的是内置类型的成员时，可以使用普通的赋值语句改变union保存的值 但是对于含有特殊类类型成员的union就没这么简单了。如果我们想将union的值改为类类型成员对应的值，或者将类类型成员的值改为一个其他值，则必须分别构造或析构该类类型的成员：当将union的值改为类类型成员对应的值时，必须运行该类型的构造函数；反之，当将类类型成员的值改为一个其他值时，必须运行该类型的析构函数 当union包含的是内置类型的成员时，编译器将按照成员的次序依次合成默认构造函数或拷贝控制成员 但是如果union含有类类型的成员，并且该类型自定义了默认构造函数或拷贝控制成员，则编译器将为union合成对应的版本并将其声明为删除的 使用类管理union成员 把含有类类型成员的union内嵌在另一个类中，可以管理并控制与union的类类型成员有关的状态转换 为了追踪union中存储什么类型的值，通常会定义一个union的判别式(独立的对象) 可以使用判别式辨别union存储的值 1234567891011121314// 定义unionunion Token&#123; char cval; int ival; double dval;&#125;;// 使用union类型Token first_token = &#123;&#x27;a&#x27;&#125;; //初始化Token last_token;Token *pt = new Token; //指向一个未初始化的Token对象的指针last_token.cval = &#x27;z&#x27;;pt-&gt;ival = 42; 19.7 局部类 局部类：类可以定义在某个函数的内部 定义只在作用域内可见，成员受到严格的限制 局部类中不允许声明静态数据成员 局部类不能使用函数作用域中的变量 局部类对其外层作用域中的名字的访问权限受到很多限制：局部类只能访问外层作用域定义的类型名,静态变量,枚举成员 如果局部类定义在某个函数内部，该函数的普通局部变量不能被局部类使用 常规的访问保护规则对局部类同样适用 外层函数对局部类的私有成员没有任何访问特权 当然，局部类可以将外层函数声明为友元；或者更常见的情况是局部类将其成员声明成公有的 在程序中有权访问局部类的代码非常有限。局部类已经封装在函数作用域中，通过信息隐藏进一步封装就显得没什么必要了 外层函数对局部类的私有成员没有任何访问特权。当然，局部类可以将外层函数声明为友元；或者更常见的情况是局部类将其成员声明成公有的。在程序中有权访问局部类的代码非常有限。局部类已经封装在函数作用域中，通过信息隐藏进一步封装就显得没什么必要了 局部类中的名字查找 局部类内部的名字查找次序与其他类相似 在声明类的成员时，必须先确保用到的名字位于作用域中，然后再使用该名字 定义成员时用到的名字可以出现在类的任意位置 如果某个名字不是局部类的成员，则继续在外层函数作用域中查找；如果还没有找到，则在外层函数所在的作用域中查找 嵌套的局部类 可以在局部类的内部再嵌套一个类 此时，嵌套类的定义可以出现在局部类之外。不过，嵌套类必须定义在与局部类相同的作用域中 19.8 固有的不可移植的特性 19.8.1 位域 类可以将其（非静态）数据成员定义成位域，在一个位域中含有一定数量的二进制位 当一个程序需要向其他程序或硬件设备传递二进制数据时，通常会用到位域 19.8.2 volatile限定符 直接处理硬件的程序常常包含这样的数据元素，它们的值由程序直接控制之外的过程控制 当对象的值可能在程序的控制或检测之外被改变时，应该将该对象声明为volatile 关键字volatile告诉编译器不应对这样的对象进行优化 19.8.3 链接指示:extern “C” 使用链接指示指出任意非C++函数所用的语言","categories":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/tags/C/"}]},{"title":"计算机网络","slug":"计算机基础知识/计算机网络","date":"2022-03-20T09:25:58.000Z","updated":"2023-04-09T13:39:29.972Z","comments":true,"path":"2022/03/20/计算机基础知识/计算机网络/","link":"","permalink":"http://jay1060950003.github.io/2022/03/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"引言 《计算机网络|自顶向下方法|第七版》学习笔记","text":"引言 《计算机网络|自顶向下方法|第七版》学习笔记 1. 计算机网络和因特网 1.1 什么是因特网 1.1.1 具体构成描述 节点: 主机及其上运行的应用程序 路由器,交换机等网络交换设备 边:通信链路 接入网链路:主机连接到互联网的链路 主干链路:路由器间的链路 主机或端系统 端系统通过通信链路和分组交换机连接到一起 不同的链路能够以不同的速率传输数据,链路的传输速率以**比特/秒(bit/s,bps)**度量 分组:当一台端系统要向另一台端系统发送数据时,发送端系统将数据分段,并为每段加上首部字节 分组交换机:转发分组 分组交换机包括:路由器和链路层交换机 链路层交换机通常用于接入网中,而路由器通常用于网络核心中 端系统,分组交换机和其他因特网部件需要运行一系列协议 TCP/IP为因特网的主要协议 Internet标准 RFC:IETF的标准文档 IETF:因特网工程任务组 1.1.2 服务描述 分布式应用程序:应用程序涉及多个相互交换数据的端系统 因特网应用程序运行在端系统上,即它们并不运行在网络核心中的分组交换机中 尽管分组交换机能够加速端系统之间的数据交换,但它们并不在意作为数据的源或宿的应用 与因特网相连的端系统提供了一个套接字接口,该接口规定了运行在一个端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交付数据的方式 1.1.3 什么是协议 协议定义了在两个或多个通信实体之间交换的报文格式和次序,以及在报文传输和/或接收或其他事件方面所采取的动作 1.2 网络边缘 通常把与因特网相连的计算机和其他设备称为端系统 位于网络的边缘,故称为端系统 划分为:客户和服务器两大类 接入网:是指将端系统屋里连接到其边缘路由器的网络 边缘路由器:是指端系统到任何其他远程端系统的路径上的第一台路由器 采用网络设施的面向连接服务:TCP——传输控制协议 采用基础设施的无连接服务:UDP——用户数据报协议 1.3 网络核心 1.3.1 分组交换 在各种网络应用中,端系统彼此交换报文 为了系统向目的端系统发送一个报文,源将长报文划分为较小的数据块,称之为分组 在源和目的地之间,每个分组都通过通信链路和分组交换机(路由器或链路层交换机)传送 分组以等于该链路最大传输速率的速度传输通过通信链路 1 存储转发传输 多数分组交换机在链路的输入端使用存储转发传输机制 存储转发传输是指在交换机能够开始向输出链路传输该分组的第一个比特之前,必须接受到整个分组 通过由N条速率均为R的链路组成的路径,从源到目的地发送一个分组,端到端时延为d端到端=NLRd_{端到端} = N \\frac{L}{R}d端到端​=NRL​ 2 排队时延和分组丢失 对于每条相连的链路,该分组交换机具有一个输出缓存(输出队列),用于存储路由器准备发往那条链路的分组,除了存储转发时延之外,分组还需要承受输出缓存的排队时延 缓存空间的大小有限,一个到达分组可能发现该缓存已被完全充满,此情况下会出现丢包,到达的分组或已经排队的分组之一会被丢弃 3 转发表和路由选择协议 路由器从相连的一条通信链路得到分组,然后向相连的另一条通信链路转发该分组 在因特网中,每个端系统都具有IP地址,当源主机向目的端系统发送分组时,源在该分组的首部包含了目的地的IP地址.当一个分组到达网络中的路由器时,路由器会检查该分组的目的地址的一部分,并向一台相邻的路由器转发该分组.每台路由器都有一个转发表,用于将目的地址映射成输出链路.当某分组到达一台路由器时,路由器会检查该地址,并用这个目的地址搜索其转发表,以发现适当的出链路,路由器将分组导向该出链路 1.3.2 电路交换 通过网络链路和交换机移动数据有两种基本方法:电路交换和分组交换 在电路交换网络中,在端系统间通信会话期间,预留了端系统沿路径通信所需要的资源,在分组交换网络中,这些资源不需要预留 端到端连接:网络在两台主机之间创建的一条专用连接 电路交换网络中的复用:链路中的电路时通过频分复用或时分复用来实现的 1.3.3 网络的网络 网络结构1,用单一的全球传输ISP互联所有接入ISP 网络结构2,由数十万接入ISP和多个全球传输ISP组成 是一种两层的等级结构,其中全球传输供应商位于顶层,而接入ISP位于底层 网络结构3,多等级结构 在等级化网络结构3上增加存在点(PoP),多宿,对等和因特网交换点就与今天的因特网相似 PoP存在于等级结构的所有层次,但底层等级除外,一个PoP只是提供商网络中的一台或多台路由器群组 任何ISP(除了第一层)可以选择多宿,即可以与两个或更多提供商ISP连接 位于相同等级结构层次的邻近一对ISP能都对等,能直接将网络连在一起,使它们之间的所有流量经直接连接而不是通过上游的中间ISP传输 沿着相同线路,第三方公司能创建一个因特网交换点(IXP),IXP是一个因特网汇合点,多个ISP在IXP一起对等 网络结构4:由接入ISP,区域ISP,第一层ISP,PoP,多宿,对等和IXP组成 网络结构5:在网络结构4顶部增加内容提供商网络 1.4 分组交换网中的时延,丢包和吞吐量 1.4.1 分组交换网中的时延概念 时延包括:节点处理时延,排队时延,传输时延和传播时延 时延总体累加起来是节点总时延 处理时延 检查分组首部和决定分组导向何处所需要的时间是处理时延的一部分,还包括其他因素 排队时延 在队列中,当分组在链路上等待传输时,经受排队时延 一个特定分组的排队时延却决于先期到达的正在排队等待向链路传输的分组数量 传输时延 假定分组以先到线服务方式传输,用L比特表示该分组的长度,用R bps表示从路由器A到路由器B的链路传输速率,传输时延是L/RL/RL/R 传播时延 从链路的起点到路由器B传播所需要的时间是传播时延,该传播时延等于两台路由器之间的距离除以传播速率d/sd/sd/s 该比特以该链路的传播速率传播.传播速率取决于链路的物体媒体 传输时延和传播时延的比较 传输时延是路由器推出该分组所需要的时间,是分组长度和链路传播速率的函数,与两路由器之间的距离无关 传播时延是一个比特从一台路由器传播到另一台路由器所需要的时间,是两台路由器之间距离函数,与分组长足或链路传输速率无关 处理时延通常是微不足道的,但对路由器的最大吞吐量有影响,最大吞吐量是一台路由器能够转发分组的最大速率 1.4.2 排队时延和丢包 令a表示分组到达队列的平均速率,R为传输速率,假定所有分组都是L比特组成的,则比特到达队列的平均速率为LabpsLa bpsLabps,流量强度为La/RLa/RLa/R,若流量强度大于1则比特到达队列的平均速率超过从该队列传输出去的速率 设计系统时流量强度不能大于1 丢包 由于路由器没有地方存储信道的分组,路由器将丢弃该分组 一个节点的性能场不仅根据时延来度量,而且根据丢包的概率来度量 1.4.3 端到端时延 端到端时延 dend−end=N(dproc+dtrans+dprop),dtrans=L/Rd_{end-end} = N(d_{proc}+d_{trans}+d_{prop}), d_{trans}=L/Rdend−end​=N(dproc​+dtrans​+dprop​),dtrans​=L/R 1.4.4 计算机网络中的吞吐量 在任何时间瞬间的瞬时吞吐量是主机接受到文件的速率 若文件由F比特组成,主机接受到所有F比特用去T秒,则文件传输的平均吞吐量为F/TbpsF/T bpsF/Tbps 令服务器的与路由器之间的链路速率为RsR_sRs​,路由器与客户之间的速率为RcR_cRc​,对于简单的两链路网络,其吞吐量是min{Rs,Rc}min\\{R_s,R_c\\}min{Rs​,Rc​},是瓶颈链路的传输速率 1.5 协议层次及其服务模型 1.5.1 分层的体系结构 为了给网络协议的设计提供一个结构,网络设计者以分层的方式组织协议以及实现这些协议的网络硬件和软件 协议分层具有概念化和结构化的优点,分层提供了一种结构化方式来讨论系统组件.模块化使更新系统组件更为容易 分层的缺点是一层可能冗余较低层的功能,某层的功能可能需要可能需要仅在其他某层才出现的信息,违反层次分离的目标 各层的所有协议被称为协议栈,目前由5层组成:物理层,链路层,网络层,运输层和应用层 ISO OSI参考模型为7层:物理层,链路层,网络层,运输层,会话层,表示层和应用层 表示层的作用是使通信的应用程序能够解释交换数据的含义,包括数据压缩,数据加密和数据描述 会话层提供了数据交换的定界和同步功能,包括了建立检查点和恢复方案的方法 应用层 应用层是网络引用程序以及它的应用层协议存留的地方 应用层协议分布在多个端系统上,而一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息分组,把这种位于应用层的信息分组称为报文 运输层 因特网的运输层在应用程序端点之间传送应用层报文 在因特网中,有两种运输层协议,即TCP和UDP TCP向它的应用程序提供了面向连接的服务,包括了应用层报文向目的地的确保传递和流量控制,并提供拥塞控制机制 UDP协议向它的应用程序提供无连接服务,不提供不必要服务的服务,没有可靠性,没有流量控制,也没有拥塞控制 运输层的分组称为报文段 网络层 网络层负责将称为数据报的网络层分组从一台主机移动到另一台主机 在一台源主机中的因特网运输层协议向网络层递交运输层报文段和目的地址 网络层包括IP协议,定义了在数据报中各个字段以及端系统和路由器如何作用于这些字段,也包括决定路由的路由选择协议,根据该路由将数据报从源传输给目的地 网络层简单地称为IP层 链路层 因特网的网络层通过源和目的地之间的一系列路由器路由数据报 为了将分组从一个节点移动到路径上的下一个节点,网络层必须依靠该链路层的服务.特别是在每个节点,网络层将数据报下传给链路层,链路层沿着路径将数据报传递给下一个节点,在该下一个节点,链路层将数据包上传至网络层 链路层的分组称为帧 物理层 物理层的任务是将该帧的一个个比特从一个节点移动到下一个节点,在这层中的协议仍然是链路相关的,并且进一步与该链路的实际传输媒体相关 1.5.2 封装 链路层交换机实现了第一层和第二层 路由器实现了第一层到第三层 封装: 在发送主机端,一个应用层报文被传给运输层.在最简单的情况下,运输层收取报文并附上附加信息,该首部将被接收端的运输层使用,应用层报文和传输层首部信息一道构成了运输层报文段,运输层报文段因此封装了应用层报文 运输层向网络层传输该报文段,网络层增加了如源和目的端系统地址等网络层首部信息,生成了网络层数据报 该数据包被传递给链路层,链路层增加了它自己链路层首部信息并生成链路层帧 在每一个层中,一个分组具有两个类型的字段:首都字段和有效载荷字段,有效载荷通常使来自上一层的分组 1.6 面对攻击网络 拒绝服务攻击(DDOs) 弱点攻击 带宽洪泛 连接洪泛 分组嗅探器:记录每个流经的分组副本的被动接收机 IP哄骗:将具有虚假源地址的分组注入因特网的能力 2 应用层 2.1 应用层协议原理 研发的网络应用程序是写出能够运行在不同的端系统和通过网络彼此通信的程序 网络核心设备并不是在应用层上起作用,而仅在较低层起作用,特别是在网络层及下面层次起作用,这种基本设计,即将应用软件限制在端系统的方法,促进了大量的网络应用程序的迅速研发和部署 2.1.1 网络应用程序体系结构 应用程序体系结构由应用程序研发者设计,规定了如何在各种端系统上组织该应用程序.在选择应用程序体系结构时,应用程序研发者利用两种主流结构之一:客户-服务器体系或对等(P2P)体系结构 在客户-服务器体系结构中,有一个总是打开打主机称为服务器,它服务于来自许多其他称为客户的主机的请求 客户相互之间不直接通信 服务器具有固定的,周知的地址称为IP地址 在P2P体系结构中,对位于数据中心的专用服务器有最小的依赖,相反应用程序在间断连接的主机对之间使用直接通信,主机称为对等方 P2P的自扩展性,尽管每个对等方都由于请求文件产生工作负载,但每个对等方通过向其他对等方分发文件也为系统增加服务能力 2.1.2 进程通信 进行通信的实际上是进程 在两个不同端系统的进程,通过跨越计算机网络交换报文而相互通信 发送进程生成并向网络中发送报文 接受进程接受报文并可能通过会送报文进行相应 客户和服务器进程 网络应用程序由成对的进程组成,这些进程通过网络相互发送报文,发起通信的进程被标识为客户,在会话开始时等待联系的进程称为服务器 进程和计算机网络之间的接口 多数应用程序是由通信进程对组成的,每对中的两个进程互相发送报文 进程通过一个称为套接字的软件接口向网络发送报文和从网络接受报文 套接字是同一台主机内应用层与运输层之间的接口,套接字也称为应用程序和网络之间的应用程序编程接口(API) 进程寻址 在因特网中,主机由IP地址标识,目的地端口号指定了接受主机上的接受进程 web服务器用端口号80来标识,邮件服务器进程用端口号25来标识 2.1.3 可供应用程序使用的运输服务 在发送端的应用程序将报文推进该套接字,在套接字的另一侧运输层协议负责从接受进程的套接字得到该报文 一个运输层协议能够为调用它的应用程序提供可靠的数据传输,吞吐量,定时和安全性服务 可靠的数据传输 可靠的数据传输:一个协议提供了确保数据交付服务 运输层协议能够潜在的向应用程序提供的一个重要服务是进程到进程的可靠数据传输.当一个运输协议提供这种服务时,发送进程只要将其数据传递进该套接字,就可以完全相信该数据能无差错的到达接收进程 容忍丢失的应用可以接收运输层协议不提供可靠数据传输时,发送进程发送的某些数据可能到达不了的接收进程 吞吐量 带宽敏感的应用:具有吞吐量要求的应用程序 弹性应用:能够根据当时可用的带宽或多或少地利用使用的吞吐量 定时:运输层协议能提供定时保证 安全性:运输层协议能为应用程序提供一种或多种安全性服务 2.1.4 因特网提供的运输服务 TCP服务 TCP服务模型包括面向连接服务和可靠数据传输服务 面向连接的服务 可靠的数据传输服务 拥塞控制机制 TCP安全性 安全套接字层(SSL)加强后的TCP不仅能做传统TCP的一切,而且能提供关键的进程到进程的安全性服务,包括加密,数据完整性和端点检测 在应用层实现的 当一个应用使用SSL时,发送进程向SSL套接字传输明文数据;在发送主机中的SSL则加密该数据并将加密的数据传递给TCP套接字 UDP服务 不提供不必要服务的轻量级运输协议,仅提供最小服务,无连接的(没有握手过程),没有拥塞控制机制 2.1.5 应用层协议 应用层协议定义了运行在不同端系统上的应用程序进程如何相互传递报文 应用层协议规定了 交换的报文类型 各种报文类型的语法 字段的语义 确定了一个进程何时以及如何发送报文,对报文进行响应的规则 2.2 Web和HTTP 2.2.1 HTTP概况 Web的应用层协议是超文本传输协议(HTTP) HTTP由两个程序实现:一个客户程序和一个服务器程序.客户程序和服务器程序运行在不同的端系统中,通过交换HTTP报文进行会话 HTTP定义了报文的结构以及客户和服务器进行报文交换的方式 HTTP定义了Web客户向Web服务器请求Web页面的方式,以及服务器向客户传送Web页面的方式 HTTP是一个无状态协议 不保存关于客户的任何信息,服务器在接收相同对象第二次请求时,重新发送对象 HTTP使用TCP作为它的支撑运输协议 Web页面由对象组成 多个Web页面含有一个HTML基本文件以及几个引用对象 Web浏览器实现了HTTP的客户端 Web服务器实现了HTTP的服务器端,用于存储Web对象,每个对象由URL寻址 2.2.2 非持续连接和持续连接 非持续连接:每个请求是经一个单独的TCP连接发送 持续连接:所有的请求及其响应经相同的TCP发送 HTTP默认情况下为持续连接 采用非持续连接的HTTP HTTP客户进程在端口号80发起服务器的TCP连接,该端口号是HTTP默认的端口.在客户和服务器上分别有一个套接字与该连接相关联 HTTP客户经它的套接字向该服务器发送一个HTTP请求报文 HTTP服务器进程经它的套接字接收该请求报文,从其存储器检出对象,在一个HTTP响应报文中封装对象,并通过其套接字向客户发送响应报文 HTTP服务器进程通知TCP断开该TCP连接 HTTP客户接收响应报文,TCP连接关闭 对每个引用的对象重复前4个步骤 非持续连接的作用 每个TCP连接在服务器发送一个对象后关闭,即该连接并不为其他的对象而持续下来 每个TCP连接只传输一个请求报文和响应报文 HTML的往返时间(RTT):包括分组传播时延,分组在中间路由器和交换机上的排队时延以及分组处理时延 总的响应时间是两个RTT加上服务器传输HTML文件的时间 非持续连接的缺点 必须为每一个请求的对象建立和维护一个全新的连接 每一个对象经受两倍RTT的交付时延,即一个RTT用于创建TCP,一个RTT用于请求和接收一个对象 采用HTTP1.1持续连接的情况下,在相同的客户与服务器之间,后续的请求和相应报文通过相同的连接进行传送 如果一条连接经过一定时间间隔未被使用,HTTP服务器将关闭连接 2.2.3 HTTP报文格式 HTTP请求报文,报文由ASCII文本书写 请求报文的第一行叫做请求行,后继的行称为首部行 请求行有3个字段:方法字段,URL字段和HTTP版本字段 方法字段包括:GET,POST,HEAD,PUT,DELETE 使用GET方法时实体体为空,而使用POST方法时才使用该实体体 方法字段是POST时,实体体中包含的是用于在表单字段中的输入值 HTML表单经常使用GET方法,并在所请求的URL中包括的输入的数据 HEAD方法类似GET方法,服务器受到HEAD请求时,将会用一个HTTP报文进行相应,但是并不返回请求对象 PUT方法常与WEB发行工具联合使用,允许用户上传对象到指定的WEB服务器上指定的路径 DELETE方法允许用户或应用程序删除WEB服务器上的对象 首部行提供信息是Web代理高速缓存所要求的 Connection:close首部行,该浏览器告诉服务器不要麻烦地使用持续连接,要求服务器在发送完请求后就关闭该连接 User-agent首部行,指明用户代理,即浏览器地类型 Accept-lanuage首部行(协商首部之一):用户想得到该对象的法语版本 HTTP响应报文 有三部分:初始状态行,6个首部行,实体体 状态行有3个字段:协议版本字段,状态码和相应状态信息 首部行 Connection:close首部行,告诉客户发送完报文后将关闭该TCP连接 Data首部行,指示服务器产生并发生该响应报文的日期和时间(服务器从文件系统中检索到该对象,将该对象插入响应报文,并发送该响应报文的时间) server首部行,类似HTTP请求报文中的User-agent首部行 Last-Modified首部行,指示对象创建或最后修改的日期和时间 Content-length首部行,指示被发送对象中的字节数 COntent-Type首部行,指示实体体中的对象是HTML文本 状态码 200 oK,请求成功,信息在返回的响应报文中 301 Moved Permanently,请求的对象已经被永久转移了,新的URL定义在响应报文的Location首部行中 400 Bad Reauest,通用差错代码,指示该请求不能被服务器理解 404 Not Found,被请求的文芳不在服务器上 505 HTTP Version Not Supported,服务器不支持请求报文使用的HTTP协议版本 2.2.4 用户与服务器的交互:cookie cookie在RFC6265中定义,允许站点对用户进行跟踪 有4个组件: 在HTTP响应报文中的一个cookie首部行 在HTTP请求报文中的一个cookie首部行 在用户端系统中保留一个cookie文件,并由用户的浏览器进行管理 位于web站点的一个后端数据库 HTTP报文的Set-cookie首部含有识别码,该识别码用于跟踪用户 cookie可以用于标识一个用户,用户首次访问一个站点时,可能需要提供一个用户标识,在后继会话中,浏览器向服务器传递一个cookie首部,从而向该服务器标识了用户 cookie可以在无状态的HTTP之上建立一个用户会话层 2.2.5 Web缓存 Web缓存器也叫代理服务器(proxy server) 能够代表初始web服务器来满足http请求的网络实体 web缓存器由自己的磁盘存储空间,并在存储空间中保存最近请求过的对象的副本 假设浏览器正在请求对象,会发生以下情况 浏览器创建一个到Web缓存器的TCP连接,并向缓存服务器中的对象发送一个HTTP请求 web缓存器进行检查,看本地是否存储了该对象的副本,若有则向客户浏览器用http响应报文返回该对象 若没有该对象,则打开一个与该对象的初始服务器的tcp连接.web浏览器则在这个缓存器到服务器的tcp连接上送一个对象的http请求,收到请求后,初始服务器向该web缓存器发送具有该对象的http响应 web缓存器接收该对象时,在本地存储空间存储一份副本,并向客户用http响应报文发送该副本 在因特网部署web缓存器的两个原因 web缓存器可以大大减少对客户请求的响应时间 总的响应时间即从浏览器请求一个对象到接收到该对象为止的时间,时局域网时延,接入时延和因特网时延之和 通过CDN,web缓存器在因特网发挥重要的作用 web缓存器可以大大减少一个机构的接入链路到因特网的通信量 2.2.6 条件GET方法 允许缓存器正式它的对象是最新的机制为条件GET 如果请求报文使用GET方法,并且请求报文包含If-Modified-Since首部行,则这个报文iu是条件GET方法 GET方法操作方式 代理缓存器代表一个请求浏览器,向某web服务器发送一个请求报文 该web服务器向缓存器发送具有被请求的对象的响应报文 该缓存器在将对象发到请求的浏览器的同时,也在本地缓存该对象 若If-Modified-Since首部行的值等于Last-Modified首部行的值,条件GET报文告诉服务器,仅当指定日期之后该对象被修改过,才发送该对象；假定该对象没有修改,接下来,web服务器向该缓存器发送一个响应报文 2.3 因特网中的电子邮件 电子邮件系统具有3个主要组成部分:用户代理,邮件服务器和简单邮件传输协议(SMTP) 用户代理又叫邮件阅读器,撰写,边集和阅读邮件 邮件服务器 邮件中管理和维护发送给用户的邮件 输出报文队列保持发送邮件报文 邮件服务器之间的SMTP协议:发送email报文 客户:发送方邮件服务器 服务器:接收端邮件服务器 SMTP 使用TCP在客户端和服务器之间传送报文,端口号为25 直接传输:从发送方服务器到接收方服务器 传输的3个阶段 握手 传输报文(报文必须为7为ASCII码) 关闭 命令/响应交互 命令:ASCII文本 响应:状态码和状态信息 SMTP使用持久连接 SMTP与HTTP比较 HTTP:拉(pull) SMTP:推(push) 两者都是ASCII形式的命令/响应交互,状态码 HTTP:每个对象封装在各自的响应报文中 SMTP:多个对象包含在一个报文中 邮件报文格式:每个首部必须含有一个From首部行和一个TO首部行,可能需要Subject首部行,报文主体为ASCII码字符 邮件访问协议 SMTP:传送到接收方的邮件服务器 邮件访问协议:从服务器访问邮件 POP:用户身份确认并下载 IMAP:更多特性,在服务器上处理存储的报文 HTTP POP3协议(本地管理文件夹) 用户确认阶段 客户端命令:user声明用户名,pass口令 服务器响应:+OK,-ERR 事务处理阶段,客户端: list报文号列表 retr根据报文号检索报文 dele删除 quit 下载并保留,不用客户机上为报文的拷贝 POP3在会话中是无状态的 IMAP(远程管理文件夹) IMAP服务器将每个报文与一个文件夹联系起来 允许用户用目录来组织报文 允许用户读取报文组件 IMAP在会话过程中保留用户状态 目录名,报文ID与目录名之间映射 2.4 DNS:因特网的目录服务 主机的一种标识方法是用主机名,而主机名难以被路由器处理,使用IP地址进行标识 2.4.1 DNS提供的服务 **域名系统(DNS)**的任务:进行主机名到IP地址转换的目录服务 一个由分层的DNS服务器实现的分布式数据库 一个使得主机能够查询分布式数据库的应用层协议 DNS协议运行在UDP上,使用53号端口 DNS协议是应用层协议的原因 使用客户-服务器模式运行在通信的端系统之间 在通信的端系统之间通过下面的端到端运输层协议来传送DNS报文 DNS服务器的做法 同一台用户主机上运行着DNS应用的客户端 浏览器上URL中抽取出主机名,并将这台主机名传给DNS应用的客户端 DNS客户向DNS服务器发送一个包含主机名的请求 DNS客户最终会受到一份回答报文,其中包含对应于该主机名的IP地址 一旦浏览器接收到来自DNS的该IP地址,它能够向位于该IP地址的80端口的HTTP服务器进程发起一个TCP连接 DNS提供的其他服务: 主机别名 邮件服务器别名 负载分配 2.4.2 DNS工作机理概述 假设运行在用户主机上的某些应用程序需要将主机名转换为IP地址 应用程序将调用DNS的客户端,并指明需要被转换的主机名.用户主机上的DNS接收到后,向网络中发送一个DNS查询报文.所有的DNS请求和回答报文使用UDP数据报经端口53发送.经过若干毫秒到若干秒的时延后,用户主机上的DNS接收到一个提供所希望映射的DNS回答报文.这个映射结果则被传递到调用DNS的应用程序 集中式设计的问题:单点故障,通信容量,远距离的集中式数据库,维护 在单一DNS服务器上运行集中式数据库没有可扩展能力,故采用分布式的方案 分布式,层次数据库 根DNS服务器,顶级域DNS服务器和权威服务器 本地DNS服务器不属于该服务器的层次结构,但它对DNS层次结构至关重要 在查询时,使用递归查询和迭代查询 从请求主机到本地DNS服务器的查询是递归的,其余的查询时迭代的 DNS缓存 为了改善时延性能并减少在因特网上到处传播的DNS报文数量 在一个请求链中,当某DNS服务器接收一个DNS回答时,能将映射缓存在本地存储器中 由于主机和主机名与IP地址间的映射并不是永久的,DNS服务器在一段事件后将丢弃缓存的信息 2.4.3 DNS记录和报文 共同实现DNS分布式数据库的所有DNS服务器存储了资源记录(RR),RR提供了主机名到IP地址的映射 资源记录是一个4元组, (Name, Value, Type, TTL) TTL是该记录的生存时间,决定了资源记录应当从缓存中删除的时间 若Type=A,则Name是主机名,Value是主机名对应的IP地址,一条类型为A的资源记录提供了标准的主机名到IP地址的映射 若Type=NS,则Name是一个域,Value是获得域中主机IP地址的权威DNS服务器的主机名,这个记录用于沿着查询链来路由DNS查询 若Type=CNAME,则Value是别名Name的主机对应的规范主机名 若Type=MX,则Value是个别名为Name的邮件服务器的规范主机名 如果一台DNS服务器是用于某特定主机名的权威DNS服务器,那该DNS服务器会有一条包含用于该主机名的类型A记录 如果服务器不是用于主机名的权威服务器,那么该服务器将包含一条类型NS记录,该记录对应于包含主机名的域,还将包括一条类型A记录,该记录提供了在NS记录的Value字段中的DNS服务器IP地址 DNS报文 DNS查询和回答报文具有相同的格式 前12个字节是首部区域 第一个字段标识符是16比特的数,用于标识该查询,会被复制到对查询的回答报文中,以便客户用它匹配发送的请求和接收到的回答 标志字段含有若干个标志,查询/回答标志用0标识查询报文1标识回答报文 若希望执行递归查询,将设置1比特的希望递归标志位 问题区域包含正在查询的信息 名字字段,包含正在被查的主机名 类型字段,指出有关该名字的正被询问的问题类型 回答区域包含了对最初请求的名字的资源记录,包含多条RR 使用nslookup程序从工作的主机直接向某些DNS服务器发送DNS查询报文 2.5 P2P文件分发 在P2P文件分发中,每个对等方能够向任何其他对等方重新分发它已经收到的该文件的任何部分,从而在分发过程中协助该服务器 2.6 视频流和内容分发网 视频的一个重要特性:能被压缩,因而可用比特率来权衡视频质量 2.6.2 HTTP流和DASH HTTP流具有严重缺陷,即所有客户接收到相同编码的视频,尽管对不同的客户或者对于相同客户的不同时间而言,客户可用的带宽大小有很大不同 经HTTP的动态适应性流(DASH): 在DASH中,视频编码为几个不同的版本,其中每个版本具有不同的比特率,对应于不同的质量水平.客户动态地请求来自不同版本且长度为几秒的视频段数据块.当可用带宽量较高时,客户自然地选择来自高速率版本的块；当可用带宽量较低时,客户自然地选择来自低速率版本的块.客户用HTTP GET请求报文一次选择一个不同的块 使用DASH后,每个视频版本存储在HTTP服务器中,每个版本都有一个不同的URL HTTP服务器也有一个告示文件,为每个版本提供了一个URL及其比特率 2.6.3 内容分发网 CDN两种不同的服务器安置原则 深入 邀请做客 许多CDN 没有将视频推入它们的集群,而是使用一种简单的拉策略 如果客户向一个未存储该视频的集群请求某视频,则该集群检索该视频(从某中心仓库或者从另一个集群),向客户流式传输视频时的同时在本地存储一个副本 集群选择策略:动态地将客户定向到CDN中的某个服务器集群或数据中心机制 地理上最为临近 为了基于当前流量条件为客户决定最好的集群,CDN能够对其集群和客户之间的时延和丢包性能能进行周期性的实时测量 2.7 套接字编程:生成网络应用 当生成一个套接字时,就为它分配一个端口号的标识符 分组的目的地址包括该套接字的端口号,发送进程为分组附上目的地址,该目的地址是由目的主机IP地址和目的地套接字的端口号组成的 3 运输层 运输层位于应用层和网络层之间,是分层的网络体系结构的重要部分 该层为运行在不同主机上的应用进程提供直接的通信服务起着至关重要的作用 3.1 概述和运输层服务 运输层协议为运行在不同主机上的应用进程之间提供了逻辑通信功能 运输层协议是在端系统中而不是在路由器中实现的 在发送端,运输层将从发送应用程序进程接收到的报文转换成运输层分组,该分组称为运输层报文段 实现的方法是将应用报文划分为较小的块,并为每块加上一个运输层首部以生成运输层报文段.然后,在发送端系统中,运输层将这些报文段传递给网络层,网路层将其封装成网络层分组并向目的地发送 网络路由器仅作用于该数据报的网络层字段；即它们不检查封装在该数据报的运输层报文段的字段.在接收端,网络层从数据报中提取运输层报文段,并将该报文段向上交给运输层.运输层则处理接收到的报文段,使该报文段中的数据为接收应用进程使用. 3.1.1 运输层和网络层的关系 网络层提供了主机之间的逻辑通信,运输层为运行在不同主机上的进程之间提供了逻辑通信 即使底层网络协议不能在网络层提供响应的服务,运输层协议也能提供某些服务 即使底层网络协议是不可靠的,也就是说网络层协议会使分组丢失,篡改和冗余,运输协议也能为应用程序提供可靠的数据传输服务 3.1.2 因特网运输层概述 UDP(用户数据报协议),为调用它的应用程序提供了一种不可靠,无连接的服务 TCP(传输控制协议),为调用它的应用程序提供一种可靠的,面向连接的服务 将运输层分组称为报文段 网络层包括IP协议,其服务模型为尽力而为交付服务,为不可靠服务 UDP和TCP的服务模型 基本责任是将两个端系统间IP的交付服务扩展为运行在端系统上的两个进程之间的交付服务 将主机间交付扩展到进程间交付被称为运输层的多路复用与多路分解 UDP和TCP可以通过在其报文段首部中包括差错检查字段而提供完整性检查 进程到进程的数据交付和差错检查是两种最低限度的传输层服务,也是UDP仅能提供的两种服务,UDP也是一种不可靠的服务 TCP提供可靠数据传输,通过流量控制,序号,确认和定时器,确保正确地,按序地将数据从发送进程交付给接收进程 提供拥塞控制机制,防止任何一条TCP连接用过多流量来淹没通信主机之间的链路和交换设备 通过控制发送端的流量速率来力求为每一个通过一条拥塞网络链路的连接平等地共享网络链路带宽 3.2 多路复用与多路分解 运输层的多路复用与多路分解:将由网络层提供的主机到主机交付服务延伸到为运行在主机上的应用程序提供进程到进程到交付服务 在目的主机,运输层从紧邻其下的网络层接收报文段,运输层负责将这些报文段中的数据交付给主机上运行的适当的应用程序进程 一个进程有一个或多个套接字,相当于从网络向进程传递数据和从进程向网络传递数的用户 在接收主机中的运输层实际上并没有直接将数据交付给进程,而是将数据交给了中间的套接字 套接字具有唯一的标识符,标识符的格式取决于是TCP还是UDP的套接字 多路分解:在接收端,运输层检查这些字段,标识出接受套接字,进而将报文段定向到该套接字.将运输层报文段中的数据交付到正确的套接字的工作 多路复用:在源主机从不用套接字中收集数据块,并为每个数据块封装上首部信息从而生成报文段,然后将报文段传递到网络 运输层多路复用要求 套接字由唯一标识符 每个报文段由特殊字段来指示该报文段所要交付的套接字 特殊字段是端口号字段和目的端口号字段 端口号是一个16比特的数,范围为0~65535之间 0~1023范围内的端口号是周知端口号,是受限制的 在运输层实现分解服务 在主机上的每个套接字能够分配一个端口号,当报文段到达主机时,运输层检查报文段中的目的端口号,并将其定向到相应的套接字.然后报文段中的数据通过套接字进入其所连接的进程 UDP套接字由二元组全面表示的,该二元组包含一个目的IP地址和一个目的端口号 TCP套接字由四元组(源IP地址,源端口号,目的IP地址,目的端口号)来标识 web服务器和tcp 连接套接字与进程之间并非总是有着一一对应的关系 事实上,当今的高性能web服务器使用一个进程,但是为每个新的客户连接创建一个具有新连接套接字的新线程(线程为轻量级的子进程) 3.3 无连接服务:UDP UDP从应用进程得到数据,附加上用于多路复用/分解服务的源和目的端口号字段,以及两个其他的小字段,然后将形成的报文段交给网络层.网络层将该运输层报文段封装到一个IP数据报中,然后尽力而为地尝试将此报文段交付给接收主机.如果该报文段到达接收主机,UDP使用目的端口号将报文段中的数据交付给正确的应用进程.值得注意的是,使用UDP时,在发送报文段之前,发送方和接收方的运输层实体之间没有握手 许多应用更适合UDP的原因 关于发送什么数据以及何时发送的应用层控制更加精细 采用UDP时,只要应用进程将数据传递给UDP,UDP就会将此数据打包进UDP报文段并立即将其传递给网络层 无需连接建立 DNS运行在UDP之上的原因 无连接状态 TCP需要在端系统中维护连接状态.此连接状态包括接收和发送缓存,拥塞控制参数以及序号与确认号的参数 分组首部开销小 每个TCP报文段都有20字节的首部开销,UDP仅有8字节的开销 由无控制的UDP发送发引入的高丢包率将引起TCP发送方大大减小它们的速率 因此UDP中缺乏拥塞控制导致UDP发送方和接收方之间的高丢包率,并挤垮了TCP会话 使用UDP的应用是可能实现可靠数据传输的,应用层自身保证可靠性 3.3.2 UDP检验和 发送方的UDP对报文段中的所有16比特字的和进行反码运算,求和时遇到的任何溢出都被回卷 许多链路层协议提供差错检测的原因:是不能保证源和目的之间的所有链路都提供差错检测 如果端到端数据传输服务要提供差错检测,UDP就必须在端到端基础上再运输层提供差错检测 端到端原则:因为某种功能必须基于端到端实现 3.4 可靠数据传输原理 可靠数据传输协议(rdt) 3.4.1 构造可靠数据传输协议 经完全可靠信道的可靠数据传输:rdt1.0:底层信道完全可靠 有限状态机(FSM) 箭头指示了协议从一个状态变迁到另一个状态 引起变迁的时间显示在标识变迁的横线的上方 事件发生时所采取的动作显式再横线下方 如果对一个时间没有动作,或没有就事件发生而采取一个动作,横线上方或下方使用符号明确表示缺少动作或事件 初始状态用虚线表示 经具有比特差错信道的可靠数据传输:rdt2.0:停等协议 控制报文使得接收方可以让发送方直到哪些内容被正确接收 基于重传机制的可靠数据传输协议称为**自动重传(ARQ)**协议 ARQ协议中三种协议功能来处理存在比特差错的情况 差错检测 接收方反馈 反馈ACK或NAK 重传 有比特差错信道上实现的一个无NAK的可靠数据传输协议:rdt2.2 解决ACK或NAK可能出错的问题:在数据分组中添加一个新字段,让发送方对其数据分组编号,即将发送数据分组的序号放在该字段,接收方检查序号即可确定收到的分组是否一次重传 如果收到受损的分组,则接收方将发送一个否定确认,对上次正确接收的分组发送一个ACK,发送方接收到对同一个分组的两个ACK,就知道接收方没有正确接收 接收方必须包括有一个ACK报文所确认的分组序号,发送方此时必须检查接收到的ACK报文中被确认的分组序号 经具有比特差错的丢包信道的可靠数据传输:rdt3.0 发送方与接收方之间的一个往返时延加上接收方处理一个分组所需的时间,等待这样长的时间确定分组已被丢失 基于时间的重传机制,需要一个倒计数定时器 分组在0和1之间交替,rdt3.0被称为比特交换协议 3.4.2 流水线可靠数据传输协议 发送方(或信道)的利用率:发送方实际忙于将发送比特送进信道的那部分时间与发送时间的之比Usender=L/RRTT+L/RU_{sender} = \\frac{L/R}{RTT+L/R}Usender​=RTT+L/RL/R​ 流水线(pipelining)技术:不以停等方式运行,允许发送方发送多个分组而无需等待确认 对可靠数据传输协议的影响 必须增加序号范围 协议的发送方和接收方缓存多个分组 解决流水线的差错恢复的两种基本方法:回退N步和选择重传 3.4.3 回退N步 回退N步(GBN)协议,滑动窗口协议 基序号(base):最早未确认分组的序号 下一个序号(nextseqnum):最小的未使用序号(下一个待发送分组的序号) 窗口长度:N 已被发送但还未被确认的分组需要序号范围可看作是一个需要范围内长度为N的窗口.随着协议的运行,该窗口在序号空间向前滑动 在实践中,一个分组的序号承载在分组首部的一个固定长度的字段中,若分组序号的比特数是k,则序号范围是[0,2k−1][0, 2^k-1][0,2k−1] 在一个有限的序号范围内,所涉及序号的运算必须使用模2k2^k2k运算 GBN发送方必须响应三种类型的事件 上层的调用 收到一个ACK 在GBN协议中,对序号为n的分组的确认采取累计确认的方式,表明接收方已正确接收到序号为n的以前且包括n在内的所有分组 超时事件 如果出现超时,发送方重传所有已发送但还未被确认过的分组 在GBN中,接收方的动作简单,如果一个序号为n的分组被正确接收到,并且按需,则接收方为分组n发送一个ACK,并将该分组中的数据部分交付到上层.在所有其他情况下,接收方丢弃该分组,并为最近按序接收的分组重新发送ACK GBN重传机制的优点是接收缓存简单,即接收方不需要缓存任何失序妇女组.虽然发送方必须维护窗口的上下边界及nextseqnum在该窗口中的位置,但是接收方需要维护唯一信息就是下一个按序接收的分组的序号 3.4.4 选择重传 选择重传(SR)协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免了不必要的重传 SR接收方将确认一个正确接收的分组而不管其是否按序 失序的分组将被缓存直到所有丢弃分组皆被收到位置,这时可以将一批分组按序交付给上层 发送方和接收方的窗口并不总是一致的 窗口长度必须小于或等于序号空间大小的一半 3.5 面向连接的运输:TCP 3.5.1 TCP连接 TCP被称为面向连接的 TCP提供的是全双工服务 TCP连接总是点对点的 TCP建立的过程:三次挥手 客户首先发送一个特殊的TCP报文段,服务器用另一个特殊的TCP报文段来响应.最后,客户再用第三个特殊报文段作为响应 前两个报文不包含应用层数据,第三个报文段可以承载有效载荷 TCP可以从缓存中取出并放入报文段中的数据数量受限于最大报文段长度(MSS) MSS通常根据最初确定的由本地发送主机的最大链路层帧长度(所谓的最大传输单元(MTU))来设置 设置MSS要保证一个TCP报文段(当封装在IP数据报中)加上**TCP/IP首部长度(通常为40字节)**将适合单个链路层帧 以太网和PPP链路层协议都具有1500字节的MTU,因此MSS典型值为1460字节 MSS是指在报文段里应用层数据的最大长度,而不是指包括首部TCP报文段的最大长度 TCP为每块客户数据配上一个TCP首部,从而形成多个TCP报文段,这些报文段被下传到网络层,网络层将其封装在网络层IP数据报中,然后数据报将被发送到网络中.当TCP在另一端接收到一个报文段后,该报文段的数据就被放入该TCP连接的接收缓存中 3.5.2 TCP报文段结构 首部包括源端口号和目的端口号,被用于多路复用/分解来自或送到上层应用的数据据 首部包括检验和字段 32比特的序号字段和32比特的确认号字段:被TCP发送方和接收方用来实现可靠数据传输服务 16比特的接收窗口字段,用于流量控制 4比特的首部长度字段,指示了以32比特的字为单位的TCP的首部长度 可选与变长的选项字段,用于发送方与接收方协商最大报文段长度(MSS),或在高速网络下用作窗口调节因子使用 6比特的标志字段 ACK比特用于指示确认字段中的值是有效的 RST,SYN,FIN比特用于连接建立和拆除 CWR,ECE比特用于明确拥塞通告 PSH被置位时,就指示接收方应立即将数据交给上层 URG比特指示报文段里存在着被发送端的上层实体置为“紧急”的数据 紧急数据的最后一个字节由16比特的紧急数据指针字段指出 当紧急数据存在并给出指向紧急数据尾指针时,TCP必须通知接收端的上层实体 序号和确认号 TCP把数据看成一个无结构,有序的字节流 序号建立在传送的字节流上,而不是建立在传送的报文段的序列之上 一个报文段的序号因此是该报文段首字节的字节流编号 主机A填充仅报文段的确认号是主机A期望从主机B收到的下一字节的序号 TCP提供累积确认 一条TCP连接的双方均可随机地选择初始序号,可以减少将那些仍在网络中存在地两台主机之间先前已终止的连接报文段,误认为是后来这两台主机之间新建连接所产生的有效报文段的可能性 对客户到服务器的数据确认被装载在一个承载服务器到客户的数据的报文段中,这种确认被称为是被捎带 3.5.3 往返时间的估计与超时 估计往返时间 大多数TCP的实现仅在某个时刻做一次SampleRTT测量,而不是为每个发送的报文段测量一个SampleRTT 一旦获得一个新的SampleRTT时,TCP就会根据公式来更新EstimatedRTT(SampleRTT均值) EstimatedRTT=(1−α)EstimatedRTT+αSampleRTTEstimatedRTT = (1-\\alpha) EstimatedRTT+\\alpha SampleRTTEstimatedRTT=(1−α)EstimatedRTT+αSampleRTT RFC中的推荐值α=0.125\\alpha = 0.125α=0.125 RFC定义了RTT偏差DevRTT,用于估算SampleRTT一般会偏离EstimateRTT的程度:DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣DevRTT = (1-\\beta) DevRTT + \\beta |SampleRTT - EstimatedRTT|DevRTT=(1−β)DevRTT+β∣SampleRTT−EstimatedRTT∣ RFC中的推荐值β=0.25\\beta = 0.25β=0.25 设置和管理重传超市时间间隔 TimeoutInterval=EstimatedRTT+4DevRTTTimeoutInterval = EstimatedRTT + 4 DevRTTTimeoutInterval=EstimatedRTT+4DevRTT 推荐的初始值TimeoutInterval值为1秒.同时当出现超时后,TimeoutInterval值将加倍,以免即将被确认的后继报文段过早出现超时 3.5.4 可靠数据传输 IP不保证数据报的交付,不保证数据报的按序交付,也不保证数据报中数据的完整性 TCP的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流时无损坏,无间隔,非冗余和按序的数据流 字节流与连接的另一方端系统发送出的字节流是完全相同 TCP发送方有3个与发送和重传有关的主要事件: 从上层应用程序接收数据；定时器超时和收到ACK 一旦第一个主要事件发生,TCP从应用程序接收数据,将数据封装在一个报文段中,并把该报文段交给IP,每个报文段含有一个序号,该序号为该报文段第一个数据字节的字节流编号.若定时器还没有为某些其他报文段而运行,则当报文段被传给IP时,TCP就启动该定时器 超时 TCP重传引起超时的报文段来响应超时事件,然后TCP重启定时器 到达一个来自接收方的确认报文段(ACK) 当该事件发生时,TCP将ACK的值y与变量SendBase进行比较.TCP状态变量SendBase是最早未被确认的字节的序号 TCP采取累积确认,y确认了字节编号在y之前的所有字节都已经收到 若y&gt;SendBasey&gt;SendBasey&gt;SendBase,则该ACK是在确认一个或多个先前未被确认的报文段,发送方更新SendBase变量；若当前有未被确认的报文段,TCP还要重启定时器 超时间隔加倍 每次TCP重传时都会将下一次的超时间隔设为先前的两倍,而不是从EstimatedRTT和DevRTT更新 超时间隔在每次重传后会呈指数型增长 然而,每当定时器在另两个事件中的任意一个启动时,TimeoutInterval由最近的EstimatedRTT与DevRTT值推算得到 快速重传 当一个报文段丢失时,这种长超时周期迫使发送方延迟重传丢失的分组,因此增加了端到端时延 冗余ACK就是再次确认某个报文段的ACK,而发送方先前已经收到对该报文段的确认 当TCP接收方收到一个具有序号大于下一个所期望的,按序的报文段,它检测到了数据流的一个间隔,着就是说有报文段丢失 如果TCP发送方接收到对相同数据的3个冗余ACK,说明这个被确认过3次的报文段已经丢失 一旦收到3个冗余ACK,TCP就执行快速重传,在该报文段的定时器过期之前重传丢失的报文段 回退N步还是选择重传 TCP采用选择确认 允许TCP接收方有选择地确认失序报文段,而不是累积的确认最后一个正确接收地有序报文段 3.5.5 流量控制 TCP为应用程序提供了流量控制服务 流量控制是一个速度匹配服务 TCP发送方也可能因为IP网络的拥塞控制而被抑制,这种形式的发送方控制称为拥塞控制 TCP通过让发送方维护一个称为接收窗口的变量来提供流量控制 定义变量 LastByteRead:主机B上的应用进程从缓存读出的数据流的最后一个字节的编号 LastByteRcvd:从网络中到达的并且已经放入主机B接收缓存中的数据流的最后一个字节的编号 TCP不允许已分配的缓存溢出,故LaseByteRcvd−LastByteRead&lt;=RcvBuffer,rwnd=RcvBuffer−[LastByteRcvd−LastByteRead]LaseByteRcvd-LastByteRead&lt;=RcvBuffer,rwnd=RcvBuffer-[LastByteRcvd-LastByteRead]LaseByteRcvd−LastByteRead&lt;=RcvBuffer,rwnd=RcvBuffer−[LastByteRcvd−LastByteRead] 使用rwnd来提供流量控制机制 主机B通过把当前的rwnd值放入它发送给主机A的报文段接收窗口字段中,通知主机A它在该连接的缓存中还有多少可用空间 开始时,主机B设定rwnd=RcvBuffer 主机A轮流跟踪两个变量LastByteSent和LastByteAcked,主机A发送到连接中但未被确认的数据量LastByteSent-LastByteAcked.通过将未确认的数据量控制在值rwnd以内,就可能保证主机A不会使主机B溢出,主机A在整个生命周期内保证LastByteSent−LastByteAcked&lt;=rwndLastByteSent-LastByteAcked&lt;=rwndLastByteSent−LastByteAcked&lt;=rwnd TCP仅当在它有数据或有确认要发时才会发送报文段该主机A 当主机B的接收窗口为0时,主机A继续发送只有一个字节数据的报文段 报文段将会被接收方确认,最终缓存将开始清空,并且确认报文里将包含一个非0的rwnd值 3.5.6 TCP连接管理 通过TCP建立连接(三次握手) 第一步:客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段.该报文段中不包含应用层数据.但是在报文段的首部中的一个标志位(即SYN比特)被置为1.因此,这个特殊报文段被称为SYN报文段.另外,客户会随机地选择一个初始序号(client_isn),并将此编号放置于该起始的TCP SYN报文段的序号字段中.该报文段会被封装在一个IP数据报中,并发送给服务器 第二步:一旦包含TCP SYN报文段的IP数据报到达服务器主机()假定它的确到达了),服务器会从该数据报中提取出TCP SYN报文段,为该TCP连接分配TCP缓存和变量,并向该客户TCP发送允许连接的报文段.(在完成三次握手的第三步之前分配这些缓存和变量,使得TCP易于受到称为SYN洪泛的拒绝服务攻击)这个允许连接的报文段也不包含应用层数据 但是,在报文段的首部却包含3个重要的信息 首先,SYN比特被置为1 其次,该TCP报文段首部的确认号字段被置为client_isn＋1 服务器选择自己的初始序号(server_isn),并将其放置到TCP报文段首部的序号字段中 第三步:在收到SYNACK报文段后,客户也要给该连接分配缓存和变量.客户主机则向服务器发送另外一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认(该客户通过将值server_isn＋1放置到TCP报文段首部的确认字段中来完成此项工作) 因为连接已经建立了,所以该SYN比特被置为0.该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据 在以后的每一个报文段,SYN比特都i将将被置为0 关闭连接 客户应用进程发出一个关闭连接命令,引起客户TCP向服务器进程发送一个特殊的TCP报文段.这个特殊的报文段让其首部中的一个标志位即 FIN比特被设置为1.当服务器接收到该报文段后,就向发送方回送一个确认报文段.然后,服务器发送它自己的终止报文段,其FIN比特被置为1.最后,该客户对这个服务器的终止报文段进行确认.此时,在两台主机上用于该连接的所有资源都被释放了 TCP状态变迁 客户的应用程序发起一个新的TCP连接,引起客户中的TCP向服务器中TCP发送一个SYN报文段.在发送过SYN报文段后,客户TCP进入了SYN_SENT状态.当客户TCP处于SYN_SENT状态时,它等待来自服务器TCP的对客户所发报文段文段进行确认且SYN比特被置为1的一个报文段.收到这样一个报文段之后,客户TCP进入ESTABLISHED(已建立)状态.当处在ESTABLISHED状态时,TCP客户就能发送和接收包含有效载荷数据(即应用层产生的数据)的TCP报文段了 假设客户应用程序决定要关闭该连接.这引起客户TCP发送一个带有FIN比特被置为1的TCP报文段,并进入FIN_WAIT_1状态.当处在FIN_WAIT1状态时,客户TCP等待一个来自服务器的带有确认的TCP报文段.当它收到该报文段时,客户TCP进入FIN_WAIT_2状态.当处在FIN_WAIT_2状态时,客户等待来自服务器的FIN比特被置为1的另一个报文段；当收到该报文段后,客户TCP对服务器的报文段进行确认,并进入TIME_WAIT状态.假定ACK丢失,TIME_WAIT状态使TCP客户重传最后的确认报文.在TIME_WAIT状态中所消耗的时间是与具体实现有关的,而典型的值是30秒、1分钟或2分钟.经过等待后,连接就正式关闭,客户端所有资源(包括端口号)将被释放 考虑主机接收一个tCP报文段,其端口号或源IP地址与该主机上进行中的套接字都不匹配的情况 该主机将向源发送一个特殊重置报文段,该TCP报文段将RST标志位置为1 当一台主机接收一个UDP分组,它的目的端口与进行中的UDP套接字不匹配,该主机发送一个特殊的ICMP数据报 3.6 拥塞控制机制 3.6.1 拥塞原因与代价 情况1:两个发送方和一个具有无穷大缓存的路由器 当分组的到达速率接近链路容量时,分组经历巨大的排队时延 情况2:两个发送方和一台具有有限缓存的路由器 发送方必须执行重传以补偿因为缓存溢出而丢弃的分组 发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组 情况3:4个发送方和具有有限缓存的多台路由器及多跳路径 一个分组沿一条路径被丢弃时,每个上有路由器用于转发该分组到丢弃该分组而使用的传输容器最终被浪费掉了 3.6.2 拥塞控制方法 端到端拥塞控制 网络层没有为运输层拥塞控制提供显式支持 网络中存在拥塞,端系统也必须通过对网络行为的观察来推断 网络辅助的拥塞控制 路由器向发送方提供关于网络中拥塞状态的显式反馈 3.7 TCP拥塞控制 TCP所采用的方法是让每一个发送方格局所感知到的网络拥塞程序来限制其能向连接发送流量的速率 TCP连接的每一段都是由一个接收缓存,一个发送缓存和几个变量组成 运行在发送方的TCP拥塞控制机制跟踪一个额外的变量,即拥塞控制窗口cwnd,对一个TCP发送方能向网络中发送流量的速率进行了限制 发送方的发送概率大概是cwnd/RTT字节/秒cwnd/RTT 字节/秒cwnd/RTT字节/秒,通过调节cwnd的值,发送方因此能调整它向连续发送数据的速率 当出现过度的拥塞时,在沿着这条路径上的一台路由器的缓存会溢出,引起一个数据报被丢弃.丢弃的数据报接着会引起发送方的丢包事件,发送方就认为在发送方到接收方的路径上出现了拥塞的指示 TCP是自计时的:TCP使用确认来触发增大它的拥塞窗口长度 TCP的指导性原则来设置发送速率 一个丢弃的报文段表意味着拥塞,因此当丢弃报文段时应当降低TCP发送方的速率 从拥塞控制的观点,该问题是TCP发送方应当如何减小它的拥塞控制窗口长度,即减小其发送速率,以应对这种推测的丢包事件 一个确认报文段指示网络正向接收方交付发送方的报文段 因此,当对先前未确认报文段的确认到达时,能够增加发送方的速率 带宽探测 给定ACK指示源到目的地路径无拥塞,而丢包事件指示路径拥塞,TCP调节其传输速率的策略是增加其速率以响应到达的ACK,除非出现丢包事件,此时才减小传输速率 TCP拥塞控制算法 慢启动 当一条TCP连接开始时,cwnd的值通常初始置为一个MSS较小值,使得初始发送速率大约为MSS/RTTMSS/RTTMSS/RTT 在慢启动状态,cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加1个MSS 每过一个RTT,发送速率就翻翻番 TCP发送速率起始慢,在慢启动阶段以指数增长 结束指数增长 如果存在一个由超时指示的丢包事件,TCP发送方将cwnd设置为1并重新开始慢启动过程 并且将ssthresh(慢启动阈值的速记)设置为cwnd/2cwnd/2cwnd/2,即当检测到拥塞时将ssthresh置为拥塞窗口的一半 当cwnd等于ssthresh时,结束慢启动并且TCP转移到拥塞避免模式 进入拥塞避免模式时,TCP更加谨慎地增加cwnd 当检测到3个冗余ACK时,TCP执行快速重传并进入快速恢复状态 拥塞避免 一旦进入拥塞避免状态,cwnd的值大约是上次遇到拥塞时的值的一半,即距离拥塞可能并不遥远 TCP无法每过一个RTT再将cwnd的值翻番,而是每个RTT只将cwnd的值增加一个MSS 一种通用的方法是对于TCP发送方无论何时到达一个新的确认,就将cwnd增加一个MSS(MSS/cwnd)字节 何时应当结束拥塞避免的线性增长? 当出现超时时,TCP的拥塞避免算法行为相同.与慢启动的情况一样,cwnd的值被设置为1个MSS,当丢包事件出现时,ssthresh的值被更新为cwnd值的一半 丢包事件也能由一个三个冗余ACK事件触发.在这种情况下,网络继续从发送方向接收方交付报文段,TCP将cwnd的值减半,并且当收到3个冗余的ACK,将ssthresh的值记录为cwnd的值的一半.接下来进入快速恢复状态 快速恢复 在快速恢复中,对于引起TCP进入快速恢复状态的缺失报文段,对收到的每个冗余的ACK,cwnd的值增加一个MSS.最终,当对丢失报文段的一个ACK到达时,TCP在降低cwnd后进入拥塞避免状态.如果出现超时事件,快速恢复在执行如同在慢启动和拥塞免中相同的动作后,迁移到慢启动状态:当丢包事件出现时,cwnd的值被设置为1个MSS,并且 ssthresh的值设置为cwnd值的一半 快速恢复是TCP推荐的而非必需的构件.一种称为TCP的TCP早期版本,不管是发生超时指示的丢包事件,还是发生3个冗余ACK指示的天包事件,都无条件地将其拥塞窗口减至1个MSS,并进人慢启动阶段 TCP拥塞控制:回顾 每个RTT内cwnd线性(加性)增加1MSS,然后出现3个冗余ACK事件时,cwnd减半(乘性减) TCP拥塞控制称为加性增,乘性减 TCP线性增加它的拥塞窗口长度,直到出现3个冗余ACK事件,然后以2个因子来减少它的拥塞窗口长度,然后又开始了线性增长,探测是否还有另外地可用带宽 对TCP吞吐量地宏观描述 在分析中,将忽略在超时事件后出现的慢启动阶段(这些阶段通常非常短,因为发送方很快就以指数增长离开该阶段) 在一个特定的往返间隔内,TCP发送数据的速率是拥塞窗口与当前RTT的函数.当窗口长度是w字节,且当前往返时间是RTT秒时,则TCP的发送速率大约是w/RTTw/RTTw/RTT TCP通过每经过1个RTT将w增加1个MSS探测出额外的带宽,直到一个丢包事件发生为止.当一个丢包事件发生时,用W表示w的值. 假设在连接持续期间RTT和W几乎不变,TCP的传输速率在W/(2RTT)W/(2RTT)W/(2RTT)到W/RTTW/RTTW/RTT之间变化 TCP稳态行为的一个高度简化的宏观模型 当速率增长至W/RTT时,网络丢弃来自连接的分组；然后发送速率就会减半,进而每过一个RTT就发送速率增加MSS/RTT,直到再次达到W/RTT为止 这一过程不断地自我重复.因为TCP吞吐量(即速率)在两个极值之间线性增长 一条连接地平均吞吐量=0.75WRTT一条连接地平均吞吐量=\\frac{0.75W}{RTT}一条连接地平均吞吐量=RTT0.75W​ 经高带宽路径地TCP 丢包率为L,往返事件RTT和最大报文长度MSS 一条连接地平均吞吐量=1.22MSSRTTL一条连接地平均吞吐量=\\frac{1.22MSS}{RTT \\sqrt{L}}一条连接地平均吞吐量=RTTL​1.22MSS​ 3.7.1 公平性 考虑K条TCP连接,每条都有不用的端到端路径,但是都经过一段传输速率为R bps的瓶颈链路 瓶颈链路:指对于每条连接,沿着该连接路径上所有其他段链路都不拥塞,而且与该瓶颈链路的传输容量相比,都有充足的传输容量 如果每条连接的平均传输速率接近R/KR/KR/K,即每条连接都得有相同份额的链路带宽 从TCP的观点看,运行在UDP上的多媒体运用时不公平的 它们不与其他连接合作,也不适合地调整其传输速率,因此TCP拥塞控制在面临拥塞增加时,将降低其传输速率,而UDP源则不必这样做 UDP源有可能压制TCP流量 4 网络层:数据平面 网络层能够分解成两个相互作用的部分：数据平面和控制平面 4.1 网络层概述 每台路由器的数据平面的主要作用是从其输入链路向其输出链路转发数据报 控制平面的主要作用是协调一些本地的每台路由器转发动作，使得数据报沿着源和目的地主机之间的路由器路径最终进行端到端传送 4.1.1 转发和路由选择:数据平面和控制平面 转发:指将分组从一个输入链路接口转移到适当的输出链路接口的路由器本地动作 当一个分组到达某路由器的一条输入链路时，该路由器必须将该分组移动到适合的输出链路 转发是在数据平面中实现的唯一功能 路由选择:指确定分组从源到目的地所采取的端到端路径的网络范围处理过程 当分组从发送方流向接收方时，网络层必须决定这些分组所采用的路由或路径 计算这些路径的算法称为路由选择算法 路由选择算法决定了插入该路由器转发表的内容 运行在每台路由器中，并且在每台路由器中都包含转发和路由选择两种功能 每台网络路由器中有一个关键元素是它的转发表 路由器检查到达分组首部的一个或多个字段值，进而使用这些首部值在其转发表中索引，通过这种方法来转发分组。这些值对应存储在转发表项中的值，指出了该分组将被转发的路由器的输出链路接口 控制平面:SDN方法 软件定义网络(SDN):计算转发表并与路由器交互的控制器是用软件实现的，网络是软件定义的 4.1.2 网络服务模型 网络服务模型定义了分组在发送与接收端系统之间的端到端运输特性，该服务包括 确保交付 具有时延上界的确保交付 有序分组交付 确保最小带宽 安全性 因特网的网络层提供单一的服务，称为尽力而为服务 传送的分组既不能保证以它们发送的顺序被接收，也不能保证它们最终交付 既不能保证端到端时延，也不能保证最小带宽 分组交换机是一台通用分组交换设备，根据分组首部字段中的值，从输入链路接口到输出链路接口转移分组 某些链路层帧的字段值做出转发决定，交换机因此称为链路层(第二层)设备 其他分组交换机称为路由器，基于网络层数据报中的首部字段值做出转发决定 4.2 路由器工作原理 路由器的4个组件 输入端口 交换结构 输出端口 路由选择处理器 路由器处理的信息 基于目的地转发 通用转发 4.2.1 输入端口处理和基于目的地转发 输入端口的线路端接功能与链路层处理实现了用于各个输入链路的物理层和链路层。在输入端口中执行的查找对于路由器运行时至关重要的 路由器使用转发表来查找输出端口，使得到达的分组能经过交换结构转发到该输出端口。 转发表时路由选择处理器计算和更新的，或者转发表接收来自远程SDN控制器的内容 使用在每个输入端口的影子副本，转发决策能在每个输入端口本地做出，无须基于每个分组调用集中式路由选择处理器，避免了集中式处理的瓶颈 当使用转发表时，路由器用分组目的地址的前缀与该表中的表象进行匹配 如果存在一个匹配项，则路由器向与该匹配项相关联的链路转发分组 当有多个匹配项时，该路由器使用最长前缀匹配规则，寻找在表中最长的匹配项，并与最长前缀匹配相关联的链路接口转发分组 4.2.2 交换 经内存交换 经总线交换 输入端口经一根共享总线将分组直接传送到输出端口，不需要经过路哟选择处理器的干预 路由器的交换带宽受到总线速率的限制 经互联网络交换 纵横式交换机是一种由2N条总线组成的互联网络，它连接N个输入端口与N个输出端口 纵横式交换机是非阻塞的，即只要没有其他分组当前被转发到该输出端口，转发到输出端口的分组将不会被到达输出端口的分组阻塞 4.2.4 何时出现排队 因为随着队列的增长，路由器的缓存空间最终将会耗尽，并且当无内存可用于存储到达的分组时将会出现丢包 线路前部阻塞(HOL):在一个输入队列中排队的分组必须等待通过交换结构发哦是那个，因为它被位于线路前部的另一个分组所阻塞 当没有足够的内存来缓存一个入分组时 要么丢弃到达的分组(弃尾) 要么删除一个或多个已排队的分组 4.2.5 分组调度 先进先出(FIFO) 当链路当前正忙于传输另一个分组，到达链路输出队列的分组要排队等待传输，若没有足够的缓存空间来容纳到达的分组，队列的分组丢弃测量确定该分组是否被丢弃 按照分组到达输出链路队列的相同次序来选择分组在链路上传输 优先权排队 到达输出链路的分组被分类放入输出队列中的优先权类 非抢占式优先排队:一旦分组开始传输，就不能打断 循环和加权公平排队 循环排队规则:分组像使用优先权排队那样被分类，在类之间不存在严格的服务优先权，循环调度器在这些类之间轮流提供服务 最简单的循环调度中，类1的分组被传输，接着是类2的分组，接着又是类1的分组 保持工作排队规则 在有分组排序等待传输时，不允许链路保持空闲 当寻找给定类的分组但是没有找到时，保持工作的循环规则将立即检查循环序列中的下一个类 4.3 网络协议:IPv4,寻址,IPV6及其他 4.3.1 IPv4数据报格式 网络层分组被称为数据报 IPv4数据报的关键字 版本(号)，4比特规定了数据报的IP协议版本 首部长度，4比特确定IP数据报中的载荷实际开始的地方 大多数IP数据报不包含选项 一般的IP数据报具有20字节的首部 服务类型 使不同类型的IP数据报能相互区别开来 数据报长度 16比特，IP数据报的总长度，以字节计 IP数据报的理论最长长度为65535字节，数据报很少有超过1500字节的，该长度使得IP数据报能容纳最大长度以太网帧的载荷字段 标识，标志，片偏移 寿命(TTL) 确保数据报不会永远在网络中循环 每当一台路由器处理数据报时，该字段的值减1，若TTL字段减为0，则该数据报必须丢弃 协议 仅当一个IP数据报到达其最终目的地才会有用。该字段值指示了IP数据报的数据部分应当给哪个特定的运输层协议 值为6表明数据部分要交给TCP，值为17表明数据要交给UDP 首部检验和:用于帮助路由器检测受到的IP数据报中的比特错误 源和目的IP地址:当源生成一个数据报时，在源IP字段中插入它的IP地址，在目的IP地址字段中插入其最终目的地的地址 选项:允许IP字段被扩展 数据:有效载荷 一个IP数据报有总长为20字节的首部，如果数据报承载一个TCP报文段，则每个数据报共承载总长40字节的首部(20字节的IP首部加上20字节的TCP首部)以及应用层报文 4.3.2 IPv4数据报分片 一个链路层帧能承载的最大数据量叫做最大传输单元(MTU) 每个IP数据报封装在链路层帧中从一台路由器传输到下一台路由器，故链路层协议的MTU严格地限制着IP数据报的长度 IPv4设计者将标识，标志和片偏移字段放在IP数据报首部中 当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时贴上标识号 发送主机通常将它的发送的每个数据报的标识号加1 当某路由器需要对一个数据报分片时，形成的每个数据报具有初始数据报的源地址，目的地址与标识号 当目的地从同一发送主机收到一系列数据报时，能够检查数据报的标识号以确定哪些数据报实际上是同一较大数据报的片 为了让目的主机绝对地相信它已收到了初始数据报地最后一个片，最后一个片地标志比特被设为0，而所有其他片地标志比特被设为1 4.3.3 IPv4编址 简述主机与路由器连入网络的方法 一台主机通常只有一个链路连接网络；当主机中的IP想发送一个数据报时，它就在该链路上发送 主机与物理链路之间的边界叫做接口 路由器的任务是从链路层上接收数据报并从某些其他链路转发出去，路由器必须拥有两条或更多条链路与它连接 路由器与它的任意一条链路之间的边界称做接口 一个IP地址与一个接口相关联，而不是与包括该接口的主机或路由器相关联 IP地址为32比特，采用点分十进制记法 地址中的每个字节用它的十进制形式书写，各字节间以句号隔开 在全球因特网中每台主机和路由器的每个接口都不许有全球唯一的IP地址 一个接口的IP地址的一部分需要由其连接的子网来决定 子网掩码，指示32比特中最左侧的x比特定义了子网地址 一个子网的IP地址定义并不局限于连接多台主机到一台路由器接口的以太网段 确认子网 分开主机和路由器的每个接口，产生几个隔离的网络岛，使用接口端接这些隔离的网络的端口 隔离的网络中的每一个都叫做一个子网 因特网的地址分配策略称为无类别域间路由选择(CIDR) 将子网的概念一般化 当使用子网寻址时，32比特的IP被划分为两部分，并且也具有点分十进制数形式a.b.c.d/xa.b.c.d/xa.b.c.d/x x指示了地址第一部分中的比特数,指示了子网掩码 x最高比特构成了IP地址的网络部分，并且经常被称为前缀 使用单个网络前缀通过多个网络的能力称为地址聚合或路由聚合 a.b.c.d/xa.b.c.d/xa.b.c.d/x中前x比特定义了组织的网络前缀，网络部分，剩余的32-x部分在该组织中划分子网 网络部分划分为长度为8位,16或24比特分别为A,B和C类网络，是一种称为分类编址的编址方案 A(/8)类网络 B(/16)类网络，可容纳65534台主机 C(/24)类网络，可容纳28−2=2542^8-2=25428−2=254台主机 当主机发出一个目的地址位255.255.255.255的数据报时，该报文会交付给同一网络中的所有主机 也会向邻近的子网转发该报文 动态主机协议配置(DHCP) 即插即用协议，零配置协议 某些主机将被分配一个临时的IP地址，每次与网络连接时该地址也许不同 是一个客户-服务器协议，在最简单场合下，每个子网将具有一台DHCP服务器，如果在某子网中没有服务器，则需要一个DHCP中继代理 DHCP是一个4个步骤的过程 DHCP服务器发现： 通过使用DHCP发送报文来完成，客户在UDP分组中向端口67发送该发现报文。该UDP分组封装在一个IP数据报中 在这种情况下，DHCP客户生成包含DHCP发现报文的IP数据报，其中使用广播目的地址255.255.255.255并且使用“本主机”源IP地址0.0.0.0 DHCP客户将该IP数据报传递给链路层，链路层然后将该帧广播到所有与该子网连接的节点 DHCP服务器提供 DHCP服务器收到一个DHCP发现报文时，用DHCP提供报文向客户做出响应，该报文向该子网的所有节点广播，仍然使用IP广播地址255.255.255.255 每台路由器提供的报文包含有收到的发现报文事务ID，向客户推荐的IP地址，网络掩码以及IP地址租用期 DHCP请求 新到达的客户从一个或多个服务器提供中选择一个，并向选中的服务器提供用DHCP请求报文进行响应，回显配置的参数 DHCP ACK 服务器用DHCP ACK报文对DHCP请求报文进行响应，证实所要求的参数 4.3.4 网络地址转换 网络地址转换NAT 使能路由器对于外部世界来说甚至不像一台路由器 相反NAT路由器对外界的行为就如同具有单一IP地址的单一设备 从本质上讲，NAT使能路由器对外界隐藏了家庭网络的细节 从广域网到达NAT路由器的所有数据报都具有相同的目的IP地址，路由器上的NAT转换表，并且在表项中包含了端口号及其IP地址，使路由器讲某个分组转发给内容主机 NAT穿越和通用即插即用(UPnP) UPnP是一种允许主机发现和配置邻近NAT的协议 4.3.5 IPv6 IPv6数据报 扩大的地址容量 IPv6将IP地址长度从32比特增加到128比特 IPv6引入了一种任播地址的新型地址，可以是数据报交付给一组主机中的任意一个 简化高效的40字节首部:形成的40字节定长首部允许路由器更快地处理IP数据报 流标签:具有流定义 IPv4向IPv6的迁移 建隧道:两台IPv6路由器之间的IPv4路由器的集合称为隧道 借助于隧道，在隧道发送端的IPv6节点可将IPv6的数据报放在一个IPv4数据报的数据字段中 4.4 通用转发和SDN 将基于目的地转发的特征总结为两个步骤 查找目的IP地址(“匹配”) 然后将分组发送到有特定输出端口的交换结构(“动作”) 匹配加动作转发表在OpenFlow中称为流表，表项包括 首部字段值的集合 计数器集合 当分组匹配流表项时所采取的动作集合 4.4.1 匹配 11个分组首部字段和入端口ID，该ID能被OpenFlow 1.0中的匹配加动作规则所匹配 到达一台分组交换机的一个链路层（第二层）帧将包含一个网络层（第三层）数据报作为其有效载荷，该载荷通常依次将包含一个运输层（第四层）报文段 OpenFlow的匹配抽象允许对来自三个层次的协议首部所选择的字段进行匹配 源和目的MAC地址是与帧的发送和接收接口相关联的链路层地址；通过基于以太网地址而不是IP地址进行转发，OpenFlow使能的设备能够等价于路由器（第三层设备）转发数据报以及交换机（第二层设备）转发帧。以太网类型字段对应于较高层协议（例如IP），利用该字段分解该帧的载荷，并且VLAN字段与所谓虚拟局域网相关联 入端口是指分组交换机上接收分组的输入端口 4.4.2 动作 每个流表项都有零个或多个动作列表，决定了应用与流表项匹配的分组的处理 若有多个动作，则按在表中规定的次序执行 其中最为重要的动作可能是 转发 丢弃 修改字段 5 网络层:控制平面 转发表和流变计算，维护和安装的方法 每路由器控制：在每台路由器中运行一种路由选择算法的情况，每台路由器中都包含转发和路由功能 逻辑集中式控制：逻辑集中式控制器计算并分发转发表以供每台路由器使用 5.2 路由选择算法 用图来形式化描述路由选择问题 图G=(N,E)G=(N,E)G=(N,E)是一个N个节点和E条边的集合，其中每条边是取自N的一对节点 在网络层路由选择的环境中，图中的节点表示路由器(做出分组转发决定的点) 连接节点的边表示路由器之间的物理链路 最低开销路径问题:找出源和目的地之间具有最低开销的一条路 最低开销路径就是最短路径，及在源和目的地之间具有最小链路数量的路径 路由选择算法的分类 集中式路由选择算法 具有关于连通性和链路开销方面的完整信息 具有全局状态信息的算法称为链路状态(LS)算法 分散式路由选择算法 路由器以迭代，分布式的方式计算出最低开销路径 距离向量(DV)算法的分散式路由选择算法 静态路由选择算法,动态路由选择算法 负载敏感算法 5.2.1 链路状态路由选择算法 在链路状态算法中，网络拓扑和所有的链路开销都是一致的，可用作LS算法的输入 链路状态路由选择算法也叫做Dijkstra算法 在初始化步骤，从u到与其直接相连的邻居v、x、w的当前已知最低开销路径分别初始化为2、1和5。特别值得注意的是，到w的开销被设为5，因为这是从u到w的直接（一跳）链路开销。到y与z的开销被设为无穷大，因为它们不直接与u连接 在第一次迭代中，观察那些还未加到集合N＇中的节点，并且找出在前一次迭代结束时具有最低开销的节点。那个节点便是x，其开销是1，因此x被加到集合N＇中。于是LS算法中的第12行中的程序被执行，以更新所有节点v的D（v），产生表5-1中第2行（步骤1）所示的结果。到v的路径开销未变。经过节点x到w（在初始化结束时其开销为5）的路径开销被发现为4。因此这条具有更低开销的路径被选中，且沿从u开始的最短路径上w＇的前一节点被设为x。类似地，到y（经过x）的开销被计算为2，且该表也被相应地更新 在第二次迭代时，节点v与y被发现具有最低开销路径（2），并且我们任意改变次序将y加到集合N＇中，使得N＇中含有u、x和y。到仍不在N＇中的其余节点（即节点v、w和z）的开销通过LS算法中的第12行进行更新 如此等等 链路状态算法在最差情况下复杂性为O(n2)O(n^2)O(n2) 5.2.2 距离向量路由选择算法 距离向量算法是一种迭代器，异步的和分布式的算法 每个节点都要从一个或多个直接相连邻居接收某些信息，执行计算，然后将器计算结果分发给邻居 此过程一直要持续到邻居之间无更多信息要交换为止 不要求所有节点相互之间步伐一致地操作 最低开销与Bellman_Ford方程dx(y)=minvc(x,v)+dv(y),minv是对x地所有邻居的d_x(y) = min_v { c(x,v) + d_v(y) },min_v是对x地所有邻居的dx​(y)=minv​c(x,v)+dv​(y),minv​是对x地所有邻居的 基本思想 每个节点x以Dx(y)D_x(y)Dx​(y)开始，对在N中的所有结点y，估计从x到y的最低开销路径的开销 令Dx=[Dy:y∈N]D_x = [D_y:y \\in N]Dx​=[Dy​:y∈N]是节点x的距离向量，该向量是从x到在N中所有其他节点y的开销估计向量 使用DV算法，每个节点x维护下列路由选择信息 对于每个邻居v，从x到直接相连邻居v的开销为c(x,v)c(x,v)c(x,v) 节点x的距离向量，即Dx=[Dy:y∈N]D_x = [D_y:y \\in N]Dx​=[Dy​:y∈N]，包含了x到N中所有目的地y的开销估计值 它的每个邻居的距离向量，即对x的每个邻居v有Dv=[Dv:y∈N]D_v = [D_v:y \\in N]Dv​=[Dv​:y∈N] 在该分布式，异步算法中，每个节点不时地向它的每个邻居发送它的距离向量副本 当节点x从任何一个邻居w接收到一个新距离向量，它保存w的距离向量，然后使用dx(y)=minvc(x,v)+dv(y)d_x(y) = min_v { c(x,v) + d_v(y) }dx​(y)=minv​c(x,v)+dv​(y)方程更新自己的距离向量 如果节点x的距离向量因这个变化步骤而改变，节点x接下来将向它的每个邻居发送其更新后的距离向量，继而让所有邻居更新自己的距离向量 每个开销估计Dx(y)收敛到dx(y)D_x(y) 收敛到 d_x(y)Dx​(y)收敛到dx​(y) DV算法只需要两次迭代就达到了静止状态 在x与y之间开销减少的好消息通过网络得到了迅速传播 关于链路开销增加的坏消息传播很慢 LS与DV算法的比较 在DV算法中，每个节点仅与它直接相连的邻居交谈，但为其邻居提供了从自己到网络中所有其他节点的最低开销估计 LS算法需要全局信息 报文复杂性 LS算法要发送O(∣N∣∣E∣)O(|N||E|)O(∣N∣∣E∣)的报文 DV算法要求在每次迭代时，在两个直接相连邻居之间交换报文 当链路开销改变时，DV算法仅当在新的链路开销导致与该链路相连节点的最低开销路径发生改变时，才传播以改变的链路开销 收敛速度 LS算法的实现时一个要求O(∣N∣∣E∣)O(|N||E|)O(∣N∣∣E∣)个报文的O(N2)O(N^2)O(N2)算法 DV算法收敛较慢，且在收敛时会遇到路由选择环路，还会遭遇无穷计数问题 健壮性 5.3 因特网中自治系统内部的路由选择:OSPF 自治系统:AS 开放最短路有限(OSPF) 链路状态协议，使用洪泛链路状态信息和Dijkstra最低开销路径算法 使用OSPF，一台路由器构建了一幅关于整个自治系统的完整拓扑图。于是，每台路由器在本地运行Dijkstra的最短路径算法，以确定一个以自身为根节点到所有子网的最短路径树 使用时，路由器向自治系统内所有其他路由器广播路由选择信息。每当一条链路的状态发生变化，路由器就会广播链路状态信息。即使链路状态未发生变化，也要周期性地广播链路状态 OSPF通告包含在OSPF报文中，该OSPF报文直接由IP承载，对OSPF其上层协议地值未89 OSPF的优点 安全 多条相同开销的路径 对单播与多播路由选择的综合支持 支持在单个AS中的层次结构 5.4 ISP之间的路由选择:BGP OSPF是一个AS内部路由选择协议 当在相同AS内的源和目的地之间进行分组选路时，分组遵循的路径完全由AS内路由选择协议所决定 因为AS间路由选择协议涉及多个AS之间的协调，AS通信必须运行相同的AS间路由选择协议 在因特网中，所有的AS运行相同的AS间路由选择协议，称为边界网关协议(BGP) BGP是一种分布式和异步的协议 5.4.1 BGP的作用 作为AS间的路由选择协议，BGP为每台路由器提供了一种完成以下任务的手段 从邻居AS获得前缀的可达性信息 确定到该前缀的最好的路由器 5.4.2 通过BGP路由信息 每台路由器要么是一台网关路由器，要么是一台内部路由器 网关路由器是一台位于AS边缘的路由器，直接连接到在其他AS中的一台或多台路由器 内部路由器仅连接在它自己AS中的主机和路由器 在BGP中，每对路由器通过使用179端口的半永久TCP连接交换路由选择信息 每条直接连接以及所有通过该连接发送的BGP报文，称为BGP连接 跨越两个AS的BGP连接称为外部BGP(eBGP) 相同AS中的两台路由器之间的BGP会话称为内部BGP(iBGP) iBGP连接并不总是与物理链路对应 5.4.3 确认最好的路由 当路由器通过BGP连接通告前缀时，它在前缀中包括一些BGP属性 前缀及其属性称为路由 两个重要的属性是AS-PATH和NEXT-HOP AS-PATH属性包含了通过已经通过的AS的列表 AS-PATH属性还用来检测和防止通过环路 NEXT-HOP是AS-PATH起始的路由器的接口IP的地址 热土豆路由选择 使用热土豆路由选择，选择的路由到开始改路由的NEXT-HOP路由器具有最小的开销 路由选择算法 对于任何给定目的地前缀，进入BGP的路由选择算法的输入是到某前缀的所有路由的集合，该前缀是已被路由器学习和接受的 如果仅有一条路由，BGP则显然选择该路由 如果到相同的前缀有两条或多条路由，则顺序调用消除规则直到余一条路由 路由被指派一个本地偏好值作为其属性之一 从余下的路由中，将选择具有最短AS-PATH的路由 从余下的路由中使用热土豆路由选择 若还剩余多条路由，使用BGP标识符选择路由 5.4.4 IP任播 BGP还被用于实现IP任播服务，该服务通常用在DNS中 5.5 SDN控制平面 SDN体系结构的4个关键特征 基于流的转发 数据平面与控制平面分离 网络控制功能 可编程的网络 SDN控制器的功能大体分为3个层次 通信层:SDN控制器和受控网络设备之间的通信 网络范围状态管理层 对于网络控制应用程序层的接口 OpenFlow协议运行在TCP之上，使用6653的默认端口号 6 链路层和局域网 6.1 链路层概述 将运行链路层协议的任何设备称为节点 沿通信路径相邻节点的通信信道称为链路 为了将一个数据报从源主机传输到目的主机，数据报必须通过沿端到端路径上的各段链路传输 在通过特定的链路时，传输节点将数据报封装在链路层帧中，并将该帧传送到链路中 6.1.1 链路层提供的服务 尽管任一链路层的基本服务都是将数据报通过单一通信链路从一个节点移动到相邻节点，但所提供的服务细节能够随着链路层协议的不同而变化 链路层提供的服务 成帧 链路接入 **媒体控制访问(MAC)**协议规定了帧在链路上传输的规则 可靠交付 差错检测和纠正 6.1.2 链路层在何处出现 链路层的主体部分是在网络适配器中实现的，网络适配器有时也称为网络接口卡 位于网络适配器核心的是链路层控制器，该控制器通常是一个实现了许多链路层服务的专用芯片 在发送端，控制器取得了由协议栈较高层生成并存储在主机内存中的数据报，在链路层帧中封装该数据报，然后遵循链路接入协议将该帧传进通信链路中 在接收端，控制器接受了整个帧，抽取出网络层数据报 如果链路层执行差错检测，则需要发送控制器在该帧的首部设置差错检测比特，由接收控制器执行差错检测 6.2 差错检测和纠正计数 比特级差错检测和纠正 奇偶校验，检测和方法和循环冗余检测 6.2.1 奇偶校验 单个奇偶校验位 在偶校验方案中，发送方只需包含一个附加的比特，选择它的值，使得这d+1比特中1的总数是偶数 二维奇偶校验方案 D中的d个比特被划分为i行j列。对每行和每列计算奇偶值。产生的i+j+1奇偶比特构成链路层帧的差错检测比特 包含比特值改变的列和行的校验值都将会出现差错 接收方不仅可以检测到出现了单个比特差错的事实，而且能利用差错的索引来实际识别发生差错的比特并纠正 6.2.2 检验和方法 将k比特整数加起来，并且用得到的和作为差错检测比特 接收方通过对接收的数据的和取反码，并且检测其结果是否全1比特来检测检验和 为什么运输层使用检验和而链路层使用CRC 运输层通常是在主机中作为用户操作系统的一部分用软件实现的 运输层差错检测用软件实现，采用简单而快速如检验和方案是重要的 链路层的差错检测在适配器中用专用的硬件实现，能够快速执行更复杂的CRC操作 6.2.3 循环冗余检测 基于循环冗余检测(CRC)编码,也称为多项式编码 该编码能够将要发送的比特串看作系数是0和1的一个多项式，对比特串的操作被解释为多项式算术 考虑d比特的数据D，发送节点要将它发送给接收节点 发送方和接收方首先必须协商一个r+1比特模式，称为生成多项式 要求G的最高有效位的比特(最左边)是1 CRC编码的关键思想 对于一个给定的数据段D，发送方要选择r个附加比特R，并将它们附加到D上，使得得到的d+r比特模式用模2算数恰好能被G整除 进行差错检测的过程:接收方用G去除接收到的d+r比特。如果余数非零，则出现了差错；否则认为数据正确而被接收 CRC计算采用模2运算，在加法中不进位，在减法中不借位 等价与按位异或操作 求R公式D×2rXORR=nG⇒R=remainderD×2rG,remainder为取余数D \\times 2^r XOR R = nG \\Rightarrow R=remainder\\frac{D \\times 2^r}{G},remainder为取余数D×2rXORR=nG⇒R=remainderGD×2r​,remainder为取余数 6.3 多路访问链路和协议 两种类型的网络链路 点对点链路:由链路一端的单个发送方和链路另一端的单个接收方组成 广播链路:能让多个发送和接收节点都连接相同的，单一的共享的广播信道上 所有的节点都能够传输帧，所以多个节点可能会同时传输帧 发生这种情况时，所有节点同时接到多个帧 传输的帧在所有的接收方处发生碰撞 碰撞发生时，没有一个接收节点能够有效地获得任何传输的帧 多路访问协议划分为3种类型:信道划分协议,随机接入协议和轮流协议 6.3.1 信道划分协议 时分多路复用(TDM) 频分多路复用(FDM) 码分多址(CDMA) 6.3.2 随机接入协议 时隙ALOHA ALOHA 载波侦听多路访问(CSMA) 具有碰撞检测的载波侦听多路访问(CSMA/CD) 6.3.3 轮流协议 两种轮流协议 轮询协议 要求节点之一被指定为主节点，主节点以循环的方式轮询每个节点 主节点首先向节点1发送一个报文，告诉它能够传输帧的最多数量 在节点1传输率某些帧后，主节点告诉节点2能够传输的帧的最多数量 轮询协议消除了碰撞和空时隙，提高了效率 但引入轮询时延 若主节点有故障，整个信道变得不可操作 令牌传输协议 没有主节点，一个称为令牌的小的特殊帧在节点之间以某种固定的次序进行交换 6.4 交换因特网 6.4.1 链路层寻址和ARP MAC地址 并不是主机或路由器具有链路层地址，而是它们的适配器具有链路层地址 链路层交换机的任务是在主机与路由器之间承载数据报 主机或路由器不必明确地将帧寻址到其间的交换机 链路层地址称为LAN地址，物理地址，MAC地址 对于大多数局域网(包括以太网和802.11无线局域网)而言，MAC地址长度为6字节，共有2482^48248个MAC地址 没有两块适配器具有相同的地址 分配地址的方式:固定MAC地址的前24比特，然后公司自己分配后24个比特 当某适配器要向某些目的适配器发送一个帧时，发送适配器将目的适配器的MAC地址插入到该帧中，并且将该帧发送到局域网中 当适配器接收到一个帧时，将检查该帧中的目的MAC地址是否与自己的MAC地址匹配 若匹配，该适配将提取封装的数据报，并将其沿协议栈向上传递 若不匹配，适配器丢弃该帧 若需要让局域网上所有其他适配器接收并处理打算发送的帧，发送适配器在该帧的目的地址字段中插入一个特殊的MAC广播地址(FF-FF-FF-FF-FF-FF) 保持各层独立 局域网是为任意网络层协议而设计的，而不只是用于IP和局域网 若适配器被指派IP地址而不是中性的MAC地址，则适配器将不能够方便地支持其他网络层协议 地址解析协议(ARP):存在网络层地址和链路层地址，需要在它们之间进行转换 发送主机使用ARP确认IP地址的目的主机的MAC地址 在发送主机中的ARP模块将取在相同局域网上的任何IP地址作为输入，然后返回相应的MAC地址 ARP将一个IP地址解析为一个MAC地址，和DNS类似，DNS将主机名解析为IP地址 每台主机或路由器在其内存中具有一个ARP表，包含IP地址到MAC地址的映射关系，并包含一个寿命值(TTL)值，指示了从表中删除每个映射的时间 ARP解析的过程 首先，发送方构造一个称为ARP分组的特殊分组 一个ARP分组有几个字段，包括发送和接收IP地址和MAC地址 ARP查询分组和响应分组都具有相同的格式 查询分组的目的是询问子网上所有其他主机和路由器，以确定对于要解析的IP地址的MAC地址 主机向适配器传递一个ARP查询分组，并且指示适配器应该用MAC广播地址(FF-FF-FF-FF-FF-FF)来发送这个分组 适配器在链路层帧中封装这个ARP分组，用广播地址作为帧的目的地址，并将该帧传输进子网中 有趣的事情:查询ARP报文是在广播帧中发送的，响应ARP报文在一个标准帧中发送 一个ARP分组封装在链路层帧中，因而在体系结构上位于链路层之上 一个ARP分组具有包含链路层地址的字段，因而可认为是链路层协议，但也包含网络层地址，因而也可以认为是网络层协议 发送数据报到子网之外 对于帧来说，MAC地址是路由器接口的适配器地址 在子网上的路由器适配器看到该链路层帧是向它寻址的，因此把帧传递给了路由器的网络层 6.4.2 以太网 在安装中，主机(和路由器)直接用双绞对铜线与一台集线器相连 集线器是一种屋里层设备，作用于各个比特而不是作用与帧。当表示一个0或一个1的比特到达一个接口时，集线器只是重新生成这个比特，将其能量强度放大，并将该比特向其他所有接口传输出去 以太网帧结构 考虑从一台主机向另一台主机发送一个IP数据报，且这两台主机在相同的以太局域网上。(尽管以太网帧的负载是一个IP数据报，但我们注意到以太网帧也能够承载其他网络层分组) 设发送适配器A的MAC地址是AA-AA-AA-AA-AA-AA，接收适配器B的MAC地址是BB-BB-BB-BB-BB-BB。发送适配器在一个以太网帧中封装了一个IP数据报，并把该帧传递到物理层。接收适配器从物理层收到这个帧，提取出IP数据报，并将该IP数据报传递给网络层 6个字段 数据字段(46-1500字节),承载IP数据报，以太网的最大传输单元(MTU)是1500字节，数据字段的最小长度是46字节 目的地址(6字节),包含目的适配器的MAC地址 当适配器B收到一个以太网帧，该帧的目的地址无论是BB-BB-BB-BB-BB-BB，还是MAC广播地址，都将该帧的数据字段的内容传递给网络层;若它收到了具有任何其他MAC地址的帧，则丢弃 源地址(6字节),包含了传输该帧到局域网上的适配器上的MAC地址 类型字段(2字节) CRC(4字节),循环冗余检测字段的目的是使得接收适配器检测帧中是否引入了差错 前同步码(8字节) 以太网帧以一个8字节的前同步码字段开始 该前同步码的前7个字节都是10101010，最后一个字节是10101011 前7个字节用于唤醒接收适配器，并将其时钟和发送方的时钟同步 为什么时钟不同步?适配器A的目的是根据以太网类型的不同，分别以10Mbps,100Mbps,1Gbps的速率传输帧 适配器只需通过锁定前同步码的前7字节的比特，就能锁定适配器的时钟 前同步码的第8个字节的最后两个比特警告适配器有重要的内容到达 所有的以太网计数都向网络层提供无连接，不可靠服务 以太网技术 物理媒介仅承载以太网流量 所有的802.3标准都适用于基带以太网 通过使用转发器能够得到更长的运行距离，而转发器是一种物理层设备，能在输入端接收信号并在输出端再生该信号 吉比特以太网为IEEE802.3z,完成的工作 使用标准以太网帧结构，并且向后兼容10BASE-T与100BASE-T技术 允许点对点链路以及共享的广播信道 使用CSMA/CD来共享广播信道 对于点对点信道，允许在两个方向上以40Gbps全双工操作 6.4.3 链路层交换机 交换机的任务是接收入链路层帧并将它们转发到出链路 交换机自身对子网中的主机和路由器是透明的 某主机/路由器向另一个主机/路由器寻址一个帧(而不是向交换机寻址该帧)，顺利地将该帧发送进局域网，并不知道某交换机将会接收该帧并将它转发到另一个节点 交换机转发和过滤 过滤是决定一个帧应该转发到某个接口还是应当将其丢弃的交换机功能 转发是决定一个帧应该被导向哪个接口，并把该帧移动到那些接口的交换机功能 交换机的过滤和转发借助于交换机表 该交换机表包含某局域网上某些主机和路由器的但不必是全部的表项。交换机表中的一个表项包含：一个MAC地址;通向该MAC地址的交换机接口;表项放置在表中的时间 交换机过滤和转发的3种可能的情况 表中没有对于DD-DD-DD-DD-DD-DD的表项。在这种情况下，交换机向除接口x外的所有接口前面的输出缓存转发该帧的副本。换言之，如果没有对于目的地址的表项，交换机广播该帧 表中有一个表项将DD-DD-DD-DD-DD-DD与接口x联系起来。在这种情况下，该帧从包括适配器DD-DD-DD-DD-DD-DD的局域网网段到来。无须将该帧转发到任何其他接口，交换机通过丢弃该帧执行过滤功能即可 表中有一个表项将DD-DD-DD-DD-DD-DD与接口y≠x联系起来。在这种情况下，该帧需要被转发到与接口y相连的局域网网段。交换机通过将该帧放到接口y前面的输出缓存完成转发功能 自学习 交换机的表是自动，动态和自治地建立的，交换机是自学习的，是即插即用设备 能力的实现方式 交换机表初始为空 对于每个接口接收到的每个入帧，交换机在其表中存储 在该帧源地址字段中的MAC地址 该帧到达的接口 当前时间 如果在一段时间(老化期)后，交换机没有接收到以该地址作为源地址的帧，就在表中删除这个地址 链路层交换机的性质 消除碰撞 异质的链路 管理 交换机和路由器的比较 路由器是使用网络层地址转发分组的存储转发分组交换机 尽管交换机是一个存储转发分组交换机，而路由器是第三层的分组交换机，使用“匹配加动作”的现代交换机能够转发基于帧的目的MAC地址的第二层帧，也能转发使用数据报目的IP地址的第三层数据报 交换机的优点 即插即用 具有相对高的分组过滤和转发速率 处理高至第二层的帧，而路由器必须处理高至第三层的数据报 交换网络的活跃拓扑限制为一棵生成树 交换机对于广播风暴并不提供给任何保护措施 网络寻址通常是分层次的，即使当网络种存在冗余路径时，分组通常也不会通过路由器循环 6.4.4 虚拟局域网 使用支持虚拟局域网(VLAN)处理的难题 缺乏流量隔离 交换机的无效使用 管理用户","categories":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/categories/Basic/"}],"tags":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/tags/Basic/"}]},{"title":"数据结构与算法","slug":"计算机基础知识/数据结构与算法","date":"2022-03-04T13:27:11.000Z","updated":"2023-04-09T13:39:53.019Z","comments":true,"path":"2022/03/04/计算机基础知识/数据结构与算法/","link":"","permalink":"http://jay1060950003.github.io/2022/03/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","excerpt":"引言 数据结构与算法的学习笔记 包含Leetcode刷题笔记","text":"引言 数据结构与算法的学习笔记 包含Leetcode刷题笔记 1 数据结构绪论 数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合 数据元素：是组成数据的，有一定意义的基本单位，在计算机中通常作为整体处理，也被称为记录 数据项：一个数据元素可以由若干个数据项组成 数据项是数据不可分割的最小单位 数据对象：是性质相同的数据元素的集合，是数据的子集 数据结构：是相互之间存在一种或多种特定关系的数据元素的集合 不同数据元素之间不是独立的，而是存在特定的关系，这种关系叫做结构 逻辑结构：是指数据对象中数据元素之间的相互关系 集合结构：集合结构中的数据元素除了同属于一个集合外，之间没有其他关系 线性结构：线性结构中的数据元素之间是一对一的关系 树形结构：树形结构中的数据元素之间存在一种一对多的层次关系 图形结构：图形结构中的数据元素之间是多对多的关系 物理结构：是指数据的逻辑结构在计算机中的存储形式(存储结构应正确的反映数据元素之间的逻辑关系) 顺序存储结构：把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的 链式存储结构：把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的(需要用一个指针存放数据元素的地址) 逻辑结构是面向问题的，物理结构是面向计算机的 数据类型：是指一组性质相同的值的集合及定义在此集合上的一些操作总称 抽象数据类型(ADT)：一个数学模型及定义在该模型上的一组操作 抽象数据类型体现了程序设计中问题分解,抽象和信息隐藏的特性 2 算法 定义：算法是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作 特性 输入输出：算法具有零个或多个输入，至少有一个或多个输出 有穷性：指算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且一个步骤在可接受的时间内完成 确定性：算法的每一个步骤都具有确定的含义，不会出现二义性 可行性：算法的每一步都必须是可行的，也就是说每一步都能够通过执行有限次数完成 算法设计的要求： 正确性 可读性 健壮性：当输入数据不合法是，算法也能做出相关处理，而不是产生异常或莫名其妙的结果 时间效率高和存储量低 算法效率的度量方法 事后统计法 事前分析估算法：在计算机程序编制前，依据统计方法对算法进行估算 一个程序的运行时间，依赖于算法的好坏和问题的输入规模(输入量的多少) 在分析时，不关心那些循环索引的递增和循环终止条件，变量声明，打印结果等操作 最终在分析程序的运行时间时，最重要的时把程序看成独立于程序设计语言的算法或一系列步骤 函数的渐近增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n&gt;N，f(n)总是比g(n)大，那么我们就说f(n)的增长渐近快于g(n) 可以忽略加法常数 与最高次项相乘的常数并不重要 最高次项的指数大的，函数随着n的增长，结果也会增长更快 判断一个算法的效率时，函数中的常数和其他次要项常常可以忽略，而更应关注主项（最高阶项）的阶数 算法的时间复杂度的定义：在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作T(n)=O(f(n))。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 ==大O记法：使用大写O()来体现算法时间复杂度的记法 随着n的增加，T(n)增长最慢的算法为最优算法 O(1)为常数阶，O(n)为线性阶，$ O(n^2) $叫做平方阶 推导大O阶： 用常数1取代运行时间中的加法常数 在修改后的运行次数函数中，只保留最高阶项 如果最高阶项存在且其系数不是1，则去除与这个项相乘的系数 运算法则： 大O加法法则：T(n)=T1(n)+T2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n)))T(n)=T_1(n)+T_2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n)))T(n)=T1​(n)+T2​(n)=O(f(n))+O(g(n))=O(max(f(n),g(n))) 大O乘法法则：T(n)=T1(n)×T2(n)=O(f(n)×g(n))T(n)=T_1(n) \\times T_2(n)=O(f(n) \\times g(n))T(n)=T1​(n)×T2​(n)=O(f(n)×g(n)) 常见的阶数 常数阶O(1) 线性阶O(n) 对数阶O(logn)O(log n)O(logn) 平方阶O(n2)O(n^2)O(n2) $ O(1)&lt;O(log n)&lt;O(n)&lt;O(nlog n)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn)$ 算法空间复杂度：通过计算算法所需的存储空间实现， 计算公式：S(n)=O(f(n))S(n)=O(f(n))S(n)=O(f(n)),其中n为问题的规模，f(n)为语句关于n所占存储空间的函数 一般情况下，一个程序在机器上执行时，除了需要存储程序本身的指令、常数、变量和输入数据外，还需要存储对数据操作的存储单元。若输入数据所占空间只取决于问题本身和算法无关，这样只需要分析该算法在实现时所需的辅助单元即可 12345678910111213141516171819202122// 线性阶for(int i=0;i&lt;n;i++)&#123; // code&#125;// 对数阶for(int i=0;i&lt;n;i++)&#123; i = i*2; // code&#125;// 平方阶for(int i=0;i&lt;n;i++)&#123; for(int j=0;j&lt;n;i++)&#123; // code&#125;for(int i=0;i&lt;n;i++)&#123; for(int j=i;j&lt;n;i++)&#123; // code&#125; 3 线性表 线性表：零个或多个数据元素的有限序列 是一个序列(元素之间是有顺序的) 线性表强调有限性 ai−1a_{i-1}ai−1​是aia_{i}ai​的直接前驱元素，ai+1a_{i+1}ai+1​是aia_{i}ai​的直接后继元素 线性表元素的个数n定义为线性表的长度，当n=0时，称为空表 aia_{i}ai​是第iii是个数据元素，称iii为数据元素aia_{i}ai​在线性表中的位序 当传递一个参数给函数时，这个参数会不会在函数内被改动了决定了使用什么参数形式 如果需要被改动，则需要传递指向这个参数的指针 如果不用被改动，可以直接传递这个参数 3.4 线性表的顺序存储结构 线性表的顺序存储结构：指的是用一段地址连续的存储单元依次存储线性表的数据元素 顺序存储结构的三个属性： 存储空间的起始位置：数组data，他的存储位置就是存储空间的存储位置 线性表的最大存储容量：数组长度MAXSIZE 线性表的当前长度：length 数组长度与线性表长度的区别 数组的长度时存放线性表的存储空间的长度，存储分配后这个量一般是不变的 动态分配数组长度会带来性能上的损耗 线性表的长度是线性表中数据元素的个数，随着线性表插入和删除操作的进行，其长度可变 在任意时刻，线性表的长度应该小于数组的长度，分配的数组空间要大于等于当前线性表的长度 假设每个数据元素占用c个存储单元，对于第i个数据元素aia_iai​的存储位置为LOC(ai)=LOC(a1)+(i−1)∗cLOC(a_i)=LOC(a_1)+(i-1)*cLOC(ai​)=LOC(a1​)+(i−1)∗c 线性表的存取时间性能为O(1)，具有这一特点的存储结构称为随机存取结构 顺序存储结构的操作 获得元素操作 插入操作 算法思路： 如果插入位置不合理，抛出异常 如果线性表长度大于等于数组长度，则抛出异常或者动态增加容量 从最后一个元素开始向前遍历到第i个位置，分别将他们都向后移动一个位置 将要插入元素填入位置处 表长加1 删除操作 算法思路： 如果删除位置不合理，抛出异常 取出删除元素 从删除元素位置开始遍历到最后一个元素位置，分别将他们都向前移动一个位置 表长加1 线性表的顺序存储结构，读数据时，时间复杂度为O(1);而插入或删除时，时间复杂度为O(n) 线性表的顺序存储结构的优缺点 优点 无需为表示表中元素之间的逻辑关系而增加额外的存储空间 可以快速地存取表中任一位置的元素 缺点 插入和删除元素需要移动大量元素 当线性表长度变化大时，难以确定存储空间的容量 造成存储空间的碎片 3.6 线性表的链式存储结构 链式线性表为解决顺序线性表插入和删除需要移动大量元素问题 链式存储结构的定义： 为了表示数据元素aia_iai​与数据元素ai+1a_{i+1}ai+1​的逻辑关系 数据元素aia_iai​，除了存储本身的信息外，还需要存储一个指示其直接后继的信息 存储数据元素信息的域称为数据域 存储直接后继位置的域称为指针域，指针域中存储的信息称为指针或链 这两部分信息组成数据元素aia_iai​的存储映像，称为结点 n个结点链结称一个链表，即为线性表的链式存储结构 链表的每个结点中只包含一个指针域，所以叫做单链表 链表的第一个结点的存储位置为头指针 规定线性链表的最后一个结点指针为NULL 为了方便操作，在单链表的第一个结点前附设一个结点，称为头结点 头结点的指针域存储指向第一个结点的指针，其数据域可存线性表长度等公共信息 头指针和头节点的异同 头指针 指链表指向第一个结点的指针，若链表包含头结点，则为指向头结点的指针 具有标志作用 无论链表是否为空，头指针均不为空，头指针时链表的必备元素 头结点 为了统一操作而设立的，放在第一元素之前，数据域一般无实际意义 不一定是链表的必备元素 结点由存放数据元素的数据域和存放后继结点的地址的指针域组成 单链表的读取：获得链表第i个数据的算法思路 声明一个指针p指向链表第一个结点，初始化j从1开始； 当j &lt; i时，就遍历链表，让p的指针向后移动，不断指向下一个结点，j累加1 若到链表末尾p为空，则说明第i个结点不存在 否则查找成功，返回结点p的数据 单链表的插入：第i个数据插入结点的算法思路： 声明一指针p执行链表表头结点，初始化j从1开始 当j &lt; i时，就遍历链表，让p的指针向后移动，不断指向下一个结点，j累加1 若到链表末尾p为空，则说明第i个结点不存在 否则查找成功，在系统生成一个空结点s 将数据元素e赋值给 s-&gt;data 单链表的插入标准语句：s-&gt;next=p-&gt;next;p-&gt;next=s; 返回成功 单链表的删除：第i个数据删除结点的算法思路： 声明一指针p执行链表表头结点，初始化j从1开始 当j &lt; i时，就遍历链表，让p的指针向后移动，不断指向下一个结点，j累加1 若到链表末尾p为空，则说明第i个结点不存在 否则查找成功，将欲删除的结点 p-&gt;next 赋值给 q 单链表的删除标准语句 p-&gt;next = q-&gt;next; 将q结点中的数据赋值给e，作为返回 释放q结点 返回成功 单链表的整表创建： 算法思路： 声明一指针p和计数器变量i 初始化一空链表L 让L的头结点的指针指向NULL，即建立一个带头结点的单链表 循环 生成一新节点赋值给p 随机生成一数字赋值给p的数据域 将p插入到头结点与前一结点之间 头插法：始终让新节点在第一的位置 尾插法：每个新节点都插在终端结点的后面 单链表的整表删除： 算法思路： 声明一指针p和q 将第一个结点赋值给p 循环 将下一个结点赋值给q 释放p 将q赋值给p 在程序设计中，需要考虑到结点不仅仅包含指针域还有数据域 3.11 单链表结构与顺序存储结构的优缺点 对比 时间性能 查找：顺序存储结构O(n);单链表O(n) 插入和删除： 顺序存储结构需要平均移动表长一般的元素,时间复杂度为O(n) 单链表在找出位置的指针后，插入和删除时间复杂度仅为O(1) 存储分配方式 顺序存储结构用一段连续存储单元依次存储线性表的数据元素 单链表采用链表存储结构，用一组任意的存储单元存放线性表的元素 空间性能 顺序存储结构需要预分配存储空间 单链表不需要分配存储空间 若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构 当线性表中的元素个数变化较大或根本不知道有多大时，最好用单链表结构 3.12 静态链表 用数组代替指针描述单链表，用数组描述的链表叫做静态链表 首先让数组的元素都是由两个数据域组成,data和cur 数组的每个下标都对应一个data和cur。数据域data，用来存放数据元素；cur相当于单链表中的next指针，存放该元素的后继在数组中的下标 ==通常把未被使用的数组元素称为备用链表 数组第一个元素，即下标为0的元素的cur存放备用链表的第一个结点的下标 数组的最后一个元素cur存放第一个有数值的元素的下标，相当于单链表中的头结点 当整个链表为空时，数组最后一个元素cur为0 静态链表的插入操作 在静态链表中，操作的是数组，不存在像动态链表的结点申请和释放问题，需要自己实现 为了辨明数组中哪些分量未被使用，解决的办法是将所有未被使用过的及已被删除的分量用游标链成一个备用的链表，每当进行插入时，便可以从备用链表上取得第一个结点作为待插入的新节点 静态链表的删除操作 静态链表的长度检测 静态链表的优缺点 优点：在插入和删除操作时，只需要修改游标，不需要移动元素，从而改进了在顺序存储结构中插入和删除操作需要移动大量元素的缺点 缺点：没有解决连续存储分配带来的表长难以解决的问题；失去了顺序存储结构随机存取的特性 3.13 循环链表 将单链表中终端结点的指针端由空指针改为指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称为循环链表 循环链表和单链表的主要差异：在循环的判断条件上，原来是判断p-&gt;next是否为空，现在则是p-&gt;next不等于头结点，则循环结束 3.14 双向链表 双向链表是在单链表的每个结点中，再设置一个指向其前驱结点的指针域 在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱 双向链表可以是循环表 4 栈和队列 4.2 栈的定义 栈是限定仅在表尾进行插入和删除操作的线性表 允许插入和删除一端称为栈顶，另一端称为栈底，不含任何数据元素的栈称为空栈 栈又称为后进先出的线性表，简称LIFO结构 注意事项： 首先栈是一个线性表，定义中是在线性表的表尾进行插入和删除操作，这里表尾是指栈顶，而不是栈底 栈底是固定的，最先进栈的只能在栈底 栈的插入操作，叫做进栈，也称压栈，入栈 栈的删除操作，叫做出栈，有的也叫做弹栈 4.3 栈的抽象数据类型 12345678910111213ADT 栈Data 同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。Operation InitStack(*S):初始化操作,建立一个空栈S DestroyStack(*S):若栈存在，则销毁它 ClearStack(*S):将栈清空 StackEmpty(S):若栈为空，返回true，否则返回false GetTop(S,*e)：若栈存在且非空，用e返回S的栈顶元素 Push(*S,e):若栈存在，插入新元素e到栈s中并称为栈顶元素 Pop(*S,*e):删除栈S中的栈顶元素，并用e返回其值 StackLength(S):返回栈S的元素个数endADT 4.4 栈的顺序存储结构及实现 栈的顺序存储是线性表顺序存储的简化，简称为顺序栈 下标为0的一端作为栈底比较好，因为首元素都在栈底，变化最小 定义top变量指示栈顶元素在数组中的位置 若栈的空间为 $StackSize = n $ 空栈时top=−1top = -1top=−1 栈满时top=StackSize−1=n−1top = StackSize-1 = n-1top=StackSize−1=n−1 栈的顺序存储结构，进栈操作和出栈操作时间复杂度为O(1) 4.5 两栈共享空间 数组有两个端点，两个栈有两个栈底，让一个栈的栈底为数组的始端，即下标为0处，另一个栈为数组的末端，即下标为数组长度n-1处。若两个栈如果增加元素，就是两端点向中间延伸 栈1为空时，top1等于-1 栈2为空时，top2等于n 若栈2为空，栈1的top1等于n-1，栈1满栈 若栈1为空，栈2的top2等于0，栈2满栈 top1+1=top2为满栈 使用这样的数据结构，通常都是当两个栈的空间需求有相反关系时，也就是一个栈增长时另一个栈在缩短的情况 4.6 栈的链式存储结构及实现 栈的链式存储结构，简称链栈 栈顶放在单链表的头部，对于链表来说，是不需要头结点 对于链栈来说，基本不存在栈满的情况 对于空栈来说，链表原定义是头指针指向空，那么链栈的空其实就是top=NULL的时候 栈的链式存储结构 进栈操作,出栈操作的时间复杂度均为O(1) 假设变量p用来存储要删除的栈顶结点，将栈顶指针下移移位，最后释放p即可 顺序栈与链栈，它们在时间复杂度上是一样的，均为O(1)，顺序栈需要事先确定一个固定的长度，可能会存在内存空间浪费的问题，但它的优势是存取时定位方便，而链栈则要求每个元素都有指针域，这同时也增加一些内存开销，但对于栈的长度无限制 如果栈的使用过程中元素变化不可预料，最好用链栈，反之如果变化在可控范围内，建议使用顺序栈 4.7 栈的作用，应用 栈的引入简化了程序设计的问题，划分了不同关注层次，使得思考范围缩小，更加聚焦需要解决的问题核心 应用 递归：斐波那契数列 四则运算表达式求值： 后缀表达式 规矩：从左到右遍历中缀表达式的每个数字和符号，若是数组就输出，即成为后缀表达式的一部分；若是符号，则判断其与栈顶符号的优先级，是右括号或优先级不高于栈顶符号（乘除优先加减）则栈顶元素依次出栈并输出，并将当前符号进栈，一直到最终输出后缀表达式为止 最重要的两部： 将中缀表达式转化为后缀表达式 将后缀表达式进行运算得出结果 4.10 队列的定义 队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表 队列是一种先进先出的线性表，简称FIFO，允许插入的一端称为队尾，允许删除的一端称为队头 4.12 循环队列 为了避免当只有一个元素时，队头和队尾重合使处理变得麻烦，所以引入两个指针，==front指针指向队头元素，rear指针指向队尾元素的下一个位置，当front等于rear时，此队列是空队列 但仍然存在假溢出问题，解决的办法就是后面满了，从头开始，也就是头尾相接的循环 把队列头尾相接的顺序存储结构称为循环队列 若队列的最大尺寸为QueueSize，循环列表的队列满的条件：(rear+1)%QueueSiza==front(rear+1)\\%QueueSiza==front(rear+1)%QueueSiza==front 通用的计算队列长度公式：(rear−front+QueueSize)%QueueSize(rear-front+QueueSize)\\% QueueSize(rear−front+QueueSize)%QueueSize 4.13 队列的链式存储结构及实现 队列的链式存储结构，其实就是线性表的单链表，只不过它只能尾进头出而已，简称为链队列 队头指针指向链队列的头结点，而队尾指针指向终端结点 队列的链式存储结构——入队操作 在链表尾部插入结点 队列的链式存储结构——出队操作 出队操作时，就是在头结点的后继节点出队，将头结点的后继改为它后面的结点，若链表除头结点外只剩一个元素，则需将rear指向头结点 循环队列与链队列的比较 时间上，其实它们的基本操作都是常数时间，即都为O(1)的，循环队列是实现申请好空间，使用期间不释放；链队列，每次申请和释放结点也会存在一些时间开销，如果入队出队频繁，则两者有细微差异 空间上，循环队列必须有一个固定的长度，所以有存储元素个数和空间浪费的问题；链队列，需要一个指针域，会有一定的空间开销，链队列更加灵活 5 串 串的定义：串是由零个或多个字符组成的有限序列，又叫字符串 串中的字符数目n称为串的长度，零个字符的串称为空串，它的长度为零，可以直接用双引号表示 串的大小比较： 给定两个串：s=a1a2...an,t=b1b2...bms=a_1a_2...a_n, t=b_1b_2...b_ms=a1​a2​...an​,t=b1​b2​...bm​，当满足以下条件之一时，s&lt;ts&lt;ts&lt;t n&lt;mn&lt;mn&lt;m,且ai&lt;bi(i=1,2,...n)a_i&lt;b_i(i=1,2,...n)ai​&lt;bi​(i=1,2,...n) 存在某个k&lt;=min(m,n)k&lt;=min(m,n)k&lt;=min(m,n),使得ai=bi(i=1,2,...k−1)a_i=b_i(i=1,2,...k-1)ai​=bi​(i=1,2,...k−1),ak&lt;bka_k&lt;b_kak​&lt;bk​ 串的存储结构： 串的顺序存储是用一组地址连续的存储单元来存储串中的字符序列的 按照预定的大小，为每个定义的串变量分配一个固定长度的存储区，一般是用定长数组来定义 定长数组，就存在一个预定义的最大串长度，一般可以将实际的串长度值保存在数组的0下标位置 串的链式存储结构，与线性表相似，但由于串结构的特殊性，结构中的每个元素数据是一个字符，如果也简单地应用链表存储串值，一个结点对应一个字符，会存在很大的浪费。 一个结点可以存放一个字符，也可以考虑存放多个字符，最后一个结点若是未被占满时，可以用&quot;#&quot;或其他非串值字符补全 一个结点存放多少个字符才合适就变得很重要，直接影响着串处理的效率，需要根据实际情况做出选择 串的链式存储结构除了在连接串与串操作时有一定方便之外，总的来说不如顺序存储灵活，性能也不如顺序存储结构好 5.6 朴素的模式匹配算法 对主串的每一个字符作为子串开头，与要匹配的字符串进行匹配，对主串做大循环，每个字符开头做T的长度的小循环，直到匹配成功或全部遍历完成为止 时间复杂度为O(n+m),其中n为主串长度,m为要匹配的子串长度，根据等概率原则，平均是(n+m)/2次查找，时间复杂度为O(n+m) 5.7 KMP模式匹配算法 KMP匹配算法：一个模式匹配算法，可以避免重复遍历的情况 在朴素的模式算法中，主串的i值是不断地回溯来完成的。分析后，这种回溯其实可以省略 T串的首字符与自身后面字符的比较，发现如果有相等字符，j值的变化就会不同。j值的变化与主串其实没有什么关系 j值的大小取决于当前字符之前的串的前后缀的相似度 在需要查找字符串之前，先对要查找的字符串进行分析，可以减少查找的难度，提高查找的速度 T串各个位置j值的变化定义为一个数组next，next的长度就是T串的长度 next[j]={−1,j=0max⁡{k∣1≤k≤j且t[0]…t[k−1]=t[j−k]…t[j−1]},集合非空0,其他情况.next[j]=\\{\\begin{array}{l}-1, \\quad j=0 \\\\\\max \\{k \\mid 1 \\leq k \\leq j { 且 } t[0] \\ldots t[k-1]=t[j-k] \\ldots t[j-1]\\}, \\quad { 集合非空 } \\\\0, \\quad { 其他情况 }\\end{array}.next[j]={−1,j=0max{k∣1≤k≤j且t[0]…t[k−1]=t[j−k]…t[j−1]},集合非空0,其他情况​. 算法实现整个算法的时间复杂度为O(n+m),相较于朴素模式匹配算法的O((n-m+1)*m)较好 ==KMP算法仅当模式与主串之间存在许多“部分匹配”的情况下才会具有较大优势 KMP算法进行改进，用首位next[i]的值代替与它相等的字符后续next[j]的值 改进的KMP算法，是在计算出next值得同时，如果a位字符与它next值指向的b位字符相等，则a位的nextval就指向b位的nextval值，如果不等则该a位的值就是它自己的next值 6 树 6.2 树的定义 树是n个结点的有限集。n=0时称为空树。在任意一颗非空树中，有且仅有一个特定的称为根的结点；当n&gt;1时，其他结点可分为m个互不相交的有限集，其中每一个集合本身优势一棵树，并且称为根的子树 n&gt;0时，根节点是唯一的 m&gt;0时，子树的个数没有限制，但它们一定时不相交的 结点拥有的子树称为结点度(degree)，度为0的结点称为终端结点；度不为0的结点称为非终端结点或分支结点。除根节点之外，分支结点也称为内部结点。树的度是树内各节点的度的最大值。 结点的子树的根称为该结点的孩子，相应，该结点称为孩子的双亲 同一个双亲的孩子之间互称兄弟 结点的祖先是从根到该结点所经历分支上的所有结点 以某结点为根的子树中的任一结点都称为该结点的子孙 树的层次从根开始定义起，根为第一层，树的孩子为第二层，双亲在同一层的结点互称为堂兄弟。树中结点的最大层次称为树的深度(depth) 如果将树中结点的各个子树看成从左到右有次序，不能互换的，则称概述为有序树 森林是m棵互不相交的树的集合 6.3 树的存储结构 双亲表示法 假设以一组连续空间存储树的结点，同时在每个节点中，附设一个指示器指示其双亲结点在数组中的位置，也就是说，每个结点除了知道自己是谁外，还知道它的双亲在什么位置。 data,parent data是数据域，存储结点的数据信息；parent是指针域，存储该结点的双亲在数组中的下标 根节点没有双亲，约定根节点的位置域(双亲的位置)设置为-1，根节点的下标为0开始 可以增加其他的域，如最左的孩子的域(长子域)，若没有长子域就设置为-1；右兄弟域等 孩子表示法 使用多重链表，每个结点有多个指针域，其中每个指针指向一棵子树的根节点，这种方法称为多重链表表示法 方案一：指针域的个数等于树的度(各个结点度的最大值)，浪费空间 方案二：将每个结点放到一个顺序存储结构的数组中，每个结点的孩子建立一个单链表 把每个结点的孩子结点排列起来，以单链表作为存储结构，则n个结点有n个孩子链表，若是叶子结点，则该单链表为空。然后n个头指针组成一个线性表，用顺序存储结构，存放进一个一维数组中 孩子结点 child next ,child为数据域用来存储某个结点在表头数组中的下标，next是指针域，用来存储下一个孩子结点的指针 表头结点：data firstchild ,data数据域存储某结点的数据信息,firstchild是头指针，存储该结点孩子链表的头指针 双亲孩子表示法：将双亲表示法和孩子表示法结合，在表头结点增加域 孩子兄弟表示法： 任何一个树，它的结点的第一个孩子如果存在就是唯一的，它的右兄弟存在即唯一，可以设置两个指针分别指向该结点的第一个孩子和此结点的兄弟 data firstchild rightsib 好处，将一个复杂的树转换为二叉树 6.5 二叉树的定义 二叉树是n个结点的有限集合，该集合或者为空集，或者由一个根节点和两棵互不相交的,分别为根节点的左子树和右子树的二叉树组成 特点： 每个结点最多由两棵子树，所以二叉树不存在度大于2的结点 左子树和右子树是有顺序的，次序不能任意颠倒 即使树中某结点只有一颗子树，也要区分他是左子树还是右子树 特殊的二叉树： 斜树：所有的结点都只有左子树的二叉树称为左斜树 满二叉树：在一颗二叉树中，如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树为满二叉树 完全二叉树：对于一颗具有n个结点的二叉树按层序编号，如果编号为i的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，则这棵二叉树成称为完全二叉树 特点 叶子结点只能出现在最下两层 最下层的叶子一定集中在左部连续位置 倒数第二层，若有叶子结点，一定都在右部连续位置 如果结点度为1，则该结点只有左孩子，不存在只有右孩子的情况 同样结点数的二叉树，完全二叉树的深度最小 二叉树的性质 在二叉树的第i层至多有2i−12^{i-1}2i−1个结点 深度为k的二叉树至多有2k−12^k-12k−1个结点 对于任何一棵二叉树T，如果其终端结点数为n0n_0n0​，度为2的结点数为n2n_2n2​，则n0=n2+1n_0=n_2+1n0​=n2​+1 具有n个结点的完全二叉树的深度为$ |\\log_2n |+1,|x|表示不大于x的最大整数$ 如果有一棵n个结点的完全二叉树有 如果i=1，则结点i是二叉树的根，无双亲；如果i&gt;1其双亲是结点∣i/2∣|i/2|∣i/2∣ 如果2i&gt;n，则结点i无左孩子；否则其左孩子的结点是2i 如果2i+1&gt;n，则该结点i无右孩子；否则其右孩子是结点2i+1 6.7 二叉树的存储结构 二叉树的顺序存储结构就是用一维数组存储二叉树中的结点，并且结点的存储位置，也就是数组的下标要能体现结点之间的逻辑关系 对于一般的二叉树，尽管层序编号不能反映其逻辑关系，但可以将其按照完全二叉树编号，将不存在的点设置为&quot;^&quot; 顺序结构一般只用于完全二叉树 二叉链表 二叉树的每个结点最多有两个孩子，所以设计一个数据域和两个指针域，将这样的链表称为二叉链表 6.8 遍历二叉树 二叉树的遍历是指从根节点触发，按照某种次序依次访问二叉树中的所有结点，使得每个结点都被访问一次且仅被访问一次 前序遍历 规则是若二叉树为空，则空操作返回，否则先访问根节点，然后前序遍历左子树，再前序遍历右子树 中序遍历 规则是若二叉树为空，则空操作返回，否则从根节点开始，中序遍历根节点的左子树，然后是访问根节点，最后中序遍历右子树 后序遍历 规则是若二叉树为空，则空操作返回，否则从左到右先叶子后结点的方式遍历左右子树，最后是访问根节点 层序遍历 规则是若二叉树为空，则空操作返回，否则从根节点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问 遍历算法在实现时按照递归算法进行实现，推导访问顺序时注意递归的思想 中序遍历将访问左孩子的递归函数提前 后序遍历先递归左子树 性质 已知前序遍历序列和中序遍历序列，可以唯一确定一个二叉树 已知后序遍历序列和中序遍历序列，可以唯一确定一个二叉树 已知前序遍历序列和后序遍历序列，不可以唯一确定一个二叉树 建立二叉树，利用递归原理 6.10 线索二叉树 将指向前驱和后继的指针称为线索，加上线索的二叉链表称为线索链表。相应的二叉树为线索二叉树 ==中序遍历之后，将所有的空指针域中的rchild指向后继结点，lchild指向当前结点的前驱，添加两个标志位ltag和rtag，为0时指示指向的是孩子，为1时指示后继或前驱 如果所用的二叉树需要经常遍历或查找结点时需要某种遍历序列中的前驱和后继，宜采用线索二叉链表结构 6.11 树,森林与二叉树的转换 树转换为二叉树，步骤 加线，在所有兄弟结点之间加一条线 去线，对树中每个结点，只保留它与第一个孩子结点的连线，删除它与其他孩子结点之间的连线 层次调整，以树的根节点为轴心，将整棵树顺时针旋转一定的角度。注意第一个孩子是二叉树的左孩子，兄弟转换过来的孩子是结点的右孩子 森林转换为二叉树(森林的每一个树都是兄弟) 将每个树转换为二叉树 第一棵二叉树不懂，从第二可二叉树开始，依次把后一棵二叉树的根节点作为前一棵二叉树的根节点的右孩子 二叉树转换为树 加线 去线 层次调整 二叉树转换为森林 二叉树的根节点有右孩子，有就是森林，否则为树 树的遍历 先根遍历树，先访问树的根节点，然后依次先根遍历根的每棵子树 后根遍历树，先依次后根遍历每棵子树，然后再访问根结点 森林的遍历 前序遍历：先访问森林中第一棵树的根节点，然后再依次先根遍历根的每棵子树，再依次用同样的方式遍历出去第一棵树的剩余树构成的森林 后序遍历：先访问森林中第一颗树，后根遍历的方式遍历每棵子树，然后再访问根节点，再依次用同样方式遍历除去第一棵树的剩余树构成的森林 6.12 哈夫曼树及其应用 从树中的一个结点到另一个结点之间的分支构成两个结点之间的路径，路径上的分支数目称作路径长度 树的路径长度就是从树根到每一结点的路径长度之和 带权路径长度WPL最小的二叉树称为哈夫曼树(最优二叉树) 构造哈夫曼树的算法流程 根据给定的n个权值构成n棵二叉树的集合F，其中每棵二叉树T中只有一个带权为w的根节点，其左右子树都为空 在F中选取两棵根节点的权值最小的树作为左右子树构造一棵新的二叉树，且新的二叉树的根节点的权值为其左右子树上根节点权值之和 在F中删除这两棵树，同时将新得到的二叉树加入F中 重复步骤2和3，直到F只含一棵树位置 7 图 7.4 图的定义 图是由顶点的有穷非空集合和顶点之间边的集合组成的，通常表示为G(V,E),其中G表示一个图,V是图G中顶点的集合,E是图G中边的集合 线性表中数据元素叫元素，树中数据元素叫结点，图中数据元素叫顶点 定义强调顶点集合V的有穷非空 任意两个顶点之间都可能有关系，顶点之间的逻辑关系用边来表示，边集是可空 无向边：若顶点ViV_iVi​到VjV_jVj​之间的边没有方向，则称这条边为无向边，用无序偶对(Vi,Vj)(V_i,V_j)(Vi​,Vj​)表示 无向图：任意两个顶点之间的边都是无向边 有向边：若从顶点ViV_iVi​到VjV_jVj​的边有方向，则称这条边为有向边，也称为弧。==用有序偶数对&lt;Vi,Vj&gt;&lt; V_i,V_j &gt;&lt;Vi​,Vj​&gt;表示，ViV_iVi​称为弧尾，VjV_jVj​称为弧头 有向图：任意两个顶点之间的边都是有向边 无向边用小括号表示，有向边用尖括号表示 简单图：在图中若不存在顶点到其自身的边，且同一条边不重复出现 无向完全图：在无向图中，任意两个顶点之间都存在边(含有n个顶点的无向完全图有n∗(n−1)2\\frac{n*(n-1)}{2}2n∗(n−1)​条边) 有向完全图：在有向图中，任意两个顶点之间都存在方向相反的两条弧(含有n个顶点的有向完全图有n∗(n−1)n*(n-1)n∗(n−1)条边) 权：与图的边或弧相关的数 网：带权的图 子图：假设有两个图G=(V,E),G′=(V′,E′)G=(V,{E}),G^{\\prime}=(V^{\\prime},{E^{\\prime}})G=(V,E),G′=(V′,E′)，如果V′⊆V,E′⊆EV^{\\prime} \\subseteq V ,E^{\\prime}\\subseteq EV′⊆V,E′⊆E，则称G′G^{\\prime}G′为GGG的子图 对于无向图G=(V,E)G=(V,{E})G=(V,E),如果边(v′,v′)∈E(v^{\\prime},v^{\\prime}) \\in E(v′,v′)∈E,则称顶点vvv和v′v^{\\prime}v′互为邻接点 边(v,v′)(v, v^{\\prime})(v,v′) 依附于顶点 vvv 和 v′v^{\\prime}v′ 顶点 vvv 的度是和 vvv 相关联的边的数目, 记为 TD (v) 边数和顶点度数和的关系:e=12∑i=1nTD(vi)e=\\frac{1}{2} \\sum_{i=1}^{n} T D(v_{i})e=21​∑i=1n​TD(vi​) 对于有向图G=(V,E)G=(V,{E})G=(V,E),如果边&lt;v′,v′&gt;∈E&lt;v^{\\prime},v^{\\prime}&gt; \\in E&lt;v′,v′&gt;∈E,则称顶点v′v^{\\prime}v′邻接自顶点vvv 以顶点vvv为头的弧的数目称为v的入度,即为ID(v)ID(v)ID(v)；以vvv为尾的弧的数目称为v的出度,即为OD(v)OD(v)OD(v) 顶点 vvv 的度TD(v)=ID(v)+OD(v)TD (v) = ID(v) + OD(v)TD(v)=ID(v)+OD(v),e=∑i=1nID(vi)=∑i=1nOD(vi)e=\\sum_{i=1}^{n} I D\\left(v_{i}\\right)=\\sum_{i=1}^{n} O D\\left(v_{i}\\right)e=∑i=1n​ID(vi​)=∑i=1n​OD(vi​) 路径的长度是路径上的边或弧的数目 回路(环)：第一个顶点和最后一个顶点相同的路径 简单路径：序列中顶点不重复出现的路径称为简单路径 简单回路：除了第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路 连通：在无向图G中，如果从顶点V到顶点V′V^\\primeV′有路径，则称V和V′V^\\primeV′连通 连通图：图中任意两个顶点之间都是连通的 连通分量：无向图中的极大连通子图 子图 子图要连通 连通子图含有极大顶点数 具有极大顶点数的连通子图包含依附于这些顶点的所有边 强连通图：在有向图 G{G}G 中, 如果对于每一对 v&lt;!−−swig￼10−−&gt;,v&lt;!−−swig￼11−−&gt;∈V、v&lt;!−−swig￼12−−&gt;≠v&lt;!−−swig￼13−−&gt;{v}_, {v}_ \\in {V} 、 {v}_ \\neq {v}_v&lt;​!−−swig￼10−−&gt;,v&lt;​!−−swig￼11−−&gt;∈V、v&lt;​!−−swig￼12−−&gt;=v&lt;​!−−swig￼13−−&gt;, 从 vi{v}_{\\mathrm{i}}vi​ 到 v&lt;!−−swig￼14−−&gt;{v}_v&lt;​!−−swig￼14−−&gt; 和从 v&lt;!−−swig￼15−−&gt;{v}_v&lt;​!−−swig￼15−−&gt; 到 v&lt;!−−swig￼16−−&gt;{v}_v&lt;​!−−swig￼16−−&gt; 都存 在路径 有向图的强连通分量：有向图中的极大强连通子图 连通图的生成树：一个连通图的生成树是一个极小的连通子图，含有图中全部的n个顶点，但只有足以构成一棵树的n-1条边 如果一个有向树恰有一个顶点的入度为0，其余顶点的入度为1，则是一个有向树 一个有向树的生成森林由若干棵有向树组成，含有图中全部顶点，但只有足以构成若干棵不相交的有向树的弧 7.4 图的存储结构 对于图而言，任意两个顶点之间都可能存在联系，故不可以使用简单的顺序结构实现 多重链表实现时，一个数据域和多个指针域组成的结点表示一个顶点，可以实现图结构，但是若各个顶点的度相差很大，按度最大的顶点设计会造成存储空间的浪费；但按照每个顶点自己的度进行设计，操作不便 7.4.1 邻接矩阵 图的邻接矩阵：是用两个数组来表示图。一个一维数组存储图中的顶点信息，一个二维数组(称为邻接矩阵)存储图中的边或弧的信息 邻接矩阵的计算方法(图G有n个顶点，邻接矩阵为n*n方阵) arc[i][i]⁡={1,若(vi,vj)∈E或⟨vi,vj⟩∈E0,其他\\operatorname{arc[i][i]}=\\{\\begin{array}{l}1, { 若 }\\left(v_{i}, v_{j}\\right) \\in E { 或 }\\left\\langle v_{i}, v_{j}\\right\\rangle \\in E \\\\ 0, { 其他 }\\end{array}arc[i][i]={1,若(vi​,vj​)∈E或⟨vi​,vj​⟩∈E0,其他​ 可设置顶点数组和边数组 无向图的边数组为一个对称矩阵 某个顶点的度其实就是这个顶点在邻接矩阵中第i行的元素之和 顶点的所有邻接点就是将矩阵中的第i行元素扫描一遍 有向图讲究入度和出度，入度为第i列的各数之和，出度为第i行的个数之和 网(每条边上带权的图) 设G为网图，有n个结点，则邻接矩阵为一个n*n的方阵 arc⁡[i][j]={Wi,若(vi,vj)∈E或&lt;vi,vj&gt;∈E0,若i=j∞,其他\\operatorname{arc}[i][j]= \\begin{cases}W_{i}, &amp; { 若 }\\left(v_{i}, v_{j}\\right) \\in E { 或 }&lt;v_{i}, v_{j}&gt;\\in E \\\\ 0, &amp; { 若 } i=j \\\\ \\infty, &amp; { 其他 }\\end{cases}arc[i][j]=⎩⎪⎪⎨⎪⎪⎧​Wi​,0,∞,​若(vi​,vj​)∈E或&lt;vi​,vj​&gt;∈E若i=j其他​ 有了结构的i当以，构造一个图就是给顶点表和边表输入数据的过程 n个顶点和e条边的无向网图的创建，时间复杂度为O(n+n2+e)O(n+n^2+e)O(n+n2+e),其中对邻接矩阵的初始化花费了O(n2)O(n^2)O(n2) 7.4.2 邻接表 数组与链表相结合的存储方式称为邻接表 邻接表的处理办法 图中顶点用一个一维数组存储；当然顶点可以用单链表存储，不过数组比较容易读取顶点信息，更加方便，对于顶点数组中每个元素需要存储指向第一个邻接点的指针，便于查找该顶点的边信息 图中每个顶点ViV_iVi​的所有邻接点构成一个线性表，由于邻接点的个数不定，使用单链表存储，无向图称为顶点ViV_iVi​的边表，有向图则称为顶点ViV_iVi​作为弧尾的出边表 顶点表的各个结点有data和firstedge两个域表示,data是数据域存储顶点的信息,firstedge是指针域，指向边表的第一个结点 边表结点由adjvex和next两个域组成。adjvex是邻接点域，存储某顶点的邻接点在顶点表中的下标，next则存储指向边表中下一个结点的指针 以顶点作为弧尾来存储边表，可以容易得到每个顶点的出度 逆邻接表：一个有向图的逆邻接表，对每个顶点ViV_iVi​都建立一个链接为ViV_iVi​为弧头的表 网图：可以在边表结点定义中增加一个weight的数据域，存储权值信息 7.4.3 十字链表 将邻接表和逆邻接表结合起来，形成十字链表 顶点表结点的结构：data firstin firstout ;firstin表示入边表头指针，指向该顶点的入边表中第一个结点；firstout表示出边表头指针，指向该顶点的出边表中的第一个结点 边表结点的结构：tailvex headvex headlink taillink; tailvex指弧起点在顶点表中的下标；headvex指弧终点在顶点表中的下标；headlink指入边表指针域，指向终点相同的下一条边；taillink指边表指针域，指向起点相同的下一条边；如果是网还可以增加weight域存储权值 十字链表的好处就是因为把邻接表和逆邻接表整合在一起，容易找到以ViV_iVi​为尾的弧，也容易找到以ViV_iVi​为头的弧，因而容易求得顶点的出度和入度。而且它除了结构复杂一些，其实创建图算法的时间复杂度和邻接表相同 7.4.4 邻接多重表 更加关注边的操作 边表结点重新定义：ivex ilink jvex jlink ；ivex和jvex是与某条边依附的两个顶点在顶点表中的下标;ilink和jlink指向依附顶点ivex的下一条边：jlink指向依附顶点jvex的下一条边 ilink指向的结点的jvex一定要和它本身的ivex相同 邻接多重表与邻接表的差别 邻接表同一条边在邻接表中用两个结点表示，而邻接表多重表中只有一个结点 7.4.5 边集数组 边集数组是由两个一维数组构成的。一个存储顶点的信息；另一个存储边的信息，这个边数组每个数据元素由一条边的起点下标,终点下标和权构成。 边集数组关注的是边的集合，在边集数组中要查找一个顶点的度需要扫描整个边数组，效率并不高。更适合对边依次进行处理的操作，不适合对顶点相关的操作 边数组结构: begin end weight ;begin存储起点下标，end存储终点下标，weigth存储权值 7.5 图的遍历 图的遍历：从图中某一顶点出发访问图中其余顶点，且使每一个顶点仅被访问一次 7.5.1 深度优先遍历(DFS) 从图中某一顶点v出发，访问此顶点，然后从v的未被访问的邻接点出发深度有限遍历图，直至图中所有和v有路径相通的顶点都被访问到 实际这里讲的是连通图，对于非连通图，只需要对它的连通分量分别进行深度有限遍历，即在先前一个顶点进行一次深度优先遍历后，若图中尚有顶点未被访问，则另选图中一个未曾被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问为止 邻接矩阵方式和邻接表结构方式，邻接矩阵是二维数组，要查找每个顶点需要访问矩阵中的所有元素，因此时间复杂度为O(n2)O(n^2)O(n2)；而邻接表做存储结构时，找邻接点所需的时间取决于顶点和边的数量，时间复杂度为O(n+m)O(n+m)O(n+m) 显然，对于点多边少的稀疏图，邻接表结构使得算法在时间效率上大大提高 7.5.2 广度优先遍历(BFS) 图的广度优先遍历类似树的层序遍历 图的深度优先遍历类似树的前序遍历 图的深度优先遍历和广度优先遍历，在时间复杂度上一致，不同的是对顶点访问的顺序不同 深度优先更适合目标比较明确，以找到目标为主要目的的情况，广度优先适合在不断扩大遍历范围时找到最优解的情况 7.6 最小生成树 最小生成树：构造连通网的最小代价生成树 普利姆(Prim)算法： 假设 N=(P,{E})\\mathrm{N}=(\\mathrm{P},\\{\\mathrm{E}\\})N=(P,{E}) 是连通网, TE\\mathrm{TE}TE 是 N\\mathrm{N}N 上最小生成树中边的集合。算法从 U={u0}\\mathrm{U}=\\left\\{\\mathrm{u}_{0}\\right\\}U={u0​} (u0∈V),TE={}\\left(u_{0} \\in V\\right), T E=\\{\\}(u0​∈V),TE={} 开始。重复执行下述操作: 在所有 u∈U,v∈V−Uu \\in U, v \\in V-Uu∈U,v∈V−U 的边 ( u,v)∈E\\left.u, v\\right) \\in Eu,v)∈E 中 找一条代价最小的边 (u0,v0)\\left(u_{0}, v_{0}\\right)(u0​,v0​) 并入集合 TET ETE, 同时 v0v_{0}v0​ 并入 UUU, 直至 U=VU=VU=V 为止。此时 TET ETE 中必有 n−1n-1n−1 条边, 则 T=(V,{TE})T=(V,\\{T E\\})T=(V,{TE}) 为 NNN 的最小生成树 算法的时间复杂度为O(n2)O(n^2)O(n2) 克鲁斯卡尔(Kruskal)算法： 假设 N=(V,{E})\\mathrm{N}=(\\mathrm{V},\\{\\mathrm{E}\\})N=(V,{E}) 是连通网, 则令最小生成树的初始状态为只有 n\\mathrm{n}n 个顶点而无边的 非连通图 T={V,{}}\\mathrm{T}=\\{\\mathrm{V},\\{\\}\\}T={V,{}}, 图中每个顶点自成一个连通分量。在 E\\mathrm{E}E 中选择代价最小的边, 若 该边依附的顶点落在 TTT 中不同的连通分量上, 则将此边加入到 TTT 中, 否则舍去此边而 选择下一条代价最小的边。依次类推, 直至 T\\mathrm{T}T 中所有顶点都在同一连通分量上为止 算法的FIND函数由变数e决定，时间复杂度为O(loge)O(log e)O(loge)，外面有一个for循环e次,故整个算法的时间复杂度为O(eloge)O(elog e)O(eloge) 克鲁斯卡尔算法针对边展开，边数较少时效率高，对稀疏图有很大优势；普利姆算法针对于稠密图，边数非常多的情况更好 7.7 最小路径 非网图的最小路径：指两个顶点之间经过边数最小的路径 网图：两顶点之间经过边上权值之和最少的路径，并且称路径上第一个顶点为源点，最后一个顶点为终点 迪杰斯拉特算法：一步步求出顶点之间的最短路径，过程中都是基于已经求出的最短路径的基础上，求得更远顶点的最短路径，最终得到结果 弗洛伊德算法：D代表顶点到顶点的最短路径权值和矩阵，P代表对应顶点的最短路径的前驱矩阵 在未分析任何顶点之前，将D命名为D−1D^{-1}D−1，其实它就是初始的图的邻接矩阵。将P命名为P−1P^{-1}P−1 面临需要求所有顶点到所有顶点的最短路径问题，弗洛伊德算法较好 7.8 拓扑排序 在一个表示工程的有向图中，用顶点表示活动，用弧表示活动之间的优先关系，这样的有向图为顶点表示活动的网，为AOV图 设 G=(V,E)\\mathbf{G}=(\\mathbf{V}, \\mathrm{E})G=(V,E) 是一个具有 nnn 个顶点的有向图, VVV 中的顶点序列 v1,v2,⋯⋯ ,vn\\mathbf{v}_{\\mathbf{1}}, \\mathbf{v}_{\\mathbf{2}}, \\cdots \\cdots, \\mathbf{v}_{\\mathrm{n}}v1​,v2​,⋯⋯,vn​, 满足若从顶点 vi\\mathbf{v}_{\\mathbf{i}}vi​ 到 vj\\mathbf{v}_{\\mathbf{j}}vj​ 有一条路径，则在顶点序列中顶点 vi\\mathbf{v}_{\\mathbf{i}}vi​ 必在顶点 vi\\mathbf{v}_{\\mathbf{i}}vi​ 之前。则我们 称这样的顶点序列为一个拓扑序列 所谓拓扑排序, 其实就是对一个有向图构造拓扑序列的过程。构造时会有两个结 果, 如果此网的全部顶点都被输出, 则说明它是不存在环（回路）的 AOV 网; 如果输 出顶点数少了, 哪怕是少了一个, 也说明这个网存在环（回路）, 不是 AOV 网 对 AOV 网拓扑排序算法：从 AOV 网中选择一个入度为 0 的顶点输 出, 然后删去此顶点, 并删除以此顶点为尾的弧, 继续重复此步骤, 直到输出全部顶 点或者 AOV 网中不存在入度为 0 的顶点为止 7.9 关键路径 在一个表示工程的有向图中，用顶点表示事件，用有向边表示活动，用边上的权值表示活动的持续时间，这种有向图的边表示活动的网，为AOE图 AOE网中，没有入边的顶点称为始点或源点，没有出边的顶点称为终点或汇点 把路径上各个活动所持续的时间之和称为路径长度，从源点到汇点具有最大长度的路径叫做关键路径，在关键路径上的活动称为关键活动 关键路径算法 参数：事件的最早发生时间etv,即顶点v的最早发生时间；事件的最晚发生时间ltv,即顶点v的最晚发生时间；活动的最早发生时间ete,即弧a的最早发生时间；活动的最晚发生时间lte,即弧a的最晚发生时间； 顶点VkV_kVk​即etv[k]的最早发生时间公式 etv[k]={0,，当k=0时max⁡{etv[i]+len&lt;vi,vk&gt;},当k≠0且&lt;vi,vk&gt;∈P[k]时e t v[k]=\\left\\{\\begin{array}{l}0, ，当k=0时 \\\\ \\max \\left\\{e t v[i]+l e n&lt;v_{i}, v_{k}&gt;\\right\\}, { 当 } k \\neq 0 { 且 }&lt;v_{i}, v_{k}&gt;\\in P[k] { 时 }\\end{array}\\right.etv[k]={0,，当k=0时max{etv[i]+len&lt;vi​,vk​&gt;},当k=0且&lt;vi​,vk​&gt;∈P[k]时​ 顶点VkV_kVk​即ltv[k]的最晚发生时间公式 ltv[k]={etv[k]，当k=n−1时min⁡{ltv[j]+len&lt;vk,vj&gt;},当k&lt;n−1且&lt;vk,vj&gt;∈[k]时l t v[k]=\\left\\{\\begin{array}{l}e t v[k] ，当 k=n-1时 \\\\ \\min \\left\\{l t v[j]+l e n&lt;v_{k}, v_{j}&gt;\\right\\}, 当k&lt;n-1且&lt;v_{k}, v_{j}&gt; \\in[k]时\\end{array}\\right.ltv[k]={etv[k]，当k=n−1时min{ltv[j]+len&lt;vk​,vj​&gt;},当k&lt;n−1且&lt;vk​,vj​&gt;∈[k]时​ 8 查找 8.2 查找概论 查找表：由同一个类型的数据元素（或记录）构成的集合 关键字：数据元素中某个数据项的值，又称为键值；用它可以标志一个数据元素 关键码：标志一个记录的某个数据项 主关键字：此关键字可以唯一地标志一个记录 主关键码：主关键字所在的数据项 次关键字：可以识别多个数据元素的关键字 次关键码：次关键字对应的数据项 查找按操作方式分为两大类：静态查找表和动态查找表 静态查找表：只做查找操作的查找表 查找某个“特定的”数据元素是否在查找表中 检索某个特定的数据元素和属性 动态查找表：在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素 查找时插入数据元素 查找时删除数据元素 面向查找的数据结构为查找结构 从逻辑上上，查找所基于的数据结构是集合，集合中的记录之间没有本质关系。但需要获得更高的查找性能，需要改变数据结构，在查找时将集合组织成表,树等结构 8.3 顺序表查找 顺序查找：线性查找 查找过程为：从表中第一个记录开始，逐个进行记录的关键字和给定值比较，若某个记录的关键字和给定值相等，则查找成功，找到所查的记录；如果直到最后一个记录，其关键字和给定值比较都不等时，则表中没有所查的记录，查找不成功 顺序表查找的优化： 利用哨兵：在查找方向的尽头放置哨兵，免去了在查找过程中每一次比较后都要判断查找位置是否越界 在数据量较大时，效率有所提高 时间复杂度为O(n) 8.4 有序表查找 折半查找 折半查找技术，又称为二分查找。前提是线性表中的记录必须是关键字有序，线性表必须采用顺序存储 折半查找的基本思想：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键字相等，则查找成功；若给定值小于中间记录的关键字，则在中间记录的左半区继续查找，若给定值大于中间记录的关键字，则在中间记录的右半区继续查找。不断重复上述操作，直到查找成功，过所有查找区域无记录，查找失败为止 折半查找的时间复杂度为O(logn)O(logn)O(logn) 折半查找的前提条件是需要有序表顺序存储，对于静态查找表，一次排序后不再变化，但对于频繁执行插入或删除操作的数据集，维护有序的排列成本较高 插值查找 根据要查找的关键字key与查找表中最大最小记录的关键字比较后的查找方法，核心在于插值的计算，mid=key−a[low]a[high]−a[low]mid=\\frac{key-a[low]}{a[high]-a[low]}mid=a[high]−a[low]key−a[low]​ 时间复杂度为O(log n) 对于表长较大，而关键字分布比较均匀的查找表插值查找性能较好；极端不均匀的数据，效率不高 斐波那契查找 利用黄金分割的原理 算法的核心：(F[k]为斐波那契数列) 当key = a[mid]时，查找成功 当key &lt; a[mid]时，新范围为第low个到第mid-1个，此时范围个数为F[k-1]-1个 当key &gt; a[mid]时，新范围为第m+1个到第high个，此时范围个数为F[k-2]-1个 折半查找是加法和除法运算mid=low+high2mid=\\frac{low+high}{2}mid=2low+high​；插值查找是进行复杂的四则运算mid=key−a[low]a[high]−a[low]mid=\\frac{key-a[low]}{a[high]-a[low]}mid=a[high]−a[low]key−a[low]​；斐波那契查找是进行简单的加减运算mid=low+F[k−1]−1mid = low+F[k-1]-1mid=low+F[k−1]−1 8.5 线性索引查找 数据结构的最终目的就是提高数据的处理速度，索引是为了加快查找速度而设计的一种数据结构 索引：把关键字与它对应的记录相关联的过程，一个索引由若干个索引项构成，每个索引至少包含关键字和其对应的记录在存储器中的位置信息 索引按照结构分为线性索引,树形索引和多级索引 线性索引就是将索引项集合组织为线性结构，也称索引表 三种线性索引结构：稠密索引,分块索引和倒排索引 稠密索引 稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项 对于稠密索引这个索引表说，索引项一定是按照关键码有序排列的 分块索引 对于分块有序的数据集，将每块对应一个索引项，该索引方法称为分块索引，(为了减少索引项的个数，可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数) 分块有序是把数据集的记录分成了若干块，并且块满足： 块内无序，每一块内的记录不要求有序 块间有序 分块索引的索引项结构 最大关键码，存储每一块中的最大关键字 存储了块中的记录个数 用于指向块首数据元素的指针 倒排索引 索引项的通用结构，次关键码和记录表号，其中记录表存储具有相同次关键字的所有记录的记录号(可以是指向记录的指针或者该记录的主关键字)。这样的索引方法就是倒排索引 倒排索引根据属性的值查找记录，这种索引表中的每一项都包括一个属性值和具有该属性值的各记录地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因此称为倒排索引 8.6 二叉排列树 动态查找表的数据结构之一 二叉排序树(二叉查找树)：或者是一棵空树，或者是具有以下性质的二叉树 若它的左子树不空，则左子树上的所有结点的值均小于它的根结点的值 若它的右子树不空，则右子树上的所有结点的值均大于它的根结点的值 它的左,右子树也分别为二叉排序树 前提是二叉树，采用递归的定义方式，结点之间满足次序关系，左子树结点一定比双亲结点小，右子树结点一定比其双亲节点大 二叉树的查找操作,二叉树的插入操作和二叉树的删除操作 对于二叉树的查找，走的就是从根节点到查找的结点的路径，其比较次数等于给定值的结点在二叉排序树中的层数 极端情况，最少为1次，即根节点到要找到的结点最多不会超过树的深度，二叉排序树的查找性能取决于二叉排序树的形状 二叉排序树以链接的方式存储，保持了链接存储结构在执行插入或删除操作时不用移动元素的优点，只要找到合适的插入和删除位置后，仅需要修改链接指针即可 希望二叉排序树是平衡的，即深度与完全二叉树相同，都为[log2n]+1[log_2n]+1[log2​n]+1，时间复杂度为O(logn)O(logn)O(logn),近似于折半查找 8.7 平衡二叉树(AVL树) 平衡二叉树：是一种二叉排序树，其中每一个结点的左子树和右子树的高度差至多等于1 平衡因子BF：二叉树上的结点的左子树高度减右子树高度的值 最小不平衡子树：距离插入结点最近的，且平衡因子的绝对值大于1的结点为根的子树 实现原理： 构建二叉排序树的过程中，每当插入一个结点时，先检查是否因插入而破坏了树的平衡性，若是，则找出最小不平衡子树。在保持二叉排序树特性的前提下，调整最小不平衡子树中个结点之间的连接关系，进行相应的旋转，使之称为新的平衡子树 当最小平衡子树根结点平衡因子BF大于1时，右旋，小于-1就左旋 当最小不平衡子树的BF与它的子树的BF符号相反时，就需要对结点先进行一次旋转使得符号相同后，再反向旋转一次完成平衡操作 二叉排序树是平衡二叉树，查找的时间复杂度为O(logn)O(logn)O(logn)，插入和删除操作为O(logn)O(logn)O(logn) 8.8 多路查找树(B树) 多路查找树，其每一个结点的孩子数可以多余两个，且每一个结点处可以存储多个元素 每一个结点存储多少个元素，以及它的孩子树的多少是非常关键的，四种特殊结构：2-3树,2-3-4树,B树,B+树 2-3树：其中每个结点都具有两个孩子(2结点)或三个孩子(3结点) 一个2结点包含一个元素和两个孩子(或没有孩子),且与二叉排序树类似，左子树包含的元素小于该元素，右子树包含的元素大于该元素 一个3结点包含一小一大两个元素和三个孩子(或没有孩子)，左子树包含小于较小元素的元素，右子树包含大于该元素的元素 2-3树复杂的地方在于新节点的插入和已有结点的删除 插入分为3种情况： 对于空树，插入一个2结点即可 插入结点到一个2结点的叶子上 要往3结点种插入元素 2-3树插入的传播效应导致根节点的拆分，则树的高度会增加 删除的3种情况 所删除元素位于一个3结点的叶子结点上 所删除元素位于一个2结点上，即要删除的是一个只有一个元素的结点 此结点的双亲也是2结点，且拥有一个3结点的孩子 此结点的双亲是2结点，它的右孩子也是2结点 此结点的双亲是一个3结点 若当前树是一个满二叉树的情况，此时删除任何一个叶子都会是整棵树不能满足2-3树的定义 所删除的元素位于非叶子的分支结点，通常将树按中序遍历后得到此元素的前驱或后继元素，考虑让它们来补位即可 2-3-4树 2-3树的概念扩展，包括了4结点的使用；一个4结点包含小中大三个元素和4个孩子(或没有孩子) B树 B树是一种平衡的多路查找树，2-3树和2-3-4树都是B树的特例 B树的阶：结点最大的孩子数目称为B树的阶 m阶B树具有的属性： 如果根节点不是叶结点，则其至少有两棵子树 每一个非根的分支节点都有k-1个元素和k个孩子，其中[m/2]⩽k⩽m[\\mathrm{m} / 2] \\leqslant \\mathrm{k} \\leqslant \\mathrm{m}[m/2]⩽k⩽m。每一个叶子结点结点n都有k-1个元素，其中[m/2]⩽k⩽m[\\mathrm{m} / 2] \\leqslant \\mathrm{k} \\leqslant \\mathrm{m}[m/2]⩽k⩽m 所有叶子结点都位于同一层次 所有分支结点包含下列信息数据(n,A0, K1, A1, K2, A2,⋯ ,Kn,An)\\left(\\mathrm{n}, \\mathrm{A}_{0}, \\mathrm{~K}_{1}, \\mathrm{~A}_{1}, \\mathrm{~K}_{2}, \\mathrm{~A}_{2}, \\cdots, \\mathrm{K}_{\\mathrm{n}}, \\mathrm{A}_{\\mathrm{n}}\\right)(n,A0​, K1​, A1​, K2​, A2​,⋯,Kn​,An​) 在B树上查找是一个顺指针查找结点和在结点中查找关键字的交叉过程 外存是将所有的信息分割称相等大小的页面，每次硬盘读写的都是一个或多个完整的页面，对于一个硬盘来说，一页的长度可能是21-214B B树的一个典型应用：要处理的硬盘数据量很大，无法一次全部装入内存 将B树进行调整，使B树的阶数与硬盘存储的页面大小相匹配 一棵B树的阶为1001，高度为2，可以存储超过10亿个关键字，只要让根节点持久的保留在内存中，那么在这棵树上，寻找某一个关键字至多需要两次硬盘的读写 B树的数据结构就是为内外存的数据交互准备的 在含有n个关键字的B树上查找时，从根节点到关键字结点的路径上涉及的点数不超过log⁡[m2](n+12)+1\\log _{[\\frac{m}{2}]}\\left(\\frac{n+1}{2}\\right)+1log[2m​]​(2n+1​)+1 B+树 为了解决所有元素遍历等问题，我们在原有B树结构基础上，加上了新的元素组织方式，形成B+树 在B+树中，出现在分支节点中的元素会被当做它们在该分支结点位置的中序后继者中再次列出。另外，每一个叶子结点都会存储一个指向后一叶子结点的指针 m阶B+树和m阶B树的差别 有n棵子树的结点中含有n个关键字 所有的叶子结点包含全部关键字信息，及指向含这些关键字记录的指针，叶子结点本身依关键字的大小自小而大顺序链接 所有分支结点可以看成索引，结点中仅含有其子树中的最大（或最小）关键字 好处： 如果是要随机查找，从根结点触发，与B树的查找方式相同，只不过即使在分支结点找到了待查找的关键字，也只是用来索引的，不能提供实际记录的访问，还是需要到达包含次关键字的终端结点 如果需要从最小关键字进行从小到大的顺序查找，可以从最左侧的叶子结点出发，不经过分支结点，而是沿着指向下一叶子的指针就可遍历所有的关键字 B+树的插入，删除过程都与B树类似，只不过插入和删除的元素都是在叶子结点上进行而已 8.9 散列表查找(哈希表)概述 散列技术：在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key) 对应关系f称为散列函数，又称为哈希(Hash)函数 采用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间称为散列表或哈希表 查找步骤： 在存储时，通过散列函数计算记录的散列地址，并按此散列地址存储该记录 当查找记录时，通过同样的散列函数计算记录的散列函数，按此散列地址访问该记录 散列技术最适合求解的问题是查找与给定值相等的记录 冲突：两个关键字key1≠key2key_1 \\not ={ key_2 }key1​=key2​,但是却有f(key1)=f(key2)f(key_1) = f(key_2)f(key1​)=f(key2​)，并且将key1,key2key_1,key_2key1​,key2​称为这个散列函数的同义词 散列函数的构造函数 直接定址法： 取关键字的某个线性函数为散列函数,f(key)=a×key+b(a,b为常数)f(key)=a \\times key +b(a,b为常数)f(key)=a×key+b(a,b为常数) 散列函数的优点简单,均匀，也不会产生冲突，但问题是这需要事先知道关键字的分布情况，适合查找表较小且连续的情况 数学分析法 抽取方法是使用关键字的一部分来计算散列存储位置的方法 数学分析法通常适合处理关键字位数比较多的情况，事先知道关键字的分布且关键字的若干位分布较均匀，可以使用该方法 平方取中法 平方取中法比较适合不知道关键字的分布，而位数又不是很多的情况 折叠法 折叠法是将关键字从左到右分割成位数相等的几部分，然后将这几部分叠加求和，并按散列表表长，取后几位作为散列地址 折叠法实现不需要知道关键字的分布，适合关键字位数较多的情况 除留余数法(最常用的构造散列函数的方法) 散列表长为m的散列函数f(key)=mod(key,p)f(key)=mod(key,p)f(key)=mod(key,p)，对key取模 不仅可以对关键字直接取模，也可在折叠,平方取中后再取模 若散列表表长为m，通常p为小于或等于表长的最小质数或不包含小于20质因子的合数 随机数法 f(key)=random(key)f(key)=random(key)f(key)=random(key) 当关键字的长度不等时，采用这个方法构造散列函数是比较适合的 8.11 处理散列冲突的办法 开放定址法 开放定址法是一旦发生了冲突，就取寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存下 线性探测法：公式：fi(key)=MOD(f(key)+di,m),(di=1,2,3...m−1)f_i(key) = MOD(f(key)+d_i,m),(d_i=1,2,3...m-1)fi​(key)=MOD(f(key)+di​,m),(di​=1,2,3...m−1) 本身不是同义词却需要争夺一个地址的情况称为堆积 二次探测法：公式：fi(key)=MOD(f(key)+di,m),(di=12,−12,22,−22...q2,−q2,q⩽m/2)f_i(key) = MOD(f(key)+d_i,m),(d_i=1^2,-1^2,2^2,-2^2...q^2,-q^2,q \\leqslant m/2)fi​(key)=MOD(f(key)+di​,m),(di​=12,−12,22,−22...q2,−q2,q⩽m/2) 增加平方运算的目的是为了不让关键字都聚集在某一个区域 随机探测法：fi(key)=MOD(f(key)+di,m),(di为随机数列f_i(key) = MOD(f(key)+d_i,m),(d_i为随机数列fi​(key)=MOD(f(key)+di​,m),(di​为随机数列 did_idi​为伪随机数 再散列函数法 fi(key)=RHi(key)f_i(key) = RH_i(key)fi​(key)=RHi​(key),RH为不同的散列函数 链地址法 将所有关键字为同义词的记录存储在一个单链表中，这种表为同义词子表 链地址法对于可能会造成很多冲突的散列函数来说，提供了绝不会出现找不到地址的保障，查找时需要遍历单链表，性能损耗 公共溢出区法 在查找时，对给定值通过散列函数计算出散列地址后，先与基本表的相应位置进行比对，如果相等，则查找成功；如果不相等，则到溢出表取进行顺序查找。如果相对于基本表而言，有冲突的数据很少的情况下，公共溢出区的结构对查找性能来说非常高 散列表查找的性能分析 ==若没有冲突，散列查找的性能最高，时间复杂度为O(1) 散列函数是否均匀 处理冲突的方法 散列表的装填因子 所谓的装填因子a=填入表中的记录个数/散列表长度 a标志着散列表的装满程度，填入表中的记录越多，a越大，产生冲突的可能性越大 9 排序 9.2 排序的基本概念与分类 排序：假设含有 n\\mathbf{n}n 个记录的序列为 {r1,r2,⋯⋯ ,rn}\\left\\{\\mathbf{r}_{1}, \\mathbf{r}_{2}, \\cdots \\cdots, \\mathbf{r}_{\\mathbf{n}}\\right\\}{r1​,r2​,⋯⋯,rn​}, 其相应的关键字分别为 {k1,k2,⋯⋯ \\left\\{\\mathbf{k}_{1}, \\mathbf{k}_{2}, \\cdots \\cdots\\right.{k1​,k2​,⋯⋯, kn}\\left.\\mathbf{k}_{\\mathbf{n}}\\right\\}kn​}, 需确定 1,2,⋯⋯ ,n1,2, \\cdots \\cdots, \\mathbf{n}1,2,⋯⋯,n 的一种排列 p1,p2,⋯⋯ ,pn\\mathbf{p}_{\\mathbf{1}}, \\mathbf{p}_{2}, \\cdots \\cdots, \\mathbf{p}_{\\mathbf{n}}p1​,p2​,⋯⋯,pn​, 使其相应的关键字满足 kp1⩽\\mathbf{k}_{\\mathbf{p} 1} \\leqslantkp1​⩽ kp2⩽⋯⋯⩽kpn\\mathbf{k}_{\\mathrm{p} 2} \\leqslant \\cdots \\cdots \\leqslant \\mathbf{k}_{\\mathrm{pn}}kp2​⩽⋯⋯⩽kpn​ (非递减或非递增) 关系, 即使得序列成为一个按关键字有序的序列 {rp1,rp2,⋯⋯ ,rpn}\\left\\{\\mathbf{r}_{\\mathbf{p} 1}, \\mathbf{r}_{\\mathbf{p} 2}, \\cdots \\cdots, \\mathbf{r}_{\\mathbf{p n}}\\right\\}{rp1​,rp2​,⋯⋯,rpn​}, 这样的操作就称为排序 排序的稳定性：假设 ki=kj(1⩽i⩽n,1⩽j⩽n,i≠jk_{\\mathbf{i}}=k_{\\mathbf{j}}\\left(1 \\leqslant i \\leqslant n, 1 \\leqslant \\mathbf{j} \\leqslant n, i \\neq j\\right.ki​=kj​(1⩽i⩽n,1⩽j⩽n,i=j ), 且在排序前的序列中 rir_{i}ri​ 领先于 rjr_{\\mathbf{j}}rj​ （即 i&lt;j\\mathbf{i}&lt;\\mathbf{j}i&lt;j )。如 果排序后 ri\\mathbf{r}_{\\mathbf{i}}ri​ 仍领先于 rj\\mathbf{r}_{\\mathbf{j}}rj​, 则称所用的排序方法是稳定的; 反之, 若可能使得排序后的 序列中 rjr_{j}rj​ 领先 r1r_{1}r1​, 则称所用的排序方法是不稳定的 排序分为内排序和外排序 内排序：内排序是在排序整个过程中, 待排序的所有记录全部被放置在内存中。外排序是 由于排序的记录个数太多, 不能同时放置在内存, 整个排序过程需要在内外存之间多 次交换数据才能进行 内排序的排序算法性能： 时间性能 辅助空间 算法的复杂性 9.3 冒泡排序 冒泡排序是一种交换排序,基本思想是：两两比较相邻记录的关键字，如果反序则交换，知道没有反序的记录为止 最简单排序的实现 思路：让每一个关键字都和它后面的每一个关键字比较，如果大则交换，这样第一位置的关键字就在一次循环后一定变成最小值，(效率低) 冒泡排序算法 冒泡排序算法优化 使用flag标记变量实现算法改进，避免重复比较 复杂度分析： 最好的情况O(n)，最坏的情况，逆序时需要比较∑i=2n(i−1)=1+2+3+⋯+(n−1)=n(n−1)2\\sum_{i=2}^{n}(i-1)=1+2+3+\\cdots+(n-1)=\\frac{n(n-1)}{2}∑i=2n​(i−1)=1+2+3+⋯+(n−1)=2n(n−1)​ 时间复杂度为O(n2)O(n^2)O(n2) 12345678910111213141516171819202122232425262728293031323334353637// 最简单排序的实现// 对顺序表L左交换排序(冒泡排序初级版)void BubbleSort0(SqList *p)&#123; int i,j; for(i=1;i &lt; L-&gt;length;i++)&#123; for(j=i+1;j &lt; L-&gt;length;j++)&#123; if(L-&gt;r[i] &gt; L-&gt;r[j]) swap(L,i,j); //交换L-&gt;r[i]和L-&gt;r[j]的值 &#125; &#125;&#125;// 冒泡排序算法void BubbleSort1(SqList *p)&#123; int i,j; for(i=1;i &lt; L-&gt;length;i++)&#123; for(j=L-&gt;length-1;j &gt;= i;j--)&#123; //注意j时从后向前循环 if(L-&gt;r[i] &gt; L-&gt;r[j+1]) //若前置大于后者 swap(L,j,j+1); //交换L-&gt;r[j]和L-&gt;r[j+1]的值 &#125; &#125;&#125;// 冒泡排序的优化版本void BubbleSort2(SqList *p)&#123; int i,j; Status flag = TRUE; //flag作为标记 for(i=1;i &lt; L-&gt;length &amp;&amp; flag;i++)&#123; //若flag为TRUE则有数据交换，否则退出循环 flag = FALSE; //初始化为false for(j=L-&gt;length-1;j &gt;= i;j--)&#123; //注意j时从后向前循环 if(L-&gt;r[i] &gt; L-&gt;r[j+1])&#123; //若前置大于后者 swap(L,j,j+1); //交换L-&gt;r[j]和L-&gt;r[j+1]的值 flsg = TRUE; &#125; &#125; &#125;&#125; 9.4 简单选择排序 选择排序的基本思想：每一趟在n-i+1个记录中选取关键字最小的记录作为有序序列的第i个记录 简单选择排序：通过n-i次关键字间的比较，从n-i+1个数据中选出关键字最小的记录，并在第i个记录交换 复杂度分析 最大特点时交换移动数据次数相当少 无论最好最差的情况，其比较的次数时一样多的，第i趟排序需要进行n-i次关键字的比较，需要进行∑i=1n−1(n−i)=1+2+3+⋯+(n−1)=n(n−1)2\\sum_{i=1}^{n-1}(n-i)=1+2+3+\\cdots+(n-1)=\\frac{n(n-1)}{2}∑i=1n−1​(n−i)=1+2+3+⋯+(n−1)=2n(n−1)​次比较 交换而言，最好的时候交换次数为0,最差的情况(初始降序)，交换次数为n-1 基于最终的排序时间是比较与交换的次数总和，总的时间复杂度为O(n2)O(n^2)O(n2) 简单选择排序的性能比冒泡排序高 12345678910111213// 简单排序void SelectSort(SqList *L)&#123; int i,j,min; for(i=1;i&lt;L-&gt;length;i++)&#123; min = i; //将当前下标定义为最小值下标 for(j = i+1;j&lt;=L-&gt;length;j++)&#123; //循环之后的数据 if(L-&gt;r[min] &gt; L-&gt;r[j]) //如果有小于当前最小值的关键字 min=j; //将此下标赋值给min &#125; if(i!=min) //若min不等于i，说明找到最小值，交换 swap(L,i,min); //交换 &#125;&#125; 9.5 直接插入排序 直接插入排序：基本操作是将一个记录插入到已经排好序的有序表中，从而得到一个新的,记录数增1的有序表 复杂度分析： 空间上只需要一个记录的辅助空间 最好的情况下没有移动的记录，比较了n-1次，时间复杂度为O(n) 最坏的情况下(逆序)，比较∑i=2ni=2+3+⋯+n=(n+2)(n−1)2\\sum_{i=2}^{n} i=2+3+\\cdots+n=\\frac{(n+2)(n-1)}{2}∑i=2n​i=2+3+⋯+n=2(n+2)(n−1)​次，移动了∑i=2n(i+1)=(n+4)(n−1)2\\sum_{i=2}^{n}(i+1)=\\frac{(n+4)(n-1)}{2}∑i=2n​(i+1)=2(n+4)(n−1)​次 等概率原则，平均比较和移动次数约为n24\\frac{n^2}{4}4n2​次 直接插入排序的时间复杂度为O(n2)O(n^2)O(n2),但性能比冒泡和简单排序好 1234567891011void InsertSort(SqList *L)&#123; int i,j; for(i = 2;i&lt;=L-&gt;length;i++)&#123; if(L-&gt;r[i] &lt; L-&gt;r[i-1])&#123; //需要将L-&gt;r[i]插入到有序表中 L-&gt;r[0] = L-&gt;r[i]; //设置哨兵 for(j=i-1;L-&gt;r[j]&gt;L-&gt;r[0];j--) L-&gt;r[j+1] = L-&gt;r[j]; //记录后移 L-&gt;r[j+1] = L-&gt;r[0]; //插入到正确位置 &#125; &#125;&#125; 9.6 希尔排序算法 思想：大量数据时，将原本有大量记录数的记录进行分组。分割成若干个子序列，此时每个子序列待排序的记录个数就比较少了，然后在这些子序列内分别进行直接插入排序，当整个序列都基本有序时，再对全体记录进行一次直接插入排序 基本有序：小的关键字基本在前面，大的基本在后面，不大不小的基本在中间 问题的关键，分割待排序记录的目的是减少待排序记录的个数，并使整个序列向基本有序发展 跳跃分割策略：将相距某个“增量”的记录组成一个子序列，这样才能保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不是局部有序 复杂度分析： 关键并不是随便分组后各自排序，而是将相隔某个增量的记录组成一个子序列，实现跳跃式的移动，使得排序效率提高 研究表明，当增量序列为dlta⁡[k]=2t−k+1−1(0⩽k⩽t⩽⌊log⁡2(n+1)⌋)\\operatorname{dlta}[k]=2^{\\mathrm{t}-\\mathrm{k}+1}-1 \\quad\\left(0 \\leqslant \\mathrm{k} \\leqslant \\mathrm{t} \\leqslant\\left\\lfloor\\log _{2}(\\mathrm{n}+1)\\right\\rfloor\\right)dlta[k]=2t−k+1−1(0⩽k⩽t⩽⌊log2​(n+1)⌋)时，效率不错，==其时间复杂度为O(n3/2)O(n^{3/2})O(n3/2) 需要注意，增量序列的最后一个增量必须等于1才可以 由于记录时跳跃式的移动，希尔排序不是稳定排序算法 1234567891011121314151617// 希尔排序(传入的r[10]=&#123;0,9,1,5,8,3,7,4,6,2&#125;,length=9(第一位0不算长度))void ShellSort(SqList *L)&#123; int i,j,k=0; int increment = L-&gt;length; do&#123; increment = increment/3+1; //增量序列 for(i=increment+1;i&lt;=L-&gt;length;i++)&#123; if(L-&gt;r[i] &lt; L-&gt;r[i-increment])&#123; //将L-&gt;r[i]插入有序增量子表 L-&gt;r[0] = L-&gt;r[i]; //暂存在L-&gt;r[0] for(j=i-increment;j&gt;0 &amp;&amp; L-&gt;r[0] &lt; L-&gt;r[j]; j-=increment) L-&gt;r[j+increment] = L-&gt;r[j]; //记录后移,查找插入位置 L-&gt;r[j+increment] = L-&gt;r[0]; //插入 &#125; while(increment&gt;1) &#125; &#125;&#125; 9.7 堆排序 堆排序做到每次在选择最小记录的同时，并根据比较结果对其他记录做出相应的调整，排序的总体效率非常高 堆是具有以下性质的二叉树 每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆 或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆 根结点一定是堆中所有结点最大(小)者，较大(小)的结点靠近根结点 按照层序遍历的方式给结点从1开始编号，结点之间满足的关系 {ki⩾k2iki⩾k2i+1\\left\\{\\begin{array}{l}k_{i} \\geqslant k_{2 i} \\\\ k_{i} \\geqslant k_{2 i+1}\\end{array}\\right.{ki​⩾k2i​ki​⩾k2i+1​​ 或 {ki⩽k2iki⩽k2i+11⩽i⩽n2⌋\\left\\{\\begin{array}{l}k_{i} \\leqslant k_{2 i} \\\\ k_{i} \\leqslant k_{2 i+1}\\end{array} 1 \\leqslant i \\leqslant \\frac{n}{2}\\right\\rfloor{ki​⩽k2i​ki​⩽k2i+1​​1⩽i⩽2n​⌋ i&lt;[n/2]i&lt;[n/2]i&lt;[n/2]的原因 二叉树性质的第五条跳转:一棵完全二叉树,如果i=1,则根结点i是二叉树的根，无双亲；如果i&gt;1,则其双亲是结点[i/2]。对于有n个结点的二叉树，i值自然小于等于[i/2] 堆排序算法 基本思想：将待排序的序列构造成一个大顶堆。此时，整个序列的最大值就是堆顶的根结点。将它移走(其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值)，然后将剩余的n-1个序列重新构造成一个堆，这样就会得到n个元素中的次大值。如此反复执行，便能得到一个有序序列 整个排序过程分为两个for循环，第一个循环完成将现在的待排序序列构建成一个大顶堆。第二个循环完成逐步将每个最大值的根结点与末尾元素交换，并且再调整其成为大顶堆 待排序的序列构建成一个大顶堆，其实就是从下往上，从右往左，将每个非终端结点当作根节点，将其和其子树调整成大顶堆 复杂度分析 运行时间主要小号在初始构建堆和在重建堆时的反复筛选上 在构建堆的过程中，因为是完全二叉树从最下层最右边的非终端结点开始构建的，将它与其孩子进行比较，若有必要进行互换，对于每个非终端结点来说，其实最多进行两次比较和互换操作，整个堆构建的时间复杂度为O(n) 在正式排序时，第i次取堆顶记录重建堆需要用O(logi)O(log i)O(logi)的时间(完全二叉树的某个结点到根节点的距离为[log2i]+1[log_2 i]+1[log2​i]+1)，并且需要取n-1次堆顶记录，因此，重建堆的时间复杂度为O(nlogn)O(n log n)O(nlogn) 总体堆排序的时间复杂度为O(nlogn)O(n log n)O(nlogn) 由于堆排序对原始记录的排序状态不敏感，因此最好,最坏和平均时间复杂度为O(nlogn)O(n log n)O(nlogn).性能上优于冒泡,简单选择,直接插入排序 空间复杂度上，只有一个用来交换的暂存空间 由于初始构建堆所需的比较次数较多，不适合待排序个数较少的情况 123456789101112131415161718192021222324252627282930// 堆排序void HeapSort(SqList *L)&#123; int i; for(i = L-&gt;length/2;i&gt;0;i--) HeapAdjust(L,i,L-&gt;length); //构建大顶堆 for(i=L-&gt;length;i&gt;1;i--)&#123; swap(l,1,i); //将堆顶元素和当前未经排序子序列的最后一个交换 HeapAdjust(l,1,i-1) //重新调整L-&gt;r[1..i-1]位大顶堆 &#125;&#125;// 大顶堆生成void HeapAdjust(SqList *L, int s, int m)&#123; int temp,j; temp=L-&gt;r[s]; for(j=2*s;j&lt;=m;j*=2)&#123; //沿关键字较大的孩子结点向下筛选 if(j&lt;m &amp;&amp; L-&gt;r[j] &lt; L-&gt;r[j+1]) ++j; //j为关键字中较大的记录的下标 if(temp &gt;= L-&gt;r[j]) break; //rc应插入在位置s上 L-&gt;r[s] = L-&gt;r[j]; s=j; &#125; L-&gt;r[s] = temp; //插入&#125;//j变量为什么是从2*s开始？为什么是j*2递增？原因在于二叉树的性质5,因为是完全二叉树，当前结点序号是s，其左孩子的序号一定是2s，右孩子的序号一定是2s+1，它们的孩子当然也是以2的位数序号增加*/ 9.8 归并排序 堆排序用到了完全二叉树，充分利用了完全二叉树的深度[log2n]+1[log_2 n]+1[log2​n]+1的特性，效率较高 归并：在数据结构中的定义是将两个或两个以上的有序表合成一个新的有序表 归并排序：利用归并思想实现的排序方法 原理：假设初始序列含有n个记录，则可以看成是n个有序的子序列，每个子序列的长度为1，然后两两归并，得到[n/2]（[x]表示不小于x的最小整数）个长度为2或1的有序子序列；再两两归并，……,如此重复，直至得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序 复杂度分析： 一趟归并需要将SR[1]~SR[n]中相邻的长度为h的有序序列进行两两归并。并将结果放到TR1[1]~TR1[n]中，需要将带排序序列中的所有记录扫描一遍，耗费**O(n)**的时间 由完全二叉树的深度可知,整个归并排序需要进行log2nlog_2 nlog2​n次，因此总的时间复杂度为O(nlogn)O(n logn)O(nlogn)(归并算法最好,最坏,平均的时间性能) 由于归并排序在归并过程中需要与原始记录序列同样数量的存储空间存放归并结果以及递归时深度为log2nlog_2 nlog2​n的栈空间,空间复杂度为O(n+logn)O(n+logn)O(n+logn) 归并排序是稳定的排序算法，但比较占用内存，效率较高且稳定 非递归实现归并排序 非递归的迭代方法，避免了递归时深度为log2nlog_2 nlog2​n的栈空间,空间只是用到申请归并临时用的TR数组,因此空间复杂度为O(n)O(n)O(n),并且避免递归在时间性能上有所提升 使用归并排序时优先考虑使用非递归方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 对顺序表L作归并排序void MergeSort(SqList *L)&#123; MSort(L-&gt;r,L-&gt;r,1,L-&gt;length);&#125;// 将SR[s..t]归并排序为TR1[s..t]void MSort(int SR[],int TR1[],int s, int t)&#123; int m; int TR2[MAXSIZE+1]; if(s==t) TR1[s]=SR[s]; else &#123; m=(s+t)/2; // 将SR[s..t]平分为SR[s..m]和SR[m+1..t] MSort(SR,TR2,s,m); // 递归地将SR[s..m]归并为有序的TR2[s..m] MSort(SR,TR2,m+1,t); // 递归地将SR[m+1..t]归并为有序的TR2[m+1..t] Merge(TR2,TR1,s,m,t); // 将TR2[s..m]和TR2[m+1..t]归并到TR1[s..t] &#125;&#125;void Merge(int SR[],int TR[],int i,int m,int n)&#123; // 将有序的SR[i..m]和SR[m+1..n]归并为有序的TR[i..n] int j,k,l; for(j=m+1,k=i;i&lt;=m &amp;&amp; j&lt;=n;k++) // 将SR中记录由小到大地并入TR &#123; if (SR[i]&lt;SR[j]) TR[k]=SR[i++]; else TR[k]=SR[j++]; &#125; if(i&lt;=m) &#123; for(l=0;l&lt;=m-i;l++) TR[k+l]=SR[i+l]; // 将剩余的SR[i..m]复制到TR &#125; if(j&lt;=n) &#123; for(l=0;l&lt;=n-j;l++) TR[k+l]=SR[j+l]; // 将剩余的SR[j..n]复制到TR &#125;&#125;//非递归实现// 对顺序表L作归并非递归排序void MergeSort2(SqList *L)&#123; int* TR=(int*)malloc(L-&gt;length * sizeof(int)); // 申请额外空间 int k=1; while(k&lt;L-&gt;length) &#123; MergePass(L-&gt;r,TR,k,L-&gt;length); k=2*k; // 子序列长度加倍 MergePass(TR,L-&gt;r,k,L-&gt;length); k=2*k; // 子序列长度加倍 &#125;&#125;void MergePass(int SR[],int TR[],int s,int n)&#123;// 将SR[]中相邻长度为s的子序列两两归并到TR[] int i=1; int j; while(i &lt;= n-2*s+1) // 两两归并 &#123; Merge(SR,TR,i,i+s-1,i+2*s-1); i=i+2*s; &#125; if(i&lt;n-s+1) // 归并最后两个序列 Merge(SR,TR,i,i+s-1,n); else // 若最后只剩下单个子序列 for(j =i;j &lt;= n;j++) TR[j] = SR[j];&#125; 9.9 快速排序 希尔排序为直接插入排序的升级版，都属于插入排序类 堆排序为选择排序的升级版，都属于选择排序类 快速排序为冒泡排序的升级版，都属于交换排序类 快速排序的基本思想：通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续排序，以达到整个序列有序的目的 算法中Partition()函数的作用就是先选取当中的一个关键字，想尽办法将它放到一个位置，使得它左边的值都比它小，右边的值都比它大，将这样的关键字称为枢轴(pivot) 复杂度分析: 快速排序的时间性能取决于快速排序递归的深度,可以使用递归树描述递归算法的执行情况 在最优情况下，Partition每次都划分得很均匀，如果排序n个关键字，其递归树的深度为[log2n]+1[log_2 n]+1[log2​n]+1([x]表示不大于x的最大整数),仅需递归log2nlog_2 nlog2​n次，需要的时间为T(n)的话，第一次Partition应该时需要对整个数组扫描一遍，做n次比较。然后获得的枢轴将数组一分为二，那么各自需要T(n/2)的时间，归纳可得，最优情况下，快速排序算法的时间复杂度为O(nlogn)O(nlog n)O(nlogn) 最坏的情况下,待排序的序列为正序或逆序，每次划分只得到一个比上一次划分少一个记录的子序列，注意另一个为空。递归树为一棵斜树。需要执行n-1次递归调用，且第i次划分需要经过n-i次关键字的比较才能找到第i个记录，比较的次数为∑i=1n−1(n−i)=1+2+3+⋯+(n−1)=n(n−1)2\\sum_{i=1}^{n-1}(n-i)=1+2+3+\\cdots+(n-1)=\\frac{n(n-1)}{2}∑i=1n−1​(n−i)=1+2+3+⋯+(n−1)=2n(n−1)​次比较,最终的时间复杂度为O(n2)O(n^2)O(n2) 平均情况,枢轴位置在第k个位置,T(n)=1n∑k=1n(T(k−1)+T(n−k))+n=2n∑k=1nT(k)+nT(n)=\\frac{1}{n} \\sum_{k=1}^{n}(T(k-1)+T(n-k))+n=\\frac{2}{n} \\sum_{k=1}^{n} T(k)+nT(n)=n1​∑k=1n​(T(k−1)+T(n−k))+n=n2​∑k=1n​T(k)+n,数学归纳法可得其时间复杂度为O(nlogn)O(nlogn)O(nlogn) 空间复杂度： 主要是递归导致的栈空间的使用 最好情况下，递归树的深度为log2nlog_2 nlog2​n，其空间复杂度为O(logn)O(logn)O(logn) 最坏的情况下，需要n-1次递归调用，空间复杂度为O(n) 平均情况下，空间复杂度为O(logn)O(logn)O(logn) 关键字的比较和交换是跳跃进行的，故是一种不稳定的排序方法 123456789101112131415161718192021222324252627282930313233// 对顺序表L作快速排序void QuickSort(SqList *L)&#123; QSort(L,1,L-&gt;length);&#125;// 对顺序表L中的子序列L-&gt;r[low..high]作快速排序void QSort(SqList *L,int low,int high)&#123; int pivot; if(low&lt;high) &#123; // 将L-&gt;r[low..high]一分为二，算出枢轴值pivot pivot=Partition(L,low,high); QSort(L,low,pivot-1); // 对低子表递归排序 QSort(L,pivot+1,high); // 对高子表递归排序 &#125;&#125;int Partition(SqList *L,int low,int high)&#123; // 交换顺序表L中子表的记录，使枢轴记录到位，并返回其所在位置，此时在它之前(后)均不大(小)于它。*/ int pivotkey; pivotkey=L-&gt;r[low]; // 用子表的第一个记录作枢轴记录 while(low&lt;high) //从表的两端交替地向中间扫描 &#123; while(low&lt;high&amp;&amp;L-&gt;r[high]&gt;=pivotkey) high--; swap(L,low,high); // 将比枢轴记录小的记录交换到低端 while(low&lt;high&amp;&amp;L-&gt;r[low]&lt;=pivotkey) low++; swap(L,low,high); // 将比枢轴记录大的记录交换到高端 &#125; return low; // 返回枢轴所在位置&#125; 9.9.3 快速排序优化 优化选取枢轴 随机选取枢轴法 三数取中法：取三个关键字先进行排序，将中间数作为枢轴，一般是取左端，右端和中间三个数 九数取中法，从数组中分别三次取样，每次取三个数，三个样品各取出中数，然后将这三个中数当中再取出一个中数作为枢轴 优化不必要的交换 优化小数组时的排序方法 优化递归操作 QSort()函数在其尾部有两次递归操作 如果待排序的序列划分极端不平衡，递归深度将趋于n，而不是平衡时的log2nlog_2 nlog2​n，不仅仅是速度快慢的问题 栈的大小是有限的，每次递归调用都会耗费一定的栈空间，函数的参数越多，每次递归耗费的空间也越多；若递归减少，将会大大提高性能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 优化选择枢轴int pivotkey;int m = low + (high - low) / 2; // 计算数组中间的元素的下标if (L-&gt;r[low]&gt;L-&gt;r[high]) swap(L,low,high); // 交换左端与右端数据，保证左端较小if (L-&gt;r[m]&gt;L-&gt;r[high]) swap(L,high,m); // 交换中间与右端数据，保证中间较小if (L-&gt;r[m]&gt;L-&gt;r[low]) swap(L,m,low); // 交换中间与左端数据，保证左端较小// 此时L.r[low]已经为整个序列左中右三个关键字的中间值pivotkey=L-&gt;r[low]; // 用子表的第一个记录作枢轴记录// 优化不必要的交换// 快速排序优化算法int Partition1(SqList *L,int low,int high)&#123; int pivotkey; int m = low + (high - low) / 2; // 计算数组中间的元素的下标 if (L-&gt;r[low]&gt;L-&gt;r[high]) swap(L,low,high); // 交换左端与右端数据，保证左端较小 if (L-&gt;r[m]&gt;L-&gt;r[high]) swap(L,high,m); // 交换中间与右端数据，保证中间较小 if (L-&gt;r[m]&gt;L-&gt;r[low]) swap(L,m,low); // 交换中间与左端数据，保证左端较小 pivotkey=L-&gt;r[low]; // 用子表的第一个记录作枢轴记录 L-&gt;r[0]=pivotkey; // 将枢轴关键字备份到L-&gt;r[0] while(low&lt;high) // 从表的两端交替地向中间扫描 &#123; while(low&lt;high&amp;&amp;L-&gt;r[high]&gt;=pivotkey) high--; L-&gt;r[low]=L-&gt;r[high]; // 采用替换而不是交换的方式进行操作 while(low&lt;high&amp;&amp;L-&gt;r[low]&lt;=pivotkey) low++; L-&gt;r[high]=L-&gt;r[low]; // 采用替换而不是交换的方式进行操作 &#125; L-&gt;r[low]=L-&gt;r[0]; // 将枢轴数值替换回L.r[low] return low; // 返回枢轴所在位置&#125;//优化小数组时的排序#define MAX_LENGTH_INSERT_SORT 7 // 用于快速排序时判断是否选用插入排序阙值// 对顺序表L中的子序列L.r[low..high]作快速排序void QSort1(SqList *L,int low,int high)&#123; int pivot; if((high-low)&gt;MAX_LENGTH_INSERT_SORT) &#123; pivot=Partition1(L,low,high); // 将L-&gt;r[low..high]一分为二，算出枢轴值pivot QSort1(L,low,pivot-1); // 对低子表递归排序 QSort1(L,pivot+1,high); // 对高子表递归排序 &#125; else InsertSort(L); // 当high-low小于等于常数时用直接插入排序&#125;// 优化递归操作// 尾递归void QSort2(SqList *L,int low,int high)&#123; int pivot; if((high-low)&gt;MAX_LENGTH_INSERT_SORT) &#123; while(low&lt;high) &#123; pivot=Partition1(L,low,high); // 将L-&gt;r[low..high]一分为二，算出枢轴值pivot QSort2(L,low,pivot-1); // 对低子表递归排序 low=pivot+1; // 尾递归 &#125; &#125; else InsertSort(L); // 当high-low小于等于常数时用直接插入排序&#125; 9.10 总结回顾 算法概念 算法名称 算法介绍 冒泡排序 两两比较相邻记录的关键字,如果反序则交换,直到没有反序的记录为止 简单选择排序 通过n-i次关键字之间的比较,从n-i+1个记录中选出关键字最小的记录,并和第i个记录交换 直接插入排序 将一个记录插入到已经排好序的有序表中,从而得到一个新的,记录数增1的有序表 希尔排序 将相聚某个增量的记录组成一个子序列,保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不是局部有序 堆排序 将待排序的序列构造成一个大顶堆。此时，整个序列的最大值就是堆顶的根结点。将它移走(其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值)，然后将剩余的n-1个序列重新构造成一个堆，这样就会得到n个元素中的次大值 归并排序 假设初始序列含有n个记录，则可以看成是n个有序的子序列，每个子序列的长度为1，然后两两归并，得到[n/2]（[x]表示不小于x的最小整数）个长度为2或1的有序子序列；再两两归并，……,如此重复，直至得到一个长度为n的有序序列为止 快速排序 通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续排序，以达到整个序列有序的目的 算法性能指标 排序方法 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n2)O(n^2)O(n2) O(n)O(n)O(n) O(n2)O(n^2)O(n2) O(1)O(1)O(1) 稳定 简单选择排序 O(n2)O(n^2)O(n2) O(n2)O(n^2)O(n2) O(n2)O(n^2)O(n2) O(1)O(1)O(1) 稳定 直接插入排序 O(n2)O(n^2)O(n2) O(n)O(n)O(n) O(n2)O(n^2)O(n2) O(1)O(1)O(1) 稳定 希尔排序 O(nlogn) O(n2)O(nlogn) ~ O(n^2)O(nlogn) O(n2) O(n1.3)O(n^{1.3})O(n1.3) O(n2)O(n^2)O(n2) O(1)O(1)O(1) 不稳定 堆排序 O(nlogn)O(nlogn)O(nlogn) O(nlogn)O(nlogn)O(nlogn) O(nlogn)O(nlogn)O(nlogn) O(1)O(1)O(1) 不稳定 归并排序 O(nlogn)O(nlogn)O(nlogn) O(nlogn)O(nlogn)O(nlogn) O(nlogn)O(nlogn)O(nlogn) O(n)O(n)O(n) 稳定 快速排序 O(nlogn)O(nlogn)O(nlogn) O(nlogn)O(nlogn)O(nlogn) O(n2)O(n^2)O(n2) O(logn) O(n)O(logn)~O(n)O(logn) O(n) 不稳定 三种简单排序算法移动次数比较 排序方法 平均情况 最好情况 最坏情况 冒泡排序 O(n2)O(n^2)O(n2) 0 O(n2)O(n^2)O(n2) 简单选择排序 O(n)O(n)O(n) 0 O(n)O(n)O(n) 直接插入排序 O(n2)O(n^2)O(n2) O(n)O(n)O(n) O(n2)O(n^2)O(n2)","categories":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/categories/Basic/"}],"tags":[{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/tags/Basic/"}]},{"title":"Java核心技术","slug":"计算机基础知识/Java核心技术","date":"2022-01-10T07:22:12.000Z","updated":"2023-04-16T12:15:50.274Z","comments":true,"path":"2022/01/10/计算机基础知识/Java核心技术/","link":"","permalink":"http://jay1060950003.github.io/2022/01/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/","excerpt":"引言 Java核心思想的学习笔记 包含第一卷除swing章节，并包含第二卷的文件流部分","text":"引言 Java核心思想的学习笔记 包含第一卷除swing章节，并包含第二卷的文件流部分 1 Java程序设计概述 1.2 Java“白皮书”的关键术语 11个关键术语： 简单性 面向对象 分布式 健壮性： Java的设计目标之一在于使得Java编写的程序具有多方面的可靠性 Java和C++最大的不同在于Java采用的指针模型可以消除重写内存和损坏数据的可能性 安全性： Java代码不论来自哪里，都不能脱离沙箱 编译器生成一个体系结构中立的目标文件格式，这是一种编译过的代码，这些编译后的代码可以在许多处理器上运行 解释虚拟机指令肯定会比全速运行机器指令慢很多 即时编译：虚拟机的一个选项，可以将执行最频繁的字节码序列翻译成机器码 可移植性： 数据类型具有固定的大小 消除了代码移植时的问题 二进制数据以固定的格式进行存储和传输，消除了字节顺序的困扰 字符串是用标准的Unicode格式存储的 除了与用户界面有关的部分外，所有其他Java库都能很好地支持平台独立性。可以处理文件、正则表达式、XML、日期和时间、数据库、网络连接、线程等，而不用操心底层操作系统。不仅程序是可移植的，Java API往往也比原生API质量更高 解释型 高性能 多线程 动态性 3 Java的基本程序设计结构 3.1 一个简单的Java应用程序 关键字class： 关键字class后面紧跟类名,表明Java程序中的全部内容都包含在类中 类作为加载程序逻辑的容器，程序逻辑定义了应用程序的行为。 源代码的文件名必须与公共类的名字相同，并用.java作为扩展名 运行已编译的程序时，JVM将从指定类中的main方法开始执行，main方法必须声明为public，且必须为静态static的 Java的类与C++的类很相似，但Java中的所有函数都属于某个类的方法。因此，Java中的main方法必须有一个外壳类 3.2 注释 使用 //，其注释容从 // 开始到本行结尾。内 使用/*和 */ ：使用较长篇幅的注释 以 /** 开始，以 */ 结束：可以用来自动地生成文档 在Java中，/**/注释不能嵌套 3.3 数据结构 Java是一种强类型语言，意味着必须为每一个变量声明一种类型 8种基本类型: 4种整型 跳转至整型 2种浮点类型 跳转至浮点 1种用于表示Unicode编码的字符单元的字符类型char 跳转至char 1种用于表示真值的boolean类型 另：Java有一个能够表示任意精度的算术包，通常称为“大数值”（为Java对象） 跳转至大数据类 3.3.1 整型 类型 存储需求(字节) 取值范围 int 4 -2147483~2147483647(正好超过20亿) short 2 -32768~32767 long 8 -9223372036854775808~9223372036854775807 byte 1 -128~127 在Java中，整型的范围与运行Java代码的机器无关 Java没有任何无符号(unsigned)形式的int、long、short或byte类型 长整型数值有一个后缀L或l 十六进制数值有一个前缀0x或0X 八进制有一个前缀0 加上前缀0b或0B就可以写二进制数 可以为数字字面量加下划线(如用1_000_000(或0b1111_0100_0010_0100_0000)表示一百万) 3.3.2 浮点类型 类型 存储需求(字节) 取值范围 float 4 ±3.40282347E+38F(有效位数6~7位) double 8 ±1.79769313486231570+308F(有效位数15位) 浮点数值存在舍入误差 若不允许任何舍入误差，就应该使用BigDecimal类 跳转至大数据类 double（绝大多数程序使用）表示这种类型的数值精度是float类型的两倍。 float类型的数值有一个后缀F或f 没有后缀F的浮点数值，默认为double类型 使用十六进制表示浮点数值 例如，0.125=1.0*2^(-3)可以表示成0x1.0p-3(尾数十六进制，指数十进制) 在十六进制表示法中，使用p表示指数，而不是e 1234567//表示溢出和出错情况的三个特殊的浮点数值：//不可用于比较大小Double.POSITIVE_INFINITY //正无穷大Double.NEGATIVE_INFINITY //负无穷大Double.NaN //NaN(不是一个数字) if(Double.isNaN(x)) //需要使用该方法检测非数值 3.3.3 char类型 转义序列\\u可以出现在加引号的字符常量或字符串之外(而其他所有转义序列不可以) 转义序列 名称 unicode值 \\b 退格 \\u0008 \\t 制表 \\u0009 \\n 换行 \\u000a \\r 回车 \\u000d &quot; 双引号 \\u0022 ' 单引号 \\u0027 \\ 反斜杠 \\u005c 一定要当心注释中的\\u 3.3.4 Unicode和char类型 在Java中，char类型描述了UTF-16编码中的一个代码单元 强烈建议不要在程序中使用char类型，除非确实需要处理UTF-16代码单元 设计Unicode编码的目的 对于任意给定的代码值，在不同的编码方案下有可能对应不同的字母 采用大字符集的语言其编码长度有可能不同。 码点是指与一个编码表中的某个字符对应的代码值。 在Unicode标准中，码点采用十六进制书写，并加上前缀U+ Unicode的码点可以分成17个代码级别 第一个代码级别称为基本的多语言级别(basic multilingual plane)，码点从U+0000到U+FFFF，其中包括经典的Unicode代码 其余的16个级别码点从U+10000到U+10FFFF，其中包括一些辅助字符(supplementary character)。 UTF-16编码采用不同长度的编码表示所有Unicode码点 在基本的多语言级别中，每个字符用16位表示，通常被称为代码单元 而辅助字符采用一对连续的代码单元进行编码 这样构成的编码值落入基本的多语言级别中空闲的2048字节内，通常被称为替代区域 可以从中迅速地知道一个代码单元是一个字符的编码，还是一个辅助字符的第一或第二部分。 3.3.5 boolean类型 boolean类型有两个值：false,true 用来判定逻辑条件 整型值和布尔值之间不能进行相互转换 3.4 变量 声明变量时，变量的类型位于变量名之前 在Java中，不区分变量的声明与定义 声明一个变量之后，必须用赋值语句对变量进行显式初始化，不要使用未初始化的变量 3.4.2 常量 利用关键字final指示常量,常量名一般都是全大写 关键字final表示这个变量只能被赋值一次。一旦被赋值之后，就不能够再更改了 类常量：某个常量可以在一个类中的多个方法中使用。 使用关键字static final设置一个类常量 类常量的定义位于main方法的外部 同一个类的其他方法中也可以使用这个常量 一个常量被声明为public，其他类的方法也可以使用这个常量 3.5 运算符 除号/： 两个操作数都是整数时，表示整数除法 否则，表示浮点除法 整数被0除将产生一个异常 浮点数被0除将会得到无穷大或NaN结果 默认情况下，虚拟机设计者允许对中间计算结果采用扩展的精度 对于使用strictfp关键字标记的方法必须使用严格的浮点计算来生成可再生的结果 如果将一个类标记为strictfp，这个类中的所有方法都要使用严格的浮点计算 采用默认的方式不会产生溢出，而采用严格的计算有可能产生溢出 3.5.1 数学函数与常量 1234double x = 4;double y = Math.sqrt(x); //计算数值平方根double y = Math.pow(x,4); //计算幂运算System.out.println(y); Math类提供的各种各样的数学函数： 平方根 sqrt 幂 pow 取余 floorMod 三角函数 Math.sin Math.cos Math.tan Math.atan Math.atan2 自然对数运算 Math.exp Math.log Mtah.log10 结果比运行速度更重要，应该使用StrictMath类 println方法和sqrt方法存在微小的差异 println方法处理System.out对象 Math类中的sqrt方法为静态方法，处理的不是对象 3.5.2 数值类型之间的类型转换 6个实心箭头，表示无信息丢失的转换；3个虚箭头，表示可能有精度损失的转换 3.5.3 强制类型转换 123double x = 9.997;int y = (int) x; //在圆括号中给出想要转换的目标类型，后面紧跟待转换的变量名 将一个数值从一种类型强制转换为另一种类型，而又超出了目标类型的表示范围，结果就会截断成一个完全不同的值 不要在boolean类型与任何数值类型之间进行强制类型转换 极少数的情况才需要将布尔类型转换为数值类型,使用条件表达式 b?1:0 对浮点数进行舍入运算，使用Math.round方法 3.5.5 自增与自减运算符 后缀 i++ : 表示先使用当前值，在完成加一 前缀 ++i : 表示先完成加一，在使用变量值 3.5.6 关系和boolean变量 == 检测相等性 \\ != 检测不相等 &amp;&amp; || ! 与或非运算符 三元操作符 ? : 3.5.7 位运算符 &amp; | ^ ~ &gt;&gt; 左移运算符 &lt;&lt; 右移运算符 &gt;&gt;&gt; 左移 使用0填充最高位 &lt;&lt;&lt; 右移 使用0填充最低位 移位运算符的右操作数要完成模32的运算(除非左操作数是long类型 3.5.9 枚举类型 需要定义枚举类，参考枚举类 1234// 可以自定义枚举类型// 枚举类型包括有限个命名的值enum Size &#123; SMALL, MEDIUM, LARGE, EXTRA_LARGE&#125;; //声明枚举类型SizeSize s = Size.MEDIUM; //声明枚举变量s 3.6 字符串 Java没有内置的字符串类型，而是在标准Java类库中提供了一个预定义类String 3.6.1 子串 123456String greeting = &quot;Hello&quot;;// String类的substring方法// 可以从一个较大的字符串提取出一个子串// 容易计算子串的长度。字符串s.substring(a,b)的长度为b-aString s = greeting.substring(0,3); //从位置0处开始提取到第 3 字符为止(0 1 2) 3.6.2 拼接 允许使用 + 进行拼接两个字符串 当将一个字符串与一个非字符串的值进行拼接时，后者被转换成字符串 把多个字符串拼接并用定界符分隔，可以使用静态join方法 1String all = String.join(&quot;/&quot; , &quot;S&quot;, &quot;M&quot;, &quot;L&quot;, &quot;XL&quot;); 3.6.3 不可变字符串 String类没有提供修改字符串的方法（Java文档中将String类对象称为不可变字符串） 修改步骤：首先提取需要的字符，然后再拼接上替换的字符串 不可变字符串的优点：编译器可以让字符串共享 各种字符串存放在公共的存储池中 字符串变量指向存储池中相应的位置 如果复制一个字符串变量，原始字符串与复制的字符串共享相同的字符 Java字符串大致类似于char*指针 3.6.4 检测字符串是否相等 123456// 使用equals方法检测字符串是否相等（相等则返回true，否则返回false）s.equals(t); //用于检测可变字符串s与可变字符串t是否相等&quot;Hello&quot;.equals(greeting); //检测字符串常量与字符串变量greeting是否相等//不区分大小写检测：使用equalsIgnoreCase方法&quot;Hello&quot;.equalsIgnoreCase(&quot;hello&quot;); 一定不要使用==运算符检测两个字符串是否相等 该运算符只能够确定两个字符串是否放置在同一个位置上 若虚拟机始终将相同的字符串共享，就可以使用==运算符检测是否相等 但实际上只有字符串常量是共享的，而+或substring等操作产生的结果并不是共享的 3.6.5 空串和Null串 12345678// 空串是长度为0的字符串(一个Java对象,有自己的串长度(0)和内容(空))if (str.length() ==0)if (str.equals(&quot;&quot;))// String变量还可以存放一个特殊的值null//这表示目前没有任何对象与该变量关联if (str == null)if (str != null &amp;&amp; str.length() != 0) //检测既不是空串也不是null 3.6.6 码点与代码单元 char数据类型是一个采用UTF-16编码表示Unicode码点的代码单元 length方法将返回采用UTF-16编码表示的给定字符串所需要的代码单元数量 调用s.charAt(n)将返回位置n的代码单元，n介于0~s.length()-1之间 使用codePoints方法，它会生成一个int值的“流”,每个int值对应一个码点 将码点数组转换为字符串，可以使用构造函数 12//要想得到实际的长度，即码点数量，可以调用int cpCount = greeting.codePointCount(0,greeting.length()); 3.6.9 构建字符串 1234StringBulider builder = new StringBulider(); //构造空的字符串构造器builder.append(ch); //调用append方法添加内容builder.append(str); String completedString = builder.toString(); //调用toString方法转换为字符串String 使用StringBuilder类适用于由较短的字符串构造较短的字符串 避免每次连接字符串，都会构建一个新的String对象，既耗时，又浪费空间 StringBuilder类将所有的字符串在一个单线程中编辑 StringBuffer效率较低，但可以使用多线程方式执行添加或删除字符串的操作 3.7 输入与输出 3.7.1 读取输入 读取“标准输入流”操作 123456789101112131415//使用Scanner类实现（输入是可见的）//Scanner类定义在java.util包中import java.util.* //导入包Scanner in = new Scanner(System.in); //构造Scanner对象，并且与标准输入流System.in关联String name = in.nextline(); //使用nextline输入一行(输入行可能有空格)String firstname = in.next(); //读取一个单词输入(空格作为分隔符)int age = in.nextInt(); //读取一个整数Double times = in.nextDouble(); //读取一个浮点数//输入不可见，用于从控制台读取密码Console cons = System.console(); //Console实现String username = Cons.readLine( &quot;User name; &quot;);char[] passwc = cons.readPassword(&quot;Password: &quot;); 返回的密码存放在一维字符数组中 在对密码进行处理之后，应该马上用一个填充值覆盖数组元素. 采用Console对象处理输入不如采用Scanner方便（每次只能读取一行输入，而没有能够读取一个单词或一个数值的方法） 3.7.2 格式化输出 每一个以%字符开始的格式说明符都用相应的参数替换。 用于print的转换符： 用于print的标志： 可以使用s转换符格式化任意的对象 对于任意实现了Formattable接口的对象都将调用formatTo方法 否则将调用toString方法，它可以将对象转换为字符串 可以使用静态的String.format方法创建一个格式化的字符串，而不打印输出： 1String message = String.format(&quot;Hello, %s. Next year, you&#x27;ll be %d&quot;, name, age); 日期和时间： 可以采用一个格式化的字符串指出要被格式化的参数索引 索引必须紧跟在%后面，并以$终止。 1234System.out.printf(&quot;%1$s %2$tB %2$te, %2$tY&quot;, &quot;Due date;&quot;,new Date());System.out.printf(&quot;%s %tB %&lt;te, %&lt;tY&quot;, &quot;Due date:&quot;,new Date()); //&lt;标志前面格式说明中的参数将被再次使用。//参数索引值从1开始，而不是从0开始，%1$...对第1个参数格式化。这就避免了与0标志混淆。 3.7.3 文件输入与输出 123456Scanner in = new Scanner(Paths.get(&quot;myfile.txt&quot;),&quot;UTF-8&quot;);//对文件进行读取，就需要一个用File对象构造一个Scanner对象Scanner in = new Scaner(&quot;myfile.txt&quot;); //构造一个带有字符串参数的Scanner，但这个Scanner将字符串解释为数据，而不是文件名。PrintWriter out = new PrintWriter(&#x27; myfile.txt&quot;,&quot;UTF-8&quot;);//写入文件，就需要构造一个PrintWriter对象 如果用一个不存在的文件构造一个Scanner，或者用一个不能被创建的文件名构造一个PrintWriter，那么就会发生异常 1234567//告知编译器：已经知道有可能出现“输入/输出”异常//需要在main方法中用throws子句标记public static void main(String[] args) throws IOException&#123; Scanner in = new Scanner(Paths.get(&quot;myfi1e.txt&quot;),&quot;UTF8&quot;);&#125; 3.8 控制流程 Java的控制流程结构没有goto语句，但break语句可以带标签，可以利用它实现从内层循环跳出的目的 不能在嵌套的两个块中声明同名的变量 3.8.4 确定循环 在循环中，检测两个浮点数是否相等需要格外小心 由于舍入的误差，最终可能得不到精确值 例如，因为0.1无法精确地用二进制表示，所以，x将从9.99999999999998跳到10.09999999999998 如果在for语句内部定义一个变量，这个变量就不能在循环体之外使用 如果希望在for循环体之外使用循环计数器的最终值，就要确保这个变量在循环语句的前面且在外部声明 可以在各自独立的不同for循环中定义同名的变量。 3.8.5 多重选择：switch语句 switch语句将从与选项值相匹配的case标签处开始执行直到遇到break语句，或者执行到switch语句的结束处为止 有可能触发多个case分支。如果在case分支语句的末尾没有break语句，那么就会接着执行下一个case分支语句 编译代码时可以考虑加上==-Xlint:fallthrough选项，如果某个分支最后缺少一个break语句，编译器就会给出一个警告消息== 当在switch语句中使用枚举常量时，不必在每个标签中指明枚举名，可以由switch的表达式值确定 12345678Size SZ =...;switch (sz)&#123; case SMALL: // no need to use Size.SMALL ... break; ...&#125; 3.8.6 中断控制流程语句 标签必须放在希望跳出的最外层循环之前，并且必须紧跟一个冒号 continue语句越过了当前循环体的剩余部分，立刻跳到循环首部 continue语句用于for循环中，就可以跳到for循环的“更新”部分 3.9 大数值 java.math包中的两个很有用的类：BigInteger和BigDecimal 可以处理包含任意长度数字序列的数值 BigInteger类实现了任意精度的整数运算 BigDecimal实现了任意精度的浮点数运算。 12345//静态的valueOf方法可以将普通的数值转换为大数值BigInteger a = BigInteger.value0f(100);BigInteger c = a.add(b);BigInteger d = c.multiply(b.add(BigInteger.vale0f(2)));// 不可以使用+，*表示加法和乘法，只可以使用add和multiply方法进行 3.10 数组 声明数组变量时，需要指出数组类型(数据元素类型紧跟[])和数组变量的名字 123456789//使用new运算符创建数组int [] a; //声明数组变量int[] a = new int[100]; //创建长度为100的数组//创建一个数字数组时，所有元素都初始化为0//boolean数组的元素会初始化为false//对象数组的元素则初始化为一个特殊值null，这表示这些元素(还)未存放任何对象for (int i =0; i &lt; a.length; i++) //获得数组元素个数(length方法) System.out.println(a[i]); 一旦创建了数组，就不能再改变它的大小(尽管可以改变每一个数组元素) 需要在运行过程中扩展数组的大小，使用数组列表(array list) 3.10.1 for each循环 for each循环可以用来依次处理数组中的每个元素而不必指定下标值 12//collection集合表达式必须是一个数组或者是一个实现了Iterable接口的类对象for (variable:collection) statement 语句格式 调用Arrays.toString(a)，返回一个包含数组元素的字符串，可以打印数组中的所有值 3.10.2 数组初始化以及匿名数组 123456789//创建数组对象并同时赋予初始值的简化书写(不需要使用new)int[] smallPrimes = &#123; 2, 3, 5, 7, 11, 13 ]; //匿名数组new int[] &#123; 17, 19, 23, 29, 31, 37 &#125;; //在不创建新变量的情况下重新初始化一个数组smallPrimes = new int[] &#123; 17, 19, 23, 29, 31, 37 &#125;; //简化写法int[] anonynous = &#123; 17, 19, 23, 29, 31, 37 &#125;; smaPrimes = anonynous; 3.10.3 数组拷贝 在Java中，允许将一个数组变量拷贝给另一个数组变量,两个变量将引用同一个数组 将一个数组的所有值拷贝到一个新的数组中去，就要使用Arrays类的copyOf方法 1234567int[] luckyNumbers = smallPrimes; //数组拷贝luckyNunbers[5] = 12;int[] copiedLuckyNunbers = Arrays.copyOf(luckyNumbers,luckyNumbers.length); //第2个参数是新数组的长度//可用来调整数组的大小//如果长度小于原始数组的长度，则只拷贝最前面的数据元素 3.10.4 命令行参数 每一个Java应用程序都有一个带String arg[]参数的main方法 这个参数表明main方法将接收一个字符串数组，也就是命令行参数。 3.10.5 数组排序 对数值型数组进行排序，使用Arrays类中的sort方法 3.10.6 多维数组 与一维数组一样，在调用new对多维数组进行初始化之前不能使用它 若知道数组元素，就可以不调用new，而直接使用简化的书写形式对多维数组进行初始化 1234567891011balances = new double[NYEARS] [NRATES];int[][] magicSquare =&#123; 16, 3, 2, 13&#125;, &#123;5，10，11, B&#125;, &#123;9; 6, 7, 12&#125;, &#123;4，15，14, 1&#125;&#125;;System.out. println(Arrays.deepToString(a)); //快速地打印一个二维数组的数据元素列表 快速地打印一个二维数组的数据元素列表Arrays.deepToString方法 for each循环语句处理二维数组的每一个元素(需要使用两个嵌套的循环) for each循环语句对二维数组按照行(一维数组)处理 3.10.7 不规则数组 12345double[] temp = balances[i]; //数组两行交换balances[i] = balances[i + 1];balances[i + 1] = temp;//构造“不规则”数组，即数组的每一行有不同的长度。 4 对象与类 4.1.1 类 封装是与对象有关的一个重要概念 从形式上看，封装不过是将数据和行为组合在一个包中，并对对象的使用者隐藏了数据的实现方式 对象中的数据称为实例域，操纵数据的过程称为方法 对于每个特定的类实例(对象)都有一组特定的实例域值。这些值的集合就是这个对象的当前状态 无论何时，只要向对象发送一个消息，它的状态就有可能发生改变。 4.1.2 对象 对象状态的改变必须通过调用方法实现 如果不经过方法调用就可以改变对象状态，只能说明封装性遭到了破坏 需要注意，作为一个类的实例，每个对象的标识永远是不同的，状态常常也存在着差异 4.1.4 类之间的关系 依赖：如果一个类的方法操纵另一个类的对象，我们就说一个类依赖于另一个类。 聚合：意味着类A的对象包含类B的对象。 继承：是一种用于表示特殊与一般关系的。 4.2 使用预定类 Math类只封装了功能，它不需要也不必隐藏数据 由于没有数据，因此也不必担心生成对象以及初始化实例域 4.2.1 对象与对象变量 在Java程序中，使用构造器构造新实例 构造器是一种特殊的方法，用来构造并初始化对象 构造器的名字应该与类名相同 在构造器前面加上new操作符,new操作符的返回值是一个引用 定义对象变量后必须初始化对象变量,所有的Java对象都存储在堆中 一个对象变量并没有实际包含一个对象，而仅仅引用一个对象 任何对象变量的值都是对存储在另外一个地方的一个对象的引用 如果将一个方法应用于一个值为null的对象上，那么就会产生运行时错误 局部变量不会自动地初始化为null，而必须通过调用new或将它们设置为null进行初始化 当一个对象包含另一个对象变量时，这个变量依然包含着指向另一个堆对象的指针 在Java中，必须使用clone方法获得对象的完整拷贝 1234Date deadline; //定义对象变量deadline = new Date(); //初始化对象变量deadline = birthday; //或者引用一个存在的对象Date deadline = new Date(); //定义并初始化对象 4.2.2 Java类库中的LocalDate类 Date类:表示时间点 LocalDate类:日历表示法 不要使用构造器来构造LocalDate类的对象 使用静态工厂方法代表调用构造器 123456789LocalDate.now(); //构造新对象，表示构造这个对象时的日期LOcalDate.of(1999, 12, 31); //构造特定日期的对象//不可以使用构造器方法构造LocalDate对象LocalDate newYearsEve = LocalDate.of(1998, 12, 31); //用静态工厂方法构造对象int year = newYearsEve.getYear(); //返回年int month = newYearsEve.getMonthVa1ue(); //月int day = nenYearsEve.getDayOfMonth(); //日//返回一个新的LocalDate对象，为距当前对象之情天数的日期LocalDate aThousandDaysLater = newYearsEve.plusDays(1000); 4.2.3 更改器方法与访问器方法 访问器方法:只访问对象而不修改对象的方法,如LocalDate.getYear() 更改器方法:访问对象并修改对象的方法,如GregorianCalendar.add() 在C++中，带有const后缀的方法是访问器方法;默认为更改器方法 4.3 用户自定义类 在Java中，最简单的类定义形式： 123456789101112class ClassName&#123; field1 field2 ... constructor1 constructor2 ... method1 method2 ...&#125; 4.3.2 多个源文件的使用 使用通配符调用Java编译器:java Employee*.java 或编译 java EmployeeTest.java 4.3.3 剖析Employee类 关键字private确保只有Employee类自身的方法能够访问这些实例域，而其他类的方法不能够读写这些域 可以用public标记实例域（一种极为不提倡的做法） public数据域允许程序中的任何方法对其进行读取和修改（完全破坏了封装） 4.3.4 从构造器开始 构造器与类同名,可以拥有0个、1个或多个参数，没有返回值 构造器总是伴随着new操作符的执行被调用，而不能对一个已经存在的对象调用构造器来达到重新设置实例域的目的 每个类可以有一个以上的构造器 不要在构造器中定义与实例域重名的局部变量 必须注意在所有的方法中不要命名与实例域同名的变量 4.3.5 隐式参数与显式参数 在每一个方法中，关键字this表示隐式参数 在Java中，所有的方法都必须在类的内部定义，但并不表示它们是内联方法 4.3.6 封装的优点 需要获得或设置实例域的值，应该提供下面三项内容： 一个私有的数据域 一个公有的域访问器方法 一个公有的域更改器方法 更改器方法可以执行错误检查，然而直接对域进行赋值将不会进行这些处理 注意不要编写返回引用可变对象的访问器方法 如果需要返回一个可变对象的引用，应该首先对它进行克隆(clone) 对象clone是指存放在另一个位置上的对象副本。 Date类存在更改器方法setTime,因此Date对象是可变的，破坏了封装性 如需要使用Date类，返回时返回Date类的clone对象（使用clone方法） 4.3.7 基于类的访问权限 一个方法可以访问所属类的所有对象的私有数据 4.3.8 私有方法 在Java中，为了实现一个私有的方法，只需将关键字public改为private即可 对于私有方法，如果改用其他方法实现相应的操作，则不必保留原有的方法 4.3.9 final实例域 将实例域定义为final，构建对象时必须初始化这样的域 即必须确保在每一个构造器执行之后，这个域的值被设置，并且值不能改变 final修饰符大都应用于基本类型域或不可变类的域 对于可变的类，使用final修饰符表示对象引用不会指向其他对象，但对象是可以改变的 123456789101112131415class Employee &#123; //instance fields private final String name; ...&#125;//final关键字只是表示存储在evaluations变量中的对象引用不会再指示其他StringBuilder对象//不过这个对象可以更改private final StringBuilder evaluations; evaluations = new StringBuilder(); //构造器中初始化操作public void giveColdStar() //但可以修改该对象的值&#123; evaluations.append(LocalDate.nowO + &quot;: Cold star!\\n&quot;);&#125; 4.4 静态域与静态方法 4.4.1 静态域 如果将域定义为static，每个类中只有一个这样的域 每一个对象对于所有的实例域却都有自己的一份拷贝 静态域属于类而不属于任何独立的对象，所有该类的对象共享一个静态域 4.4.2 静态常量 在常量的声明中,添加关键词static表示静态常量 如Math类，若关键字static被省略，PI就变成了Math类的一个实例域 需要通过Math类的对象访问PI，并且每一个Math对象都有它自己的一份PI拷贝 由于每个类对象都可以对公有域进行修改，所以，最好不要将域设计为public.然而，公有常量(即final域)却没问题 静态常量System.out,out被声明为final,故不允许再将其他打印流赋给它 System类有一个setOut方法可以将System.out设置为不同的流 ==为什么这个方法可以修改final变量的值? 原因在于，setOut方法是一个本地方法，而不是用Java语言实现的==,可以绕过Java语言的存取控制机制 4.4.3 静态方法 静态方法是一种不能向对象实施操作的方法 静态方法是没有this参数的方法(在一个非静态的方法中，this参数表示这个方法的隐式参数 建议使用类名，而不是对象来调用静态方法,可以使用对象名进行调用静态方法 在下面两种情况下使用静态方法： 一个方法不需要访问对象状态，其所需参数都是通过显式参数提供(例如：Math.pow)。 一个方法只需要访问类的静态域(例如：Employee.getNextId) 4.4.4 工厂方法 工厂方法用于生成不同风格的格式化对象(静态方法的另一种用途[静态工厂方法]) 为什么NumberFormat类不利用构造器完成构建对象操作 原因： 无法命名构造器。构造器的名字必须与类名相同。但是，这里希望将得到的货币实例和百分比实例采用不用的名字 当使用构造器时，无法改变所构造的对象类型。而工厂方法将返回一个DecimalFormat类对象，这是NumberFormat的子类 4.4.5 main方法 main方法不对任何对象进行操作 事实上，在启动程序时还没有任何一个对象。静态的main方法将执行并创建程序所需要的对象。 每一个类可以有一个main方法(常用于对类进行单元测试) 4.5 方法参数 Java程序设计语言总是采用按值调用 方法得到的是所有参数值的一个拷贝,方法不能修改传递给它的任何参数变量的内容 方法可以通过对象引用的拷贝修改所引用的对象状态 总结一下Java中方法参数的使用情况： 一个方法不能修改一个基本数据类型的参数(即数值型或布尔型) 一个方法可以改变一个对象参数的状态 一个方法不能让对象参数引用一个新的对象 4.6 对象构造 4.6.1 重载 如果多个方法有相同的名字、不同的参数，便产生了重载 重载解析:编译器必须挑选出具体执行哪个方法，它通过用各个方法给出的参数类型与特定方法调用所使用的值类型进行匹配来挑选出相应的方法;如果编译器找不到匹配的参数，就会产生编译时错误 Java允许重载任何方法(包括构造器方法) 方法的签名:方法名以及参数类型 4.6.2 默认域初始化 如果在构造器中没有显式地给域赋予初值，那么就会被自动地赋为默认值 数值为0 布尔值为false 对象引用为null 4.6.3 无参数的构造器 对象由无参数构造函数创建时，其状态会设置为适当的默认值 如果类提供了至少一个构造器，但是没有提供无参数构造器，在构造对象时必须提供参数 仅当类没有提供任何构造器的时候，系统才会提供一个默认的构造器 4.6.4 显式域初始化 可以在类定义中，直接将一个值赋给任何域 初始值不一定是常量值 4.6.5 参数名 参数变量用同样的名字将实例域屏蔽起来 例如，如果将参数命名为salary，salary将引用这个参数，而不是实例域 但是，可以采用this.salary的形式访问实例域 this指示隐式参数，也就是所构造的对象 4.6.6 调用另一个构造器 如果构造器的第一个语句形如this(…)，这个构造器将调用同一个类的另一个构造器。 123456public Employee (double s)&#123; // calls Employee(String, double) this(&quot;Employee #&quot; + nextId, s); //调用Employee(String, double) 构造器 nextId++;&#125; 4.6.7 初始化块 初始化数据块的方法： 在构造器中设置值 在声明中赋值 初始化代码块：只要构造类的对象，这些块就会执行 1234567891011121314151617181920class Employee&#123; private static int nextId; private int id; private String name; private double salary; //初始化代码块 &#123; id = nextId; nextId++; &#125; public Employee(String n, double s) &#123; name = n; salary = s; &#125;...&#125; 通常会直接将初始化代码放在构造器中 调用构造器的具体处理步骤： 所有数据域被初始化为默认值(0、false或null) 按照在类声明中出现的次序，依次执行所有域初始化语句和初始化块 如果构造器第一行调用了第二个构造器，则执行第二个构造器主体 执行这个构造器的主体 4.6.8 对象析构与finalize方法 由于Java有自动的垃圾回收器，不需要人工回收内存，所以Java不支持析构器 可以为任何一个类添加finalize方法。finalize方法将在垃圾回收器清除对象之前调用。在实际应用中，不要依赖于使用finalize方法回收任何短缺的资源 有个名为System.runFinalizersOnExit(true)的方法能够确保finalizer方法在Java关闭前被调用。不过，这个方法并不安全，也不鼓励使用 有一种代替的方法是使用方法Runtime.addShutdownHook添加“关闭钩”(shutdown hook) 对象用完时，可以应用一个close方法来完成相应的清理操作 4.7 包 使用包的主要原因是确保类名的唯一性 一个类可以使用所属包中的所有类，以及其他包中的公有类 访问方法 在每个类名之前添加完整的包名 使用import语句：import语句应该位于源文件的顶部(但位于package语句的后面) import语句不仅可以导入类，还可以导入静态方法和静态域 123456//要想将一个类放入包中，就必须将包的名字放在源文件的开头，包中定义类的代码之前package com.horstmann.corejava;public class Employee&#123; ...&#125; 编译器对文件(带有文件分隔符和扩展名.java的文件)进行操作 而Java解释器加载类(带有.分隔符) 4.8 类路径 类存储在文件系统的子目录中 类的路径必须与包名匹配 类文件也可以存储在JAR(Java归档)文件中 在一个JAR文件中，可以包含多个压缩形式的类文件和子目录，这样既可以节省又可以改善性能 在程序中用到第三方(third-party)的库文件时，通常会给出一个或多个需要包含的JAR文件。 为了使类能够被多个程序共享，需要做到下面几点 把类放到一个目录中，需要注意，这个目录是包树状结构的基目录 如果希望将com.horstmann.corejava.Employee类添加到其中，这个Employee.class类文件就必须位于子目录/home/user/classdir/com/horstmann/corejava中 将JAR文件放在一个目录中 设置类路径(类路径是所有包含类文件的路径的集合) 最好采用-classpath(或-cp)选项指定类路径 4.9 文档注释 javadoc实用程序从下面几个特性中抽取信息，并编写注释 包 公有类与接口 公有的和受保护的构造器及方法 公有的和受保护的域 注释应该放置在所描述特性的前面,以/**开始，并以*/结束 标记由@开始 用于强调的＜em＞…＜/em＞ 用于着重强调的＜strong＞…＜/strong＞以及包含图像的＜img…＞ 不过，一定不要使用＜h1＞或＜hr＞，因为它们会与文档的格式产生冲突;若要键入等宽代码，需使用{@code…} 如果文档中有到其他文件的链接，就应该将这些文件放到子目录doc-files中 javadoc实用程序将从源目录拷贝这些目录及其中的文件到文档目录中。在链接中需要使用doc-files目录，例如：＜img src=“doc-files/uml.png”alt=“UML diagram”＞ 4.9.3 方法注释 每一个方法注释必须放在所描述的方法之前 除了通用标记之外，还可以使用下面的标记： @param变量描述：这个标记将对当前方法的“param”(参数)部分添加一个条目。这个描述可以占据多行，并可以使用HTML标记。一个方法的所有@param标记必须放在一起。 @return描述：这个标记将对当前方法添加“return”(返回)部分。这个描述可以跨越多行，并可以使用HTML标记。 @throws类描述：这个标记将添加一个注释，用于表示这个方法有可能抛出异常。 @version文本：这个标记将产生一个“version”(版本)条目(通用注释) 4.9.6 包与概述注释 可以直接将类、方法和变量的注释放置在Java源文件中，只要用/**…*/文档注释界定就可以了 要想产生包注释，就需要在每一个包目录中添加一个单独的文件 提供一个以package.html命名的HTML文件: 在标记＜body＞…＜/body＞之间的所有文本都会被抽取出来 提供一个以package-info.java命名的Java文件: 文件必须包含一个初始的以/**和*/界定的Javadoc注释，跟随在一个包语句之后。它不应该包含更多的代码或注释 4.9.7 注释的抽取 注释的抽取步骤： 切换到包含想要生成文档的源文件目录 如果有嵌套的包要生成文档，例如com.horstmann.corejava，就必须切换到包含子目录com的目录(如果存在overview.html文件的话，这也是它的所在目录) 如果是一个包，应该运行命令：javadoc -d docDirectory nameOfPackage;对于多个包生成文档，运行：javadoc -d docDirectory nameOfPackage1 nameOfPackage2 …;如果文件在默认包中，就应该运行：javadoc -d docDirectory *.java 4.10 类设计技巧 一定要保证数据私有 一定要对数据初始化 不要在类中使用过多的基本类型 不是所有的域都需要独立的域访问器和域更改器 将职责过多的类进行分解 类名和方法名要能够体现它们的职责 优先使用不可变的类 5 继承 继承已存在的类就是复用(继承)这些类的方法和域，在此基础上，还可以添加一些新的方法和域，以满足新的需求 反射是指在程序运行期间发现更多的类及其属性的能力 5.1 类、超类和子类 5.1.1 定义子类 关键字extends表示继承 关键字extends表明正在构造的新类派生于一个已存在的类 已存在的类称为超类、基类或父类;新类称为子类、派生类 12345//Manager继承Employee类public class Manager extends Employee&#123; 添加方法和域&#125; 5.1.3 子类构造器 覆盖方法：提供一个与超类方法同名的方法进行覆盖 在子类中可以增加域、增加方法或覆盖超类的方法，绝对不能删除继承的任何域和方法 可以使用super关键字调用超类 super与this的区别 super只是指示编译器调用超类方法的特殊关键字,不是一个对象的引用,不能将super赋给另一个对象变量 this关键字有两个用途:(1)引用隐式参数 (2)调用该类其他的构造器 super关键字两个用途:(1)调用超类的方法 (2)调用超类的构造器 调用构造器的语句只能作为另一个构造器的第一条语句出现,使用super调用超类构造器的语句必须是子类构造器的第一条语句 如果子类的构造器没有显式地调用超类的构造器，则将自动地调用超类默认(没有参数)的构造器 构造参数既可以传递给本类(this)的其他构造器,也可以传递给超类(super)的构造器 在Java中，虚拟机知道对象实际引用的对象类型，能够正确地调用相应的方法 多态:一个对象变量可以指示多种实际类型的现象 动态绑定:在运行时能够自动地选择调用哪个方法的现象 在Java中，不需要将方法声明为虚拟方法,动态绑定是默认的处理方式.如果不希望让一个方法具有虚拟特征，可以将它标记为final 123456789101112131415161718//Manager子类的构造器方法public Manager(String name, double salary, int year, int month, int day)&#123; //由于Manager类的构造器不能访问Employee类的私有域，所以必须利用Employee类的构造器对这部分私有域进行初始化 super(name, salary, year, month, day); bonus = 0;&#125;//主程序Manger boss = new Manger(&quot;Carl&quot;, 8000, 1987, 12, 15);boss.setBonus(5000);staff[0] = boss;staff[1] = new Employee(&quot;Harry&quot;, 5000, 1989, 10, 1);staff[2] = new Employee(&quot;Tony&quot;, 4000, 1990, 3, 15);for(Employee e : staff) System.out.println(e.getSalary());//对staff[0]，其为Manger类对象，调用的为Manger类的getSalary方法//对staff[1]，其为Employee类对象，调用的为Employee类的getSalary方法 5.1.4 继承层次 继承层次：由一个公共超类派生出来的所有类的集合 继承并不仅限于一个层次，可以由子类再次派生出其他类 在继承层次中，从某个特定的类到其祖先的路径被称为该类的继承链 Java不支持多继承(但可以利用接口实现) 5.1.5 多态 不能将一个超类的引用赋给子类变量 在Java中，子类数组的引用可以转换成超类数组的引用，而不需要采用强制类型转换 需要注意子类数组的引用与超类数组的引用，引用同一个对象时，调用子类的方法可能调用一个不存在的实例域 为了确保不发生这类错误，所有数组都要牢记创建它们的元素类型，并负责监督仅将类型兼容的引用存储到数组中 判断是否可以设计为继承关系的简单规则 “is-a”规则:表明子类的每个对象也是超类的对象 置换法则:程序中出现超类对象的任何地方都可以用子类对象置换 在Java程序设计语言中，对象变量是多态的 一个Employee变量既可以引用一个Employee类对象，也可以引用一个Employee类的任何一个子类的对象 5.1.6 理解方法调用 方法调用流程: 编译器查看对象的声明类型和方法名。编译器获得所有可能被调用的候选方法 编译器将查看调用方法时提供的参数类型。编译器已获得需要调用的方法名字和参数类型 如果是private方法、static方法、final方法或者构造器，那么编译器将可以准确地知道应该调用哪个方法(静态绑定)。与此对应的是，调用的方法依赖于隐式参数的实际类型，并且在运行时实现动态绑定 当程序运行，并且采用动态绑定调用方法时，虚拟机一定调用与所引用对象的实际类型最合适的那个类的方法 在运行时，调用e.getSalary()的解析过程为： 虚拟机提取e的实际类型的方法表。既可能是Employee、Manager的方法表，也可能是Employee类的其他子类的方法表 虚拟机搜索定义getSalary签名的类,虚拟机已经知道应该调用哪个方法 虚拟机调用方法 动态绑定有一个非常重要的特性：无需对现存的代码进行修改，就可以对程序进行扩展 假设增加一个新类Executive，并且变量e有可能引用这个类的对象，我们不需要对包含调用e.getSalary()的代码进行重新编译 如果e恰好引用一个Executive类的对象，就会自动地调用Executive.getSalary()方法 在覆盖一个方法的时候，子类方法不能低于超类方法的可见性 特别是，如果超类方法是public，子类方法一定要声明为public 5.1.7 组织继承:final类和方法 不允许扩展的类被称为final类,用于阻止利用该类定义子类 在定义类的时候使用final修饰符就表明这个类是final类,该类不可以被继承 类中的方法也可以被声明为final 子类不能覆盖该方法 final类，只有其中的方法自动转换为final,域不进行转换 声明final域 (final域在构造对象之后不允许被改变) 5.1.8 强制类型转换 跳转至强制类型转换 将某个类的对象引用转换成另外一个类的对象引用 仅需要用一对圆括号将目标类名括起来，并放置在需要转换的对象引用之前(与数值类型转换类似) 进行类型转换的唯一原因是：在暂时忽视对象的实际类型之后，使用对象的全部功能 在Java中，每个对象变量都属于一个类型(类型描述了这个变量所引用的以及能够引用的对象类型) 将一个值存入变量时，编译器将检查是否允许该操作 子类的引用赋给超类变量，编译器允许 超类的引用赋给子类变量，必须进行类型转换(为通过运行时的检查) 只能在继承层次内进行类型转换 在超类转换成子类之前，使用instanceof操作符查看一下是否能够成功地转换 实际上，通过类型转换调整对象类型并不是好的做法(因为多态性的动态绑定机制能够自动地找到相应的方法) 只有在使用Manager中特有的方法时才需要进行类型转换 12345if(staff[1] instanceof manager)&#123; boss = (Manager) staff[1]; ...&#125; 5.1.9 抽象类 建议将通用的域和方法放在超类中 抽象方法充当着占位的角色，具体的实现在子类中 扩展抽象类可以有两种选择： 一种是在抽象类中定义部分抽象类方法或不定义抽象类方法 另一种是定义全部的抽象方法 抽象类不能被实例化 不能创建abstract类的对象 可以定义一个抽象类的对象变量，但是只能引用非抽象子类的对象 在接口中大量使用抽象方法 在抽象类定义的抽象方法 若在超类中不定义该方法，则不可以通过抽象类对象变量调用类的方法 若超类定义了该方法，则可以通过抽象类的对象变量调用超类的方法 12345678//使用abstract关键字不需要实现方法//包含一个或多个抽象方法的类本身必须声明为抽象abstract的//抽象类Personpublic abstract class Person&#123; ... public abstract String getDescription();&#125; 5.1.10 受保护访问 4个访问修饰符 仅对本类可见——private 对所有类可见——public 对本包和所有子类可见——protected 对本包可见——默认，不需要修饰符 5.2 Object：所有类的超类 Object类是Java中所有类的始祖(每个类都是由它扩展而来的) 在Java中，只有基本类型不是对象 5.2.1-2 equals方法_相等测试与继承 Object类中的equals方法用于检测一个对象是否等于另外一个对象 在Object类中，equals方法将判断两个对象是否具有相同的引用(如果两个对象具有相同的引用，它们一定是相等的),但该方法没有实际意义,需要在自己的类中重写该方法 getClass()方法将返回一个对象所属的类,其进行相等检测的思考 如果子类能够拥有自己的相等概念，则对称性需求将强制采用getClass进行检测 如果由超类决定相等的概念，那么就可以使用instanceof进行检测，这样可以在不同子类的对象之间进行相等的比较 隐式参数和显示参数不属于同一个类，如何进行比较？ 使用equals方法，类不匹配则不相同 若使用instanceof进行检测(if(!(otherObject instanceof Employee)) return false;)不能解决otherObject是子类的问题，且还会带来新的麻烦 123456789101112131415161718192021222324252627//超类Employee的equals方法public class Employee &#123; ... public boolean equals(Object otherObject) &#123; if(this == otherObject) return true; if(otherObject == null) return false; if(this.getClass() != otherObject.getClass()) return false; Employee other = (Employee) otherObject; return Objects.equals(name,other.name) &amp;&amp; salary == other.salary &amp;&amp; Objects.equals(hireDay,other.hireDay); &#125; ...&#125;//在子类中定义equals方法时，首先调用超类的equals==//如果检测失败，对象就不可能相等//如果超类中的域都相等，就需要比较子类中的实例域public class Manager extends Employee &#123; private double bonus; ... public boolean equals(Object otherObject)&#123; if (!super.equals(otherObject)) return false; Manager other = (Manager) otherObject; return bonus == other.bonus; &#125; ...&#125; 语言规范要求equals方法应具有的特性 自反性：对于任何非空引用x，x.equals(x)应该返回true 对称性：对于任何引用x和y，当且仅当y.equals(x)返回true，x.equals(y)也应该返回true 传递性：对于任何引用x、y和z，如果x.equals(y)返回true，y.equals(z)返回true，x.equals(z)也应该返回true 一致性：如果x和y引用的对象没有发生变化，反复调用x.equals(y)应该返回同样的结果 对于任意非空引用x，x.equals(null)应该返回false 完美equals方法的建议 显式参数命名为otherObject(稍后需要类型转换) 检测this与otherObject是否引用同一个对象:(if(this == otherObject) return true;)实际上，这是一种经常采用的形式。因为计算这个等式要比一个一个地比较类中的域所付出的代价小得多 检测otherObject是否为null，如果为null，返回false(必要) 比较this与otherObject是否属于同一个类 如果equals的语义在每个子类中有所改变，就使用getClass检测 如果所有的子类都拥有统一的语义，就使用instanceof检测 将otherObject转换为相应的类类型变量 现在开始对所有需要比较的域进行比较了。使用==比较基本类型域，使用equals比较对象域。如果所有的域都匹配，就返回true；否则返回false 5.2.3 hashCode方法 散列码是由对象导出的一个整型值: 散列码没有规律(如果x和y是两个不同的对象,x.hashCode()与y.hashCode()基本上不会相同) 在String类中，可以使用hashCode()方法获取散列码 hashCode方法定义在Object类中，每个对象都有一个默认的散列码，其值为对象的存储地址 若重新定义equals方法，必须重新定义hashCode方法，以便将对象插入到散列表中 Equals与hashCode的定义必须一致(如果x.equals(y)返回true，那么x.hashCode()就必须与y.hashCode()具有相同的值) hashCode方法应该返回一个整型数值(也可以是负数)，并合理地组合实例域的散列码，以便能够让各个不同的对象产生的散列码更加均匀。 定义hashCode方法的注意事项： 最好使用null安全的方法Objects.hashCode 如果其参数为null，其结果为0 使用静态的Double.hashCode方法类避免创建Double对象 组合多个散列值，可以使用Objects.hash并提供多个参数 该方法会对各个参数调用Objects.hashCode，并组合这些散列值 123456789101112131415161718192021//Employee类的hashCode方法public class Employee&#123; public int hashCode() &#123; return 7*name.hashCode() + 11*new Double(salary).hashCode() + 13*hireDay.hashCode(); &#125; ...&#125;//Employee类的优化hashCode方法public class Employee&#123; public int hashCode() &#123; return Object.hash(name, salary, hireDay); &#125; ...&#125; 5.2.4 toString方法 在Object中toString方法，用于返回表示对象值的字符串 绝大多数的toString方法都采用的格式：类的名字，随后是一对方括号括起来的域值 Object类定义了toString方法，用来打印输出对象所属的类名和散列码 子类需要定义自己的toString方法，并将子类域的描述添加进去 如果超类使用了getClass().getName()，那么子类只要调用super.toString() 随处可见toString方法的主要原因（只要对象与一个字符串通过操作符“+”连接起来，Java编译就会自动地调用toString方法，以便获得这个对象的字符串描述） 数组继承了object类的toString方法，数组按照旧的格式打印 使用静态方法Arrays.toString可以获得数组字符串 多维数组使用Arrays.deepToString方法 可以使用该toString方法进行调试信息输出 1234567891011121314151617//Employee类的toString方法public String toString()&#123; //使用getClass.getName方法获得类名的字符串 return getClass.getName() + &quot;[name=&quot; + name + &quot;,salary=&quot; + salary + &quot;hireDay=&quot; + hireDay + &quot;]&quot;; &#125;//输出java.io.PrintStream@2f6684//PrintStream类没有覆盖toString方法System.out.println(System.out);//打印调试信息的方法:使用Logger.global.info方法//需要结合日志使用Logger.global.info(&quot;Current position = &quot; + position); 5.3 泛型数组列表 Java支持数组在运行时确定数组的大小，即将一个变量赋值给数组大小 Java具有ArrayList的类 类似数组，但在添加或删除元素时，具有自动调节数组容量的功能 ArrayList是一个采用类型参数的泛型类 为了指定数组列表保存的元素对象类型，需要用一对尖括号将类名括起来加在后面(ArrayList&lt;Employee&gt;) 数组列表的容量与数组的大小有一个非常重要的区别 如果为数组分配100个元素的存储空间，数组就有100个空位置可以使用 容量为100个元素的数组列表只是拥有保存100个元素的潜力(实际上，重新分配空间的话，将会超过100) 但是在最初，甚至完成初始化构造之后，数组列表根本就不含有任何元素 一旦能够确认数组列表的大小不再发生变化，就可以调用trimToSize方法(将存储区域的大小调整为当前元素数量所需要的存储空间数目) 一旦整理了数组列表的大小，添加新元素就需要花时间再次移动存储块(应该在确认不会添加任何元素时，再调用trimToSize) 123456789101112131415161718192021222324//声明和构造保存Employee对象的数组列表ArrayList&lt;Employee&gt; staff = new ArrayList&lt;Employee&gt;();//在JavaSE7中，可以省略右边的类型参数ArrayList&lt;Employee&gt; staff = new ArrayList&lt;&gt;();//使用add方法将元素添加到数组列表中//如果调用add且内部数组已经满了，数组列表就将自动地创建一个更大的数组，并将所有的对象从较小的数组中拷贝到较大的数组中staff.add(new Employee(&quot;Harry&quot;,...));//如果已经清楚或能够估计出数组可能存储的元素数量//在填充数组之前调用ensureCapacity方法staff.ensureCapacity(100); //分配100个对象的内部数组//可以将初始容量传递至ArrayList构造器ArrayList&lt;Employee&gt; staff = new ArrayList&lt;&gt;(100);//size方法返回数组列表中包含的实际元素数目staff.size();//在数组列表的中间插入元素使用带参数的add方法//为了插入一个新元素，位于n之后的所有元素都要向后移动一个位置//如果插入新元素后，数组列表的大小超过了容量，数组列表就会被重新分配存储空间staff.add(n,new Employee(&quot;Harry&quot;,...));//可以从数组列表中删除一个元素//位于这个位置之后的所有元素都向前移动一个位置，并且数组的大小减1Employee e = staff.remove(n); 5.3.1 访问数组列表元素 使用get和set方法实现访问或改变数组元素的操作 不使用[]语法格式进行索引元素 使用add方法为数组添加新元素，而不要使用set方法 set方法只能替换数组中已经存在的元素内容 get方法可获得数组列表的元素 没有泛型类时，原始的ArrayList类的get方法只能返回Object，因此还需要对返回值进行类型转换 add方法和set方法允许接受任何类型对象 对数组实施插入和删除元素的操作其效率比较低 对于小型数组来说，这一点不必担心 但如果数组存储的元素数比较多，又经常需要在中间位置插入、删除元素，就应该考虑使用链表了 5.3.2 类型化与原始数组列表的兼容性 只要在与遗留的代码进行交叉操作时，研究一下编译器的警告性提示，并确保这些警告不会造成太严重的后果就行了。 一旦能确保不会造成严重的后果，可以用@SuppressWarnings(“unchecked”)标注来标记这个变量能够接受类型转换。 123@SuppressWarnings(&quot; unchecked&quot;) ArrayList&lt;Employee&gt; result =(ArrayList&lt;Employee&gt;) emoloyeeDB.find(query); // yields another warning 5.4 对象包装器与自动装箱 所有的基本类型都有一个与之对应的类，这些类称为包装器 Integer,Long,Float,Double,Short,Byte,Character,Void和Boolean(前6个类派生于公共的超类Number) 对象包装器类是不可变的，即一旦构造了包装器，就不允许更改包装在其中的值 对象包装器类还是final，不能定义它们的子类 由于每个值分别包装在对象中，ArrayList&lt;Integer&gt;的效率远远低于int[]数组 自动装箱: 便于添加int类型的元素到ArrayList&lt;Integer&gt;中 要求boolean、byte、char≤127，介于-128~127之间的short和int被包装到固定的对象中 在算术表达式中也能够自动地装箱和拆箱 在自增自减操作中，编译器将自动地插入一条对象拆箱的指令，然后进行自增(自减)计算，最后再将结果装箱 基本类型与它们的对象包装器是一样的，只是它们的相等性不同 ==运算符也可以应用于对象包装器对象，只不过检测的是对象是否指向同一个存储区域 在两个包装器对象比较时调用equals方法 自动装箱的问题说明： 由于包装器类引用可以为null，所以自动装箱有可能会抛出一个NullPointerException异常 如果在一个条件表达式中混合使用Integer和Double类型，Integer值就会拆箱，提升为double，再装箱为Double 使用数值对象包装器还有另外一个好处。Java设计者发现，可以将某些基本方法放置在包装器中，例如，将一个数字字符串转换成数值 123456789101112//自动转换(自动装箱)list.add(3);//等效于list.add(Integer.valueOf(3));//当将一个Integer对象赋给一个int值时(自动拆箱)int n = list.get(i);//等效于int n = list.get(i).intValue();//将字符串转换为整数//与Integer对象没有任何关系，parseInt是一个静态方法//Integer类是放置这个方法的一个好地方int x = Integer.parseInt(s); Integer对象是不可变的：包含在包装器中的内容不会改变 不能使用这些包装器类创建修改数值参数的方法 如果想编写一个修改数值参数值的方法，就需要使用在org.omg.CORBA包中定义的持有者(holder)类型，包括IntHolder、BooleanHolder等。每个持有者类型都包含一个公有(！)域值，通过它可以访问存储在其中的值 123456789101112131415//按值传递，故x不会发生改变public static void triple(int x)&#123; x = 3*x;&#125;//Integer对象不可变public static void triple(Integer x)&#123; x = 3*x;&#125;//使用IntHolder改变对象中的内容public static void triple(IntHolder x)&#123; x.value = 3*x.value;&#125; 5.5 参数数量可变的方法 提供了可以用可变的参数数量调用的方法(变参方法),利用…符号表示参数数量可变 省略号…是Java代码的一部分，它表明这个方法可以接收任意数量的对象 printf方法接收两个参数，一个是格式字符串，另一个是Object[]数组，其中保存着所有的参数 对于printf的实现者来说，Object…参数类型与Object[]完全一样 编译器需要对printf的每次调用进行转换，以便将参数绑定到数组上，并在必要的时候进行自动装箱 可以定义可变参数的方法，并将参数指定为任意类型，甚至是基本类型 允许将一个数组传递给可变参数方法的最后一个参数 可以将已经存在且最后一个参数是数组的方法重新定义为可变参数的方法，而不会破坏任何已经存在的代码 12345public class PrintStream&#123; public PrintStream printf(String fmt,Object... args) return format(fmt,args);&#125; 5.6 枚举类 比较两个枚举类型的值，不需要调用equals，而直接使用“==”就可以了 可以在枚举类型中添加一些构造器、方法和域(构造器只是在构造枚举常量的时候被调用) 12345678910111213public enum Size&#123; SMALL(&quot;S&quot;)，MEDIUM(&quot;W&quot;), LARGE(&quot;L&quot;)，EXTRA_ LARGE(&quot;XL&quot;); private String abbreviation; private Size(String abbreviation) &#123; this.abbreviation = abbreviation; &#125; public String getAbbreviation() &#123; return abbreviation; &#125;&#125; 所有的枚举类型都是Enum类的子类 继承了Enum类的许多方法 其中最有用的一个是toString，这个方法能够返回枚举常量名 toString的逆方法是静态方法valueOf 每个枚举类型都有一个静态的values方法，它将返回一个包含全部枚举值的数组 ordinal方法返回enum声明中枚举常量的位置，位置从0开始计数 同Class类一样，鉴于简化的考虑，Enum类省略了一个类型参数(实际上，应该将枚举类型Size扩展为Enum&lt;Size&gt; 类型参数在compareTo方法中使用(compareTo方法 类型参数) 5.7 反射 反射库提供了一个非常丰富且精心设计的工具集，以便编写能够动态操纵Java代码的程序 能够分析类能力的程序称为反射，反射机制可以用来： 在运行时分析类的能力 在运行时查看对象，例如，编写一个toString方法供所有类使用 实现通用的数组操作代码 利用Method对象，这个对象很像C++中的函数指针 5.7.1 Class类 在程序运行期间，系统始终为所有的对象维护一个运行时的类型标识，该标识的信息跟踪着每个对象所属的类。虚拟机利用运行时类型信息选择相应的方法执行 可以通过专门的Java类访问这些信息(保存这些信息的类被称为Class) 一个Class对象实际上表示的是一个类型，而这个类型未必一定是一种类，且Class类实际上是一种泛型类 相关方法: 利用Object类中的getClass()方法获得Class类型的实例(获得class对象) T.class可获得匹配的类对象(T为任意的java类型)(获得class对象) Class类的forName()方法可以获得类名对应的Class对象(全路径名) Class类的getName()方法获得返回类的名字 newInstance()方法可以创建一个类的实例 配合forName()和newInstance()方法可以根据储存在字符串中的类名动态创建一个对象 1234567891011121314151617181920//一个Class对象将表示一个特定类的属性//Object类中的getClass()方法会返回一个Class类型的实例Employee e;Class cl = e.getClass();//最常用的方法时getName，该方法将返回类的名字//如果类在一个包中，则包的名字也作为类名的一部分System.out.println(e.getClass.getName);//可以使用静态的forName方法获得类名对应的Class对象//该方法只有在className是类名或者接口名时才能够执行//若类名保存在字符串中，可以在运行中改变String className = &quot;java.util.Random&quot;;Class cl = Class.forName(className);//可以使用T.class获得匹配的类对象（T为任意的java类型）class cl1 = Random.class;//newInstance方法调用默认的构造器初始化新创建的对象(若该类没有默认的构造器，就会抛出checked exception异常)//该方法创建一个与e具有相同类型的实例e.getClass.newInstance();//可以将forName和newInstance配合起来使用，可以根据储存在字符串中的类名创建一个对象String s = &quot;java.util.Random&quot;;Object m = Class.forName(s).newInstance(); 5.7.2 捕获异常 异常有两种类型： 未检查异常 已检查异常 对于已检查异常，编译器将会检查是否提供了处理器 使用try_catch语句 12345678910111213//将可能抛出已检查异常的一个或多个办法调用代码放在try块中//在catch子句中提供处理器代码try&#123; String name = ...// get class name Class cl = Class.forName(name); // might throw exception do something with cl&#125;catch (Exception e)&#123; e. printStackTrace();&#125;//如果类名不存在，则将跳过try块中的剩余代码，程序直接进入catch子句 5.7.3 利用反射分析类的能力 Class类中的getFields,getMethods和getConstructors方法分别返回类提供的public域,方法和构造器数组(包括超类的公有成员) Class类的getDeclareFields,getDeclareMethods和getDeclaredConstructors方法分别返回类中声明的全部域、方法和构造器(包括私有和受保护成员,但不包括超类的成员) 在java.lang.reflect包中有三个类Field,Method和Constructor分别用于描述类的域、方法和构造器 Method和Constructor类有能够报告参数类型的方法，Method类还有一个可以报告返回类型的方法 三个类都有getName方法(返回项目的名称) 三个类都有getModifiers方法(返回整型数值，用不同的位开关描述public和static这样的修饰符使用状况) 可利用java.lang.reflect包中的Modifier类的静态方法分析getModifiers返回的整型数值 Field类有getType方法(返回描述域所属类型的Class对象) 5.7.4 在运行时使用反射分析对象 查看对象域的关键方法是Field类中的get方法 只有利用get方法才能得到可访问域的值。除非拥有访问权限，否则Java安全机制只允许查看任意对象有哪些域，而不允许读取它们的值 setAccessible方法是AccessibleObject类中的一个方法,是Field、Method和Constructor类的公共超类 该特性是为调试、持久存储和相似机制提供的 1234567891011121314Employee harry = new Employee(&quot;Harry Hacker&quot;, 35000, 10，1, 1989);Class cl = harry.getClass();Field f = cl.getDeclaredField(&quot;name&quot;);Object v = f.get(harry);//name是一个私有域，get方法将会抛出IllegalAccessException//反射机制的默认行为受限于Java的访问控制//然而，如果一个Java程序没有受到安全管理器的控制，就可以覆盖访问控制//需要调用Field、Method或Constructor对象的setAccessible方法设置访问权限f.serAccessible(true);//name域是一个String作为Object返回没有问题//但是,假定查看salary域(double类型,不是对象)，使用Field类中的getDouble方法，也可以调用get方法//反射机制将会自动地将这个域值打包到相应的对象包装器中，这里将打包成Double//调用f.set(obj, value)可以将obj对象的f域设置成新值 5.7.5 使用反射编写泛型数组代码 java.lang.reflect包中的Array类允许动态地创建数组 getLength()是Array类的方法，而getCOmponentType()是Class类的方法 123456789101112131415161718192021222324252627//将Employee[]数组转换为Object[]数组public static Object[] badCopyOf(Object[] a, int newLength) &#123; Object[] newArray = new Object[newLength]; System.arraycopy(a, 0, newArray, 0, Math.min(a.length,newLength)); return newArray;&#125;//该段代码,在实际使用时返回Object[]类型 //一个对象数组不能转换为Employee[],会产生CLassCastException异常 //将一个Employee[]临时地转换成Object[]数组，然后再把它转换回来是可以的，但一个从开始就是Object[]的数组却永远不能转换成Employee[]数组//为解决该问题，编写通用的数组代码 //Array类中的静态方法newInstance能够构造新数组。在调用它时必须提供两个参数，一个是数组的元素类型，一个是数组的长度 //可以通过调用Array.getLength(a)获得数组的长度，也可以通过Array类的静态getLength方法的返回值得到任意数组的长度//获得新数组元素类型，就需要进行以下工作： //1)首先获得a数组的类对象。 //2)确认它是一个数组。 //3)使用Class类(只能定义表示数组的类对象)的getComponentType方法确定数组对应的类型public static Object goodCopy0f(Object a, int newLength)&#123; Class c1 = a.getClass(); if (!cl.isArray()) return null; Class componentType = cl.getConponentType(); int length = Array.getLength(a); Object newArray = Array. newInstance(componentType，newLength); System.arraycopy(a, 0, newArray, 0, Math.min(length, newLength)); return newArray;&#125; 5.7.6 调用任意方法 反射机制允许调用任意方法 在Method类中有一个invoke方法(允许调用包装在当前Method对象中的方法) invoke的参数和返回值必须是Object类型(必须进行多次的类型转换) 12345678910111213141516171819//invoke方法签名//第一个参数是隐式参数，其余的对象提供了显式参数//对于静态方法，第一个参数可以被忽略，即可以将它设置为nullObject invoke(Object obj, Object... args)//假设用ml代表Employee类的getName方法//如果返回类型是基本类型，invoke方法会返回其包装器类型String n = (String) ml.invoke(harry);//如果返回类型是基本类型，invoke方法会返回其包装器类型//假设m2表示Employee类的getSalary方法，那么返回的对象实际上是一个Double，必须相应地完成类型转换。可以使用自动拆箱将它转换为一个double：double n = (Double) m2.invoke(harry);//如何得到Method对象呢？ //当然，可以通过调用getDeclareMethods方法，然后对返回的Method对象数组进行查找，直到发现想要的方法为止 //也可以通过调用Class类中的getMethod方法得到想要的方法。它与getField方法类似(getField方法根据表示域名的字符串，返回一个Field对象) //然而，有可能存在若干个相同名字的方法，因此要格外小心，以确保能够准确地得到想要的那个方法。有鉴于此，还必须提供想要的方法的参数类型//getMethods的签名Method getMethod(String name, Class... parameterTypes)//获取Employee类的getName方法和raiseSalary方法指针Method m1 = Employee.class.getMethod(&quot;getName&quot;);Method m2 = Employee.class.getMethod(&quot;raiseSalary&quot;, double, class); 5.8 继承的设计技巧 将公共操作和域放在超类 不要使用受保护的域 protected机制并不能够带来更好的保护 1.子类集合是无限制的，任何一个人都能够由某个类派生一个子类，并编写代码以直接访问protected的实例域，从而破坏了封装性。 2.在Java程序设计语言中，在同一个包中的所有类都可以访问proteced域，而不管它是否为这个类的子类 protected方法对于指示那些不提供一般用途而应在子类中重新定义的方法很有用 使用继承实现“is-a”关系 除非所有继承的方法都有意义，否则不要使用继承 如果扩展LocalDate就不会出现这个问题。由于这个类是不可变的，所以没有任何方法会把假日变成非假日 在覆盖方法时，不要改变预期的行为 使用多态，而非类型信息 action1与action2表示的是相同的概念吗？如果是相同的概念，就应该为这个概念定义一个方法，并将其放置在两个类的超类或接口中 可以调用以便使用多态性提供的动态分派机制执行相应的动作 不要过多地使用反射 6 接口,Lambda表达式与内部类 接口技术，主要用来描述类具有什么功能，而并不给出每个功能的具体实现 一个类可以实现一个或多个接口，并在需要接口的地方，随时使用实现了相应接口的对象 使用lambda表达式，可以用一种精巧而简洁的方式表示使用回调或变量行为的代码 内部类机制 内部类定义在另外一个类的内部，其中的方法可以访问包含它们的外部类的域 内部类技术主要用于设计具有相互协作关系的类集合 代理(实现任意接口的对象),代理是一种非常专业的构造工具，可以用来构建系统级的工具 6.1 接口 6.1.1 接口概念 在Java程序设计语言中，接口不是类，而是对类的一组需求描述，这些类要遵从接口描述的统一格式进行定义 一个具体的示例 Arrays类的sort方法可以对对象数组进行排序 但对象所属的类必须实现了Comparable接口 任何实现Comparable接口的类都需要包含compareTo方法 在调用x.compareTo(y)的时候，compareTo方法必须比较两个对象的内容，并返回比较的结果 当x小于y时，返回一个负数 当x等于y时，返回0；否则返回一个正数 接口可能包含多个方法 接口中的所有方法默认为public(在声明方法时，不必提供关键字public) 接口还可以定义常量 提供实例域和方法实现的任务应该由实现接口的那个类来完成 接口看成是没有实例域的抽象类 让类实现接口，需要两个步骤： 将类声明为实现给定的接口 对接口中的所有方法进行定义 使用implements关键字将类声明为实现某个接口 让一个类使用排序服务必须让它实现compareTo方法 两个整数利用减法操作进行大小比较 整数的范围不能过大，以避免造成减法运算的溢出 如果能够确信ID为非负整数，或者它们的绝对值不会超过(Integer.MAX_VALUE-1)/2，就不会出现问题 否则，调用静态Integer.compare方法 相减技巧不适用于浮点值 为什么不能在类中直接提供一个compareTo方法，而必须使用接口 Java程序设计语言是一种强类型语言。在调用方法的时候，编译器将会检查这个方法是否存在 如果a是一个Comparable对象的数组，就可以确保拥有compareTo方法，因为每个实现Comparable接口的类都必须提供这个方法的定义 将Arrays类中的sort方法定义为接收一个Comparable[]数组就可以在使用元素类型没有实现Comparable接口的数组作为参数调用sort方法时，由编译器给出错误报告，但事实并非如此。在这种情况下，sort方法可以接收一个Object[]数组，并对其进行笨拙的类型转换 语言标准规定 对于任意的x和y，实现必须能够保证sgn(x.compareTo(y))=-sgn(y.compareTo(x)) 即y.compareTo(x)抛出一个异常，x.compareTo(y)也应该抛出一个异常 这里的“sgn”是一个数值的符号：如果n是负值，sgn(n)等于-1；如果n是0，sgn(n)等于0；如果n是正值，sgn(n)等于1。简单地讲，如果调换compareTo的参数，结果的符号也应该调换(而不是实际值) 如果子类之间的比较含义不一样，那就属于不同类对象的非法比较参考第五章equals方法 通用算法(能够对两个不同的子类对象进行比较)，应该在超类中提供一个final常量的compareTo方法 123456789101112131415161718192021222324252627282930313233343536373839//Comparable接口的代码 //任何实现Comparable接口的类都需要包含compareTo方法 //并且这个方法的参数必须是一个Object对象，返回一个整型数值public interface Comparable&#123; int CompareTo(Object other);&#125;//可使用泛型类型进行public interface Comparable&lt;T&gt; &#123; int CompareTo(T other);&#125;//在实现Compareable&lt;Employee&gt;接口的类中，必须提供方法int CompareTo(Employee other)&#123; ...&#125;//还可以使用不带类型参数的“原始”Comparable类型//其CompareTo方法就有一个Object类型参数//必须手动将CompareTo方法的参数强制转换至所需要的类型//将类声明为实现Comparable接口class Employee implements Comparable&#123; //在实现接口时，必须把方法声明为public //否则，编译器将认为这个方法的访问属性是包可见性，即类的默认访问属性 //之后编译器就会给出试图提供更严格的访问权限的警告信息 public int compareTo(Object otherObject) &#123; Employee other = (Employee) otherObject; return Double.compare(salary, other.salary); &#125;&#125;//使用泛型提供类型参数class Employee implements Comparable&lt;Employee&gt;&#123; public int compareTo(Employee otherObject) &#123; return Double.compare(salary, other.salary); &#125;&#125; 6.1.2 接口的特性 接口不是类，尤其不能使用new运算符实例化一个接口 尽管不能构造接口的对象，却能声明接口的变量,接口变量必须引用实现了接口的类对象 可以使用instance检查一个对象是否实现了某个特定的接口 接口中可以包含常量，但不可以包含实例域和静态方法 与接口中的方法都自动地被设置为public一样，接口中的域将被自动设为public static final 12345678910111213141516171819202122//定义接口变量Comparable x;//接口变量必须引用实现了接口的类对象x = new Employee(...);//可以使用instanceof检查一个对象是否实现了某个特定的接口if (anObject instanceof Comparable)&#123; ...&#125;//允许存在多条从具有较高通用性的接口到较高专用性的接口的链public interface Moveable&#123; void move(double x, double y);&#125;public interface Powered extends Moveable&#123; double milesPerCallon(); double SPEED_LIMIT = 95;&#125;//如果希望自己设计的类拥有克隆和比较的能力，只要实现这两个接口就可以了//使用逗号将实现的各个接口分隔开class Employee implements Cloneable,Comparable 6.1.3 接口与抽象类 使用抽象类表示通用属性存在这样一个问题 每个类只能扩展于一个类。假设Employee类已经扩展于一个类，例如Person，它就不能扩展第二个类了 但每个类可以实现多个接口 Java的不支持多继承，其主要原因是多继承会让语言本身变得非常复杂(如同C++)，效率也会降低 接口可以提供多重继承的大多数好处，同时还能避免多重继承的复杂性和低效性 6.1.4 静态方法 通常静态方法放在伴随类中，例如Collection/Collections或Path/Paths 在Java SE 8中，允许在接口中增加静态方法 实现自己的接口不再需要为实用工具方法另外提供一个伴随类 6.1.5 默认方法 可以用default修饰符为接口方法提供一个默认方法 默认方法可以调用任何其他方法 默认方法的一个重要用法是“接口演化” 假设stream方法不是一个默认方法。那么Bag类将不能编译，因为它没有实现这个新方法。为接口增加一个非默认方法不能保证“源代码兼容” 不过，假设不重新编译这个类，而只是使用原先的一个包含这个类的JAR文件。这个类仍能正常加载，尽管没有这个新方法。程序仍然可以正常构造Bag实例，不会有意外发生。 如果程序在一个Bag实例上调用stream方法，就会出现一个AbstractMethodError 将方法实现为一个默认方法就可以解决这两个问题。Bag类又能正常编译了。另外如果没有重新编译而直接加载这个类，并在一个Bag实例上调用stream方法，将调用Collection.stream方法 12345public interface Comparable&lt;T&gt;&#123; default int compareTo(T other)&#123;return 0;&#125; //可以为接口方法提供一个默认实现。必须用default修饰符标记这样一个方法&#125; 6.1.6 解决默认方法冲突 如果先在一个接口中将一个方法定义为默认方法，然后又在超类或另一个接口中定义了同样的方法，会发生什么情况？ 超类优先。如果超类提供了一个具体方法，同名而且有相同参数类型的默认方法会被忽略 一个类扩展了一个超类，同时实现了一个接口，并从超类和接口继承了相同的方法 在这种情况下，只会考虑超类方法，接口的所有默认方法都会被忽略 “类优先”规则可以确保与Java SE 7的兼容性 如果为一个接口增加默认方法，这对于有这个默认方法之前能正常工作的代码不会有任何影响 千万不要让一个默认方法重新定义Object类中的某个方法 例如，不能为toString或equals定义默认方法，尽管对于List之类的接口这可能很有吸引力.由于“类优先”规则，这样的方法绝对无法超越Object.toString或Objects.equals 接口冲突。如果一个超接口提供了一个默认方法，另一个接口提供了一个同名而且参数类型(不论是否是默认参数)相同的方法，必须覆盖这个方法来解决冲突(解决二义性问题) 12345678910111213141516interface Named&#123; default String getName() &#123; return getClass().getName() + &quot;_&quot; + hashCode); &#125;//类会继承Person和Named接口提供的两个不一致的getName方法,出现二义性问题//Java设计者更强调一致性//两个接口如何冲突并不重要。如果至少有一个接口提供了一个实现，编译器就会报告错误，而程序员就必须解决这个二义性class Student implements Person, Named&#123; public String getName()&#123; return Person.super.getName(); &#125; ...&#125;//如果两个接口都没有为共享方法提供默认实现，那么就与Java SE 8之前的情况一样，这里不存在冲突//实现类可以有两个选择：实现这个方法，或者干脆不实现。如果是后一种情况，这个类本身就是抽象的 6.2 接口示例 6.2.1 接口与回调 回调(是一种常见的程序设计模式) 在这种模式中，可以指出某个特定事件发生时应该采取的动作 6.2.2 Comparator接口 假设我们希望按长度递增的顺序对字符串进行排序，而不是按字典顺序进行排序 Arrays.sort方法还有第二个版本，有一个数组和一个比较器(comparator)作为参数，比较器是实现了Comparator接口的类的实例 12345678910111213141516171819//Comparator接口public interface Comparator&lt;T&gt; &#123; int compare(T first, T second);&#125;//实现按长度比较字符串的类class LengthComparator implements Comparator&lt;String&gt;&#123; public int compare(String first, String second) &#123; return first.length()-second.length(); &#125;&#125;//建立实例进行比较//尽管LengthComparator对象没有状态，不过还是需要建立这个对象的一个实例//需要这个实例来调用compare方法(不是一个静态方法)Comparator&lt;String&gt; comp = new LengthComparator();if(comp.compare(words[i],words[j])&gt;0)...//对数组排序//为Arrays.sort方法传入LengthComparator对象String[] friends = &#123;&quot;Peter&quot;,&quot;Paul&quot;&#125;;Arrays.sort(friends,new LengthComparator()); 6.2.3 对象克隆 Cloneable接口(指示一个类提供了一个安全的clone方法) Cloneable接口是Java提供的一组标记接口(标记接口不包含任何方法,唯一的作用是允许在类型查询中使用instanceof)之一 Comparable等接口的通常用途是确保一个类实现一个或一组特定的方法 clone方法是Object的一个protected方法(不能直接调用anObject.clone()) 只有Employee类可以克隆Employee对象 限制的原因： 如果对象中的所有数据域都是数值或其他基本类型，拷贝没有问题 如果对象包含子对象的引用，拷贝域就会得到相同子对象的另一个引用，原对象和克隆的对象仍然会共享一些信息 默认的克隆操作是“浅拷贝”，并没有克隆对象中引用的其他对象 浅拷贝的影响 如果原对象和浅克隆对象共享的子对象是不可变的，共享是安全的 如果子对象属于一个不可变的类，如String。或者在对象的生命期中，子对象一直包含不变的常量，没有更改器方法会改变它，也没有方法会生成它的引用，安全 通常子对象是可变的，必须重新定义clone方法来建立深拷贝，同时克隆所有子对象 对于每一个类，需要确定 默认的clone方法是否满足要求 是否可以在可变的子对象上调用clone来修补默认的clone方法 是否不该使用clone 第3个选项是默认选项;如果选择第1项或第2项，类必须： 实现Cloneable接口 重新定义clone方法，并指定public访问修饰符 clone方法实现的注意事项： 必须重新定义clone为public才能允许所有方法克隆对象(子类只能调用受保护的clone方法来克隆它自己的对象) Cloneable接口的出现与接口的正常使用并没有关系 具体来说，它没有指定clone方法，这个方法是从Object类继承的 Cloneable接口只是作为一个标记，指示类设计者了解克隆过程。对象对于克隆很“偏执”，如果一个对象请求克隆，但没有实现这个接口，就会生成一个受查异常 12345678910111213141516171819202122232425262728293031323334//即使clone的默认(浅拷贝)实现能够满足要求，还是需要实现Cloneable接口//将clone重新定义为public，再调用super.clone()//与Object.clone提供的浅拷贝相比，该clone方法并没有增加任何功能//只是让clone方法是公有的class Employee implements Cloneable&#123; // raise visibility level to public, change return type public Employee clone() throws CloneNotSupportedException return (Employee) super.clone();&#125;//深拷贝class Employee implements Cloneable&#123; //声明了这个异常:如果在一个对象上调用clone，但这个对象的类并没有实现Cloneable接口，Object类的clone方法就会抛出一个CloneNotSupportedException public Employee clone() throws CloneNotSupportedException Employee cloned = (Employee) super.clone(); cloned.hireDay = (Date) hireDay.clone(); return cloned;&#125;//使用异常捕获,非常适用于final类//否则，最好还是保留throws说明符(允许子类在不支持克隆时选择抛出一个CloneNotSupportedException)try&#123; Employee cloned = (Employee) super.clone();&#125;catch (CloneNotSupportedException e) &#123; return null; &#125;//必须当心子类的克隆//例如，一旦为Employee类定义了clone方法，任何人都可以用它来克隆Manager对象//出于这个原因，在Object类中clone方法声明为protected//不过，如果你希望类用户调用clone，就不能这样做。//所有数组类型都有一个public的clone方法，而不是protected//可以用这个方法建立一个新数组，包含原数组所有元素的副本int[] luckyNumbers = &#123; 2, 3, 5, 7, 11, 13 &#125;;int[] cloned = luckyNumbers.clone(); 6.3 Lambda表达式 6.3.1_2 引入Lambda表达式及语法 lambda表达式是一个可传递的代码块，可以在以后执行一次或多次 语法：参数，箭头(-&gt;)以及一个表达式 如果代码要完成的计算无法放在一个表达式中，就可以像写方法一样，把这些代码放在{}中，并包含显式的return语句 即使lambda表达式没有参数，仍然要提供空括号，就像无参数方法一样 如果可以推导出一个lambda表达式的参数类型，则可以忽略其类型 无需指定lambda表达式的返回类型(返回类型会由上下文推导得出) 如果一个lambda表达式只在某些分支返回一个值，在另外一些分支不返回值(不合法) 123456(String first, String second) -&gt;&#123; if (first.length() &lt; second.length()) return -1; else if (first.length() &gt; second.length()) return 1; else return 0;&#125; 6.3.3 函数式接口 函数式接口：对于只有一个抽象方法的接口，需要这种接口的对象时，就可以提供一个lambda表达式 为什么函数式接口必须有一个抽象方法： 接口中的方法并不是完全抽象的 接口完全有可能重新声明Object类的方法，如toString或clone，这些声明有可能会让方法不再是抽象的 在JavaSE8中，接口可以声明非抽象方法 在Java中，对lambda表达式所能做的也只是能转换为函数式接口 不能把lambda表达式赋给类型为Object的变量，Object不是一个函数式接口 123456//展示如何转化为函数式接口//考虑Arrays.sort方法//第二个参数需要一个Comparator实例，Comparator就是只有一个方法的接口，所以可以提供一个lambda表达式Arrays.sort(words, (first,second) -&gt; first.length() - second.length());//在底层，Arrays.sort方法会接收实现了Comparator＜String＞的某个类的对象。在这个对象上调用compare方法会执行这个lambda表达式的体 6.3.4 方法引用 表达式System.out::println是一个方法引用，等价于lambda表达式x-&gt;System.out.println(x) 要用::操作符分隔方法名与对象或类名。主要有3种情况: object::instanceMethod Class::staticMethod Class::instanceMethod 前2种情况中，方法引用等价于提供方法参数的lambda表达式 对于第3种情况，第1个参数会成为方法的目标。例如，String::compareToIgnoreCase等同于(x，y)-&gt;x.compareToIgnoreCase(y) 如果有多个同名的重载方法，编译器就会尝试从上下文中找出你指的那一个方法 类似于lambda表达式，方法引用不能独立存在，总是会转换为函数式接口的实例 可以在方法引用中使用this参数。例如，this::equals等同于x-&gt;this.equals(x) ==使用super也是合法的,super::instanceMethod 使用this作为目标，会调用给定方法的超类版本 6.3.5 构造器引用 构造器引用与方法引用很类似，只不过方法名为new Person::new是Person构造器的一个引用 可以用数组类型建立构造器引用 例如，int[]::new是一个构造器引用，它有一个参数:即数组的长度。这等价于lambda表达式x-&gt;new int[x] 1234567//Java有一个限制，无法构造泛型类型T的数组。数组构造器引用对于克服这个限制很有用//表达式new T[n]会产生错误，因为这会改为new Object[n]//假设我们需要一个Person对象数组。Stream接口有一个toArray方法可以返回Object数组Object[] people = stream.toArray();//流库利用构造器引用解决了这个问题。可以把Person[]::new传入toArray方法Person[] people = stream.toArray(Person[]::new);//toArray方法调用这个构造器来得到一个正确类型的数组。然后填充这个数组并返回 6.3.6变量作用域 lambda表达式有3个部分: 一个代码块 参数 自由变量的值(指非参数而且不在代码中定义的变量) 关于代码块以及自由变量值有一个术语：闭包 lambda表达式可以捕获外围作用域中变量的值 在Java中，要确保所捕获的值是明确定义的，在lambda表达式中，只能引用值不会改变的变量,如果在lambda表达式中引用变量，而这个变量可能在外部改变，这也是不合法的 lambda表达式中捕获的变量必须实际上是最终变量 最终变量是指，这个变量初始化之后就不会再为它赋新值 在lambda表达式中声明与一个局部变量同名的参数或局部变量是不合法的 在方法中，不能有两个同名的局部变量，因此，lambda表达式中同样也不能有同名的局部变量 在一个lambda表达式中使用this关键字时，是指创建这个lambda表达式的方法的this参数 123456789//表达式this.toString()会调用Application对象的toString方法，而不是ActionListener实例的方法public class Application()&#123; public void init() ActionListener listener = event -&gt; &#123; System.out.println(this, toString()); &#125;&#125; 6.3.7 处理lambda表达式 使用lambda表达式的重点是延迟执行 大多数标准函数式接口都提供了非抽象方法来生成或合并函数 已经提供了默认方法and、or和negate来合并谓词 如果设计你自己的接口，其中只有一个抽象方法，可以用@FunctionalInterface注解来标记这个接口 优点： 如果你无意中增加了另一个非抽象方法，编译器会产生一个错误消息 另外javadoc页里会指出你的接口是一个函数式接口 任何有一个抽象方法的接口都是函数式接口 1234567//假设重复一个动作n次repeat(10，() -&gt; System.out.println(&quot;He11o, Wor1d!&quot;));//可以使用Runnable接口,调用action.run()时会执行这个lambda表达式的主体public static void repeat(int n, Runnable action)&#123; for (int i =0; i &lt; n; i++) action.run();&#125; 6.4 内部类 内部类是定义在另一个类中的类 内部类方法可以访问该类定义所在的作用域中的数据，包括私有的数据 内部类可以对同一个包中的其他类隐藏起来 当想要定义一个回调函数且不想编写大量代码时，使用匿名内部类比较便捷 相较于C++嵌套类的好处 内部类的对象有一个隐式引用，它引用了实例化该内部对象的外围类对象。通过这个指针，可以访问外围类对象的全部状态 6.4.1 使用内部类访问对象状态 12345678910111213141516171819public class TalkingClock&#123; private int interval; private boolean beep; public TalkingClock(int interval, boolean beep) &#123;...&#125; public void start() &#123;...&#125; //定义一个内部类 //TimePrinter类位于TalkingClock类内部。这并不意味着每个TalkingClock都有一个TimePrinter实例域 //TimePrinter类的详细内容//需要注意一点，actionPerformed方法在发出铃声之前检查了beep标志public class TimePrinter implements ActionListener&#123; public void actionPerformed(ActionEvent event) &#123; System.out.println(&quot;At the tone, the time is&quot; + new Date()); if (beep) Toolkit.getDefaultToolkit().beep(); &#125;&#125; TimePrinter类没有实例域或者名为beep的变量 取而代之的是beep引用了创建TimePrinter的TalkingClock对象的域 一个方法可以引用调用这个方法的对象数据域 内部类既可以访问自身的数据域，也可以访问创建它的外围类对象的数据域 内部类的对象总有一个隐式引用，它指向了创建它的外部类对象 6.4.2 内部类的特殊语法规则 内部类中声明的所有静态域都必须是final 原因:静态域只有一个实例，不过对于每个外部对象，会分别有一个单独的内部类实例(若不是final，它可能就不是唯一的) 内部类不能有static方法,可以允许有静态方法，但只能访问外围类的静态域和方法 123456789101112131415161718//外围类引用的表达式OuterClass.this//TimePrinter内部类的actionPerformed方法public void actionPerformed(ActionEvent event)&#123; ... if (TalkingClock.this.beep) Toolkit.getDefaultToolkit().beep();&#125;//编写内部对象的构造器outerObject.new InnerClass(construction paraments)//最新构建的TimePrinter对象的外围类引用被设置为创建内部类对象的方法中的this引用ActionListener listener = this.new TimePrinter();//如果TimePrinter是一个公有内部类，对于任意的语音时钟都可以构造一个TimePrinterTalkingClock jabberer = new TakingClock(1000, true);TalkingClock.TimePrinter listener = jabberer.new TimePrinter();//在外围类的作用域之外，可以这样引用内部类OuterClass.InnerClass 6.4.3 内部类是否有用_必要和安全 内部类是一种编译器现象，与虚拟机无关 编译器将会把内部类翻译成用$(美元符号)分隔外部类名与内部类名的常规类文件，而虚拟机则对此一无所知 如果内部类访问了私有数据域，就有可能通过附加在外围类所在包中的其他类访问它们，但做这些事情需要高超的技巧和极大的决心 程序员不可能无意之中就获得对类的访问权限，而必须刻意地构建或修改类文件才有可能达到这个目的 6.4.4 局部内部类 可以在方法中定义局部类 局部类不能用public或private访问说明符进行声明 它的作用域被限定在声明这个局部类的块中 局部类有一个优势，即对外部世界可以完全地隐藏起来 6.4.5 由外部方法访问变量 局部类还有一个优点。 它们不仅能够访问包含它们的外部类，还可以访问final局部变量 局部变量必须事实上为final(一旦赋值就绝不会改变) 6.4.6 匿名内部类 匿名内部类：假如只创建这个类的一个对象，就不必命名了 匿名类不能有构造器(构造器的名字必须与类名相同，匿名类没有类名) 将构造器参数传递给超类构造器。尤其是在内部类实现接口的时候，不能有任何构造参数 Java程序员习惯的做法是用匿名内部类实现事件监听器和其他回调。如今最好还是使用lambda表达式。 1234567891011121314151617181920public void start(int interval, boolean beep)&#123; //匿名内部类 //含义：创建一个实现ActionListener接口的类的新对象，需要实现的方法actionPerformed定义在括号&#123;&#125;内 Actionlistener listener = new ActionListener () &#123; public void actionPerformed (ActionEvent event) System.out.println(&quot;At the tone, the time is &quot; + new Date()); if (beep) Too1kit.getDefaultTookit().beep(); &#125;; Timer t = new Timer(interval, listener); t.start();&#125;//匿名内部类的常见定义//SuperType可以是ActionListener这样的接口，于是内部类就要实现这个接口//SuperType也可以是一个类，于是内部类就要扩展它new Super Type(construction parameters)&#123; inner class methods and data&#125; 6.4.7 静态内部类 静态内部类：为了把一个类隐藏在另外一个类的内部，并不需要内部类引用外围类对象 将内部类声明为static，以便取消产生的引用 内部类在静态方法中构造，必须将内部类声明为静态内部类 6.5 代理 利用代理可以在运行时创建一个实现了一组给定接口的新类 这种功能只有在编译时无法确定需要实现哪个接口时才有必要使用 6.5.1 何时使用代理 假设有一个表示接口的Class对象(有可能只包含一个接口)，它的确切类型在编译时无法知道 要想构造一个实现这些接口的类，就需要使用newInstance方法或反射找出这个类的构造器 但是，不能实例化一个接口，需要在程序处于运行状态时定义一个新类 代理类可以在运行时创建全新的类，能够实现指定的接口 尤其是，它具有下列方法： 指定接口所需要的全部方法 Object类中的全部方法，例如，toString、equals等。 不能在运行时定义这些方法的新代码，而是要提供一个调用处理器 调用处理器是实现了InvocationHandler接口的类对象 调用处理器必须给出处理调用的方式 无论何时调用代理对象的方法，调用处理器的invoke方法都会被调用，并向其传递Method对象和原始的调用参数 12//InvocationHandler接口的唯一方法Object invoke(Object proxy, Method method, Object[] args) 6.5.2 创建代理对象 使用Proxy类的newProxyInstance方法创建代理对象 参数 一个类加载器 一个Class对象数组，每个元素都是需要实现的接口 一个调用处理器 6.5.3 代理类的特性 代理类是在程序运行过程中创建的 代理类一旦被创建，就变成了常规类，与虚拟机中的任何其他类没有什么区别 所有的代理类都扩展于Proxy类,一个代理类只有一个实例域—(调用处理器，它定义在Proxy的超类中) 所有的代理类都覆盖了Object类中的方法toString、equals和hashCode Object类中的其他方法(如clone和getClass)没有被重新定义= 没有定义代理类的名字，Sun虚拟机中的Proxy类将生成一个以字符串$Proxy开头的类名 对于特定的类加载器和预设的一组接口来说，只能有一个代理类（如果使用同一个类加载器和接口数组调用两次newProxyInstance方法的话，那么只能够得到同一个类的两个对象，也可以利用getProxyClass方法获得这个类） 代理类一定是public和final 如果代理类实现的所有接口都是public，代理类就不属于某个特定的包 否则，所有非公有的接口都必须属于同一个包，同时，代理类也属于这个包 通过调用Proxy类isProxyClass方法检测一个特定的Class对象是否代表一个代理类 7 异常_断言和日志 7.1 处理错误 7.1.1 异常分类 异常对象都是派生于Throwable类的一个实例 所有的异常都是Throwable继承下而来的,但分解为Error和Exception Error类层次结构描述了Java运行时系统的内部错误和资源耗尽错误(应用程序不应该抛出这种类型的对象) 需要关注Exception层次该层次结构又分解为两个分支：一个分支派生于RuntimeException;另一个分支包含其他异常 划分两个分支的规则是： 程序错误导致的异常属于RuntimeException 程序本身没有问题,但由于像I/O错误这类问题导致的异常属于其他异常 Java语言规范将派生于Error类或RuntimeException类的所有异常称为非受查异常，所有其他的异常称为受查异常 编译器将核查是否为所有的受查异常提供了异常处理器 7.1.2 声明受查异常 方法应该在其首部声明所有可能抛出的异常 12345678910111213141516171819202122232425//例//标准类库中提供的FileInputStream类的一个构造器的声明public FileInputStream (String name) throws FileNotFoundExpection//这个声明表示这个构造器将根据给定的String参数产生一个FileInputStream对象，但也有可能抛出一个FileNotFoundException异常//对于那些可能被他人使用的Java方法//应该根据异常规范，在方法的首部声明这个方法可能抛出的异常class MyAnimation&#123; ... public Image loadImage(String s) throws IOException &#123; ... &#125;&#125;//一个方法有可能抛出多个受查异常类型class MyAnimation&#123; ... public Image loadImage(String s) throws FileNotFoundException,EOFException &#123; ... &#125;&#125; 在自己写的方法中.需要抛出异常的4种情况： 调用一个抛出受查异常的方法，例如，FileInputStream构造器 程序运行过程中发现错误，并且利用throw语句抛出一个受查异常 程序出现错误，例如，a[–1]=0会抛出一个ArrayIndexOutOfBoundsException这样的非受查异常 Java虚拟机和运行时库出现的内部错误 不需要声明Java的内部错误，即从Error继承的错误 一个方法必须声明所有可能抛出的受查异常，而非受查异常要么不可控制(Error)，要么就应该避免发生(RuntimeException) 如果在子类中覆盖了超类的一个方法，子类方法中声明的受查异常不能比超类方法中声明的异常更通用 也就是说，子类方法中可以抛出更特定的异常，或者根本不抛出任何异常 如果超类方法没有抛出任何受查异常，子类也不能抛出任何受查异常 如果类中的一个方法声明将会抛出一个异常，而这个异常是某个特定类的实例时，则这个方法就可能抛出一个这个类的异常，或者这个类的任意一个子类的异常 7.1.3 如何抛出异常 对于一个已经存在的异常类,抛出方法： 找到一个合适的异常类 创建这个类的一个对象 将对象抛出 1234567891011//EOFException异常描述的是“在输入过程中遇到了一个未预期的EOF后的信号”//抛出异常的语句throw new EOFException();//orEOFException e = new EOFException();throw e;//EOFException类还有一个含有一个字符串型参数的构造器//这个构造器可以更加细致的描述异常出现的情况String gripe = &quot;Content Length: &quot; + len + &quot;, Received: &quot; + n;throw new EOFException(gripe); 7.1.4 创建异常类 需要做的只是定义一个派生于Exception的类，或者派生于Exception子类的类 例如，定义一个派生于IOException的类 习惯上，定义的类应该包含两个构造器 一个是默认的构造器 另一个是带有详细描述信息的构造器(超类Throwable的toString方法将会打印出这些详细信息，这在调试中非常有用) 12345678910//定义自己的异常类class FileFormatException extends IOException&#123; public FileFormatException() &#123;&#125; public FileFormatException(String gripe) &#123; super(gripe); &#125;&#125;//抛出throw new FileFormatException(); 7.2 捕获异常 7.2.1 捕获异常 要想捕获一个异常，必须设置try/catch语句块 如果在try语句块中的任何代码抛出了一个在catch子句中说明的异常类 程序将跳过try语句块的其余代码 程序将执行catch子句中的处理器代码 如果在try语句块中的代码没有抛出任何异常，那么程序将跳过catch子句 如果方法中的任何代码抛出了一个在catch子句中没有声明的异常类型，那么这个方法就会立刻退出 如果编写一个覆盖超类的方法，而这个方法又没有抛出异常，那么这个方法就必须捕获方法代码中出现的每一个受查异常 不允许在子类的throws说明符中出现超过超类方法所列出的异常类范围 1234567//try/catch语句try &#123; code morecode&#125; catch (ExceptionType e) &#123; //TODO: handle exception&#125; 7.2.2 捕获多个异常 捕获多个异常时，异常变量隐含为final变量 123456789101112131415161718192021222324252627282930313233343536//捕获多个异常类型，并对不同类型的异常做出不同的处理try &#123; code morecode&#125;catch (FileNotFoundException e) &#123; //TODO: handle exception&#125;catch (UnknownHostException e) &#123; //TODO: handle exception&#125;catch (IOException e) &#123; //TODO: handle exception&#125;//获得异常对象的更多信息e.getMessage();//获得更详细的错误信息e.getClass().getName();//在Java SE 7中，同一个catch子句中可以捕获多个异常类型try &#123; code morecode&#125;catch (FileNotFoundException | UnknownHostException e) &#123; //TODO: handle exception&#125;catch (IOException e) &#123; //TODO: handle exception&#125; 7.2.3 再次抛出异常与异常链 在catch子句中可以抛出一个异常，这样做的目的是改变异常的类型 12345678910111213141516171819202122232425262728//捕获异常并将它再次抛出的基本方法try &#123; code morecode&#125; catch (SQLException e) &#123; throw new ServletException(&quot;database error: &quot; + e.getMessage());&#125;//更好的处理方式，并且将原始异常设置为新异常的原因try &#123; code morecode&#125; catch (SQLException e) &#123; Throwable se = new ServletException(&quot;database erroe:&quot;); se.initCause(e); throw se;&#125;//当捕获到异常时，就可以使用下面这条语句重新得到原始异常Throwable e = se.getCause();//只想记录一个异常，再将它重新抛出，而不做任何改变try &#123; code morecode&#125; catch (Exception e) &#123; logger.log(level,message, e); throw e;&#125; 7.2.4 finally子句 如果方法获得了一些本地资源，并且只有这个方法自己知道，又如果这些资源在退出方法之前必须被回收，那么就会产生资源回收问题 一种解决方案是捕获并重新抛出所有的异常(需要在正常的代码中和异常代码中清除所分配的资源) 一种更好的解决方案，finally子句 不管是否有异常被捕获，finally子句中的代码都被执行 finally中的代码总会执行 当finally子句包含return语句时，将会出现错误的结果 假设利用return语句从try语句块中退出 在方法返回前，finally子句的内容将被执行 如果finally子句中也有一个return语句，这个返回值将会覆盖原始的返回值 清理资源的方法也有可能抛出异常 close方法本身也有可能抛出IOException异常。当出现这种情况时，原始的异常将会丢失，转而抛出close方法的异常 可以使用带资源的try语句解决 1234567891011121314151617181920212223242526//try语句可以只有finally子句,而没有catch子句InputStream in = new FileInputStream(...)try &#123; try &#123; //code &#125; finally&#123; //code in.close(); &#125;&#125; catch (IOException e) &#123; //show error message&#125; //内层的try语句块只有一个职责，就是确保关闭输入流//外层的try语句块也只有一个职责，就是确保报告出现的错误public static int f(int n) &#123; try &#123; int r = n * n; return r; &#125; finally&#123; if (n==2) return 0; &#125;&#125;//如果调用f(2)，那么try语句块的计算结果为r=4，并执行return语句//然而，在方法真正返回前，还要执行finally子句。finally子句将使得方法返回0，这个返回值覆盖了原始的返回值4 7.2.5 带资源的try语句 12345678910111213//带资源的try语句的简单形式try (Resource res = ...) &#123; //work with res &#125;//try块退出时，会自动调用res.close()//可以指定多个资源try (Scanner in = new Scanner(new FileInputStream(&quot;user/share/dict/words&quot;),&quot;UTF-8&quot;); PrintWriter out = new PrintWriter(&quot;out.txt&quot;)) &#123; while(in.hasNext()) out.println(in.next().toUpperCase()); &#125; 带资源的try语句可以很好地处理:try块抛出一个异常，而且close方法也抛出一个异常 原来的异常会重新抛出，而close方法抛出的异常会“被抑制” 这些异常将自动捕获，并由addSuppressed方法增加到原来的异常 如果对这些异常感兴趣，可以调用getSuppressed方法，它会得到从close方法抛出并被抑制的异常列表 只要需要关闭资源,就要尽可能使用带资源的try语句 带资源的try语句的catch子句和一个finally子句在关闭资源之后执行 7.2.6 分析堆栈轨迹元素 堆栈轨迹是一个方法调用过程的列表，它包含了程序执行过程中方法调用的特定位置 可以调用Throwable类的printStackTrace方法访问堆栈轨迹的文本描述信息 使用getStackTrace方法得到StackTraceElement对象的一个数组，可以在程序中分析这个对象数组 StackTraceElement类含有能够获得文件名和当前执行的代码行号的方法;同时,还含有能够获得类名和方法名的方法 使用toString方法将产生一个格式化的字符串，其中包含所获得的信息 静态的Thread.getAllStackTrace方法可以产生所有线程的堆栈轨迹 123456789101112131415Throwable t = new Throwable();StringWriter out = new StringWriter();t.printStackTrace(new PrintWriter(out));String description = out.toString();StackTraceElement[] frams = t.getStackTrace();for (StackTraceElement frame : frames) //analyze frameMap&lt;Tread, StackTraceElement[]&gt; map = Tread.getAllStackTrace();for (Tread t :map.keySet())&#123; StackTraceElement[] frames = map.get(t); //analyze frames&#125; 7.3 使用异常的技巧 异常处理不能代替简单的测试：只在异常情况下使用异常机制 不要过分地细化异常 利用异常层次结构 不要只抛出RuntimeException异常。应该寻找更加适当的子类或创建自己的异常类 不要只捕获Thowable异常，否则，会使程序代码更难读、更难维护 不要压制异常 在检测错误时，“苛刻”要比放任更好 不要羞于传递异常 7.4 使用断言 7.4.1 断言的概念 断言机制允许在测试期间向代码中插入一些检查语句 当代码发布时，这些插入的检测语句将会被自动地移走 123456//两种形式:assert 条件//orassert 条件:表达式;//这两种形式都会对条件进行检测，如果结果为false，则抛出一个AssertionError异常//在第二种形式中，表达式将被传入AssertionError的构造器，并转换成一个消息字符串 7.4.2 启用和禁用断言 默认情况下，断言被禁用 可以在运行程序时用-enableassertions或-ea选项启用 在启用或禁用断言时不必重新编译程序 启用或禁用断言是类加载器的功能。当断言被禁用时，类加载器将跳过断言代码，因此，不会降低程序运行的速度 可以用选项-disableassertions或-da禁用某个特定类和包的断言 启用和禁用所有断言的-ea和-da开关不能应用到那些没有类加载器的“系统类”上 对于这些系统类来说，需要使用-enablesystemassertions/-esa开关启用断言 1234567//启用断言java -enableassertions MyApp//在某个类或整个包中使用断言java -ea:MyClass -ea:com.mycompany.mylib...MyApp//禁用断言java -ea:... -da:MyClass MyApp 7.4.3 使用断言完成参数检查 使用断言的情况： 断言失败是致命的、不可恢复的错误 断言检查只用于开发和测阶段 7.5 记录日志 记录日志API的优点: 可以很容易地取消全部日志记录,或者仅仅取消某个级别的日志,而且打开和关闭这个操作也很容易 可以很简单地禁止日志记录的输出 日志记录可以被定向到不同的处理器.用于在控制台中显示,用于存储在文件中等 日志记录器和处理器都可以对记录进行过滤.过滤器可以根据过滤实现器制定的标准丢弃那些无用的记录项 日志记录可以采用不同的方式格式化 应用程序可以使用多个日志记录器，它们使用类似包名的这种具有层次结构的名字 在默认情况下，日志系统的配置由配置文件控制 7.5.1 基本日志 1234//使用全局日志记录器并调用其info方法,可以生成简单的日志记录Logger.getGlobal().info(&quot;File-&gt;Open menu item selected&quot;);//在适当的地方调用将会取消所有的日志Logger.getGlobal().setLevel(Level.OFF); 7.5.2 高级日志 使用getLOgger方法创建或获取记录器 未被任何变量引用的日志记录可能会被垃圾回收,需要用静态变量存储日志记录器的一个引用 日志的七个等级： SEVERE WARNING INFO CONFIG FINE FINER FINEST 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//创建或获取记录器public static final Logger myLogger = Logger.getLogger(&quot;com.mycompany.myapp&quot;);//设置日记等级只记录前三个等级Logger.setLevel(Level.FINE);//可以使用Level.ALL开启所有级别的记录Logger.setLevel(Level.ALL);//使用Level.OFF关闭所有级别的记录Logger.setLevel(Level.OFF);//对于所有的级别有下面几种记录方法logger.warning(message);logger.fine(message);//使用logger指定等级logger.log(Level.FINE, message);//默认的日志记录将显示包含日志调用的类名和方法名,如同堆栈所显示的那样//如果虚拟机对执行过程进行了优化，就得不到准确的调用信息//此时,可以调用logp方法获得调用类和方法的确切位置,这个方法的签名:void logp(Level 1, String className, String methodName, String message)//用来跟踪流程执行的方法void entering(String ClassName, String methodName)void entering(String className, String methodName, 0bject param)void entering(String className, String methodName, Object[] params)void exiting(String className, String methodName)void exiting(String classNare, String methodName, 0bject result)//未来，带Object[]参数的日志记录方法可能会被重写，以便支持变量参数列表(“varargs”)//此后就可以用logger.entering(“com.mycompany.mylib.Reader”，“read”，file，pattern)格式调用这个方法了//记录日志的常见用途是记录那些不可预料的异常//可以使用下面两个方法提供日志记录中包含的异常描述内容void throwing(String classNare, String methodName, Throwable t)void log(Level 1, String message, Throwable t)//典型用途if (...)&#123; IOException exception = new IOException(&quot;...&quot;); logger.throwing(&#x27;com.mycompany.mylib.Reader&#x27;, &quot;read&quot;, exception); throw exception;&#125;//ortry &#123; ...&#125; catch (IOException e) &#123; Logger.getLogger(&quot;com.mycompany.myapp&quot;).log(Level.WARNING, &quot;Reading image&quot;, e);&#125;//调用throwing可以记录一条FINER级别的记录和一条以THROW开始的信息 7.5.3 修改日志管理器配置 可以通过编辑配置文件来修改日志系统的各种属性 要想使用另一个配置文件，就要将java.util.logging.config.file特性设置为配置文件的存储位置 日志管理器在VM启动过程中初始化，在main执行之前完成 如果在main中调用System.setProperty(“java.util.logging.config.file”,file) 也会调用LogManager.readConfiguration()来重新初始化日志管理器 修改默认的日志记录级别 编辑配置文件，并修改**.LEVEL=INFO** 日志记录并不将消息发送到控制台上，这是处理器的任务,且处理器也有级别 java.util.logging.ConsoleHandler.level=FINE (在控制台上看到FINE级别的消息) 在日志管理器配置的属性设置不是系统属性，因此，用-Dcom.mycompany.myapp.level=FINE启动应用程序不会对日志记录器产生任何影响 日志属性文件由java.util.logging.LogManager类处理 可以通过将java.util.logging.manager系统属性设置为某个子类的名字来指定一个不同的日志管理器 另外，在保存标准日志管理器的同时，还可以从日志属性文件跳过初始化 还有一种方式是将java.util.logging.config.class系统属性设置为某个类名，该类再通过其他方式设定日志管理器属性 在运行的程序中，使用jconsole程序也可以改变日志记录的级别 12345678910//默认情况下配置文件路径jre/lib/1ogging.properties//使用其他配置文件java -Djava.util.logging.config.fi1e=configFile MainClass//指定自己的日志记录级别(在日志记录器名后面添加后缀.level)com.mycompany.myapp.level = FINE//在控制台上看到FINE级别的消息，就需要进行下列设置java.util.logging.ConsoleHandler.level=FINE 7.5.4 本地化 本地化的应用程序包含资源包中的本地特定信息 一个程序可以包含多个资源包，一个用于菜单;其他用于日志消息 要想将映射添加到一个资源包中，需要为每个地区创建一个文件 英文消息映射位于com/mycompany/logmessages_en.properties文件中 德文消息映射位于com/mycompany/logmessages_de.properties文件中 通常需要在本地化的消息中增加一些参数，因此，消息应该包括占位符{0}、{1}等 123456789101112//请求日志记录器，指定资源包Logger logger = Lgger.getlogger(loggerName，&quot;com.mycompany.logmessages&quot;);//为日志消息指定资源包的关键字，而不是实际的日志消息字符串logger.info(&quot;readingFile&quot;);//在日志消息中包含文件名，就应该用下列方式包括占位符Reading file: &#123;0&#125;.Achtung! Datei &#123;0&#125; wird eingelesen.//然后通过调用下面的一个方法向占位符传递具体的值logger.log(Level.INFO, &quot;readingFile&quot;, fileName);lagger.log(Level.INF0, &quot;renamingFile&quot;, new 0bject[] &#123;oldNane, newName&#125;); 7.5.5 处理器 在默认情况下，日志记录器将记录发送到ConsoleHandler中，并由它输出到System.err流中 特别是，日志记录器还会将记录发送到父处理器中，而最终的处理器有一个ConsoleHandler 处理器也有日志记录级别 对于一个要被记录的日志记录，它的日志记录级别必须高于日志记录器和处理器的阈值 修改文件处理器的默认行为 日志记录文件名：例如%h/myapp.log 如果多个应用程序(或者同一个应用程序的多个副本)使用同一个日志文件，就应该开启append标志 另外，应该在文件名模式中使用%u，以便每个应用程序创建日志的唯一副本 可以使用文件循环功能 12345678910111213141516171819//日志管理器默认配置文件设置的默认控制台处理器的日志记录级别java.util.logging.ConsoleHandler.level = INFO//绕过配置文件,安装自己的处理器Logger logger = Logger.getLogger(&quot;com.mycompany.myapp&quot;);logger.setLevel(Level.FINE);loger.setUseParentHandlers(false);Handler handler = new ConsoleHandler();handler.setLevel(Level.FINE);logger.addHandler(handler); //默认情况下，日志记录器将记录发送到自己的处理器和父处理器 //我们的日志记录器是原始日志记录器(命名为“”)的子类，而原始日志记录器将会把所有等于或高于INFO级别的记录发送到控制台 //然而，并不想两次看到这些记录,故将useParentHandlers属性设置为false//要想将日志记录发送到其他地方,就要添加其他的处理器//日志API为此提供了两个很有用的处理器//一个是FileHandler;另一个是SocketHandler(SocketHandler将记录发送到特定的主机和端口)FileHandler handler = new FileHandler();logger.addHander(handler); 7.5.6 过滤器 在默认情况下，过滤器根据日志记录的级别进行过滤 每个日志记录器和处理器都可以有一个可选的过滤器来完成附加的过滤 另外，可以通过实现Filter接口并定义下列方法来自定义过滤器 要想将一个过滤器安装到一个日志记录器或处理器中，只需要调用setFilter方法就可以了 同一时刻,最多只能有一个过滤器 123//实现Filter接口并定义自定义过滤器boolean isLoggable(LogRecord record)//在这个方法中，可以利用自己喜欢的标准，对日志记录进行分析，返回true表示这些记录应该包含在日志中 7.5.7 格式化器 ConsoleHandler类和FileHandler类可以生成文本和XML格式的日志记录 扩展Formatter类可以实现自定义格式 123456789//扩展Formatter类并覆盖方法String format(LogRecord record)//在format方法中,formatMessage方法对记录中的部分消息进行格式化、参数替换和本地化应用操作String formatMessage(LogRecord record)//很多文件格式(如XML)需要在已格式化的记录的前后加上一个头部和尾部//在已格式化的记录前后增加头部和尾部的覆盖方法String getHead(Handler h)String getTail(Handler h)//最后，调用setFormatter方法将格式化器安装到处理器中 7.5.8 日志记录说明 为一个简单的应用程序，选择一个日志记录器，并把日志记录器命名为与主应用程序包一样的名字 为了方便起见，可能希望利用一些日志操作将静态域添加到类中 默认的日志配置将级别等于或高于INFO级别的所有消息记录到控制台 用户可以覆盖默认的配置文件(最好在应用程序中安装一个更加适宜的默认配置) 可以记录自己想要的内容 所有级别为INFO、WARNING和SEVERE的消息都将显示到控制台上 最好只将对程序用户有意义的消息设置为这几个级别(设定为FINE是一个很好的选择) 12345678910111213141516//下列代码确保将所有的消息记录到应用程序特定的文件中//可以将这段代码放置在应用程序的main方法中if (System.getPropery(&quot;java.util.logging.config.class&quot;) == null&amp;&amp; System.getProperty(&quot;java.util.logging.confg.fine&quot;) == null)&#123; try &#123; Logger.getLogger(&quot;&quot;).setlevel(Level.ALl); final int LOG_ROTATION_COUNT = 10; Handler handler = new FileHandler(&quot;%h/myapp.log&quot;, 0, LOG_ROTATION_COUNT); Logger.getLoggr(&quot;&quot;).addHandler(handler); &#125;&#125;catch (IOException e) logger.log(Level.SEVERE, &quot;Can&#x27;t create log file handler&quot;, e);&#125; 7.6 调试技巧 可以用方法打印或记录任意变量的值 一个不太为人所知但却非常有效的技巧是在每一个类中放置一个单独的main方法 日志代理(logging proxy)是一个子类的对象，它可以截获方法调用，并进行日志记录，然后调用超类中的方法 利用Throwable类提供的printStackTrace方法，可以从任何一个异常对象中获得堆栈情况 一般来说，堆栈轨迹显示在System.err上。也可以利用printStackTrace(PrintWriter s)方法将它发送到一个文件中。如果想记录或显示堆栈轨迹，可以将它捕获到一个字符串中 通常，将一个程序中的错误信息保存在一个文件中是非常有用的。然而，错误信息被发送到System.err中，而不是System.out中。 让非捕获异常的堆栈轨迹出现在System.err中并不是一个很理想的方法。如果在客户端偶然看到这些消息，则会感到迷惑，并且在需要的时候也无法实现诊断目的。比较好的方式是将这些内容记录到一个文件中。可以调用静态的Thread.setDefaultUncaughtExceptionHandler方法改变非捕获异常的处理器 要想观察类的加载过程，可以用-verbose标志启动Java虚拟机 -Xlint选项告诉编译器对一些普遍容易出现的代码问题进行检查 Java虚拟机增加了对Java应用程序进行监控(monitoring)和管理(management)的支持;它允许利用虚拟机中的代理装置跟踪内存消耗、线程使用、类加载等情况 可以使用jmap实用工具获得一个堆的转储，其中显示了堆中的每个对象 如果使用-Xprof标志运行Java虚拟机，就会运行一个基本的剖析器来跟踪那些代码中经常被调用的方法;剖析信息将发送给System.out。输出结果中还会显示哪些方法是由即时编译器编译的 8 泛型程序设计 8.1 为什么要使用泛型程序设计 8.1.1 类型参数的好处 在Java中增加范型类之前，泛型程序设计是用继承实现的 ArrayList类只维护一个Object引用的数组 具有两个问题: 获取一个值时必须进行强制类型转换 没有错误检查(可以向数组列表中添加任何类的对象) 使用类型参数可以很好的解决问题 再使用get方法时,不需要进行强制类型转换 只能允许前一个调用，而不能允许后一个调用 ArrayList类有一个方法addAll用来添加另一个集合的全部元素。程序员可能想要将ArrayList&lt;Manager&gt;中的所有元素添加到ArrayList&lt;Employee&gt;中去。然而，反过来就不行了 可以使用通配符类型解决该问题 12345678910111213//ArrayList类只维护一个Object引用的数组public class ArrayList&#123; private Object[] elementData; ... public Object get(int i)&#123;...&#125; public void add(Object o)&#123;...&#125;&#125;//ArrayList类有一个类型参数用来指示元素的类型ArrayList&lt;String&gt; files = new ArrayList&lt;String&gt;();//JavaSE7之后可以省略泛型类型ArrayList&lt;String&gt; files = new ArrayList&lt;&gt;(); 8.2 定义简单泛型类 一个泛型类就是具有一个或多个类型变量的类 泛型类可以有多个类型变量,在尖括号内使用逗号隔开 类定义中的类型变量指定方法的返回类型以及域和局部变量的类型 类型变量使用大写形式,且比较短 使用变量E表示集合的元素类型 K和V分别表示表的关键字与值的类型 T (需要时还可以用临近的字母U和S)表示“任意类型” 1234567891011121314151617181920//定义Pair类public class Pair&lt;T&gt; //Pair类引入了一个类型变量T，用尖括号&lt;&gt;括起来，并放在类名的后面&#123; private T first; private T second; public Pair()&#123; first = null;second = null; &#125; public Pair (T first, T second) &#123; this.first = first; this.second = second; &#125; public T getFirst() &#123;return first;&#125; public T getSecond() &#123;return second;&#125; public void setFirst(T newValue)&#123;first = newValue;&#125; public void setSecond(T newValue)&#123;second = newValue;&#125;&#125; 8.3 泛型方法 可以定义带有类型参数的简单方法,泛型方法 类型变量放在修饰符的后面，返回类型的前面 泛型方法可以定义在普通类中，也可以定义在泛型类中 12345678910111213141516//定义泛型方法class ArrayAlg&#123; public static&lt;T&gt; T getMiddle(T...a) &#123; return a[a.length / 2]; &#125;&#125;//调用方法,在方法名前面的尖括号内放入具体的类型String middle = ArrayAlg.&lt;String&gt;getMiddle(&quot;John&quot;,&quot;Q.&quot;);//在大多数情况下，方法调用中可以省略&lt;String&gt;类型参数//编译器有足够的信息能够推断出所调用的方法。它用names的类型(即String[])与泛型类型T[]进行匹配并推断出T一定是StringString middle = ArrayAlg.getMiddle(&quot;John&quot;,&quot;Q.&quot;);double middle = ArrayAlg.getMiddle(3.14,1729,0);//编译器将会自动打包参数为1个Double和2个Integer对象，而后寻找这些类的共同超类型。事实上，找到2个这样的超类型：Number和Comparable接口，其本身也是一个泛型类型5//可以采取的补救措施是将所有的参数写为double值 8.4 类型变量的限定 类和方法需要对类型变量加以约束 解决办法:将T限制为实现了Comparable接口的类.可以通过对类型变量T设置限定实现 一个类型变量或通配符可以有多个限定 限定类型使用 &amp; 分隔，而逗号用来分隔类型变量 在Java的继承中,可以根据需要拥有多个接口超类型,但限定中至多有一个类 如果用一个类作为限定,它必须是限定列表中的第一个 123456789101112131415161718//对类型变量限制//将T限制为实现了Comparable接口(只含一个方法compareTo的标准接口)的类public static&lt;T extends Comparable&gt; T min(T[] a)...//限定类型使用&amp;分隔，而逗号用来分隔类型变量T extends Comparable &amp; Serializable//计算数组中最小元素class ArrayAlg&#123; public static&lt;T extends Comparable&gt; T min(T[] a) &#123; if(a == null || a.length == 0) return null; T smallest = a[0]; for(int i = 1; i&lt;a.length;i++) if(smallest.compareTo(a[i])&gt;0) smallest = a[i]; return smallest; &#125;&#125; 8.5 泛型代码和虚拟机 虚拟机没有泛型类型对象,所有对象都属于普通类 8.5.1 类型擦除 无论何时定义一个泛型类型,都自动提供了一个相应的原始类型 原始类型的名字就是删去类型参数后的泛型类型名 擦除类型变量并替换为限定类型 为了提高效率，应该将标签接口(即没有方法的接口)放在边界列表的末尾 Pair泛型类 12345678910111213141516171819202122//Pair原始类public class Pair &#123; private Object first; private Object second; public Pair() &#123;first = null;second = null;&#125; public Pair(Object first, Object second) &#123; this.first = first; this.second = second; &#125; public Object getFirst() &#123;return first;&#125; public Object getSecond() &#123;return second;&#125; public void setFirst(Object newValue)&#123;first = newValue;&#125; public void setSecond(Object newValue)&#123;second = newValue;&#125;&#125;//对于多个限定类型的泛型类class Interval&lt;T extends Serializable &amp; Comparable&gt;//生成原始类型时用Serializable替换T//编译器在必要时要向Comparable插入强制类型转换 8.5.2 翻译泛型表达式 当程序调用泛型方法时,如果擦除返回类型,编译器插入强制类型转换 擦除返回类型后,返回一个Object类型 编译器自动插入Employee的强制类型转换 编译器将这个方法翻译为两条虚拟机指令 对原始方法Pair.getFirst的调用 将返回的Object类型强制转换为Employee类型 12Pair&lt;Employee&gt; buddies = ...;Employee buddy = buddies.getFirst(); 8.5.3 翻译泛型方法 在泛型方法中也存在着类型擦除 完整的方法族,擦除类型后只剩下一个方法 123456789101112131415161718192021222324252627282930313233343536373839404142//泛型方法(完整的方法簇)public static &lt;T extends Comparable&gt; T min(T[] a)//擦除之后只剩下一个方法public static Comparable min(Comparable[] a)//类型擦除实例class DataInterval extends Pair&lt;LocalDate&gt;&#123; public void setSecond(LocalDate second) &#123; if(second.compareTo(getFirst()) &gt;= 0) super.setSecond(second); &#125;&#125;//方法擦除之后，带来两个问题 //一个日期区间是一对LocalDate对象,并且需要覆盖这个方法来确保第二个值永远不小于第一个值class DateInterval extends Pair&#123; public void setSecond(LocalDate second) &#123; ... &#125;&#125;//但存在另一个从Pair继承的setSecond方法//两个方法的签名不同,属于不同的方法.但其应该是相同的方法public void setSecond(Object second)//语言序列DateInterval interval = new DateInterval(...);Pair&lt;LocalDate&gt; pair = interval;pair.setSecond(aData);//希望setSecond的调用具有多态性,由于pair引用DateInterval对象,所以应该调用DateInterval.setSecond//问题在于类型擦除与多态发生了冲突,需要编译器在DateInterval类中生成一个桥方法public void setSecond(Object second)&#123;setSecond((Date) second);&#125;//桥方法应用于方法覆盖时public class Employee implements Cloneable&#123; public Employee clone() throws CloneNotSupportedException&#123;...&#125;&#125;//Object.clone和Employee.clone方法被说成具有协变的返回类型//合成的桥方法调用了新定义的方法//实际上,Employee类有两个克隆方法:Employee clone()Object clone() 桥方法的工作过程: 变量pair已经声明为类型Pair&lt;LocalDate&gt;,并且这个类型只有一个简单的方法叫setSecond,即setSecond(Object) 虚拟机用pair引用的对象调用这个方法.这个对象是DateInterval类型的,因而将会调用DateInterval.setSecond(Object)方法(合成的桥方法). 该方法调用DateInterval.setSecond(Date),正是所期望的操作效果 桥方法不仅用于泛型类型 一个方法覆盖另一个方法时可以指定一个更严格的返回类型 泛型转换的事实： 虚拟机中没有泛型，只有普通的类和方法 所有的类型参数都用于他们的限定类型替换 桥方法被合成用来保持多态 为保持类型安全性，必要时插入强制类型转换 8.5.4 调用遗留代码 设计泛型的目的：允许泛型代码和遗留代码间能够相互操作 12345678910111213141516171819202122232425//例子1//要想设置一个JSlider标签,可以使用方法void setLabelTable(Dictionary table)//Dictionary是一个原始类型,因为实现JSlider类时Java中还不存在泛型//填充字典时,使用泛型类型Dictionary&lt;Integer, Component&gt; labelTable = new Hashtable&lt;&gt;();labelTable.put(0, new JLable(new ImageIcon(&quot;nine.gif&quot;)));labelTable.put(20, new JLable(new ImageIcon(&quot;ten.gif&quot;)));...//将Dictionary&lt;Interger, Component&gt;对象传递给setLabelTable 时, 编译器会发出警告slider.setLable(labelTable);//原因://编译器无法确定setLabelTable可能会对Dictionary对象做什么操作//这个警告对操作并不会产生什么影响,最多考虑一下JSlider有可能用 Dictionary对象做什么就可以了//例子2//由一个遗留的类得到一个原始类型的对象,将它赋给一个参数化的类型变量Dictionary &lt;Integer, Components&gt; labelTable = slider.getLabelTable(); // Warning//可以利用注解使警告消失,注释必须放在生成这个警告的代码所在的方法之前@SuppressWarnings(&quot;unchecked&quot;)Dictionary&lt;Integer, Components&gt; labelTable = slider.getLabelTable(); // no warning//或标注整个方法(关闭对方法中所有代码的检查)@SuppressWarnings(&quot;unchecked&quot;)public void configureSlider()&#123;......&#125; 8.6 约束与局限性 泛型编程时,需要注意一些限制 大多数限制都是由于类型擦除引起的 8.6.1 不能用基本类型实例化类型参数 不能用类型参数代替基本类型 没有Pair&lt;double&gt;,只有Pair&lt;Double&gt; 原因：类型擦除后,Pair含有Object类型的域,而Object不能存储double值 当包装器类型不能接受替换时,可以使用独立的类和方法处理 8.6.2 运行时类型查询只适用于原始类型 虚拟机中的对象总有一个特定的非泛型类型,因此所有的类型检查只产生原始类型 倘若使用instanceof会得到一个编译器错误,如果使用强制类型转换会得到一个警告 getClass方法总是返回原始类型 8.6.3 不能创建参数化类型的数组 不允许创建参数类型化数组 而声明类型为Pair&lt;String&gt;[]的变量仍是合法的 不过不能用new Pair&lt;String&gt;[10]初始化这个变量 可以声明通配类型的数组,然后进行类型转换 如果需要收集参数化类型对象,只有一种安全而有效的方法 使用ArrayList:ArrayList&lt;Pair&lt;String&gt;&gt; 8.6.4 Varargs警告 向参数个数可变的方法传递一个泛型类型的实例 会得到一个警告(与泛型类型数组,不支持泛型类型数组冲突) 使用两种方法进行解决 一种方法是为包含addAll调用的方法增加注解@SuppressWarnings(“unchecked”) 或者在Java SE 7中，还可以用@SafeVarargs直接标注addAll方法 可以使用@SafeVarargs标注来消除创建泛型数组的有关限制 8.6.5 不能实例化类型变量 不能使用像new T(…), new T[…]或T.class这样的表达式中的类型变量 原因:类型擦除将T改为Object,违背本意 最好的解决方法:调用者提供一个构造器表达式 传统解决方法:通过反射调用Class.newInstance方法构造泛型类型,较为复杂,Class类本身是泛型 12345Pair&lt;String&gt; p = Pair.makePair(String::new);//makePair方法接收一个Supplier&lt;T&gt;,这是一个函数式接口，表示一个无参数而且返回类型为T的函数public static&lt;T&gt; Pair&lt;T&gt; makePair(Supplier&lt;T&gt; constr) &#123; return new Pair&lt;&gt;(constr.get(),constr.get());&#125; 8.6.6 不能构造泛型数组 原因：数组本身也有类型,用来监控存储在虚拟机中的数组.(该类型会被擦除) 老式方法使用反射进行，调用Array.newInstance 12345678910111213141516171819202122232425262728293031323334//类型擦除会让这个方法永远构造Comparable[2]数组public static &lt;T extends Comparable&gt; T[] minmax(T[] z) &#123;T[] mm= new T[2];,...,&#125; // Error .//如果数组仅仅作为一个类的私有实例域，就可以将这个数组声明为Object[]，并且在获取元素时进行类型转换//例子ArrayList类实现public class ArrayList&lt;E&gt;&#123; private Object[] elements; ... @SuppressWarnings(&quot;unchecked&quot;) public E get(int n) &#123; return (E) elements[n]; &#125; public void set(int n, E e) &#123; elenents[r] = e; &#125; // no cast needed&#125;//实际的实现public class ArrayList&lt;E&gt; &#123; private E[] elements; ... public ArrayList() &#123;elements = (E[]) new Object[10];&#125; //强制类型转换E[]是一个假象,而类型擦除使其无法察觉&#125;//由于minmax方法返回T[]数组使得这一技术无法施展,如果掩盖这个类型会有运行时错误结果public static &lt;T extends Comparable&gt; T[] minmax(T... a)&#123; Object[] mm = new 0bject[2]; ... return (T[]) mm; // compiles with warning&#125;//编译时不会有任何警告。当Object[]引用赋给Comparable[]变量时，将会发生ClassCastException异常String[] ss = ArrayAlg.minmax(&quot;tom&quot;,&quot;Dick&quot;);//解决方案，提供一个数组构造器String[] ss = ArrayAlg.minmax(String[]::new,&quot;tom&quot;,&quot;Dick&quot;);//构造器表达式String：：new指示一个函数，给定所需的长度，会构造一个指定长度的String数组public static &lt;T extends Comparable&gt; T[] minmax(IntFunction&lt;T[]&gt; constr, T...a)&#123; ...&#125; 8.6.7 泛型类的静态上下文中类型变量无效 不能在静态域或方法中引用类型变量 8.6.8 不能抛出或捕捉泛型类的实例 既不能抛出也不能捕获泛型类对象.实际上,甚至泛型类扩展Throwable都是不合法的 catch子句中不能使用类型变量(在异常规范中使用类型变量是允许的) 12345678910111213public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t)&#123; try &#123; //do work &#125; catch (T e) // Error--can&#x27;t catch type vari able &#123; Logger.global.info.(..) t.initCause(realCause); //允许 throw t; &#125;&#125; 8.6.9 可以消除对受查异常的检查 Java异常处理的一个基本原则,必须为所有受查异常提供一个处理器 不过可以利用泛型消除这个限制 通过使用泛型类,擦除和@SuppressWarnings注解,就能消除Java类型系统的部分基本限制 8.6.10 注意擦除后的冲突 当泛型类型被擦除时,无法创建引发冲突的条件 要想支持擦除的转换,就需要强行限制一个类或类型变量不能同时成为两个接口类型的子类,而这两个接口是同一接口的不同参数化 8.7 泛型类型的继承规则 Employee是Manager的超类 Pair&lt;Employee&gt;与Pair&lt;Manager&gt;没有任何关系 注意泛型与Java数组之间的区别 可以将一个Manager[]数组赋给一个类型为Employee[]的变量,数组带有特别的保护 如果试图将一个低级别的雇员存储到employeeBuddies[0]，虚拟机将会抛出ArrayStoreException异常 永远可以将参数化类型转换为一个原始类型 例如,Pair&lt;Employee&gt;是原始类型Pair的一个子类型. 在与遗留代码衔接时,这个转换非常必要 转换成原始类型之后不会产生类型错误 当使用getFirst获得外来对象并赋给Manager变量时,与通常一样,会抛出ClassCastException异常 失去的只是泛型程序设计提供的附加安全性 泛型类可以扩展或实现其他的泛型类 8.8 通配符类型 8.8.1 通配符概念 通配符类型中，允许类型参数变化 引入有限定的通配符的关键之处,可以用来区分安全的访问器方法和不安全的更改器方法 12345678910111213141516171819Pair&lt;? extends Employee&gt;//任何泛型Pair类型,它的类型参数是Employee的子类,如Pair&lt;Manager&gt;,但不是Pair&lt;String&gt;//编写打印雇员对的方法public static void printBuddies(Pair&lt;? extends Employee&gt; p)&#123; Employee first = p.getFirst(); Employee second = p.getSecond(); System.out.println(first.getName() + &quot; and &quot; + second.getName() + &quot; are buddies.&quot;);&#125;//&lt;? extends Employee&gt;可以将Employee的子类Manager(Pair&lt;Manager&gt;)传入该方法//使用通配符不会通过Pair&lt;? extends Employee&gt;的引用破坏Pair&lt;Manager&gt;Pair&lt;Manager&gt; managerBuddies = new Pair&lt;&gt;(ceo, cfo);Pair&lt;? extends Employee&gt; wildcardBuddies = managerBuddies；// 0KwildcardBuddies.setFirst(lowlyEmployee); //对setFirst的调用有一个类型错误//编译器只知道需要某个Employee的子类型,但不知道具体是什么类型//它拒绝传递任何特定的类型.毕竟?不能用来匹配//使用getFirst就不存在这个问题:将getFirst的返回值赋给一个Employee的引用完全合法 8.8.2 通配符的超类型限定 通配符限定与类型变量限定十分类似 但是,还有一个附加的能力,即可以指定一个超类型限定 带有超类型限定的通配符可以为方法提供参数,但不能使用返回值 带有超类型限定的通配符可以向泛型对象写入,带有子类型限定的通配符可以从泛型对象读取 12345678910//Pair&lt;? super Manager&gt;有方法void setFirst(? super Manager)? super Manager getFirst()//编译器无法知道setFirst方法的具体类型//因此调用这个方法时不能接受类型为Employee或Object的参数//只能传递Manager类型的对象,或者某个子类型(如Executive)对象//另外,如果调用getFirst,不能保证返回对象的类型.只能把它赋给一个Object? super Manager//? 限制为Manager的所有超类型 8.8.3 无限定通配符 使用无限定的通配符,例如,Pair&lt;?&gt; Pair&lt;?&gt;和Pair本质的不同在于 可以用任意Object对象调用原始Pair类的setObject方法 可以调用setFirst(null) 该类型对简单的测试操作有用 1234567//例如//用来测试一个pair是否包含一个null引用,它不需要实际的类型public static boolean hasNulls(Pair&lt;?&gt; p)&#123; return p.getFirst() == null || p.getSecond() == null&#125;//通过将hasNulls转换成泛型方法,可以避免使用通配符类型public static &lt;T&gt; boolean hasNulls(Pair&lt;T&gt; p) 8.8.4 通配符捕获 12345678910111213141516171819202122//编写一个交换成对元素的方法public static void swap(Pair&lt;?&gt; p) &#123; ? t = p.getFirst(); //通配符不是类型变量（不能在编写代码中使用“?”作为一种类型) p.setFirst(p.getSecond()); p.setSecond(t);&#125;//可以编写辅助方法swapHelperpublic static&lt;T&gt; void swapHelper(Pair&lt;T&gt; p) &#123; T t = p.getFirst(); p.setFirst(p.getSecond()); p.setSecond(t);&#125;//swapHelper是一个泛型方法,而swap不是,它具有固定的Pair&lt;?&gt;类型的参数//可以由swap调用swapHelperpublic static void swap(Pair&lt;?&gt; p) &#123; swapHelper(p);&#125;//在这种情况下，swapHelper方法的参数T捕获通配符//它不知道是哪种类型的通配符//但是,这是一个明确的类型,并且&lt;T&gt;swapHelper的定义只有在T指出类型时才有明确的含义 通配符捕获只有在有许多限制的情况下才是合法的 编译器必须能够确信通配符表达的是单个,确定的类型 8.9 反射和泛型 8.9.1 泛型Class类 Class类是泛型的 String.class实际上是Class&lt;String&gt;类的唯一对象 类型参数十分有用，它允许Class&lt;T&gt;方法的返回类型更加具有针对性 8.9.2 使用Class&lt;T&gt;参数进行类型匹配 1234567891011//有时，匹配泛型方法中的Class&lt;T&gt;参数的类型变量很有实用价值public static &lt;T&gt; Pair&lt;T&gt; makePair(Class&lt;T&gt; c) throws InstantiaticnException,IllegalAccessException&#123; return new Pair&lt;&gt;(c.newInstance(), c.newInstance());&#125;//调用makePair(Emplyee.class)//Employee.class是类型Class&lt;Employee&gt;的一个对象//makePair方法的类型参数T同Employee匹配，并且编译器可以推断出这个方法将返回一个Pair&lt;Employee&gt; 8.9.3 虚拟机中的泛型类型信息 Java泛型的卓越特性之一是在虚拟机中泛型类型的擦除 但擦除的类仍然保留一些泛型祖先的微弱记忆 9 集合 9.1 Java集合框架 使用标准库中的集合类 Java最初版本只为最常用的数据结构提供了一组类：Vector,Stack,Hashtable,BitSet与Enumeration接口 其中的Enumeration接口提供了一种用于访问任意容器中各个元素的抽象机制 9.1.1 将集合的接口与实现分离 Java集合类库将接口与实现分开 以队列为例 队列接口指出可以在队列的尾部添加元素,在队列的头部删除元素,并且可以查找队列中元素的个数 当需要收集对象,并按照“先进先出”的规则检索对象时就应该使用队列 队列的实现形式一般由两种:循环数组,或者链表 每一个实现都可以通过一个实现了Queue接口的类表示 123456789101112131415161718192021222324252627282930313233343536373839//队列接口的最简单形式public interface Queue(E) &#123; void add(E element); E remove(); int size;&#125;//队列的实现public class CircularArrayQueue&lt;E&gt; implements Queue&lt;E&gt; &#123; private int head; private int tail; CircularArrayQueue (int capacity) &#123;...&#125; public void add(E element) &#123;..&#125; public E remove()&#123;...&#125; public int size()&#123;...&#125; private E[] elements;&#125;//使用链表实现public class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt;&#123; private Link head; private Link tail; LinkedListQueue()&#123;...&#125; public void add(E element) &#123;...&#125; public E remove() &#123;...&#125; public int size() &#123;...&#125;&#125;//Java类库并没有CircularArrayQueue和LinkedListQueue的类(示例)//使用接口类型存放集合的引用Queue&lt;Customer&gt; expressLane = new CircularArrayQueue&lt;&gt;(100);expressLane.add(new Customer(&quot;Harry&quot;));//可以使用LinkedListQueue实现Queue&lt;Customer&gt; expressLane = new LinkedListQueue&lt;&gt;(100);expressLane.add(new Customer(&quot;Harry)); 需要循环数组队列,使用ArrayDeque类 需要链表队列,使用LinkedList类,这个类实现了Queue接口 循环数组要比链表更高效 循环数组是一个有界集合，即容量有限 如果程序中要收集的对象数量没有上限，就最好使用链表来实现 以Abstract开头的类,例如,AbstractQueue,是为类库实现者而设计的 如果要实现自己的队列类扩展AbstractQueue类要比实现Queue接口中的所有方法轻松得多 9.1.2 Collection接口 在Java类库中，集合类的基本接口是Collection接口 1234567public interface Collection&lt;E&gt; &#123; boolean add(E element); Iterator&lt;E&gt; iterator(); ...&#125;//add方法用于向集合中添加元素,如果添加元素改变了集合返回true//iterator方法返回一个实现了Iterator接口的对象(可以使用迭代器对象依次访问集合中的元素) 9.1.3 迭代器 1234567891011121314151617181920//Iterator接口的四个方法：public interface Iterator&lt;E&gt; &#123; E next(); boolean hasNext(); void remove(); default void forEachRemaining(Consumer&lt;? super E&gt; action);&#125;//通过反复调用next方法，可以逐个访问集合中的每个元素。但是，如果到达了集合的末尾，next方法将抛出一个NoSuchElementException//在调用next之前调用hasNext方法。如果迭代器对象还有多个供访问的元素，这个方法就返回trueCollection&lt;String&gt; c = ...;Iterator&lt;String&gt; iter = c.iterator();while(iter.hasNext())&#123; String element = iter.next() ...&#125;//在JavaSE8中，可以使用lambda表达式进行iterator.forEachRemaining(element -&gt; do something with element); 编译器简单的将“for each”循环翻译为带有迭代器的循环 “for each”循环可以与任何实现了Iterable接口的对象一起工作 Collection接口扩展了Iterable接口,对于标准类库中的任何集合都可以使用“for each”循环 元素被访问的顺序取决于集合类型 如果对ArrayList进行迭代，迭代器将从索引0开始，每迭代一次，索引值加1 如果访问HashSet中的元素，每个元素将会按照某种随机的次序出现。 虽然可以确定在迭代过程中能够遍历到集合中的所有元素，但却无法预知元素被访问的次序 这对于计算总和或统计符合某个条件的元素个数这类与顺序无关的操作来说，并不是什么问题 Iterator接口的next和hasNext方法与Enumeration接口的nextElement和hasMoreElements方法的作用一样 可以将Iterator.next与InputStream.read看作为等效的 从数据流中读取一个字节，就会自动地“消耗掉”这个字节。下一次调用read将会消耗并返回输入的下一个字节。用同样的方式，反复地调用next就可以读取集合中所有元素 1234567891011//Iterator接口的remove方法将会删除上次调用next方法时返回的元素//在删除之前，查看该元素是很具有实际意义的it.next();it.remove();//对next方法和remove方法的调用具有互相依赖性//如果调用remove之前没有调用next将是不合法的。如果这样做，将会抛出一个IllegalStateException异常//删除相邻的两个元素,必须先调用nextit.remove();it.next();it.remove(); 9.1.4 泛型实用方法 由于Collection与Iterator都是泛型接口，可以编写操作任何集合类型的实用方法 123456789101112131415161718192021222324252627282930313233343536//检测任意集合是否包含指定元素的泛型方法public static&lt;E&gt; boolean constains(Collection&lt;E&gt; c, Object obj) &#123; for(E element : c) if(element.equals(obj)) return true; return false;&#125;//Java类库的设计者认为：这些实用方法中的某些方法非常有用，应该将它们提供给用户使用//类库的使用者就不必自己重新构建这些方法//contains就是这样一个实用方法//Collection接口声明的方法int size();boolean isEmpty();boolean contains(Object obj);boolean containsAll(Collection&lt;?&gt; c);boolean equals(Object other);boolean addAll(Collection&lt;? extends E&gt; from);boolean remove(Object obj));boolean removeAll(Collection&lt;?&gt; c);void clear();boolean retainAll(Collection&lt;?&gt; c);Object[] toArray();&lt;T&gt; T[] toArray(T[] arrayToFill);//如果实现Collection接口的每一个类都要提供如此多的例行方法将是一件很烦人的事情//为了能够让实现者更容易地实现这个接口，Java类库提供了一个类AbstractCollection//AbstractCollection将基础方法size和iterator抽象化了//对于Java SE 8，这种方法有些过时了//如果这些方法是Collection接口的默认方法会更好,但实际上并不是这样//不过，确实已经增加了很多默认方法。其中大部分方法都与流的处理有关default boolean removeIf(Predicate&lt;? super E&gt; filter)//该方法可以用来删除满足一定条件的元素 9.1.5 集合框架中的接口 集合有两个基本接口 Collection Map List是一个有序集合,元素会增加到容器中的特定位置 可以采用两种方式访问元素： 使用迭代器访问 或使用一个整数索引来访问(随机访问) 123456789101112131415161718//可以使用add方法在集合中插入元素boolean add(E element);//由于映射包含键/值对，需要使用put方法进行插入V put(K key, V value);//从集合读取元素，使用迭代器访问元素//从映射中读取值，使用get方法V get(K key);//List接口定义了多个用于随机访问的方法void add(int index, E element)void remove(int index)E get(int index)E set(int index, E element)//ListIterator接口是Iterator的一个子接口,该接口定义了一个方法用于在迭代器位置前面增加一个元素void add(E element) 由数组支持的有序集合可以快速地随机访问，因此适合使用List方法并提供一个整数索引来访问 与之不同，链表尽管也是有序的，但是随机访问很慢，所以最好使用迭代器来遍历 为了避免对链表完成随机访问操作，Java SE 1.4引入了一个标记接口RandomAccess 这个接口不包含任何方法，不过可以用它来测试一个特定的集合是否支持高效的随机访问 Set接口等同于Collection接口 集(set)的add方法不允许增加重复的元素。要适当地定义集的equals方法：只要两个集包含同样的元素就认为是相等的，而不要求这些元素有同样的顺序。 hashCode方法的定义要保证包含相同元素的两个集会得到相同的散列码 既然方法签名是一样的，为什么还要建立一个单独的接口呢？ 从概念上讲，并不是所有集合都是集。建立一个Set接口可以让程序员编写只接受集的方法 SortedSet和SortedMap接口会提供用于排序的比较器对象，这两个接口定义了可以得到集合子集视图的方法 Java SE 6引入了接口NavigableSet和NavigableMap，其中包含一些用于搜索和遍历有序集和映射的方法 TreeSet和TreeMap类实现了这些接口 理想情况下，这些方法本应当直接包含在SortedSet和SortedMap接口中 9.2 具体的集合 除了以Map结尾的类之外，其他类都实现了Collection接口 以Map结尾的类，实现了Map接口 9.2.1 链表 数组及动态ArrayList类，存在重大缺陷，在中间位置删除元素(或添加元素)困难 原因：数组中处于被删除元素之后的所有元素都要向数组的前端移动 链表可以解决这个问题 链表的每个对象存放在独立的结点上，每个结点上还存放着序列中下一个结点的引用 Java中的链表为双向链表，每个结点还存放着指向前驱结点的引用 删除一个元素即更新被删除元素附近的链接 集合库中LinkedList类用于实现链表的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445//先添加3个元素，然后将第2个元素删除List&lt;string&gt; staff = new LinkedList&lt;&gt;();//LinkedList implements Liststaff.add (&quot;Amy&quot;);staff.add(&quot;Bob&quot;);staff.add(&quot;Carl&quot;);Iterator iter= staff.iterator();String first = iter.next();//visit first elementString second = iter.next()// visit second elementiter.remove; // remove last visited element//集合类库提供了子接口ListIterator，其中包含add方法//与Collection.add不同，该方法不返回boolean类型的值，它假定添加操作总会改变链表interface ListIterator&lt;E&gt; extends Iterator&lt;E&gt;&#123; void add(E elements) ...&#125;//ListIterator 反向遍历链表的方法E previous();boolean hasPrevious();//LinkedList类 listIterator方法 返回一个实现了ListIterator接口的迭代器对象ListIterator&lt;String&gt; iter = staff.listIterator();//在第二个元素之前添加元素List&lt;String&gt; staff = new LinkedList&lt;&gt;();staff.add(&quot;Amy&quot;);staff.add(&quot;Bob&quot;);staff.add(&quot;Carl&quot;);ListIterator&lt;String&gt; iter = staff.listlterator();iter.next(); // skip past first elementiter.add(&quot;Juliet&quot;);//如果多次调用add方法，将按照提供的次序把元素添加到链表中。它们被依次添加到迭代器当前位置之前//当用一个刚刚由Iterator方法返回，并且指向链表表头的迭代器调用add操作时，新添加的元素将变成列表的新表头//当迭代器越过链表的最后一个元素时(即hasNext返回false)，添加的元素将变成列表的新表尾//LinkedList类还是提供了一个用来访问某个特定元素的get方法//get方法做了微小的优化：如果索引大于size()/2就从列表尾端开始搜索元素LinkedList&lt;String&gt; list = ...;String obj = list.get(n);//该方法的效率并不太高//如果发现自己正在使用这个方法，说明有可能对于所要解决的问题使用了错误的数据结构 链表与泛型集合之间有一个重要的区别 链表是一个有序集合，每个对象的位置十分重要。LinkedList.add方法将对象添加到链表的尾部。但是，常常需要将元素添加到链表的中间。由于迭代器是描述集合中位置的，所以这种依赖于位置的add方法将由迭代器负责。只有对自然有序的集合使用迭代器添加元素才有实际意义 集(set)类型，其中的元素完全无序 在Iterator接口中就没有add方法。相反地，集合类库提供了子接口ListIterator，其中包含add方法 add方法只依赖于迭代器的位置，而remove方法依赖于迭代器的状态 set方法用一个新元素取代调用next或previous方法返回的上一个元素 如果在某个迭代器修改集合时，另一个迭代器对其进行遍历，一定会出现混乱的状况 例如，一个迭代器指向另一个迭代器刚刚删除的元素前面，现在这个迭代器就是无效的，并且不应该再使用。链表迭代器的设计使它能够检测到这种修改。如果迭代器发现它的集合被另一个迭代器修改了，或是被该集合自身的方法修改了，就会抛出一个ConcurrentModificationException异常 可以根据需要给容器附加许多的迭代器，但是这些迭代器只能读取列表。另外，再单独附加一个既能读又能写的迭代器 有一种简单的方法可以检测到并发修改的问题。集合可以跟踪改写操作(诸如添加或删除元素)的次数。每个迭代器都维护一个独立的计数值。在每个迭代器方法的开始处检查自己改写操作的计数值是否与集合的改写操作计数值一致。如果不一致，抛出一个Concurrent ModificationException异常 链表只负责跟踪对列表的结构性修改，例如，添加元素、删除元素。set方法不被视为结构性修改 链表不支持快速地随机访问 LinkedList对象根本不做任何缓存位置信息的操作 列表迭代器接口还有一个方法，可以告之当前位置的索引 实际上，从概念上讲，由于Java迭代器指向两个元素之间的位置，所以可以同时产生两个索引： nextIndex方法返回下一次调用next方法时返回元素的整数索引 previousIndex方法返回下一次调用previous方法时返回元素的整数索引。当然，这个索引只比nextIndex返回的索引值小1 list.listIterator(n)将返回一个迭代器，这个迭代器指向索引为n的元素前面的位置。也就是说，调用next与调用list.get(n)会产生同一个元素，只是获得这个迭代器的效率比较低 使用链表的唯一理由是尽可能地减少在列表中间插入或删除元素所付出的代价。如果列表只有少数几个元素，就完全可以使用ArrayList 免使用以整数索引表示链表中位置的所有方法。如果需要对集合进行随机访问，就使用数组或ArrayList，而不要使用链表 9.2.2 数组列表 List接口用于描述一个有序集合，并且集合中每个元素的位置十分重要。有两种访问元素的协议：一种是用迭代器，另一种是用get和set方法随机地访问每个元素。后者不适用于链表，但对数组却很有用 ArrayList封装了一个动态再分配的对象数组 Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象。但是，如果由一个线程访问Vector，代码要在同步操作上耗费大量的时间。这种情况还是很常见的。而ArrayList方法不是同步的，因此，建议在不需要同步时使用ArrayList，而不要使用Vector 9.2.3 散列集 可以快速地查找所需要的对象，这就是散列表 散列表为每个对象计算一个整数，称为散列码。散列码是由对象的实例域产生的一个整数。更准确地说，具有不同数据域的对象将产生不同的散列码 最重要的问题是散列码要能够快速地计算出来，并且这个计算只与要散列的对象状态有关，与散列表中的其他对象无关 在Java中，散列表用链表数组实现。每个列表被称为桶。要想查找表中对象的位置，就要先计算它的散列码，然后与桶的总数取余，所得到的结果就是保存这个元素的桶的索引 有时候会遇到桶被占满的情况，这也是不可避免的。这种现象被称为散列冲突 这时，需要用新对象与桶中的所有对象进行比较，查看这个对象是否已经存在。如果散列码是合理且随机分布的，桶的数目也足够大，需要比较的次数就会很少 如果想更多地控制散列表的运行性能，就要指定一个初始的桶数。桶数是指用于收集具有相同散列值的桶的数目。如果要插入到散列表中的元素太多，就会增加冲突的可能性，降低运行性能 通常，将桶数设置为预计元素个数的75%~150% 有些研究人员认为：尽管还没有确凿的证据，但最好将桶数设置为一个素数，以防键的集聚。标准类库使用的桶数是2的幂，默认值为16 如果散列表太满，就需要再散列。如果要对散列表再散列，就需要创建一个桶数更多的表，并将所有元素插入到这个新表中，然后丢弃原来的表。装填因子决定何时对散列表进行再散列 对于大多数应用程序来说，装填因子为0.75是比较合理的 散列表可以用于实现几个重要的数据结构。其中最简单的是set类型。set是没有重复元素的元素集合。set的add方法首先在集中查找要添加的对象，如果不存在，就将这个对象添加进去 Java集合类库提供了一个HashSet类，它实现了基于散列表的集。可以用add方法添加元素。contains方法已经被重新定义，用来快速地查看是否某个元素已经出现在集中。它只在某个桶中查找元素，而不必查看集合中的所有元素 只有不关心集合中元素的顺序时才应该使用HashSet 9.2.4 树集 树集是一个有序集合；可以以任意顺序将元素插入到集合中。在对集合进行遍历时，每个值将自动地按照排序后的顺序呈现 正如TreeSet类名所示，排序是用树结构完成的(当前实现使用的是红黑树(red-black tree) 要使用树集，必须能够比较元素。这些元素必须实现Comparable接口，或者构造集时必须提供一个Comparator 将一个元素添加到树中要比添加到散列表中慢。但是，与检查数组或链表中的重复元素相比还是快很多。如果树中包含n个元素，查找新元素的正确位置平均需要log2n次比较 从Java SE 6起，TreeSet类实现了NavigableSet接口。这个接口增加了几个便于定位元素以及反向遍历的方法 树集和散列集的区别？ 如果不需要对数据进行排序，就没有必要付出排序的开销。更重要的是，对于某些数据来说，对其排序要比散列函数更加困难。散列函数只是将对象适当地打乱存放，而比较却要精确地判别每个对象 9.2.5 队列与双端队列 Java SE 6中引入了Deque接口，并由ArrayDeque和LinkedList类实现。这两个类都提供了双端队列，而且在必要时可以增加队列的长度 9.2.6 优先级队列 优先级队列中的元素可以按照任意的顺序插入，却总是按照排序的顺序进行检索。也就是说，无论何时调用remove方法，总会获得当前优先级队列中最小的元素。然而，优先级队列并没有对所有的元素进行排序。如果用迭代的方式处理这些元素，并不需要对它们进行排序 优先级队列使用了一个优雅且高效的数据结构，称为堆 堆是一个可以自我调整的二叉树，对树执行添加(add)和删除(remore)操作，可以让最小的元素移动到根，而不必花费时间对元素进行排序 与TreeSet一样，一个优先级队列既可以保存实现了Comparable接口的类对象，也可以保存在构造器中提供的Comparator对象 使用优先级队列的典型示例是任务调度。每一个任务有一个优先级，任务以随机顺序添加到队列中。每当启动一个新的任务时，都将优先级最高的任务从队列中删除(由于习惯上将1设为“最高”优先级，所以会将最小的元素删除) 9.3 映射 集是一个集合，它可以快速地查找现有的元素。但是，要查看一个元素，需要有要查找元素的精确副本。这不是一种非常通用的查找方式 映射用来存放键/值对。如果提供了键，就能够查找到值 9.3.1 基本映射操作 Java类库为映射提供了两个通用的实现： HashMap和TreeMap 这两个类都实现了Map接口 散列映射对键进行散列，树映射用键的整体顺序对元素进行排序，并将其组织成搜索树 散列或比较函数只能作用于键。与键关联的值不能进行散列或比较 应该选择散列映射还是树映射呢？ 与集一样，散列稍微快一些，如果不需要按照排列顺序访问键，就最好选择散列 1234567891011121314151617181920212223//为存储的员工信息建立一个散列映射Map&lt;String, Employee&gt; staff = new HashMap&lt;&gt;();Employee harry = new Employee(&quot;Harry Hacker&quot;);staff.put(&quot;987-98-9969&quot;, harry);//每当往映射中添加对象时，必须同时提供一个键//在这里，键是一个字符串，对应的值是Employee对象//要想检索一个对象，必须使用(因而，必须记住)一个键String id = &quot;987-98-9996&quot;;e = staff.get(id);//使用getOrDefault方法，在映射中没有与给定键对应的信息，返回一个默认值//键必须是唯一的。不能对同一个键存放两个值//如果对同一个键两次调用put方法，第二个值就会取代第一个值。实际上，put将返回用这个键参数存储的上一个值//remove方法用于从映射中删除给定键对应的元素//size方法用于返回映射中的元素数//要迭代处理映射的键和值，最容易的方法是使用forEach方法//可以提供一个接收键和值的lambda表达式。映射中的每一项会依序调用这个表达式scores.forEach((k, v) -&gt; System.out.println(&quot;key=&quot; + k + &quot;, value=&quot; + v)); 9.3.2 更新映射项 处理映射时的一个难点就是更新映射项 正常情况下，可以得到与一个键关联的原值，完成更新，再放回更新后的值 考虑一个特殊情况，即键第一次出现 1234567891011121314151617//使用一个映射统计一个单词在文件中出现的频度。看到一个单词(word)时，计数器增1counts.put(word, counts.get(word) + 1);//就是第一次看到word时。在这种情况下，get会返回null，因此会出现一个NullPointerException异常//解决方法1//getOrDefault方法counts.put(word, counts.getOrDefault(word, 0) + 1);//解决方法2//首先调用putIfAbsent方法。只有当键原先存在时才会放入一个值counts.putIfAbsent(word, 0);counts.put(word, counts.get(word) + 1);//解决方法3//merge方法可以简化这个常见的操作。如果键原先不存在，下面的调用counts.merge(word, 1, Integer::sum);//将把word与1关联，否则使用Integer：：sum函数组合原值和1(也就是将原值与1求和) 9.3.3 映射视图 集合框架不认为映射本身是一个集合。(其他数据结构框架认为映射是一个键/值对集合，或者是由键索引的值集合。) 不过，可以得到映射的视图,这是实现了Collection接口或某个子接口的对象 有3种视图：键集、值集合(不是一个集)以及键/值对集 键和键/值对可以构成一个集，因为映射中一个键只能有一个副本 12345678910111213141516171819202122232425262728293031//分别返回键集、值集合(不是一个集)以及键/值对集//(条目集的元素是实现Map.Entry接口的类的对象。)Set&lt;K&gt; keySet()Collection&lt;V&gt; values()Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet()//keySet不是HashSet或TreeSet，而是实现了Set接口的另外某个类的对象//Set接口扩展了Collection接口。因此，可以像使用集合一样使用keySet//枚举一个映射的所有键Set&lt;string&gt; keys= map.keySet();for (string key: keys)&#123; do something with key&#125;//同时查看键和值，可以通过枚举条目来避免查找值for(Map.Entry&lt;String, Employee&gt; entry: staff, entrySet())&#123; String k=entry.getKey(); Employee v= entry.getvalue(); do something with k, v;&#125;//如今可以使用forEach方法counts.forEach((k, v) -&gt; &#123;do something with k, v&#125;);//如果在键集视图上调用迭代器的remove方法，实际上会从映射中删除这个键和与它关联的值。//不过，不能向键集视图增加元素。//另外，如果增加一个键而没有同时增加值也是没有意义的。//如果试图调用add方法，它会抛出一个UnsupportedOperationException 9.3.4 弱散列映射 设计WeakHashMap类是为了解决一个有趣的问题 如果有一个值，对应的键已经不再使用了，将会出现什么情况呢？假定对某个键的最后一次引用已经消亡，不再有任何途径引用这个值的对象了。但是，由于在程序中的任何部分没有再出现这个键，所以，这个键/值对无法从映射中删除 垃圾回收器跟踪活动的对象。只要映射对象是活动的，其中的所有桶也是活动的，它们不能被回收 当对键的唯一引用来自散列条目时，这一数据结构将与垃圾回收器协同工作一起删除键/值对 WeakHashMap使用弱引用(weak references)保存键。WeakReference对象将引用保存到另外一个对象中，在这里，就是散列键。对于这种类型的对象，垃圾回收器用一种特有的方式进行处理。通常，如果垃圾回收器发现某个特定的对象已经没有他人引用了，就将其回收。然而，如果某个对象只能由WeakReference引用，垃圾回收器仍然回收它，但要将引用这个对象的弱引用放入队列中。WeakHashMap将周期性地检查队列，以便找出新添加的弱引用。一个弱引用进入队列意味着这个键不再被他人使用，并且已经被收集起来。于是，WeakHashMap将删除对应的条目 9.3.5 链接散列集与映射 LinkedHashSet和LinkedHashMap类用来记住插入元素项的顺序。这样就可以避免在散列表中的项从表面上看是随机排列的。当条目插入到表中时，就会并入到双向链表中 访问顺序对于实现高速缓存的“最近最少使用”原则十分重要 9.3.6 枚举集与映射 EnumSet是一个枚举类型元素集的高效实现。由于枚举类型只有有限个实例，所以EnumSet内部用位序列实现。如果对应的值在集中，则相应的位被置为1 EnumMap是一个键类型为枚举类型的映射。它可以直接且高效地用一个值数组实现。 12345678910//EnumSet类没有公共的构造器。可以使用静态工厂方法构造这个集enum Weekday &#123;monday, tuesday, wednesday, thursday, friday, saturday, sunday&#125;;EnumSet&lt;weekday&gt; always= EnumSet.allOf(Weekday.class);Enum Set&lt;weekday&gt; never= EnumSet.noneof (Weekday.class);EnunSet&lt;Weekday&gt; workday= EnumSet.range(Weekday.MONDAY, Weekday.FRIDAY)EnumSet&lt;Weekday&gt; mwf = EnumSet.of(Weekday.MONDAY, Weekday.WEDNESDAY, Weekday.FRIDAY);//可以使用Set接口的常用方法来修改EnumSet。//EnumMap在使用时，需要在构造器中指定键类型EnumMap&lt;Weekday, Employee&gt; personInCharge new EnumMap&lt;&gt;(weekday.class); 9.3.7 标识散列映射 类IdentityHashMap有特殊的作用 在这个类中，键的散列值不是用hashCode函数计算的，而是用System.identityHashCode方法计算的 这是Object.hashCode方法根据对象的内存地址来计算散列码时所使用的方式。而且，在对两个对象进行比较时，IdentityHashMap类使用==，而不使用equals 也就是说，不同的键对象，即使内容相同，也被视为是不同的对象。在实现对象遍历算法(如对象串行化)时，这个类非常有用，可以用来跟踪每个对象的遍历状况 9.4 视图与包装器 通过使用视图可以获得其他的实现了Collection接口和Map接口的对象 keySet方法返回一个实现Set接口的类对象，这个类的方法对原映射进行操作。这种集合称为视图。 9.4.1 轻量级集合包装器 1234567891011121314151617//Arrays类的静态方法asList将返回一个包装了普通Java数组的List包装器//这个方法可以将数组传递给一个期望得到列表或集合参数的方法Card[] cardDeck = new Card[52];...List&lt;Card&gt; cradList = Array.asList(cardDeck);//返回的对象不是ArrayList,而是一个视图对象，带有访问底层数组的get和set方法//改变数组大小的所有方法都会抛出一个Unsupported OperationException异常//asList方法可以接收可变数目的参数List&lt;String&gt; names = Array.asList(&quot;Amy&quot;,&quot;Bob&quot;,&quot;Carl&quot;);//该方法实际调用Collection接口的npCopies方法，返回一个实现了List接口的不可修改的对象//注意区分Collections类和Collection接口Collections.singleton(anObject);//返回一个视图对象，该对象实现了Set接口//返回的对象实现了一个不可修改的单元素集，而不需要付出建立数据结构的开销//singletonList方法与singletonMap方法类似 9.4.2 子范围 可以为很多集合建立子范围视图 12345678910111213141516171819202122//假设有一个列表staff，想从中取出第10个~第19个元素。可以使用subList方法来获得一个列表的子范围视图List group2 = staff.subList(10,20);//可以将任何操作应用于子范围，并且能够自动地反映整个列表的情况//可以删除整个子范围group2.clear();//元素自动地从staff列表中清除了，并且group2为空//对于有序集和映射，可以使用排序顺序而不是元素位置建立子范围//SortedSet接口声明了3个方法SortedSet&lt;E&gt; subSet(E from, E to)SortedSet&lt;E&gt; headSet(E to)SortedSet&lt;E&gt; tailSet(E from)//这些方法将返回大于等于from且小于to的所有元素子集//有序映射类似的方法//返回映射视图，该映射包含键落在指定范围内的所有元素SortedMap&lt;K, V&gt; subMap(K from, K to)SortedMap&lt;K, V&gt; headMap(K to)SortedMap&lt;K, V&gt; tailMap(K from)//Java SE 6引入的NavigableSet接口赋予子范围操作更多的控制能力。可以指定是否包括边界 9.4.3 不可修改的视图 Collections还有几个方法，用于产生集合的不可修改视图 这些视图对现有集合增加了一个运行时的检查。如果发现试图对集合进行修改，就抛出一个异常，同时这个集合将保持未修改的状态 不可修改视图并不是集合本身不可修改 仍然可以通过集合的原始引用对集合进行修改。并且仍然可以让集合的元素调用更改器方法 由于视图只是包装了接口而不是实际的集合对象，所以只能访问接口中定义的方法 例如，LinkedList类有一些非常方便的方法，addFirst和addLast，它们都不是List接口的方法，不能通过不可修改视图进行访问 警告：unmodifiableCollection方法(与本节稍后讨论的synchronizedCollection和checked Collection方法一样)将返回一个集合，它的equals方法不调用底层集合的equals方法 相反，它继承了Object类的equals方法，这个方法只是检测两个对象是否是同一个对象。如果将集或列表转换成集合，就再也无法检测其内容是否相同了。视图就是以这种方式运行的，因为内容是否相等的检测在分层结构的这一层上没有定义妥当。视图将以同样的方式处理hashCode方法。 然而，unmodifiableSet类和unmodifiableList类却使用底层集合的equals方法和hashCode方法 1234567891011121314151617181920//获得不可修改的视图Collections.unmodifiableCollectionCollections.unmodifiableListCollections.unmodifiableSetCollections.unmodifiableSortedSetCollections.unmodifiableNavigableSetCollections.unmodifiableMapCollections.unmodifiableSortedMapCollections.unmodifiableNavigableMap//每个方法都定义于一个接口//例如，Collections.unmodifiableList与ArrayList、LinkedList或者任何实现了List接口的其他类一起协同工作//例如，假设想要查看某部分代码，但又不触及某个集合的内容List&lt;String&gt; staff= new LinkedList&lt;&gt;();...lookAt(Collections.unmodifiableList(staff));//Collections.unmodifiableList方法将返回一个实现List接口的类对象//其访问器方法将从staff集合中获取值。当然，lookAt方法可以调用List接口中的所有方法，而不只是访问器//但是所有的更改器方法(例如，add)已经被重新定义为抛出一个UnsupportedOperationException异常，而不是将调用传递给底层集合 9.4.4 同步视图 如果由多个线程访问集合，就必须确保集不会被意外地破坏 例如，如果一个线程试图将元素添加到散列表中，同时另一个线程正在对散列表进行再散列，其结果将是灾难性的 类库的设计者使用视图机制来确保常规集合的线程安全，而不是实现线程安全的集合类 123//例如，Collections类的静态synchronizedMap方法可以将任何一个映射表转换成具有同步访问方法的MapMap&lt;String, Employee&gt; map = Collections.synchronizedMap(new HashMap&lt;String, Empl oyee&gt;());//可以由多线程访问map对象了。像get和put这类方法都是同步操作的，即在另一个线程调用另一个方法之前，刚才的方法调用必须彻底完成 9.4.5 受查视图 “受查”视图用来对泛型类型发生问题时提供调试支持 123456789101112//将错误类型的元素混入泛型集合中的问题极有可能发生ArrayList&lt;String&gt; strings = new ArrayList&gt;();ArrayList rawList = strings; rawList.add(new Date());//这个错误的add命令在运行时检测不到。相反，只有在稍后的另一部分代码中调用get方法，并将结果转化为String时，这个类才会抛出异常//受查视图可以探测到这类问题//定义了一个安全列表,视图的add方法将检测插入的对象是否属于给定的类。如果不属于给定的类，就立即抛出一个ClassCastExceptionList&lt;String&gt; safeStrings = Collections.checkedList(strings, String.class);//受查视图受限于虚拟机可以运行的运行时检查//例如，对于ArrayList&lt;Pair&lt;String&gt;&gt;，由于虚拟机有一个单独的“原始”Pair类，所以，无法阻止插入Pair&lt;Date&gt; 9.4.6 关于可选操作的说明 通常，视图有一些局限性，即可能只可以读、无法改变大小、只支持删除而不支持插入，这些与映射的键视图情况相同 如果试图进行不恰当的操作，受限制的视图就会抛出一个UnsupportedOperationException 是否应该将“可选”方法这一技术扩展到用户的设计中呢？ 我们认为不应该。尽管集合被频繁地使用，其实现代码的风格也未必适用于其他问题领域。集合类库的设计者必须解决一组特别严格且又相互冲突的需求。用户希望类库应该易于学习、使用方便，彻底泛型化，面向通用性，同时又与手写算法一样高效。要同时达到所有目标的要求，或者尽量兼顾所有目标完全是不可能的。但是，在自己的编程问题中，很少遇到这样极端的局限性。应该能够找到一种不必依靠极端衡量“可选的”接口操作来解决这类问题的方案 9.5 算法 泛型集合接口具有一个很大的优点：算法只需要实现一次 9.5.1 排序与混排 Collections类中的sort方法可以对实现了List接口的集合进行排序 排序算法接收的列表，必须是可以修改的，但不必是可以改变大小的 如果列表支持set方法，则是可修改的 如果列表支持add和remove方法，则是可改变大小的 1234567891011121314151617181920//Collections类中的sort方法排序,该假定列表元素实现了Comparable接口List&lt;String&gt; staff = new LinkedList&lt;&gt;();fill collectionCollections.sort(staff);//如果想采用其他方式对列表进行排序，可以使用List接口的sort方法并传入一个Comparator对象staff.sort(Comparator.comparingDouble(Employee::getSalary));//对工资进行排序//按照降序对列表进行排序，可以使用一种非常方便的静态方法Collections.reverse-Order()//该方法将返回一个比较器，比较器则返回b.compareTo(a)staff.sort(Comparator.reverseOrder());staff.sort(Comparator.comparingDouble(Employee::getSalary).reversed());//混排列表中的元素(Collections类有一个算法shuffle)ArrayList&lt;Card&gt; cards = ...;Collections.shuffle(cards);//Java程序设计语言直接将所有元素转入一个数组，对数组进行排序，然后，再将排序后的序列复制回列表//集合类库中使用的排序算法比快速排序要慢一些，快速排序是通用排序算法的传统选择。但是，归并排序有一个主要的优点：稳定，即不需要交换相同的元素。 9.5.2 二分查找 要想在数组中查找一个对象，通常要依次访问数组中的每个元素，直到找到匹配的元素为止 如果数组是有序的，就可以直接查看位于数组中间的元素，看一看是否大于要查找的元素 如果是，用同样的方法在数组的前半部分继续查找； 否则，用同样的方法在数组的后半部分继续查找。这样就可以将查找范围缩减一半 Collections类的binarySearch方法实现了这个算法 注意，集合必须是排好序的，否则算法将返回错误的答案 要想查找某个元素，必须提供集合 (这个集合要实现List接口，如果集合没有采用Comparable接口的compareTo方法进行排序，就还要提供一个比较器对象) 只有采用随机访问，二分查找才有意义 如果必须利用迭代方式一次次地遍历链表的一半元素来找到中间位置的元素，二分查找就完全失去了优势 因此，如果为binarySearch算法提供一个链表，它将自动地变为线性查找 123456789101112131415i = Collections.binarySearch(c, element);i = Collections.binarySearch(c, element, comparator);//如果binarySearch方法返回的数值大于等于0，则表示匹配对象的索引//也就是说，c.get(i)等于在这个比较顺序下的element//如果返回负值，则表示没有匹配的元素//但是，可以利用返回值计算应该将element插入到集合的哪个位置，以保持集合的有序性//插入的位置是insertionPoint =-i-1;//这并不是简单的–i，因为0值是不确定的//也就是说if(i&lt;0)&#123; c.add(-i-1, element);&#125;//将把元素插入到正确的位置上。 从有序列表中搜索一个键，如果元素扩展了AbstractSequentialList类，则采用线性查找，否则将采用二分查找。 二分查找的时间复杂度为O(a(n)log n)，n是列表的长度，a(n)是访问一个元素的平均时间。这个方法将返回这个键在列表中的索引，如果在列表中不存在这个键将返回负值i。在这种情况下，应该将这个键插入到列表索引—i—1的位置上，以保持列表的有序性 9.5.3 简单算法 其他的简单算法： 将一个列表中的元素复制到另外一个列表中 用一个常量值填充容器 逆置一个列表的元素顺序 Java SE 8增加了默认方法Collection.removeIf和List.replaceAll，这两个方法需要提供一个lambda表达式来测试或转换元素 9.5.4 批操作 12345678910111213141516171819//很多操作会成批复制或删除元素coll1.removeAll(coll2);//将从coll1中删除coll2中出现的所有元素coll1.retainAll(coll2);//从coll1中删除所有未在coll2中出现的元素//假设有一个映射，将员工ID映射到员工对象，并且建立了一个将不再聘用的所有员工的IDMap&lt;String, Employee&gt; staffMap = ...;Set&lt;String&gt; terminatedIDs = ...;//建立一个链表，并删除种植聘用关系的所有员工IDstaffMap.keySet().removeAll(terminatedIDs);//由于键集是映射的一个视图，所以键和相关联的员工名会自动从映射中删除//通过使用一个子范围视图，可以把批操作限制在子列表和子集上。例如，假设希望把一个列表的前10个元素增加到另一个容器，可以建立一个子列表选出前10个元素：relocated.addAll(staff.sublist(0,10));//这个子范围还可以完成更改操作staff.subList(0,10).clear(); 9.5.5 集合与数组的转换 如果需要把一个数组转换为集合，Arrays.asList包装器可以达到这个目的 从集合得到数组会更困难一些。当然，可以使用toArray方法 不过，这样做的结果是一个对象数组。 尽管你知道集合中包含一个特定类型的对象，但不能使用强制类型转换 toArray方法返回的数组是一个Object[]数组，不能改变它的类型。实际上，必须使用toArray方法的一个变体形式，提供一个所需类型而且长度为0的数组。这样一来，返回的数组就会创建为相同的数组类型 为什么不能直接将一个Class对象(如String.class)传递到toArray方法 原因是这个方法有“双重职责”，不仅要填充一个已有的数组，还要创建一个新数组 123456789101112//数组转换为集合String[] values=...;HashSet&lt;String&gt; staff = new Hash&lt;&gt;(Arrays.asList(values));//集合转换为数组Object[] values = staff.toArray();//返回一个Object[]数组，不能改变其类型//使用toArray的变体形式，需要提供一个所需类型而且长度为0的数组，返回的数组就会创建为相同的数组类型String[] values = staff.toArray(new String[0]);//可以构造一个指定大小的数组staff.toArray(new String[staff.size()]); 9.5.6 编写自己的算法 编写自己的算法(实际上，是以集合作为参数的任何方法)，应该尽可能地使用接口，而不要使用具体的实现 9.6 遗留的集合 9.6.1 Hashtable类 Hashtable类与HashMap类的作用一样，实际上，它们拥有相同的接口。 与Vector类的方法一样。Hashtable的方法也是同步的。 如果对同步性或与遗留代码的兼容性没有任何要求，就应该使用HashMap。 如果需要并发访问，则要使用ConcurrentHashMap 9.6.2 枚举 遗留集合使用Enumeration接口对元素序列进行遍历 Enumeration接口有两个方法，即hasMoreElements和nextElement 这两个方法与Iterator接口的hasNext方法和next方法十分类似 12345678910//Hashtable类的elements方法将产生一个用于描述表中各个枚举值的对象Enumeration &lt;Employee&gt; e= staff.elements();while(e.hasMoreElements())&#123; Employee e = e.nextElement();&#125;//有时还会遇到遗留的方法,其参数是枚举类型的//静态方法Collections.enumeration将产生一个枚举对象，枚举集合中的元素List&lt;lnputStream&gt; streams = ...;SequenceInputstream in = new SequenceInautStrean(Collections.enumeration(streams)); 9.6.3 属性映射 属性映射(property map)是一个类型非常特殊的映射结构 它有下面3个特性： 键与值都是字符串 表可以保存到一个文件中，也可以从文件中加载 使用一个默认的辅助表。 实现属性映射的Java平台类称为Properties。 属性映射通常用于程序的特殊配置选项 9.6.4 栈 标准类库中就包含了Stack类，其中有大家熟悉的push方法和pop方法 但是，Stack类扩展为Vector类，从理论角度看，Vector类并不太令人满意，它可以让栈使用不属于栈操作的insert和remove方法，即可以在任何地方进行插入或删除操作，而不仅仅是在栈顶 9.6.5 位集 Java平台的BitSet类用于存放一个位序列(它不是数学上的集，称为位向量或位数组更为合适) 如果需要高效地存储位序列(例如，标志)就可以使用位集 由于位集将位包装在字节里，所以，使用位集要比使用Boolean对象的ArrayList更加高效 BitSet类提供了一个便于读取、设置或清除各个位的接口 使用这个接口可以避免屏蔽和其他麻烦的位操作 1234567//名为buckerOfBits的BitSetbuckerOfBits.get(i);//开为true,否则为falsebuckerOfBits.set(i);//将第i位 置为开buckerOfBits.clear(i);//将第i位 置为关 13 部署Java应用程序 首先介绍打包应用的指令 然后展示应用如何存储配置信息和用户首选项 另外还会学习如何使用ServiceLoader类在应用中加载插件 讨论applet,介绍创建或维护applet时需要了解的有关知识(已过时,忽略) 讨论Java Web Start机制——这是一种基于Internet的应用发布方法,很多方面都与applet很类似,不过更适合不在Web页面中的程序 13.1 JAR文件 一个JAR文件既可以包含类文件,也可以包含诸如图像和声音这些其他类型的文件 此外,JAR文件是压缩的,它使用了大家熟悉的ZIP压缩格式 pack200是一种较通常的ZIP压缩算法更加有效的压缩类文件的方式 13.1.1 创建JAR文件 可以使用jar工具制作JAR文件(在默认的JDK安装中,位于jdk/bin目录下) 可以将应用程序、程序组件以及代码库打包在JAR文件中 1234//创建一个新的JAR文件应该使用的常见命令格式为jar cvf JARFileName File1 File2...//例如jar cvf CalculatorClasses.jar *.class icon.gif 13.1.2 清单文件 除了类文件、图像和其他资源外,每个JAR文件还包含一个用于描述归档特征的清单文件 清单文件被命名为MANIFEST.MF,它位于JAR文件的一个特殊METANF子目录中 123456//创建一个包含清单文件的Jar文件jar cfm JARFileName ManifestFileName...//例如jar cfm MyArchive.jar manifest.mf com/mycompany/mypkg/*.class//要想更新一个已有的JAR文件的清单,则需要将增加的部分放置到一个文本文件中,然后执行下列命令jar ufm MyArcnive.jar manifest-additions.mf 13.1.3 可执行JAR文件 可以使用jar命令中的e选项指定程序的入口点,即通常需要在调用java程序加载器时指定的类 或者,可以在清单中指定应用程序的主类 不要将扩展名.class添加到主类名中 清单文件的最后一行必须以换行符结束.否则,清单文件将无法被正确地读取 常见的错误是创建了一个只包含Main-Class而没有行结束符的文本文件 13.1.4 资源 利用资源机制,对于非类文件也可以同样方便地进行操作.下面是必要的步骤 获得具有资源的Class对象,例如,AboutPanel.class 如果资源是一个图像或声音文件,那么就需要调用getresource(filename)获得作为URL的资源位置,然后利用getImage或getAudioClip方法进行读取 与图像或声音文件不同,其他资源可以使用getResourceAsStream方法读取文件中的数据. 重点在于类加载器可以记住如何定位类,然后在同一位置查找关联的资源 13.1.5 密封 可以将Java包密封(seal)以保证不会有其他的类加入到其中 如果在代码中使用了包可见的类、方法和域,就可能希望密封包 如果不密封,其他类就有可能放在这个包中,进而访问包可见的特性 13.2 应用首选项的存储 应用用户通常希望能保存他们的首选项和定制信息,以后再次启动应用时再恢复这些配置 13.2.1 属性映射 属性映射是一种存储键/值对的数据结构 属性映射通常用来存储配置信息,它有3个特性： 键和值是字符串 映射可以很容易地存入文件以及从文件加载 有一个二级表保存默认值 实现属性映射的Java类名为Properties 属性映射对于指定程序的配置选项很有用 可以使用store方法将属性映射列表保存到一个文件中 习惯上,会把程序属性存储在用户主目录的一个子目录中 目录名通常以一个点号开头(在UNIX系统中),这个约定说明这是一个对用户隐藏的系统目录 要找出用户的主目录,可以调用System.getProperties方法,它恰好也使用一个Properties对象描述系统信息 主目录包含键“user.home” 13.2.2 首选项API 使用属性文件有以下缺点： 有些操作系统没有主目录的概念,所以很难找到一个统一的配置文件位置 关于配置文件的命名没有标准约定,用户安装多个Java应用时,就更容易发生命名冲突 13.3 服务加载器 通常,提供一个插件时,程序希望插件设计者能有一些自由来确定如何实现插件的特性 另外还可以有多个实现以供选择.利用ServiceLoader类可以很容易地加载符合一个公共接口的插件 13.5 Java Web Start Java Web Start应用程序包含下列主要特性： 应用程序一般通过浏览器发布.只要Java Web Start应用程序下载到本地就可以启动它,而不需要浏览器 应用程序并不在浏览器窗口内.它将显示在浏览器外的一个属于自己的框架中 应用程序不使用浏览器的Java实现.浏览器只是在加载Java Web Start应用程序描述符时启动一个外部应用程序 数字签名应用程序可以被赋予访问本地机器的任意权限.未签名的应用程序只能运行在“沙箱”中,它可以阻止具有潜在危险的操作 13.5.1 发布Java Web Start应用 要想准备一个通过Java Web Start发布的应用程序,应该将其打包到一个或多个JAR文件中 然后创建一个Java Network Launch Protocol(JNLP)格式的描述符文件.将这些文件放置在Web服务器上 还需要确保Web服务器对扩展名为.jnlp的文件报告一个application/x-java-jnlp-file的MIME类型(浏览器利用MIME类型确定启动哪一种辅助应用程序) 步骤： 编译程序 创建JAR文件： 准备启动文件Calculator.jnlp 如果使用Tomcat则在Tomcat安装的根目录上创建一个目录tomcat/webapps/calculator.创建子目录tomcat/webapps/calculator/WEBNF,并且将最小的web.xml文件放置在WEBNF子目录下 将JAR文件和启动文件放入tomcat/webapps/calculator目录 在Java控制面板中将URL增加到可信站点列表.或者,可以为JAR文件签名. 在tomcat/bin目录执行启动脚本来启动Tomcat. 将浏览器指向JNLP文件.如果你的浏览器不知道如何处理JNLP文件,可能会提供一个选项将它们与一个应用关联.如果是这样,请选择jdk/bin/javaws.否则,明确如何将MIME类型application/x-java-jnlp-file与javaws应用关联.还可以试着重新安装可以做到这一点的JDK. 稍后,计算器就会出现,所带的边框表明这是一个Java应用程序 当再次访问JNLP文件时,应用程序将从缓存中取出.可以利用Java插件控制面板查看缓存内容.在Windows系统的Windows控制面板中可以看到Java插件控制面板.在Linux下,可以运行jdk/jre/bin/ControlPanel 13.5.2 JNLP API JNLP API允许未签名的应用程序在沙箱中运行,同时通过一种安全的途径访问本地资源 API提供了下面的服务： 加载和保存文件 访问剪贴板 打印 下载文件 在默认的浏览器中显示一个文档 保存和获取持久性配置信息 确信只运行一个应用程序的实例 14 并发 进程与多线程有哪些区别呢 本质的区别在于每个进程拥有自己的一整套变量，而线程则共享数据 14.1 什么是线程 调用Thread.sleep不会创建一个新线程 sleep是Thread类的静态方法，用于暂停当前线程的活动 sleep方法可以抛出一个InterruptedException异常 14.1.1 使用进程给其他任务提供机会 一个单独的线程中执行一个任务的简单过程 将任务代码移到实现了Runnable接口的类的run方法中 由Runnable创建一个Thread对象 启动线程 123456789101112131415161718192021222324252627282930//Runnable接口，只有一个方法public interface Runnable&#123; void run();&#125;//由于Runnable是一个函数式接口，可以用lambda表达式建立一个实例Runnable r = () -&gt; &#123;task code&#125;;//由Runnable创建一个Thread对象Thread t = new Thread(r);//启动线程t.start();//要想将弹跳球代码放在一个独立的线程中，只需要实现一个类BallRunnable，然后，将动画代码放在run方法中Runnable r= ()-&gt; &#123;try &#123; for(int i = 1; i&lt;=STEPS;i++&gt;) &#123; ball.move(comp.getBounds()); comp.repaint(); Tread.sleep(DELAY); &#125;&#125; catch (InterruptedException e) &#123; //TODO: handle exception&#125;;Thread t = new Thread(r);t.start();//需要捕获sleep方法可能抛出的异常InterruptedException 不要调用Thread类或Runnable对象的run方法 直接调用run方法，只会执行同一个线程中的任务，而不会启动新线程 应该调用Thread.start方法。这个方法将创建一个执行run方法的新线程 14.2 中断线程 当线程的run方法执行方法体中最后一条语句后，并经由执行return语句返回时，或者出现了在方法中没有捕获的异常时，线程将终止 在Java的早期版本中，还有一个stop方法，其他线程可以调用它终止线程，这个方法现在已经被弃用了 interrupt方法可以用来请求终止线程 当对一个线程调用interrupt方法时，线程的中断状态将被置位 这是每一个线程都具有的boolean标志。每个线程都应该不时地检查这个标志，以判断线程是否被中断 要想弄清中断状态是否被置位，首先调用静态的Thread.currentThread方法获得当前线程，然后调用isInterrupted方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576//isInterrupted方法while(!Thread.currentThread().isInterrupted() &amp;&amp; more work to do)&#123; do more work&#125;//如果线程被阻塞，就无法检测中断状态,产生InterruptedException异常的地方//当在一个被阻塞的线程(调用sleep或wait)上调用interrupt方法时，阻塞调用将会被Interrupted Exception异常中断//线程将简单地将中断作为一个终止的请求//这种线程的run方法具有如下形式Runnable r = () -&gt;&#123; try&#123; ... while(!Thread.currentThread().isInterrupted() &amp;&amp; more work to do) &#123; do more work &#125; &#125; catch (InterruptedException e) &#123; // thread was interrupted during sleep or wait &#125; finally&#123; cleanup, if required &#125; // exiting the run rethod terminates the thread&#125;;try//如果在每次工作迭代之后都调用sleep方法(或者其他的可中断方法)，isInterrupted检测既没有必要也没有用处//如果在中断状态被置位时调用sleep方法，它不会休眠。相反，它将清除这一状态(！)并抛出InterruptedException//因此，如果你的循环调用sleep，不会检测中断状态//相反，要如下所示捕获InterruptedException异常Runnable r = () -&gt;&#123; try&#123; ... while(!Thread.currentThread().isInterrupted() &amp;&amp; more work to do) &#123; do more work Thread.sleep(delay); &#125; &#125; catch (InterruptedException e) &#123; // thread was interrupted during sleep or wait &#125; finally&#123; cleanup, if required &#125; // exiting the run rethod terminates the thread&#125;;//InterruptedException异常被抑制在很低的层次上void mySubTask()&#123; ... try&#123;sleep(delay);&#125; catch(InterruptedException e) &#123;&#125; ...&#125;//不要这样做！//如果不认为在catch子句中做这一处理有什么好处的话，仍然有两种合理的选择：//1. 在catch子句中调用Thread.currentThread().interrupt()来设置中断状态。于是，调用者可以对其进行检测void mySubTask()&#123; ... try&#123;sleep(delay);&#125; catch(InterruptedException e) &#123;Thread.currentThread().interrupt()&#125; ...&#125;//更好的选择是，用throws InterruptedException标记你的方法，不采用try语句块捕获异常//于是，调用者(或者，最终的run方法)可以捕获这一异常void mySubTask() throws InterruptedException&#123; ... sleep(delay) ...&#125; 有两个非常类似的方法，interrupted和isInterrupted Interrupted方法是一个静态方法，它检测当前的线程是否被中断 而且，调用interrupted方法会清除该线程的中断状态 isInterrupted方法是一个实例方法，可用来检验是否有线程被中断 调用这个方法不会改变中断状态 14.3 线程状态 线程有6种状态 New(新创建) Runnable(可运行) Blocked(被阻塞) Waiting(等待) Timed waiting(计时等待) Terminated(被终止) 14.3.1 新创建线程 当用new操作符创建一个新线程时，如new Thread®，该线程还没有开始运行 这意味着它的状态是new 当一个线程处于新创建状态时，程序还没有开始运行线程中的代码。在线程运行之前还有一些基础工作要做 14.3.2 可运行线程 一旦调用start方法，线程处于runnable状态 一个可运行的线程可能正在运行也可能没有运行 一个正在运行中的线程仍然处于可运行状态 一旦一个线程开始运行，它不必始终保持运行。事实上，运行中的线程被中断，目的是为了让其他线程获得运行机会 抢占式调度：每一个可运行线程一个时间片来执行任务。当时间片用完，操作系统剥夺该线程的运行权，并给另一个线程运行机会，当选择下一个线程时，操作系统考虑线程的优先级 协作式调度：一个线程只有在调用yield方法、或者被阻塞或等待时，线程才失去控制权 14.3.3 被阻塞线程或等待线程 当线程处于被阻塞或等待状态时，它暂时不活动，它不运行任何代码且消耗最少的资源。直到线程调度器重新激活它 当一个线程试图获取一个内部的对象锁(而不是java.util.concurrent库中的锁)，而该锁被其他线程持有，则该线程进入阻塞状态 当所有其他线程释放该锁，并且线程调度器允许本线程持有它的时候，该线程将变成非阻塞状态 当线程等待另一个线程通知调度器一个条件时，它自己进入等待状态。在调用Object.wait方法或Thread.join方法，或者是等待java.util.concurrent库中的Lock或Condition时，就会出现这种情况。实际上，被阻塞状态与等待状态是有很大不同的 有几个方法有一个超时参数。调用它们导致线程进入计时等待(timed waiting)状态。这一状态将一直保持到超时期满或者接收到适当的通知。带有超时参数的方法有Thread.sleep和Object.wait、Thread.join、Lock.tryLock以及Condition.await的计时版 14.3.4 被终止的线程 线程因如下两个原因之一而被终止： 因为run方法正常退出而自然死亡 因为一个没有捕获的异常终止了run方法而意外死亡 14.4 线程属性 14.4.1 线程优先级 在Java程序设计语言中，每一个线程有一个优先级 默认情况下，一个线程继承它的父线程的优先级 可以用setPriority方法提高或降低任何一个线程的优先级 可以将优先级设置为在MIN_PRIORITY(在Thread类中定义为1)与MAX_PRIORITY(定义为10)之间的任何值。NORM_PRIORITY被定义为5 每当线程调度器有机会选择新线程时，它首先选择具有较高优先级的线程 不要将程序构建为功能的正确性依赖于优先级 如果确实要使用优先级，应该避免初学者常犯的一个错误 如果有几个高优先级的线程没有进入非活动状态，低优先级的线程可能永远也不能执行 每当调度器决定运行一个新线程时，首先会在具有高优先级的线程中进行选择，尽管这样会使低优先级的线程完全饿死 14.4.2 守护线程 守护线程的唯一用途是为其他线程提供服务 当只剩下守护线程时，虚拟机就退出了，由于如果只剩下守护线程，就没必要继续运行程序了 守护线程有时会被初学者错误地使用，他们不打算考虑关机(shutdown)动作。但是，这是很危险的。守护线程应该永远不去访问固有资源，如文件、数据库，因为它会在任何时候甚至在一个操作的中间发生中断 12t.setDaemon(true);//将线程转换为守护线程 14.4.3 未捕获异常处理器 线程的run方法不能抛出任何受查异常，但是，非受查异常会导致线程终止(线程死亡) 但是，不需要任何catch子句来处理可以被传播的异常 相反，就在线程死亡之前，异常被传递到一个用于未捕获异常的处理器 12345678//该处理器必须属于一个实现Thread.UncaughtExceptionHandler接口的类//这个接口只有一个方法void UncaughtException(Thread t, Throwable e)//可以用setUncaughtExceptionHandler方法为任何线程安装一个处理器//可以用Thread类的静态方法setDefaultUncaughtExceptionHandler为所有线程安装一个默认的处理器//如果不安装默认的处理器，默认的处理器为空//但是，如果不为独立的线程安装处理器，此时的处理器就是该线程的ThreadGroup对象 线程组是一个可以统一管理的线程集合 默认情况下，创建的所有线程属于相同的线程组，但是，也可能会建立其他的组 现在引入了更好的特性用于线程集合的操作，所以建议不要在自己的程序中使用线程组 ThreadGroup类实现Thread.UncaughtExceptionHandler接口 它的uncaughtException方法做如下操作： 如果该线程组有父线程组，那么父线程组的uncaughtException方法被调用。 否则，如果Thread.getDefaultExceptionHandler方法返回一个非空的处理器，则调用该处理器。 否则，如果Throwable是ThreadDeath的一个实例，什么都不做。 否则，线程的名字以及Throwable的栈轨迹被输出到System.err上 14.5 同步 14.5.2 竞争条件详解 123456789101112131415//假定两个线程同时执行指令accouts[to] += amount;//问题在于这不是原子操作。该指令可能被处理如下：//1)将accounts[to]加载到寄存器。//2)增加amount。//3)将结果写回accounts[to]。//现在，假定第1个线程执行步骤1和2，然后，它被剥夺了运行权。假定第2个线程被唤醒并修改了accounts数组中的同一项。然后，第1个线程被唤醒并完成其第3步。//这一动作擦去了第二个线程所做的更新。于是，总金额不再正确//出现这一讹误的可能性有多大呢//这里通过将打印语句和更新余额的语句交织在一起执行，增加了发生这种情况的机会。//如果删除打印语句，讹误的风险会降低一点，因为每个线程在再次睡眠之前所做的工作很少，调度器在计算过程中剥夺线程的运行权可能性很小。但是，讹误的风险并没有完全消失。如果在负载很重的机器上运行许多线程，那么，即使删除了打印语句，程序依然会出错。这种错误可能会几分钟、几小时或几天出现一次//真正的问题是transfer方法的执行过程中可能会被中断//如果能够确保线程在失去控制之前方法运行完成，那么银行账户对象的状态永远不会出现讹误 14.5.3 锁对象 有两种机制防止代码块受并发访问的干扰 Java语言提供一个synchronized关键字达到这一目的，并且Java SE 5.0引入了ReentrantLock类。synchronized关键字自动提供一个锁以及相关的“条件” java.util.concurrent框架为这些基础机制提供独立的类 12345678910//用ReentrantLock保护代码块的基本结构如下myLock.lock();try &#123; &#125; finally&#123; myLock.unlock();&#125;//这一结构确保任何时刻只有一个线程进入临界区//一旦一个线程封锁了锁对象，其他任何线程都无法通过lock语句//当其他线程调用lock时，它们被阻塞，直到第一个线程释放锁对象 把解锁操作括在finally子句之内是至关重要的 如果在临界区的代码抛出异常，锁必须被释放。否则，其他线程将永远阻塞 如果使用锁，就不能使用带资源的try语句 首先，解锁方法名不是close。不过，即使将它重命名，带资源的try语句也无法正常工作 它的首部希望声明一个新变量。但是如果使用一个锁，你可能想使用多个线程共享的那个变量(而不是新变量) 注意每一个Bank对象有自己的ReentrantLock对象 如果两个线程试图访问同一个Bank对象，那么锁以串行方式提供服务。但是，如果两个线程访问不同的Bank对象，每一个线程得到不同的锁对象，两个线程都不会发生阻塞 本该如此，因为线程在操纵不同的Bank实例的时候，线程之间不会相互影响。 锁是可重入的，因为线程可以重复地获得已经持有的锁 锁保持一个持有计数(hold count)来跟踪对lock方法的嵌套调用 线程在每一次调用lock都要调用unlock来释放锁。由于这一特性，被一个锁保护的代码可以调用另一个使用相同的锁的方法 通常，可能想要保护需若干个操作来更新或检查共享对象的代码块。要确保这些操作完成后，另一个线程才能使用相同对象 要留心临界区中的代码，不要因为异常的抛出而跳出临界区 如果在临界区代码结束之前抛出了异常，finally子句将释放锁，但会使对象可能处于一种受损状态 听起来公平锁更合理一些，但是使用公平锁比使用常规锁要慢很多 只有当你确实了解自己要做什么并且对于你要解决的问题有一个特定的理由必须使用公平锁的时候，才可以使用公平锁 即使使用公平锁，也无法确保线程调度器是公平的。如果线程调度器选择忽略一个线程，而该线程为了这个锁已经等待了很长时间，那么就没有机会公平地处理这个锁了 14.5.4 条件对象 线程进入临界区，却发现在某一条件满足之后它才能执行 要使用一个条件对象来管理那些已经获得了一个锁但是却不能做有用工作的线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//细化银行的模拟程序//避免选择没有足够资金的账户作为转出账户if(bank.getBalance(from) &gt;= amount)//thread might be deactivated at this point bank.transfer(from, to, amount);//在线程再次运行前，账户余额可能已经低于提款金额//必须确保没有其他线程在本检查余额与转账活动之间修改余额//通过使用锁来保护检查与转账动作来做到这一点public void transfer(int from, int to, int amount) &#123; bankLock.lock(); try &#123; while(accounts[from] &lt; amount) &#123; //wait ... &#125; &#125; finally &#123; bankLock.unlock(); &#125;&#125;//当账户中没有足够的余额时，应该做什么呢//等待直到另一个线程向账户中注入了资金//但是，这一线程刚刚获得了对bankLock的排它性访问，因此别的线程没有进行存款操作的机会//一个锁对象可以有一个或多个相关的条件对象//你可以用newCondition方法获得一个条件对象//习惯上给每一个条件对象命名为可以反映它所表达的条件的名字//设置一个条件对象来表达“余额充足”条件class bank&#123; private Condition sufficientFunds; ... public bank() &#123; ... sufficientFunds = bankLock.newCondition(); &#125;&#125;//如果transfer方法发现余额不足，它调用sufficientFunds.await();//当前线程现在被阻塞了，并放弃了锁//这样可以使得另一个线程可以进行增加账户余额的操作//等待获得锁的线程和调用await方法的线程存在本质上的不同//一旦一个线程调用await方法，它进入该条件的等待集//当锁可用时，该线程不能马上解除阻塞。相反，它处于阻塞状态，直到另一个线程调用同一条件上的signalAll方法时为止//当另一个线程转账时，它应该调用sufficientFunds.signalAll();//这一调用重新激活因为这一条件而等待的所有线程//当这些线程从等待集当中移出时，它们再次成为可运行的，调度器将再次激活它们//同时，它们将试图重新进入该对象。一旦锁成为可用的，它们中的某个将从await调用返回，获得该锁并从被阻塞的地方继续执行//signalAll方法仅仅是通知正在等待的线程：此时有可能已经满足条件，值得再次去检测该条件//通常，对await的调用应该在如下形式的循环体中while(!(ok to proceed)) condition.await(); 至关重要的是最终需要某个其他线程调用signalAll方法 当一个线程调用await时，它没有办法重新激活自身。它寄希望于其他线程 如果没有其他线程来重新激活等待的线程，它就永远不再运行了。这将导致令人不快的死锁(deadlock)现象 如果所有其他线程被阻塞，最后一个活动线程在解除其他线程的阻塞状态之前就调用await方法，那么它也被阻塞。没有任何线程可以解除其他线程的阻塞，那么该程序就挂起了。 应该何时调用signalAll呢 经验上讲，在对象的状态有利于等待线程的方向改变时调用signalAll 注意调用signalAll不会立即激活一个等待线程。它仅仅解除等待线程的阻塞，以便这些线程可以在当前线程退出同步方法之后，通过竞争实现对对象的访问 另一个方法signal，则是随机解除等待集中某个线程的阻塞状态 这比解除所有线程的阻塞更加有效，但也存在危险。如果随机选择的线程发现自己仍然不能运行，那么它再次被阻塞。如果没有其他线程再次调用signal，那么系统就死锁了 当一个线程拥有某个条件的锁时，它仅仅可以在该条件上调用await、signalAll或signal方法 14.5.5 synchronized关键字 锁和条件的关键之处： 锁用来保护代码片段，任何时刻只能有一个线程执行被保护的代码 锁可以管理试图进入被保护代码段的线程 锁可以拥有一个或多个相关的条件对象 每个条件对象管理那些已经进入被保护的代码段但还不能运行的线程 Java中的每一个对象都有一个内部锁 如果一个方法用synchronized关键字声明，那么对象的锁将保护整个方法(要调用该方法，线程必须获得内部的对象锁) 由锁来管理那些试图进入synchronized方法的线程，由条件来管理那些调用wait的线程 内部对象锁只有一个相关条件。wait方法添加一个线程到等待集中，notifyAll/notify方法解除等待线程的阻塞状态 wait、notifyAll以及notify方法是Object类的final方法。Condition方法必须被命名为await、signalAll和signal以便它们不会与那些方法发生冲突 123456789101112public synchronized void method() &#123; method body&#125;//等价于public void method() &#123; this.intrinsicLock.lock(); try &#123; method body &#125; finally &#123; this.intrinsicLock.unLock(); &#125;&#125; 内部锁和条件存在一些局限。包括： 不能中断一个正在试图获得锁的线程 试图获得锁时不能设定超时 每个锁仅有单一的条件，可能是不够的 Lock和Condition对象还是同步方法 最好既不使用Lock/Condition也不使用synchronized关键字。在许多情况下你可以使用java.util.concurrent包中的一种机制，它会为你处理所有的加锁。例如，使用阻塞队列来同步完成一个共同任务的线程 如果synchronized关键字适合你的程序，那么请尽量使用它，这样可以减少编写的代码数量，减少出错的几率 如果特别需要Lock/Condition结构提供的独有特性时，才使用Lock/Condition 14.5.6 同步阻塞 线程可以通过调用同步方法获得锁 还可以通过进入一个同步阻塞 123456//当线程进入如下形式的阻塞synchronized(obj)&#123; critical section&#125;//获得obj的锁 14.5.7 监视器概念 监视器可以在不需要程序员考虑如何加锁的情况下，就可以保证多线程的安全性 监视器的特征： 监视器是只包含私有域的类 每个监视器类的对象有一个相关的锁 使用该锁对所有的方法进行加锁 因为所有的域是私有的，这样的安排可以确保一个线程在对对象操作时，没有其他线程能访问该域 该锁可以有任意多个相关条件 可以简单地调用await accounts[from]&gt;=balance而不使用任何显式的条件变量。然而，研究表明盲目地重新测试条件是低效的。显式的条件变量解决了这一问题。每一个条件变量管理一个独立的线程集 Java中的每一个对象有一个内部的锁和内部的条件 如果一个方法用synchronized关键字声明，那么，它表现的就像是一个监视器方法。通过调用wait/notifyAll/notify来访问条件变量 在3个方面Java对象不同于监视器，从而使得线程的安全性下降： 域不要求必须是private 方法不要求必须是synchronized 内部锁对客户是可用的 14.5.8 Volatile域 多处理器的计算机能够暂时在寄存器或本地内存缓冲区中保存内存中的值。结果是，运行在不同处理器上的线程可能在同一个内存位置取到不同的值 编译器可以改变指令执行的顺序以使吞吐量最大化。这种顺序上的变化不会改变代码语义，但是编译器假定内存的值仅仅在代码中有显式的修改指令时才会改变。然而，内存的值可以被另一个线程改变！ 如果你使用锁来保护可以被多个线程访问的代码，那么可以不考虑这种问题。编译器被要求通过在必要的时候刷新本地缓存来保持锁的效应，并且不能不正当地重新排序指令 volatile关键字为实例域的同步访问提供了一种免锁机制 如果声明一个域为volatile，那么编译器和虚拟机就知道该域是可能被另一个线程并发更新的 Volatile变量不能提供原子性 不能确保翻转域中的值。不能保证读取、翻转和写入不被中断 14.5.9 final变量 除非使用锁或volatile修饰符，否则无法从多个线程安全地读取一个域 还可以安全地访问一个共享域，即这个域声明为final 14.5.10 原子性 假设对共享变量除了赋值之外并不完成其他操作，那么可以将这些共享变量声明为volatile 在Java SE 8中，可以使用一个lambda表达式更新变量 如果有大量线程要访问相同的原子值，性能会大幅下降，因为乐观更新需要太多次重试 Java SE 8提供了LongAdder和LongAccumulator类来解决这个问题。LongAdder包括多个变量(加数)，其总和为当前值。可以有多个线程更新不同的加数，线程个数增加时会自动提供新的加数。通常情况下，只有当所有工作都完成之后才需要总和的值，对于这种情况，这种方法会很高效。性能会有显著的提升。 如果认为可能存在大量竞争，只需要使用LongAdder而不是AtomicLong。方法名稍有区别。调用increment让计数器自增，或者调用add来增加一个量，或者调用sum来获取总和 14.5.11 死锁 有可能会因为每一个线程要等待更多的钱款存入而导致所有线程都被阻塞。这样的状态称为死锁 当程序挂起时，键入CTRL+\\，将得到一个所有线程的列表。每一个线程有一个栈踪迹，告诉你线程被阻塞的位置 导致死锁的另一种途径是让第i个线程负责向第i个账户存钱，而不是从第i个账户取钱。这样一来，有可能将所有的线程都集中到一个账户上，每一个线程都试图从这个账户中取出大于该账户余额的钱 还有一种很容易导致死锁的情况：在SynchBankTest程序中，将signalAll方法转换为signal，会发现该程序最终会挂起(将NACCOUNTS设为10可以更快地看到结果)。signalAll通知所有等待增加资金的线程，与此不同的是signal方法仅仅对一个线程解锁。如果该线程不能继续运行，所有的线程可能都被阻塞 14.5.12 线程局部变量 有时可能要避免共享变量，使用ThreadLocal辅助类为各个线程提供各自的实例 在多个线程中生成随机数，java.util.Random类是线程安全的。但是如果多个线程需要等待一个共享的随机数生成器，这会很低效 可以使用ThreadLocal辅助类为各个线程提供一个单独的生成器 Java SE 7还另外提供了一个便利类，ThreadLocalRandom.current()调用会返回特定于当前线程的Random类实例 14.5.13 锁测试域超时 线程在调用lock方法来获得另一个线程所持有的锁的时候，很可能发生阻塞 tryLock方法试图申请一个锁，在成功获得锁后返回true，否则，立即返回false，而且线程可以立即离开去做其他事情 12345678910111213141516171819202122if (myLock.tryLock())&#123; //now the thread owns the lock try&#123;...&#125; finaly&#123;myLock.unlock()&#125;;&#125;else //do something else//可以调用tryLock时，使用超时参数if (myLock.tryLock(100,TimeUnit.MILLISECONDS))...//TimeUnit是一个枚举类型，可以取的值包括SECONDS、MILLISECONDS、MICROSECONDS和NANOSECONDS//lock方法不能被中断。如果一个线程在等待获得一个锁时被中断，中断线程在获得锁之前一直处于阻塞状态。如果出现死锁，那么，lock方法就无法终止//如果调用带有用超时参数的tryLock，那么如果线程在等待期间被中断，将抛出InterruptedException异常。这是一个非常有用的特性，因为允许程序打破死锁//也可以调用lockInterruptibly方法。它就相当于一个超时设为无限的tryLock方法。//在等待一个条件时，也可以提供一个超时myCondition.awit(100,TimeUnit.MILLISECONDS)//如果一个线程被另一个线程通过调用signalAll或signal激活，或者超时时限已达到，或者线程被中断，那么await方法将返回//如果等待的线程被中断，await方法将抛出一个InterruptedException异常。在你希望出现这种情况时线程继续等待(可能不太合理)，可以使用awaitUninterruptibly方法代替await 14.5.14 读/写锁 如果很多线程从一个数据结构读取数据而很少线程修改其中数据的话，后者是十分有用的 在这种情况下，允许对读者线程共享访问是合适的。当然，写者线程依然必须是互斥访问的 1234567891011121314151617181920//使用读/写锁的必要步骤//1)构造一个ReentrantReadWriteLock对象private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();//2)抽取读锁和写锁private Lock readLock = rwl.readLock();private Lock writeLock = rwl.writeLock();//3)对所有的获取方法加读锁public double getTotalBalance()&#123; readLock.lock() try&#123;...&#125; finally&#123;readLock.unlock();&#125;&#125;//4)对所有的修改方法加写锁public void transfer(...)&#123; writeLock.lock(); try&#123;...&#125; finally&#123;writeLock.unlock();&#125;&#125; 14.5.15 为什么弃用stop和suspend方法 首先来看看stop方法，该方法终止所有未结束的方法，包括run方法。当线程被终止，立即释放被它锁住的所有对象的锁。这会导致对象处于不一致的状态 例如，假定TransferThread在从一个账户向另一个账户转账的过程中被终止，钱款已经转出，却没有转入目标账户，现在银行对象就被破坏了。因为锁已经被释放，这种破坏会被其他尚未停止的线程观察到 当线程要终止另一个线程时，无法知道什么时候调用stop方法是安全的，什么时候导致对象被破坏。因此，该方法被弃用了。在希望停止线程的时候应该中断线程，被中断的线程会在安全的时候停止 因为它会导致对象被一个已停止的线程永久锁定。但是，这一说法是错误的。从技术上讲，被停止的线程通过抛出ThreadDeath异常退出所有它所调用的同步方法。结果是，该线程释放它持有的内部对象锁 stop不同，suspend不会破坏对象。但是，如果用suspend挂起一个持有一个锁的线程，那么，该锁在恢复之前是不可用的。如果调用suspend方法的线程试图获得同一个锁，那么程序死锁：被挂起的线程等着被恢复，而将其挂起的线程等待获得锁 14.6 阻塞队列 对于许多线程问题，可以通过使用一个或多个队列以优雅且安全的方式将其形式化。生产者线程向队列插入元素，消费者线程则取出它们。使用队列，可以安全地从一个线程向另一个线程传递数据 当试图向队列添加元素而队列已满，或是想从队列移出元素而队列为空的时候，阻塞队列(blocking queue)导致线程阻塞 在协调多个线程之间的合作时，阻塞队列是一个有用的工具。工作者线程可以周期性地将中间结果存储在阻塞队列中。其他的工作者线程移出中间结果并进一步加以修改。队列会自动地平衡负载 如果第一个线程集运行得比第二个慢，第二个线程集在等待结果时会阻塞。如果第一个线程集运行得快，它将等待第二个队列集赶上来 如果将队列当作线程管理工具来使用，将要用到put和take方法。当试图向满的队列中添加或从空的队列中移出元素时，add、remove和element操作抛出异常。当然，在一个多线程程序中，队列会在任何时候空或满，因此，一定要使用offer、poll和peek方法作为替代 poll和peek方法返回空来指示失败。因此，向这些队列中插入null值是非法的 还有带有超时的offer方法和poll方法的变体 java.util.concurrent包提供了阻塞队列的几个变种。默认情况下，LinkedBlockingQueue的容量是没有上边界的，但是，也可以选择指定最大容量。LinkedBlockingDeque是一个双端的版本 ArrayBlockingQueue在构造时需要指定容量，并且有一个可选的参数来指定是否需要公平性。若设置了公平参数，则那么等待了最长时间的线程会优先得到处理。通常，公平性会降低性能，只有在确实非常需要时才使用它 PriorityBlockingQueue是一个带优先级的队列，而不是先进先出队列。元素按照它们的优先级顺序被移出。该队列是没有容量上限，但是，如果队列是空的，取元素的操作会阻塞 DelayQueue包含实现Delayed接口的对象 getDelay方法返回对象的残留延迟。负值表示延迟已经结束。元素只有在延迟用完的情况下才能从DelayQueue移除。还必须实现compareTo方法。DelayQueue使用该方法对元素进行排序 Java SE 7增加了一个TransferQueue接口，允许生产者线程等待，直到消费者准备就绪可以接收一个元素 14.7 线程安全的集合 如果多线程要并发地修改一个数据结构，例如散列表，那么很容易会破坏这个数据结构 可以通过提供锁来保护共享数据结构，但是选择线程安全的实现作为替代可能更容易些 14.7.1 高效的映射、集和队列 java.util.concurrent包提供了映射、有序集和队列的高效实现：ConcurrentHashMap、ConcurrentSkipListMap、ConcurrentSkipListSet和ConcurrentLinkedQueue 这些集合使用复杂的算法，通过允许并发地访问数据结构的不同部分来使竞争极小化 与大多数集合不同，size方法不必在常量时间内操作。确定这样的集合当前的大小通常需要遍历 有些应用使用庞大的并发散列映射，这些映射太过庞大，以至于无法用size方法得到它的大小，因为这个方法只能返回int。对于一个包含超过20亿条目的映射该如何处理？Java SE 8引入了一个mappingCount方法可以把大小作为long返回 集合返回弱一致性(weakly consistent)的迭代器。这意味着迭代器不一定能反映出它们被构造之后的所有的修改，但是，它们不会将同一个值返回两次，也不会抛出Concurrent ModificationException异常 与之形成对照的是，集合如果在迭代器构造之后发生改变，java.util包中的迭代器将抛出一个ConcurrentModificationException异常 并发的散列映射表，可高效地支持大量的读者和一定数量的写者 散列映射将有相同散列码的所有条目放在同一个“桶”中。有些应用使用的散列函数不当，以至于所有条目最后都放在很少的桶中，这会严重降低性能。即使是一般意义上还算合理的散列函数，如String类的散列函数，也可能存在问题 在Java SE 8中，并发散列映射将桶组织为树，而不是列表，键类型实现了Comparable，从而可以保证性能为O(log(n)) 14.7.2 映射条目的原子更新 ConcurrentHashMap原来的版本只有为数不多的方法可以实现原子更新 可以使用ConcurrentHashMap＜String，Long＞吗？考虑让计数自增的代码 为什么原本线程安全的数据结构会允许非线程安全的操作。不过有两种完全不同的情况。如果多个线程修改一个普通的HashMap，它们会破坏内部结构(一个链表数组)。有些链接可能丢失，或者甚至会构成循环，使得这个数据结构不再可用。对于ConcurrentHashMap绝对不会发生这种情况。在上面的例子中，get和put代码不会破坏数据结构。不过，由于操作序列不是原子的，所以结果不可预知 传统的做法是使用replace操作，它会以原子方式用一个新值替换原值，前提是之前没有其他线程把原值替换为其他值。必须一直这么做，直到replace成功 或者，可以使用一个ConcurrentHashMap＜String，AtomicLong＞，或者在Java SE 8中，还可以使用ConcurrentHashMap＜String，LongAdder＞ Java SE 8提供了一些可以更方便地完成原子更新的方法。调用compute方法时可以提供一个键和一个计算新值的函数。这个函数接收键和相关联的值(如果没有值，则为null)，它会计算新值 ConcurrentHashMap中不允许有null值。有很多方法都使用null值来指示映射中某个给定的键不存在 另外还有computeIfPresent和computeIfAbsent方法，它们分别只在已经有原值的情况下计算新值，或者只有没有原值的情况下计算新值 首次增加一个键时通常需要做些特殊的处理。利用merge方法可以非常方便地做到这一点。这个方法有一个参数表示键不存在时使用的初始值。否则，就会调用你提供的函数来结合原值与初始值。(与compute不同，这个函数不处理键 如果传入compute或merge的函数返回null，将从映射中删除现有的条目 警告：使用compute或merge时，要记住你提供的函数不能做太多工作。这个函数运行时，可能会阻塞对映射的其他更新。当然，这个函数也不能更新映射的其他部分 14.7.3 对并发散列映射的批操作 Java SE 8为并发散列映射提供了批操作，即使有其他线程在处理映射，这些操作也能安全地执行 3中不同的操作 搜索为每个键或值提供一个函数，直到函数生成一个非null的结果。然后搜索终止，返回这个函数的结果 归约组合所有键或值，这里要使用所提供的一个累加函数 forEach为所有键或值提供一个函数 每个操作都有4个版本 operationKeys：处理键 operationValues：处理值 operation：处理键和值 operationEntries：处理Map.Entry对象 需要指定一个参数化阈值(parallelism threshold)。如果映射包含的元素多于这个阈值，就会并行完成批操作。如果希望批操作在一个线程中运行，可以使用阈值Long.MAX_VALUE。如果希望用尽可能多的线程运行批操作，可以使用阈值1 14.7.4 并发集视图 假设你想要的是一个大的线程安全的集而不是映射。并没有一个ConcurrentHashSet类，而且你肯定不想自己创建这样一个类。当然，可以使用ConcurrentHashMap(包含“假”值)，不过这会得到一个映射而不是集，而且不能应用Set接口的操作 静态newKeySet方法会生成一个Set&lt;K&gt;，这实际上是ConcurrentHashMap&lt;K，Boolean&gt;的一个包装器。(所有映射值都为Boolean.TRUE，不过因为只是要把它用作一个集，所以并不关心具体的值 如果原来有一个映射，keySet方法可以生成这个映射的键集。这个集是可变的。如果删除这个集的元素，这个键(以及相应的值)会从映射中删除。不过，不能向键集增加元素，因为没有相应的值可以增加。Java SE 8为ConcurrentHashMap增加了第二个keySet方法，包含一个默认值 14.7.5 写数组的拷贝 CopyOnWriteArrayList和CopyOnWriteArraySet是线程安全的集合，其中所有的修改线程对底层数组进行复制 如果在集合上进行迭代的线程数超过修改线程数，这样的安排是很有用的。当构建一个迭代器的时候，它包含一个对当前数组的引用。如果数组后来被修改了，迭代器仍然引用旧数组，但是，集合的数组已经被替换了。因而，旧的迭代器拥有一致的(可能过时的)视图，访问它无须任何同步开销 14.7.6 并行数组算法 在Java SE 8中，Arrays类提供了大量并行化操作。静态Arrays.parallelSort方法可以对一个基本类型值或对象的数组排序 对对象排序时，可以提供一个Comparator 对于所有方法都可以提供一个范围的边界 parallelSetAll方法会用由一个函数计算得到的值填充一个数组。这个函数接收元素索引，然后计算相应位置上的值 parallelPrefix方法，它会用对应一个给定结合操作的前缀的累加结果替换各个数组元素 14.7.7 较早的线程安全集合 从Java的初始版本开始，Vector和Hashtable类就提供了线程安全的动态数组和散列表的实现。现在这些类被弃用了，取而代之的是ArrayList和HashMap类。这些类不是线程安全的，而集合库中提供了不同的机制。任何集合类都可以通过使用同步包装器(synchronization wrapper)变成线程安全的 确保没有任何线程通过原始的非同步方法访问数据结构。最便利的方法是确保不保存任何指向原始对象的引用，简单地构造一个集合并立即传递给包装器 在另一个线程可能进行修改时要对集合进行迭代，仍然需要使用“客户端”锁定 如果使用“for each”循环必须使用同样的代码，因为循环使用了迭代器。注意：如果在迭代过程中，别的线程修改集合，迭代器会失效，抛出ConcurrentModificationException异常。同步仍然是需要的，因此并发的修改可以被可靠地检测出来 最好使用java.util.concurrent包中定义的集合，不使用同步包装器中的。特别是，假如它们访问的是不同的桶，由于ConcurrentHashMap已经精心地实现了，多线程可以访问它而且不会彼此阻塞。有一个例外是经常被修改的数组列表。在那种情况下，同步的ArrayList可以胜过CopyOnWriteArrayList 14.8 Callable与Future Runnable封装一个异步运行的任务，可以把它想象成为一个没有参数和返回值的异步方法。Callable与Runnable类似，但是有返回值 Callable接口是一个参数化的类型，只有一个方法call Future保存异步计算的结果。可以启动一个计算，将Future对象交给某个线程，然后忘掉它。Future对象的所有者在结果计算好之后就可以获得它 14.9 执行器 如果程序中创建了大量的生命期很短的线程，应该使用线程池(thread pool)。一个线程池中包含许多准备运行的空闲线程。将Runnable对象交给线程池，就会有一个线程调用run方法。当run方法退出时，线程不会死亡，而是在池中准备为下一个请求提供服务 另一个使用线程池的理由是减少并发线程的数目。创建大量线程会大大降低性能甚至使虚拟机崩溃。如果有一个会创建许多线程的算法，应该使用一个线程数“固定的”线程池以限制并发线程的总数 执行器(Executor)类有许多静态工厂方法用来构建线程池 14.9.1 线程池 newCached-ThreadPool方法构建了一个线程池，对于每个任务，如果有空闲线程可用，立即让它执行任务，如果没有可用的空闲线程，则创建一个新线程 newFixedThreadPool方法构建一个具有固定大小的线程池。如果提交的任务数多于空闲的线程数，那么把得不到服务的任务放置到队列中。当其他任务完成以后再运行它们 newSingleThreadExecutor是一个退化了的大小为1的线程池：由一个线程执行提交的任务，一个接着一个 这3个方法返回实现了ExecutorService接口的ThreadPoolExecutor类的对象 在使用连接池时应该做的事 调用Executors类中静态的方法newCachedThreadPool或newFixedThreadPool。 调用submit提交Runnable或Callable对象。 如果想要取消一个任务，或如果提交Callable对象，那就要保存好返回的Future对象。 当不再提交任何任务时，调用shutdown 14.9.2 预定执行 ScheduledExecutorService接口具有为预定执行(Scheduled Execution)或重复执行任务而设计的方法。它是一种允许使用线程池机制的java.util.Timer的泛化 Executors类的newScheduledThreadPool和newSingleThreadScheduledExecutor方法将返回实现了Scheduled-ExecutorService接口的对象 可以预定Runnable或Callable在初始的延迟之后只运行一次。也可以预定一个Runnable对象周期性地运行 14.9.3 控制任务组 将一个执行器服务作为线程池使用，以提高执行任务的效率 有时，使用执行器有更有实际意义的原因，控制一组相关任务 invokeAny方法提交所有对象到一个Callable对象的集合中，并返回某个已经完成了的任务的结果。无法知道返回的究竟是哪个任务的结果，也许是最先完成的那个任务的结果。对于搜索问题，如果你愿意接受任何一种解决方案的话，你就可以使用这个方法 invokeAll方法提交所有对象到一个Callable对象的集合中，并返回一个Future对象的列表，代表所有任务的解决方案 缺点是如果第一个任务恰巧花去了很多时间，则可能不得不进行等待。将结果按可获得的顺序保存起来更有实际意义。可以用ExecutorCompletionService来进行排列 用常规的方法获得一个执行器。然后，构建一个ExecutorCompletionService，提交任务给完成服务(completion service)。该服务管理Future对象的阻塞队列，其中包含已经提交的任务的执行结果(当这些结果成为可用时) 14.9.4 Fork-Join框架 Java SE 7中新引入了fork-join框架，专门用来支持后一类应用。假设有一个处理任务，它可以很自然地分解为子任务 要采用框架可用的一种方式完成这种递归计算，需要提供一个扩展RecursiveTask＜T＞的类(如果计算会生成一个类型为T的结果)或者提供一个扩展RecursiveAction的类(如果不生成任何结果)。再覆盖compute方法来生成并调用子任务，然后合并其结果 在后台，fork-join框架使用了一种有效的智能方法来平衡可用线程的工作负载，这种方法称为工作密取(work stealing)。每个工作线程都有一个双端队列(deque)来完成任务。一个工作线程将子任务压入其双端队列的队头。(只有一个线程可以访问队头，所以不需要加锁。)一个工作线程空闲时，它会从另一个双端队列的队尾“密取”一个任务。由于大的子任务都在队尾，这种密取很少出现 14.9.5 可完成Future 处理非阻塞调用的传统方法是使用事件处理器，程序员为任务完成之后要出现的动作注册一个处理器 Java SE 8的CompletableFuture类提供了一种候选方法。与事件处理器不同，“可完成future”可以“组合”(composed) 利用可完成future，可以指定你希望做什么，以及希望以什么顺序执行这些工作。当然，这不会立即发生，不过重要的是所有代码都放在一处 从概念上讲，CompletableFuture是一个简单API，不过有很多不同方法来组合可完成future。下面先来看处理单个future的方法(如表14-3所示)。(对于这里所示的每个方法，还有两个Async形式，不过这里没有给出，其中一种形式使用一个共享ForkJoinPool，另一种形式有一个Executor参数)。在这个表中，我使用了简写记法来表示复杂的函数式接口，这里会把Function＜？super T，U＞写为T-＞U。当然这并不是真正的Java类型 14.10 同步器 线程之间的共用集结点模式：如果有一个相互合作的线程集满足这些行为模式之一，那么应该直接重用合适的库类而不要试图提供手工的锁与条件的集合 14.10.1 信号量 一个信号量管理许多的许可证(permit)。为了通过信号量，线程通过调用acquire请求许可。其实没有实际的许可对象，信号量仅维护一个计数。许可的数目是固定的，由此限制了通过的线程数量。其他线程可以通过调用release释放许可。而且，许可不是必须由获取它的线程释放。事实上，任何线程都可以释放任意数目的许可，这可能会增加许可数目以至于超出初始数目 14.10.2 倒计时门栓 一个倒计时门栓(CountDownLatch)让一个线程集等待直到计数变为0。倒计时门栓是一次性的。一旦计数为0，就不能再重用了 一个有用的特例是计数值为1的门栓。实现一个只能通过一次的门。线程在门外等候直到另一个线程将计数器值置为0 14.10.3 障栅 CyclicBarrier类实现了一个集结点(rendezvous)称为障栅(barrier)。考虑大量线程运行在一次计算的不同部分的情形。当所有部分都准备好时，需要把结果组合在一起。当一个线程完成了它的那部分任务后，我们让它运行到障栅处。一旦所有的线程都到达了这个障栅，障栅就撤销，线程就可以继续运行 障栅被称为是循环的(cyclic)，因为可以在所有等待线程被释放后被重用。在这一点上，有别于CountDownLatch，CountDownLatch只能被使用一次 Phaser类增加了更大的灵活性，允许改变不同阶段中参与线程的个数 14.10.4 交换器 当两个线程在同一个数据缓冲区的两个实例上工作的时候，就可以使用交换器(Exchanger)。典型的情况是，一个线程向缓冲区填入数据，另一个线程消耗这些数据。当它们都完成以后，相互交换缓冲区 14.10.5 同步队列 同步队列是一种将生产者与消费者线程配对的机制。当一个线程调用SynchronousQueue的put方法时，它会阻塞直到另一个线程调用take方法为止，反之亦然。与Exchanger的情况不同，数据仅仅沿一个方向传递，从生产者到消费者 即使SynchronousQueue类实现了BlockingQueue接口，概念上讲，它依然不是一个队列。它没有包含任何元素，它的size方法总是返回0 卷二部分 2 输入与输出 2.1 输入/输出 在JavaAPI中，可以从其中读入一个字节序列的对象称为输入流 可以向其中写入一个字节序列的对象称为输出流 抽象类InputStream和OutputStream构成了输入输出类层次结构的基础 这些类的读入和写出操作以基于二字节的char值(Unicode码元)为基础 2.1.1 读写字节 InputStream类 抽象方法: abstract int read() 读入一个字节,并返回读入的字节或者在遇到输入源结尾时返回-1 OutputStream类 抽象方法：abstract void write(int b) 从某个位置输出一个字节 read和write在执行时江北阻塞，直至字节确实被读入或写出 available()方法——检查当前可读入的字节数量 close()方法——完成对输入/输出流的读写时，关闭流释放操作系统资源 2.1.2 完整的流家族 InputStream和OutputStream流构成层次结构的基础 读写单个字节或字节数组 子类包含很多有用的输入和输出流 抽象类Reader和Writer子类,处理Unicode文本,基本方法为read()与write()方法 四个附加接口: Closeable Flushable Readable 和 Appendable Closeable Flushable分别拥有close() flush()方法 Appendable接口有两个用于添加单个字符和字符序列的方法 append(char c) append(CharSequence s) InputStream OutputStream Reader Writer 都实现了Closeable接口 OutputStream和Writer实现了Flushable接口 2.1.3 组合输入/输出流过滤器 FileInputStream和FileOutputStream可以提供附着在一个磁盘文件上的输入流和输出流,只需向构造器提供文件名或文件的完整路径名 只支持在字节级别上的读写 某些输入流(FileInputStream)可以从文件和其他外部位置获取字节;而其他的输入流(DataInputStream)可以将字节组装到更有用的数据类型中,对两者进行组合操作 输入流在默认情况下是不被缓冲区缓存的 每个对read的调用都会请求操作系统再分发一个字节，请求一个数据块，并将其置于缓冲区中会更加高效 当多个输入流链接在一起，跟踪个各个中介输入流：使用PushbackInputStream 能预先浏览并且还可以读入数字，需要一个既是可回推输入流，又是一个数据输入流的引用 12345678910111213141516171819202122232425262728293031323334//为了从文件中读入数字//首先需要创建一个FileInputStream//然后将其创建给DataInputStream的构造器FileInputStream fin = new FileInputStream(&quot;employee.dat&quot;);DataInputStream din = new DataInputStream(fin);double x = din.readDouble();//使用缓冲机制DataInputStream din = new DataInputStream( new BufferedInputStream( new FileInputStream(&quot;employee.dat&quot;) ));//跟踪中介流PushbackInputStream pbin = new PushbackInputStream( new BufferedInputStream( new FileInputStream(&quot;emoloyee.dat&quot;) ));//预读下一个字节int b = pbin.read();// 退回流中if(b != &#x27;&lt;&#x27;) pbin.unread();// 能预先浏览并且还可以读入数字// 既是可回推输入流，又是一个数据输入流的引用DataInputStream din = new DataInputStream( pbin = new PushbackInputStream( new BufferedInputStream( new FileInputStream(&quot;employee.dat&quot;) ) )); 2.2 文本输入与输出 Java内部使用UTF-16编码，字符串编码为16进制，许多应用程序使用UTF-8编码 OutputStreamWriter类将使用特定的字符编码方式，把Unicode码元的输出流转换为字节流= InputStreamReader类将包含字节的输入流转换为可以产生Unicode码元的读入器 123// 构建一个输入读入器从控制台读入键盘敲击信息，并转换为UnicodeReader in = new InputStreamReader(System.in);Reader in = new InputStreamReader(new FileInputStream(&quot;data.txt&quot;),StandardCharsets.UTF_8); 2.2.1 如何写出文本输出 对于文本输出,使用PrintWriter(存在可以链接到FileWriter的便捷写法) 为了输出到打印写出器，需要使用print,println,printf方法 println方法在行中添加了对目标系统来说恰当的行结束符 写出器设置为自动冲刷模式，那么只要println被调用，缓冲区中的所有字符都会被发送到它们的目的地 默认情况下，自动冲刷机制是禁用的，你可以通过使用PrintWriter（Writer out，Boolean autoFlush）来启用或禁用自动冲刷机制 123456789101112131415// PrintWriterPrintWriter out = new PrintWriter(&quot;employee.txt&quot;,&quot;UTF-8&quot;);String name = &quot;Harry Hacker&quot;;double salary = 75000;out.print(name);out.print(&quot; &quot;);out.println(salary);// 启用自动冲刷机制PrintWriter out = new PrintWriter( new OutputStreamWriter( new FileOutputStream(&quot;employee.txt&quot;),&quot;UTF-8&quot; ),true); 2.2.2 如何读入文本输入 使用Scanner对象 若文件太大，可以处理为Stream&lt;String&gt;对象 12345String content = new String(Files.readAllBytes(path),charset);List&lt;String&gt; lines = Files.readAllLines(path,charset);Stream&lt;String&gt; lines = Files.lines(path,charset); 2.2.4 字符编码方法 Java针对字符使用的是Unicode标准，每个字符或编码点有21位整数 最常见的编码方式是UTF-8标准，将每个Unicode编码点编码为1到4个字节的序列 UTF-8的好处是传统的包含了英语中用到的所有字符的ASCII字符集中的每个字符都只会占用一个字节 UTF-16，它会将每个Unicode编码点编码为1个或2个16位值 StandardCharsets类具有类型为Charset的静态变量，用于表示每种Java虚拟机都必须支持的字符编码方式 123456StandardCharsets.UTF_8StandardCharsets.UTF_16StandardCharsets.UTF_16BEStandardCharsets.UTF_16LEStandardCharsets.ISO_8859_1StandardCharsets.US_ASCII 2.3 读写二进制数据 2.3.1 DataInput和DataOutput接口 DataOutput接口定义了以二进制格式写数组、字符、boolean值和字符串的方法 1234567891011121314151617writeCharswriteByte// writeInt总是将一个整数写出为4字节的二进制数量值，而不管它有多少位writeIntwriteShortwriteLongwriteFloat// writeDouble总是将一个double值写出为8字节的二进制数量值writeDoublewriteCharwriteBoolean// writeUTF方法使用修订版的8位Unicode转换格式写出字符串writeUTF DataInput接口定义的方法，读回数据 DataInputStream类实现了DataInput接口 为了方便从文件中读入二进制数据，可以将DataInputStream与某个字节源相组合 1234567891011readIntreadShortreadLongreadFloatreadDoublereadCharreadBooleanreadUTFDataInputStream in = new DataInputStream(new FileInputStream(&quot;employee.dat&quot;));DataOutputStream out = new DataOuputStream(new FileOutputStream(&quot;employee.dat&quot;)); 2.3.2 随机访问文件 RandomAccessFile类可以在文件中的任何位置查找或写入数据 磁盘文件都是随机访问的，但是与网络套接字通信的输入/输出流却不是，可以打开一个随机访问文件，只用于读入或者同时用于读写 seek方法——将这个文件指针设置到文件中的任意字节位置——参数位一个long整数 getFilePointer方法——返回文件指针的位置 length方法——获得文件中的总字节数 writeFixedString方法——写出从字符串开头开始的指定数量的码元 readFixedString方法——从输入流中读入字符，直至读入size个码元，或者直至遇到具有0值得字符串 为了提高效率，使用StringBuilder类来读入字符串 123456789RandomAccessFile in = new RandomAccessFile(&quot;employee.dat&quot;,&quot;r&quot;);RandomAccessFile inOut = new RandomAccessFile(&quot;employee.dat&quot;,&quot;rw&quot;);long n = 3;in.seek((n-1)*RECOED_SIZE);Employee e = new Employee();e.readData(in);e.writeData(out); 2.3.3 ZIP文档 ZIP文档都存在一个头，包含压缩文件的信息 使用ZipInputStream来读入ZIP文档 getNextEntry方法——返回一个描述这些ZipEntry类型得对象 getInputStream方法——传递ZipEntry获得该项的输入流 closeEntry方法——读入下一项 使用ZipOutputStream写出到ZIP文件 对于希望放入到ZIP文件中的每一项，都应该创建一个ZipEntry对象，并将文件名传递给ZipEntry的构造器，它将设置其他诸如文件日期和解压缩方法等参数 putNextEntry方法——开始写出新文件，并将文件数据发送到ZIP输出流中 closeEntry方法——完成操作调用 123456789101112131415161718ZipInputStream zin = new ZipInputStream(new FileInputStream(zipname));ZipEntry entry;while((entry = zin.getNextEntry()) != null)&#123; InputStream in = zin.getInputStream(entry); ... zin.closeEntry();&#125;FileOutputStream fout = new FileOutputStream(&quot;test.zip&quot;);ZipoutputStream zout = new ZipOutputStream(fout);for all files&#123; ZipEntry ze = new ZipEntry(filename); zout.putNextEntry(ze); ... zout.closeEntry();&#125;zout.close(); 2.4 对象输入/输出流与序列化 对象序列化可以实现将任何对象写出到输出流中，并在之后将其读回 2.4.1 保存和加载序列化对象 为了保存对象数据，首先需要打开一个ObjectOutputStream对象 为了保存对象，可以直接使用ObjecyOutputStream的writeObject方法 为了将对象读回，首先需要获得一个ObjectInputStream对象 用readObject方法将这些对象被写出时的顺序获得他们 在对象输出流中存储或从对象输入流中回复的所有类必须实现Serialzable接口 每个对象都时用一个序列号保存（对象序列化的原因） 对遇到的每一个对象引用都关联一个序列号 对于每个对象，当第一次遇到时，保存其对象数据到输出流中 如果某个对象之前已经被保存过，那么只写出”与之前保存过的序列号x的对象相同“ 对于对象输入流中的对象，在第一次遇到其序列号时，构建它，并使用流中数据来初始化它，然后记录这个顺序号和新对象之间的关联 当遇到“与之前保存过的序列号为x的对象相同”标记时，获取与这个顺序号相关联的对象引用 12345678Employee harry = new Employee(&quot;Harry&quot;, 50000, 1989, 10, 1);Manager boss = new Manager(&quot;Carl&quot;, 80000, 1989, 10, 1);out.writeObject(harry);out.writeObject(boss);ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;employee.dat&quot;));Employee e1 = (Employee) in.readObject();Employee e2 = (Employee) in.readObject(); 2.4.2 理解对象序列化的文件格式 对象流输出中包含所有对象的类型和数据域 每个对象都被赋予一个序列号 相同对象的重复出现将被存储为对这个对象的序列号的引用 2.5 操作文件 Path接口和Files类 Path和Files类封装了在用户机器上处理文件系统所需的所有功能 2.5.1 Path Path表示是一个目录名序列，其后还可以跟着一个文件名 Paths.get方法——接受一个或多个字符串，并将它们用默认文件系统的路径分隔符连接起来，这个连接起来的结果就是一个Path对象 p.resolve(q)——按照规则返回一个路径，如果q是绝对路径，则结果就是q；否则，根据文件系统的规则，将“p后面跟着q”作为结果 resolveSibling()——通过解析指定路径的父路径产生器兄弟路径 p.relativize®——调用将产生路径q，而对q进行解析的结果正是r normalize()——将移除所有冗余的.和…部件(或者文件系统认为冗余的所有部件) toAbsolutePath()——将产生给定路径的绝对路径，该绝对路径从根部件开始 2.5.2 读写文件 Files类使操作普通文件更快捷 123456789101112131415161718192021// 读取文件的所有内容byte[] bytes = Files.readAllBytes(path);// 当作字符串读入String content = new String(bytes, charset);// 当作序列读入List&lt;String&gt; lines = Files.readAllLines(path,charset);// 写出一个字符串到文件中Files.write(path,content.getBytes(charset));// 指定文件追加内容Files.write(path,content.getBytes(charset)， StandardOption.APPEND);// 将一个行的集合写出到文件中Files.write(path, lines);// 如果要处理的文件长度比较大，或者是二进制文件// 那么还是应该使用所熟知的输入/输出流或者读入器/写出器InputStream in = Files.newInputStream(path);OutputStream out = Files.newOutputStream(path);Reader in = Files.newBufferedReader(path,charset);Writer out = Files.newBufferedwriter(path,charset); 2.5.3 创建文件和目录 123456789101112131415// 创建新目录Files.createDirectory(path);// 路径中除最后一个部件外，其他部分都必须是已经存在的// 要创建路径中的中间目录Files.createDirectories(path);// 创建空文件Files.createFile(path);// 有些便捷方法可以用来在给定位置或者系统指定位置创建临时文件或临时目录Path newPath = Files.createTempFile(dir,prefix,suffix);Path newPath = Files.createTempFile(prefix,suffix); Path newPath = Files.createTempDirectory(dir,prefix);Path newPath = Files.createTempDirectory(prefix); 2.5.4 复制,移动和删除文件 123456789101112131415161718192021// 复制文件Files.copy(fromPath, toPath);// 移动文件Files.move(fromPath, toPath);// 如果想要覆盖已有的目标路径，可以使用REPLACE_EXISTING选项// 如果想要复制所有的文件属性，可以使用COPY_ATTRIBUTES选项Files.copy(fromPath, toPath, StandardCopyOption.REPLACE_EXISTING, StandardCopyOption.COPY_ATTRIBUTES);// 将移动操作定义为原子性的，这样就可以保证要么移动操作成功完成，要么源文件继续保持在原来位置// 具体可以使用ATOMIC_MOVE选项来实现Files.copy(fromPath, toPath,StandardCopyOption.ATOMIC_MOVE);// 输入流复制，或将一个Path复制到输出流中Files.copy(inputStream,toPath);Files.copy(fromPath,outputStream);// 删除文件Files.delete(path);Files.deleteExists(path); 2.5.5 获取文件信息 所有的文件系统都会报告一个基本属性集，它们被封装在BasicFileAttributes接口中，这些属性与上述信息有部分重叠。基本文件属性包括： 创建文件、最后一次访问以及最后一次修改文件的时间，这些时间都表示成java.nio.file.attribute.FileTime 文件是常规文件、目录还是符号链接，抑或这三者都不是 文件尺寸 文件主键，这是某种类的对象，具体所属类与文件系统相关，有可能是文件的唯一标识符，也可能不是 1234567891011// 静态方法将返回一个boolean值，表示检查路径的某个属性的结果- exists- isHidden- isReadable，isWritable，isExecutable- isRegularFile，isDirectory，isSymbolicLink// size方法返回文件的字节数long fileSize = Files.size(path);// 获得文件属性BasicFileAttributes attributes = Files.readAttributes(path,BasicFileAttributes.class); 2.5.6 访问目录中的项 静态的Files.list方法会返回一个可以读取目录中各个项的Stream&lt;Path&gt;对象 目录是被惰性读取的，这使得处理具有大量项的目录可以变得更高效 读取目录涉及需要关闭的系统资源，所以应该使用try块 为了处理目录中的所有子目录，需要使用File.walk方法 可以通过调用File.walk（pathToRoot, depth）来限制想要访问的树的深度 两种walk方法都具有FileVisitOption…的可变长参数，但是你只能提供一种选项：FOLLOW_LINKS，即跟踪符号链接 如果要过滤walk返回的路径，并且你的过滤标准涉及与目录存储相关的文件属性，那么应该使用find方法来替代walk方法 可以用某个谓词函数来调用这个方法，该函数接受一个路径和一个BasicFileAttributes对象(效率高：因为路径总是会被读入，所以这些属性很容易获取) 无法很容易地使用Files.walk方法来删除目录树，因为你需要在删除父目录之前必须先删除子目录 2.5.7 使用目录流 对遍历过程进行更加细粒度的控制，应该使用File.newDirectoryStream对象，它会产生一个DirectoryStream 注意，它不是java.util.stream.Stream的子接口，而是专门用于目录遍历的接口 是Iterable的子接口，因此你可以在增强的for循环中使用目录流 如果想要访问某个目录的所有子孙成员，可以转而调用walkFileTree方法，并向其传递一个FileVisitor类型的对象 便捷类SimpleFileVisitor实现了FileVisitor接口，但是其除visitFileFailed方法之外的所有方法并不做任何处理而是直接继续访问，而visitFileFailed方法会抛出由失败导致的异常，并进而终止访问 2.5.8 ZIP文件系统 123456789101112131415// 如果zipname是某个ZIP文件的名字，建立一个文件系统，包含ZIP文档中的所有文件Files.copy(fs.getPath(sourceName),targetPath);// 知道文件名从ZIP文档中复制出文件FileSystem fs = FileSystem.newFileSystem(Paths.get(zipname),null);// fs.getPath对于任意文件系统来说，都与Paths.get类似// 列出ZIP文档中的所有文件，遍历文件树FileSystem fs = FileSystems.newFileSystem(Paths.get(zipname),null);Files.walkFileTree(fs.getPath(&quot;/&quot;),new SimpleFilevisitor&lt;Path&gt;()&#123; public FileVisitResult visitFile(Path file,BasicFileAttributes attrs)throws IOException&#123; System.out.println(file); return FilevisitResult.CONTINVE; &#125; &#125; Java8实战 Lambda表达式 行为参数化 一种软件开发模式，将代码块作为参数传递给另一个方法，稍后再去执行，方法的行为就基于那块代码被参数化了 Lambda表达式的三个部分:参数列表,箭头,Lambda主体 在函数式接口中使用Lambda接口 函数式接口就是只定义了一个抽象方法的接口,在该接口中可以拥有默认方法(即在类没有对方法进行实现时，其主体为方法提供默认实现的方法) Lambda表达式允许直接以内联的形式为函数式接口的抽象方法提供实现，并把整个表达式作为函数式接口的实例 @ FunctionalInterface 为函数式接口的标注, 抽象方法的签名称为函数描述符 常用的函数式接口: Predicate&lt;T&gt; boolean test(T t) Consumer&lt;T&gt; void accept(T t) Function&lt;T,R&gt; R apply(T t) Supplier&lt;T&gt; 引用类型(Byte,Integer,Object,List),与原始类型(int,double,byte,char)类型，但是泛型只能绑定到引用类型 Java中具有将原始类型转换为引用类型的机制(装箱),同时存在拆箱的机制 装箱后的值本质上就是把原始类型包裹起来，并保存在堆 若Lambda的主体是一个语句表达式， 它就和一个返回void的函数描述符兼容（当然需要参数列表也兼容） 使用局部变量 Lambda表达式允许使用自由变量(不是参数,而是在外层作用域定义的变量),被称为捕获Lambda 局部变量必须显式声明为final(Lambda表达式只能捕获派给它们的局部变量一次) 第一，实例变量和局部变量背后的实现有一个关键不同。实例变量都存储在堆中，而局部变量则保存在栈上。如果Lambda可以直接访问局部变量，而且Lambda是在一个线程中使用的，则使用Lambda的线程，可能会在分配该变量的线程将这个变量收回之后，去访问该变量。因此，Java在访问自由局部变量时，实际上是在访问它的副本，而不是访问原始变量。如果局部变量仅仅赋值一次那就没有什么区别了——因此就有了这个限制。 第二，这一限制不鼓励你使用改变外部变量的典型命令式编程模式（我们会在以后的各章中解释，这种模式会阻碍很容易做到的并行处理）。 Java8的Lambda和匿名类对值封闭，而不是对变量封闭(原因在局部变量保存在栈上，并且隐式表示他们仅限于其所在线程) 方法引用(Lambda的快捷写法) 方法引用的三类 指向静态方法的方法引用 指向任意类型实例方法的方法引用 指向现有对象的实例方法的方法引用 构造函数引用 可以利用名称和关键字new来创建引用 复合Lambda表达式 比较器复合: 1.逆序 2.比较器链 谓词复合: negate、and和or 函数复合: andThen 方法会返回一个函数，它先对输入应用一个给定函数，再对输出应用另一个函数；compose方法把给定的函数用作compose的参数里面给的那个函数，然后再把函数本身用于结果 流简介 流允许以声明性方式处理数据集合(通过查询语句来表达,而不是临时编写一个实现) 优势： 声明性:说明想要完成什么而不是说明如何实现一个操作 可复合 可并行 流: 从支持数据处理操作的源生成元素序列 元素序列——集合一样，流也提供了一个接口，可以访问特定元素类型的一组有序值，流的目的在于表达计算，集合为数据 源——流会使用一个提供数据的源，从有序集合生成流，从有序集合生成流时会保留原有的顺序 数据处理操作——流的数据处理功能支持类似于数据库的操作，以及函数式编程语言中的常用操作, filter：接受Lambda，从流中排除某些元素 map：接受Lambda，将元素转换成其他形式或提取信息 limit：截断流，使元素不超过其他给定数量 collect：将流转换成其他元素（toList()将流转换为列表） 流操作可以顺序执行，也可以并行执行 流与集合 集合是内存中的数据结构，包含数据结构中的所有值——集合中的每个元素都得先算出才能添加到集合中 流是在概念上固定得数据结构，元素是按需计算，流是延迟创建的集合(只有在消费者要求的时候才会计算值) 集合和流的关键区别之一：遍历数据的方式，集合利用迭代器来访问for-each循环中的内部成员 流只能遍历一次 ==外部迭代和内部迭代 使用Collection接口需要用户去做迭代，被称为外部迭代，(for-each循环,Iterator迭代器—外部迭代) Streams库使用内部迭代——流将迭代做了，将得到的流值存在某个地方 流操作 中间操作：可以连接起来的流操作，中间操作会返回另一个流，可以使多个操作连接 终端操作：关闭流的操作，产生结果 流的使用 一个数据源：如集合，来执行一个查询 一个中间操作链：形成一条流的流水线 filter——操作类型Predicate&lt;T&gt;——函数描述符T-&gt;boolean map——操作类型Function&lt;T,R&gt;——函数描述符T-&gt;R limit sorted——操作类型Comparator&lt;T&gt;——函数描述符(T, T)-&gt;R distinct 一个终端操作：执行流水线，并能生成结果 forEach——消费流中的每个元素并对其应用Lambda。这一操作返回void count——返回流中元素的个数。这一操作返回long collection——把流归约成一个集合 使用流 筛选和切片 用谓词筛选：filter方法，接受一个谓词(一个返回boolean的函数)作为参数，并返回一个包括所有符合谓词的元素的流 筛选各异的元素：distinct方法，返回一个元素各异(根据流所产生元素的hashCode和equals方法实现)的流 截短流：limit(n)方法，该方法会返回一个不超过给定长度的流 跳过元素：skip(n)方法，返回一个扔掉了前n个元素的流。若流中元素不足n个，则返回一个空流 映射 对流中每一个元素应用函数：map方法，接受一个函数作为参数。函数应用到每个元素上将其映射成新的元素 流的扁平化：获得单词列表总各不相同的字符 使用map()与distinct()方法返回的为Stream&lt;String[]&gt;类型，而需要的为Stream&lt;String&gt;类型 使用map与Arrays .stream()(该方法可以接受一个数组并产生一个流) words.stream().map(w-&gt;w.split(“”)).map(Arrays::stream).distinct().collect(Collectors.toList()) 返回Stream&lt;String&gt;的列表 使用flatMap解决： words.stream().map(w-&gt;w.split(“”)).flatmap(Arrays::stream).distinct().collect(Collectors.toList()) 返回List&lt;String&gt; flatmap方法把流中的每一个值都转换成另一个值，然后把所有的流连接起来成为一个流，创建扁平流 查找和匹配 检查谓词是否至少匹配一个元素 anyMatch方法——流中是否有一个元素能匹配给定谓词 检查谓词是否匹配所有元素 allMatch方法——流中是否都能匹配给定谓词 noneMatch方法——流中没有任何元素与给定谓词匹配 findAny方法——将返回当前流中的任意元素 Optional&lt;T&gt;类使一个容器类，代表一个值存在或不存在 isPresent方法——将在Optional包含值得时候返回true ifPresent(Consumer&lt;T&gt; block)方法——在值存在时执行给定的代码块 T get()方法——在值存在时返回值 T orElse(T other)方法——会在值存在时返回值，否则返回一个默认值 查找第一个元素——findFirst方法 归约 归约操作(折叠) ：将流中的元素组合起来，使用reduce操作来表达复杂的查询 元素求和： 使用reduce方法 reduce方法接受两个参数，一个参数为初始值，另一个参数为BinaryOperator&lt;T&gt;为Lambda表达式 Integer中具有sum方法可以使用进行求和 不接受初始值，返回Optional对象 最大值和最小值 使用归约可以计算最大值和最小值 Integer中的max方法可以计算最大值，min方法计算最小值 可以使用并行处理，将strean()换成parallelStream()即可实现 流操作: 无状态和有状态： 无状态操作：没有内部状态，假设用户提供的Lambda或方法引用没有内部可变状态 如map或filter等操作会从输入流中获得每一个元素，并且在输出流中得到0或者1个结果 有状态操作 数值流 原始类型流特化，专门支持数值流的方法 原始类型流特化 三个原始类型特化流接口：IntStream , DoubleStream , LongStream 分别将流中的元素特化为int , long 和long类型 避免了暗含的装箱操作成本 映射到数值流：maoToInt mapToDouble mapToLong 转换回对象流：boxed()方法——可以将原始流转换为一般流(每个元素会自动装箱成为一个引用类型) 默认值OptionalInt：存在Optional原始类型特化版本 OptionalInt OptionalDouble OptionalLong 可以使用orElse方法，在不存在时设置一个默认值 数值范围 range()方法不包含结束值，rangeClosed()方法包含结束值 构建流 由值创建流：可以使用静态Steam.of方法显式创建一个流，使用Steam.empty()方法创建一个空流 由数组创建流：可以使用静态Arrays.steam方法从数组创建一个流 由文件创建流： java.nio.file.Files中的很多静态方法都支持返回一个流 Files.lines返回一个由指定文件中各行构成的字符串流 由函数生成流 无限流：不像从固定集合创建的流那样有固定大小的流 Stream.iterate和Stream.generate方法可以生成无限流 generate接受一个Supplier&lt;T&gt;类型的Lambda提供新的值 使用iterate的方法则是纯粹不变的：它没有修改现有状态，但在每次迭代时会创建新的元组。而generate方法会使Supplier实例的状态产生变化 用流收集数据 收集器简介 收集器用作高级归纳——Collector会对元素应用一个转换函数，并且将结果累计在一个数据结构中，从而产生这一过程的最终输出 收集器的功能：将流元素归约和汇总为一个值，元素分组，元素分区 归约和汇总 查找流中的最大值和最小值 两个收集器：Collectors.maxBy和Collectors.minBy来计算流中的最大值或最小值 接收器接收一个Comparator参数来比较流中的元素 汇总 汇总的工厂方法：Collectors.summingInt 接受一个把对象映射为求和所需int的函数，并返回一个收集器，该收集器在传递给普通的collect方法后执行汇总操作 Collectors.summingLong Collectors.summingDouble ——求和 averagingLong averagingDouble 计算平均值 summarizingInt summarizingLong summarizingLong方法 返回的收集器——可以得到元素个数，总和，平均值，最大值和最小值——返回IntSummaryStatistics类,LongSummaryStatistics类,DoubleSummaryStatistics类 连接字符串 joining工厂方法——对流中每一个对象引用toString方法得到的所有字符串连接成一个字符串 重载版本可以设置元素之间的分界符 若类具有toString方法，则无需重新提取字符串 joining在内部使用了StringBuilder来把生成的字符串逐个追加起来 广义的归约汇总 Collectors.reducing方法使所有特殊情况的一般化 三个参数 第一个参数使归约操作的起始值，也是流中没有元素的返回值 第二个参数 第三个参数使BinaryOperator，将两个项目累积成一个同类型的值 单参数形式 三个参数形式的特殊情况 分组 Collectors.groupingBy工厂方法可以实现分类操作，其参数为一个分类函数，分组的结果保存在一个Map中 多级分类： 双参数版本的Collectors.groupingBy可以实现多级分类 其传入参数除了普通的分类函数之外，还可以接受Collectors类型的第二个参数，利用内层groupingBy传递给外层groupingBy，其类型为二级标准 按子组收集数据： Collectors.groupingBy的第二个参数可以使任意类型，如可以传递counting收集器作为参数统计数量 单参数的groupingBy(f)实际上使groupingBy(f,toList())的简便写法 将收集器的结果转换为另一种类型： Collectors.collectingAndThen工厂方法第一个参数为要转换的收集器，第二个参数为转换函数 Collectors.mapping——该方法接受两个参数，一个函数对流中的元素进行转换，另一个将变换的结果收集起来 分区 分组的特殊情况：由一个谓词作为分类函数，称为分区函数，分区函数返回一个布尔值，得到的Map的键为Boolean类型 分区函数 partitioningBy——其传递的函数为分区函数 分区的好处：保留了分区函数返回true或False的两套流元素列表 partitioningBy——重载版本，第一个参数为分区函数，第二个参数为收集器 partitioningBy收集器也允许结合其他收集器使用，可以实现多级分区 收集器接口 Collector接口：T是流中要收集的项目的泛型，A是累加器的类型(累加器是在收集过程中用于累计部分结果的对象)，R是收集操作得到的对象的类型 建立新的结果容器：supplier方法 将元素添加到结果容器：accumulator方法 对结果容器应用最终转换：finisher方法 合并两个结果容器：combiner方法 characteristics方法——返回一个不可变的Characteristics集合，它定义了收集器的行为——尤其是关于流是否可以并行归约，以及可以使用哪些优化的提示，为三个项目的枚举 UNORDERED——归约结果不受流中项目的遍历和累积顺序的影响 CONCURRENT——accumulator函数可以从多个线程同时调用，且该收集器可以并行归约流。如果收集器没有标为UNORDERED，那它仅在用于无序数据源时才可以并行归约 IDENTITY_FINISH——这表明完成器方法返回的函数是一个恒等函数，可以跳过。这种情况下，累加器对象将会直接用作归约过程的最终结果。这也意味着，将累加器A不加检查地转换为结果R是安全的 调用自定义实现Collector接口的类时，需要使用new方法进行实例化(toList是工厂方法，故不需要new进行实例化) 可直接在重载的collect()方法中接受三个函数supplier,accumlator和combiner函数，实现上述操作 第二个collect方法不能传递任何Characteristics，所以它永远都是一个IDENTITY_FINISH和CONCURRENT但并非UNORDERED的收集器 1234567public interface Collector&lt;T,A R&gt;&#123; Supplier&lt;A&gt;supplier(); BiConsumer&lt;A T&gt;accumulator(); Function&lt;A R&gt;finisher(); BinaryOperator&lt;A&gt;combiner(); Set &lt;Characteristics&gt;characteristics();&#125; 并行数据处理与性能 并行流 parallelStream 方法 ——将集合转换为并行流 并行流将内容分成多个数据块，并用不同的线程分别处理每个数据块的流 将顺序流转换为并行流 对顺序流调用parallel方法转换为并行流——函数的归约过程并行运行 对并行流调用sequential方法转换为顺序流 iterate产生的是装箱的对象，必须拆箱成数字才能求和 高效使用并行流 留意装箱 留意数据结构是否易于分解 ArrayList IntStream等 可分解性极佳 &gt; HashSet TreeSet 分解性较好 &gt; LinkedList 原生Stream 分支合并框架(Fork/Join框架) 以递归方式将可并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成整体结果，把子任务分配给- ForkJoinPool(线程池)中的工作线程 1234567891011121314151617// R是并行化任务产生的结果类型// 其唯一抽象方法为compute方法RecursiveTask&lt;R&gt;//伪代码compute()&#123; if(任务足够小或不可分)&#123; 顶序计算该任务 &#125;else&#123; 将任务分成两个子任务 递归调用本方法，拆分每个子任务，等待所有子任务完成 合并每个子任务的结果 &#125; &#125;// 任务不产生返回结果RecursiveAction 使用分支/合并框架的最佳做法 对一个任务调用join方法会阻塞调用方，直到该任务做出结果**(有必要在两个子任务的计算都开始之后再调用它。否则，你得到的版本会比原始的顺序算法更慢更复杂，因为每个子任务都必须等待另一个子任务完成才能启动)**； 不应该在RecursiveTask内部使用ForkJoinPool的invoke方法。相反，你应该始终直接调用compute或fork方法，只有顺序代码才应该用invoke来启动并行计算； 对子任务调用fork方法可以把它排进ForkJoinPool。同时对左边和右边的子任务调用它似乎很自然，但这样做的效率要比直接对其中一个调用compute低。这样做你可以为其中一个子任务重用同一线程，从而避免在线程池中多分配一个任务造成的开销； 和并行流一样，你不应理所当然地认为在多核处理器上使用分支/合并框架就比顺序计算快。我们已经说过，一个任务可以分解成多个独立的子任务，才能让性能在并行化时有所提升 Spliterator Java8中引入的一个新接口，为可分迭代器，用于遍历数据源中的元素，但其为了并行执行、 tryAdvance方法的行为类似于普通的Iterator，按顺序一个一个使用Spliterator中的元素，并且如果还有其他元素要遍历就返回true trySplit是专为Spliterator接口设计的，可以把一些元素划出去分给第二个Spliterator（由该方法返回），两个并行处理 Spliterator还可通过estimateSize方法估计还剩下多少元素要遍历，因为即使不那么确切，能快速算出来是一个值也有助于让拆分均匀一点 Spliterator接口声明的最后一个抽象方法是characteristics，它将返回一个int，代表Spliterator本身特性集的编码 拆分过程：递归过程拆分直至调用trySplit方法返回null，受Spliterator本身特性影响，该特性通过characteristics方法声明 12345public interface Spliterator&lt;T&gt;&#123; boolean tryAdvance(Consumer&lt;?super T&gt;action); Spliterator&lt;T&gt;trySplit(); long estimateSize(); int charactenstics(); 默认方法 Java8允许在接口内声明静态方法，同时引入了默认方法，通过默认方法可以指定接口方法的默认实现 Java的类只能继承单一的类，但一个类可以实现多接口 可以使用代理有效地规避代码复用的复杂性，即创建一个方法通过该类的成员变量直接调用该类的方法 为什么有的时候我们发现有些类被刻意地声明为final类型： 声明为final的类不能被其他的类继承，避免发生这样的反模式，防止核心代码的功能被污染 解决默认方法签名相同时产生的冲突问题(一个类使用相同的函数签名从多个地方（比如另一个类或接口）继承了方法)： 类中的方法优先级最高。类或父类中声明的方法的优先级高于任何声明为默认方法的优先级 如果无法依据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体实现的默认方法的接口，即如果B继承了A，那么B就比A更加具体 最后，如果还是无法判断，继承了多个接口的类必须通过显式覆盖和调用期望的方法，显式地选择使用哪一个默认方法的实现 用Optional取代null 避免遇到NullPointerException异常 Optional&lt;T&gt; 变量存在时，Optional类只是对类简单封装; 变量不存在时，缺失的值会被建模成一个“空”的Optional对象，由方法Optional.empty()返回 创建Optional对象 声明一个空的Optional：Optional.empty()静态方法——返回Optional类的特定单一实例 依据一个非空值创建Optional：Optional.of()静态方法——依据非空值创建一个Optional对象 可接受null的Optional：Optional.ofNullable()静态方法——创建一个允许null值得Optional对象 函数方法 map方法——使用map从Optional对象中提取和转换值；map操作会将提供的函数引用于流的每个元素，可以把Optional对象堪称一种特殊的集合数据（如果Optional包含一个值，那函数就将该值作为参数传递给map，对该值进行转换。如果Optional为空，就什么也不做） flatMap方法——将两层的Optional对象转换为单一Optional对象，使用flatMap链接Optional对象 get()——最简单但不安全，若变量存在返回封装的变量值，否则抛出NoSuchElementException异常 orElse(T other)——允许在Optional对象不包含值时提供一个默认值 orElseGet(Supplier&lt; ? extends T&gt; other)——Supplier方法只有在Optional对象不含值时才执行调用 orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)——遭遇Optional对象为空时都会抛出一个可定制的异常 ifPresent(Consumer&lt;? super T&gt;)——在变量值存在时执行一个作为参数传入的方法，否则就不进行任何操作 isPresent()——如果Optional对象包含值，该方法就返回true filter()——方法接受一个谓词作为参数；如果Optional对象的值存在，并且它符合谓词的条件，filter方法就返回其值；否则它就返回一个空的Optional对象 新的日期和时间API LocalDate LocalDate.of()——创建一个LocalDate实例 LocalDate.now()——从系统时钟中获取当前日期 get()——传递TemporalField参数获取某个字段的值(ChronoField枚举实现了TemporalField接口) parse()静态方法——格式化一个日期或者时间对象 LocalTime LocalTime.of()——创建LocalTIme实例 getHour getMinute getSecond parse()静态方法——格式化一个日期或者时间对象 LocalDateTime 是LocalDate和LocalTime的合体，同时表示了日期和时间，但不带有时区信息 of方法 atTime()方法——传递日期对象或者时间对象创建 toLocalDate或toLocalTime方法——提取LocalDate或LocalTime组件 Instant类 计算机角度的建模时间，表示一个持续时间段上某个点的单一大整型数 ofEpochSecond()——传递一个代表秒数的值创建该类的实例 重载版本，接受第二个以纳秒为单位的参数值，对传入作为秒数的参数进行调整 now()——获取当前时刻的时间戳 Duration类和Period Duration类静态方法between——传递两个LocalTimes对象，LocalDateTimes对象，Instant对象，获得两个对象之间的时间长短(秒和纳秒) Period类静态方法between——得到LocalDate之间的时长 使用TemporalAdjuster：with()——传递一个提供定制化选择的TemporalAdjuster对象，更加灵活的处理日期 打印输出及解析日期-时间对象： DateTimeFormatter类：创建格式器最简单的方法是通过静态方法和常量，BASIC_ISO_DATE和ISO_LOCAL_DATE- 为DateTimeFormatter类的预定义实例 parse()静态方法——使用同样的格式器解析字符串并重建该日期对象 ofPattern()方法——创建某了Local的格式器 DateTimeFormatterBuilder类提供更加复杂的格式器","categories":[{"name":"Java","slug":"Java","permalink":"http://jay1060950003.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://jay1060950003.github.io/tags/Java/"}]},{"title":"MSVC使用方法","slug":"小工具记录/MSVC配置","date":"2021-11-30T16:00:00.000Z","updated":"2023-04-09T13:34:40.982Z","comments":true,"path":"2021/12/01/小工具记录/MSVC配置/","link":"","permalink":"http://jay1060950003.github.io/2021/12/01/%E5%B0%8F%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/MSVC%E9%85%8D%E7%BD%AE/","excerpt":"引言 Windows环境下MSVC的在vscode中配置方法","text":"引言 Windows环境下MSVC的在vscode中配置方法 1 MSVC的VsCode配置 向windows添加环境变量 1234567891011121314# 新建INCLUDE关键字C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.19041.0\\umC:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.19041.0\\ucrtC:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.19041.0\\sharedC:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.19041.0\\winrtC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\include# 新建LIB关键字C:\\Program Files (x86)\\Windows Kits\\10\\Lib\\10.0.19041.0\\um\\x64C:\\Program Files (x86)\\Windows Kits\\10\\Lib\\10.0.19041.0\\ucrt\\x64C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\lib\\x64# 向Path中添加环境变量C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\Hostx64\\x64 1.1 使用MSVC的cl.exe进行构建 编写task.json 12345678910111213141516171819202122232425262728&#123; &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ &#123; &quot;type&quot;: &quot;cppbuild&quot;, &quot;label&quot;: &quot;MSVC build&quot;, &quot;command&quot;: &quot;cl.exe&quot;, &quot;args&quot;: [ &quot;/Zi&quot;, &quot;/EHsc&quot;, &quot;/nologo&quot;, &quot;/Fe$&#123;fileDirname&#125;\\\\$&#123;fileBasenameNoExtension&#125;.exe&quot;, &quot;$&#123;file&#125;&quot; ], &quot;options&quot;: &#123; &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot; &#125;, &quot;problemMatcher&quot;: [ &quot;$msCompile&quot; ], &quot;group&quot;: &#123; &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true &#125;, &quot;detail&quot;: &quot;MSVC Build&quot; &#125; ]&#125; 编写launch.json 12345678910111213141516171819202122&#123; // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;MSVC Debug&quot;, &quot;type&quot;: &quot;cppvsdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;fileDirname&#125;\\\\$&#123;fileBasenameNoExtension&#125;.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: true, &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;, &quot;environment&quot;: [], &quot;console&quot;: &quot;externalTerminal&quot;, &quot;externalConsole&quot;: false, &quot;preLaunchTask&quot;: &quot;MSVC build&quot; &#125; ]&#125; 1.2 使用MSVC的cl.exe进行构建 CMake生成的文件在build/bin文件夹内 编写task.json 123456789101112131415161718&#123; &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ &#123; &quot;name&quot;: &quot;MSVC Launch&quot;, &quot;type&quot;: &quot;cppvsdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;fileDirname&#125;\\\\$&#123;fileBasenameNoExtension&#125;.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: true, &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;, &quot;environment&quot;: [], &quot;console&quot;: &quot;externalTerminal&quot;, &quot;externalConsole&quot;: false, &quot;preLaunchTask&quot;: &quot;C/C++: MSVC build&quot; &#125; ]&#125; 编写launch.json 1234567891011121314151617181920&#123; // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;CMake Launch&quot;, &quot;type&quot;: &quot;cppvsdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;/build/bin/Debug/$&#123;fileBasenameNoExtension&#125;.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: true, &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;, &quot;environment&quot;: [], &quot;console&quot;: &quot;externalTerminal&quot;, &quot;externalConsole&quot;: false, &#125; ]&#125;","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"Hexo","slug":"小工具记录/Hexo","date":"2021-11-29T16:00:00.000Z","updated":"2023-05-06T16:12:53.804Z","comments":true,"path":"2021/11/30/小工具记录/Hexo/","link":"","permalink":"http://jay1060950003.github.io/2021/11/30/%E5%B0%8F%E5%B7%A5%E5%85%B7%E8%AE%B0%E5%BD%95/Hexo/","excerpt":"引言 Hexo个人博客搭建过程笔记","text":"引言 Hexo个人博客搭建过程笔记 1 安装Nodejs 12345678node -v npm -v npm install -g cnpm --registry=http://registry.npm.taobao.org cnpm -v cnpm install -g hexo-cli hexo -v mkdir blogcd blog 2 博客创建 123456hexo inithexo shexo clean #清理 hexo g#Github创建一个新的仓库 YourGithubName.github.io cnpm install --save hexo-deployer-git #在blog目录下安装git部署插件 3 配置 _config.yml 1234deploy: type: git repo: https://github.com/YourGithubName/YourGithubName.github.io.git branch: master 4 部署 1hexo d 5 后续操作 123hexo c #清理一下 hexo g #生成 hexo d #部署到远程Github仓库 6 替换渲染引擎 1234cd hexo-blog.github.io/ # 首先进入你的 hexo 的根目录npm un hexo-renderer-marked --save # 卸载 hexo 默认的 markdown 渲染引擎npm i hexo-renderer-markdown-it --save # 安装 markdown-itnpm i hexo-renderer-markdown-it-plus --save # 安装 markdown-it-plus 7 修复图片无法显示 1npm install &lt;https://github.com/CodeFalling/hexo-asset-image&gt; --save 8 搜索 1npm i -S hexo-generator-json-content 9 公式 1npm install hexo-math --save 10 升级Hexo 1234567891011121314151617181920212223242526# 使用淘宝源的 cnpm 替换 npmnpm install -g cnpm --registry=https://registry.npm.taobao.org# 升级 npmcnpm install -g cnpm# 清除 npm 缓存cnpm cache clean -f# 更新 hexo: 进入 blog 目录，执行如下命令 # 更新 package.json 中的 hexo 及个插件版本# 检查之前安装的插件，都有哪些是可以升级的 cnpm install -g npm-check# 升级系统中的插件cnpm install -g npm-upgradenpm-checknpm-upgrade# 更新 hexo 及所有插件cnpm update# 确认 hexo 已经更新hexo -v 11 删除历史提交版本 1234567891011121314151617# 创建并切换到lastest_branch分支git checkout --orphan latest_branch# 添加所有文件git add -A# 提交更改git commit -am &quot;delete history and init&quot;# 删除分支git branch -D master# 将当前分支重命名git branch -m master# 强制更新存储库git push -f origin master 其他 12npm i hexo-helper-qrcodenpm i --save hexo-wordcount","categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"}]},{"title":"C++新经典","slug":"计算机基础知识/C++新经典","date":"2021-11-20T07:32:35.000Z","updated":"2023-04-09T13:39:08.561Z","comments":true,"path":"2021/11/20/计算机基础知识/C++新经典/","link":"","permalink":"http://jay1060950003.github.io/2021/11/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/C++%E6%96%B0%E7%BB%8F%E5%85%B8/","excerpt":"引言 王建伟老师的《C++新经典》的学习笔记","text":"引言 王建伟老师的《C++新经典》的学习笔记 2 数据类型、运算符与表达式 2.1 常量、变量、整型、实型和字符串 项目要先 编译、链接、生成可执行程序 ，然后才能运行。 2.1.2 C语言的数据类型 其中包括： 基础类型：数值类型（整型、浮点型）、字符类型 构造类型：数组、结构体(struct)、共用体(union)、枚举类型(enum) 指针类型 void空类型 其中在64位系统中，int、float类型为4字节，double、long、long long类型为8字节，一个字节为8位二进制数 2.1.3 常量和变量 变量定义： 类型名 变量名[ = 变量初始值] 使用[]包括的内容可以省略 变量必须先定义才可以使用 变量命名方法：推荐第一个字符表示类型，用几个单词的组合表示含义，每个单词的第一个字符大写 2.1.4 整型数据 八进制数：以0开头的数字 十六进制：以0x开头的数字 整型变量主要包括基本型int类型、长整型long int（简写为long）类型、无符号类型（unsigned），可以使用sizeof（）函数获取变量所占字节数。 常量的类型的特殊写法 常数后加U或u，表示无符号整型类型存储，相当于unsigned int 常数后加L或l，表示长整型存储，相当于long 常数后加F或f，表示以浮点存储，相当于float 2.1.5 实型数据 实型数据是指实数，也称为浮点数，浮点数在内存中都是以指数形式存储。 如何区分float和double两种浮点数？ 精度不同，float在内存中一般占4字节，而double在内存中一般占8字节，float提供7位有效数字，而double提供15-16位有效数字。 给浮点数赋值0.51，但显示为0.509999990的原因？ Ans：计算机中，会把十进制数转换为二进制数保存，在查看时在转换为十进制数显示，在这中间存在着一些出发操作，会导致在二进制转换为十进制的过程中丢失精度 2.1.6 字符型数据 推荐单引号内只能放一个字符的规定 ^3eb832 字符变量 将一个字符常量放在字符变量中，实际上是以字符对应的ASCII码存储在内存中 ACSII码，空格字符对应32、数字0对应48、A对应65、a对应97 2.1.7 字符串变量 跳转至该位置 规定，单引号包含单个字符串。 字符串变量为双引号包含一串字符 'a’与&quot;a&quot;的区别？ 'a’表示单个字符变量，在内存中只占一个字节，而&quot;a&quot;表示字符串变量，在内存中占两个字节 2.1.9 数值型数据之间的混合运算 不同类型的数值型数据进行混合运算时，系统会尝试进行变量类型统一，然后再进行计算。 转换规则： int转为unsigned转为long转为double，当类型不同时进行转换。 char和short转换为int，float转换为double，强制转换，在该类型进行运算时，必须转为int或double类型，再进行计算 2.2 算数运算符和表达式 2.2.1 C语言的运算符 共13个大类，包括算数运算符、关系运算符、逻辑运算符、位运算符、赋值运算符、条件运算符、逗号运算符、指针运算符、求字节运算符、强制类型转换运算符、成员变量运算符、下标运算符、其他。 2.2.3 运算符优先级问题 单目运算符&gt;双目运算符&gt;三目运算符&gt;赋值运算符 单目运算符、条件运算符、赋值运算符为从右到左结合，其他的为从左到右结合。 2.2.4 强制类型转换运算符 12&gt;表达式一般形式&gt;(类型名) (表达式名) 2.2.5 自增和自减运算符 1234++i; 先加一再使用i++; 先使用再加一--i; 先减一再使用i--; 先使用再减一 -i++ 表示-(i++);i+j表示(i) +j 2.3 赋值运算符 赋值的原则:赋值符号的左右两边的数据类型应该相同,类型不同时可以使用强制转换符进行转换. **逗号运算符的求解规则:先求解表达式1,再求解表达式2. 3 程序的基本结构和语句 3.1 C语言的语句和程序的基本结构 12continue 结束本次循环,开始下次循环是否执行的判断break 终止循环的执行或者跳出switch语句 3.1.2 程序的三种基本结构 顺序结构 选择结构 循环结构 当型循环:先判断再执行 直到型循环:先执行再判断 3.2 数据的输出与输入 当使用尖括号&lt;&gt;包括头文件时,表示在系统目录中寻找头文件 当使用双引号&quot;&quot;包括头文件时,表示在源代码所在目录中搜索头文件,再到系统目录中搜索头文件 123456789printf()函数printf(格式控制字符串,输出表列)%d:表示以十进制输出数字%o:表示以八进制输出数字%x:表示以十六进制输出数字%u:以十进制输出无符号数字%c:表示输出一个字符%s:表示输出一个字符串.**字符串末尾有一个系统自动加入的’\\0&#x27;作为字符串结束标记,但输出显示不显示该字符**.%f:输出一个小数.==%x.yf表示以x宽度输出y位小数的数字== 百分号的输出方法: 使用两个百分号输出 使用%c输出‘%’ 使用%s输出“%” 3.2.2 数据的输入 在程序中,最好只使用一个getchar()输入,避免结束输入时,第二个getchar()函数读取回车符号,影响程序的正常预期. scanf(格式控制字符串,地址表列); 第二个参数为地址表列,使用的是地址,不要忘记 &amp; 符号对变量取地址 要注意输入与格式控制字符串形式相同 4 逻辑运算和判断选择 跳转至该位置 优先级顺序:算术运算符&gt;关系运算符&gt;赋值运算符 逻辑运算符: &amp;&amp; 与运算符:同真为真,有假出假 || 或运算符:有真出真,同假为假 ! 非运算符:反转 if()语句: if(判断表达式)语句; if(判断表达式)语句1; else 语句2; if(判断表达式1) 语句1; else if(判断表达式2) 语句2;······ switch()语句: 注意break语句为跳出switch()结构终止该结构的运行,注意其使用的技巧 5 循环控制 5.1 goto语句 goto语句需要搭配==语句标号:==语句一起使用,goto 语句标号;为使用方式. 主要用途: 与if语句一起使用构成循环 从循环体内跳转到循环体外(不建议使用) goto语句不能跨函数使用 5.2 while(表达式) 要执行的语句 5.3 do 要执行的语句 while(表达式) 5.4 for语句 for(表达式1(初始值);表达式2(结束条件);表达式3(变化量)) 内嵌的语句; 表达式1省略,循环外需要初始化变量 表达式2省略,需要使用break语句终止循环 表达式3省略,需要在循环内改变循环量 三个表达式都可以省略,但都需要对应的操作 三个表达式都省略,且不加对应的操作,for(;😉{}相当于while(1){} 表达式1可以设置其他变量初始化 表达式3执行很多次,但表达式1只执行1次 break语句和continue语句的区别? continue只结束本次循环,而不是结束整个循环,而break是结束整个循环 6 数组 6.1 一维数组 12345定义:类型说明 数组名\\[常量表达式\\]引用:数组名\\[下标\\] 6.2 二维数组 在C语言中,二维数组的元素存放顺序为:按行存放 多维数组在内存中排列顺序:第一维下标变化最慢,最右边维度变化最快 6.3 字符数组 6.3.3 字符串和字符串结束标记 C语言中规定了一个字符串结束标记,用’\\0’代表,如果一个字符串的第十个字符为‘\\0’,则该字符串的长度为9个,即遇到‘\\0’表示字符串结束,该字符前面的字符构成字符串.可见10个可见字符的字符串,其可见字符若每个占用一个字节,则整个字符串在内存中占用11个字节 注意:设置字符串变量的时候需要考虑–字符串结束标记–,则需要可见字符串长度加一设置大小 对于双引号包含的字符串,系统会自动往末尾添加一个’\\0’,若人工添加也是可以的,若没有字符串结束标记也是可以的 6.3.5 字符串处理函数 strcat(字符数组1,字符数组2); 把字符数组2连接到字符数组1的后面,存放在字符数组1中. 说明: 字符数组必须足够大,能够容纳连接后的新字符串. 连接前两个字符数组都包括字符结束标记,但连接时会自动删除字符数组1的字符结束标记 连接后字符数组2没有变化 strcpy(字符数组1,字符数组2); 把字符数组2复制到字符数组1中. 不能使用赋值语句对字符数组直接赋值,只能对单个字符进行赋值 strcmp(字符数组1,字符数组2); 字符串比较,若字符数组1&gt;字符数组2,使用的是ASCII码进行比较,返回一个正整数,相等返回0. strlen(字符数组); 返回字符串的长度,不包括字符结束标记. 7 函数 7.1 函数的基本概念和定义 7.1.2 函数的定义和返回值 如果函数的实参和形参为数组名(数组名代表的是数组的首地址),则传递的是数组的首地址. 7.2 函数调用的一般形式 函数声明的一般形式: 返回类型 函数名(形参列表); ==函数定义和函数声明的区别? 函数定义里面包含函数体,函数体中的代码确定了函数需要执行的功能,而函数声明,只是对一定义的函数进行说明,不包括函数体.函数声明可以提前指明该函数的参数类型、返回值类型等,让函数的调用者明确的知道这些信息.== C语言不允许嵌套定义函数,但可以嵌套调用函数 函数的递归调用:执行递归函数将反复调用其自身,每调用一次就进入新的一层,递归函数必须有结束条件 7.2.3 递归调用的出口 利用递归调用计算阶乘例程: 12345678910111213int dg_jiecheng(int n)&#123; int result; if(n = 1) &#123; result = 1; &#125; else &#123; result = dg_jiecheng(n-1)*n; &#125; return result;&#125; 7.3.3 递归调用的优缺点以及是否必须用递归 优点:代码简洁 缺点: 理解起来困难 若调用层次太深,调用栈可能会溢出 效率和性能不高 汉诺塔问题: 大梵天创造世界时造了三根金钢石柱子，其中一根柱子自底向上叠着64片黄金圆盘。大梵天命令婆罗门把圆盘从下面开始按大小顺序重新摆放在另一根柱子上。并且规定，在小圆盘上不能放大圆盘，在三根柱子之间一次只能移动一个圆盘。 解决方法: 使用递归调用方法.(将前n-1个盘子看成一个整体,递归调用函数,不断对可调动的盘子调动) TODO: 使用其他方法(之后详解). 7.4 数组作为函数参数 7.4.2 数组名作为函数实参 将数组名作为函数实参进行传递时,传递的是数组的首地址,此时函数中的形参也应该使用数组名(或者数组指针) 称为地址传递,形参数组中的各个元素的值如果发生变化,等价于数组中的元素的值发生了相应的改变 实参为数组名,形参也应该为数组名 实参数组与形参数组类型必须一致 形参数组的大小可以不指定,即使指定也可以与实参数组大小不一致 7.4.3 用多维数组作为函数实参 形参数组在定义时,可以省略第一维的大小,但不可以省略第二维的大小.实参是多少行多少列,形参应该尽量和实参大小一致. 7.5 局部变量和全局变量 7.5.1 局部变量 形参也是局部变量 不同函数内部可以使用相同的变量名,之间互不干扰 复合语句(用括号{}包括的语句),其中定义的参数为局部变量,生命周期只在定义的范围内生效 7.5.2 全局变量 如果某个函数想引用在它后面定义的全局变量,可以使用extern做外部变量说明.在进行外部变量说明时,不可以进行赋值操作. 严格区分外部变量和全局变量说明: 全局变量定义只能有一次,位于所有函数之外,定义时即分配内存. 外部变量,可以在一个文件中可以声明很多次. 同一个源文件中,局部变量和全局变量同名,则在局部变量的作用范围内,全局变量不生效. 如果在一个源程序文件中定义的全局变量想在项目其他源文件中使用,则需要在其他需要使用的源文件中添加extern关键字做外部变量声明即可使用. 7.6 变量的存储和引用与内部和外部函数 程序在内存中的存储空间分为程序代码区、静态存储区、动态存储区 全局变量存储在静态存储区 函数形参、局部变量、函数调用时的现场数据和返回地址存储在动态存储区 7.6.2 局部变量的存储方式 局部变量声明为局部静态变量时,需要添加static关键字,则在函数调用结束后,该局部变量不会被释放. 在静态存储区中分配内存,程序在整个运行期间不会释放 局部静态变量在编译时赋初值,且只赋一次初值.之后调用函数时,不再进行赋初值操作,只是保留上一次运行结束的值 定义局部静态变量时,如果不赋初值,则==编译时,自动赋初值为0. 虽然局部静态变量在函数调用结束后依然存在,但在其他函数中不能引用 局部静态变量长期占用内存 如非必要,不要过多使用局部静态变量 7.6.3 全局变量跨文件使用 跳转至该位置 跨文件使用的全局变量extern用法,一般放在程序的开头部分 若需要全局变量,只能在本文件中使用,则需要在该全局变量声明时,添加==static ==关键字声明为静态全局变量 7.6.4 函数跨文件使用 内部函数定义:只能在本文件中使用(需要添加static关键字) static 返回类型 函数名 (形参列表){…} 7.6.5 static关键字用法总结 局部变量 跳转至该位置 全局变量,只在本文件中使用 跳转至该位置 内部函数 跳转至该位置 8 编译预处理 C语言提供的三种预处理操作: 宏定义 文件包含 条件编译 8.1 宏定义 宏名一般使用大写字母表示 #define的有效范围到程序文件结束的部分,不可跨文件使用 可以使用\\undef结束宏定义的作用域 8.1.2 带参数的宏定义 一般形式: #define 宏名(参数表) 被替换的内容 作用:用右边的“被替换的内容”代替“宏名(参数表)” 对一般形式中提到的“被替换的内容”,要从左到右处理 如果“被替换的内容”中有“宏名”后列出的形参,则程序代码中相应的实参代替形参. 如果“被替换的内容”的项并不是“宏名”后列出的形参,则保留. 一般在形参外面加一个括号 宏定义时,宏名和带参数的括号之间不能加空格 函数调用是先求实参表达式的值,然后传递给形参;带参数的宏只进行简单的替换,展开时不求值 宏展开只占用编译时间,不占用运行时间;函数调用占用运行时间,不占用编译时间. 8.2 文件包含和条件编译 8.2.1 文件包含 常把一些宏定义,函数说明,甚至一些公共的#include命令、外部变量说明(extern)等,都可以写到一个.h文件中,然后在源程序中#include这个头文件即可 #include头文件允许文件嵌套使用 8.2.2 条件编译 #ifdef 标示符 程序段1 #else 程序段2 #endif 或 #ifndef 标示符 程序段1 #else 程序段2 #endif 或 #if 表达式 程序段1 #else 程序段2 #endif 或 #if 表达式1 程序段1 #elif 表达式2 程序段2 #else 程序段3 #endif 9 指针 在常见的X86、X64平台下,int类型占4字节,char占1字节,float占4字节,double占8字节 在x86平台下,整型指针变量占用4字节地址,而x64平台下,整型指针变量占用8字节地址 指针变量:用于存储另一个变量的地址 指针变量的值:为另一个变量的地址 指针就是一个地址,指针变量就是存储其他变量地址的量 9.2 变量的指针和指向变量的指针变量 定义指针变量: 类型标识符 * 标识符; 在定义指针变量时,指针变量前面具有*,表示正在定义一个指针变量,但在使用该指针变量时,指针前面的*是没有的 一个指针变量只能指向同一个类型的变量 引用指针变量: &amp; 取地址运算符 * 指针运算符(间接访问运算符) ==*p1++ 从右到左结合,等价于*(p1++) 要注意将指针作为函数参数传入函数后,操作指针可能会导致指针指向发生变化,但实际指向的变量并没有发生变化(例教材P139) 可以间接在函数中改变指针变量所指向的变量的值,从而实现在调用函数内改变外部变量的值 9.3 数组的指针和指向数组的指针变量 数组名等于数组首地址(数组第一个元素的地址),所以数组名a等效于&amp;a[0] 指向数组的指针变量,可以带下标,如p[i]与*(p +i)等效,等效于数组a的a[i]变量 *(p++)与*(++p)的区别? ++在变量p的后面,表示先用再加,在变量p的前面表示先加再用; 若p指向a[0],则*(p)表示先用后加,则使用时,p指向a[0],当使用结束后p指向a[1] 9.3.5 指向多维数组的指针和指针变量探究 二维数组: a 为二维数组名,数组首地址,第0行首地址 a + 1,表示第1行首地址 a[0],&amp;a[0][0],a,(a+0),&amp;a[0] 表示第0行首地址(第0行第0列元素地址) a[0]+1,&amp;a[0][1],*a+1 表示第0行第1列元素地址 (a[0] +1),a[0][1],(*a +1) 表示第0行第1列元素值 9.3.6 指针数组和数组指针 指针数组 int * p[10] 表示数组,但是数组的元素都是指针. 数组指针 int *p; 数组指针是指向数组地址的指针，其本质为指针； 指针变量,名称为p,表示这个指针变量用来指向含有10个元素的一维数组 指向一维数组的指针变量 设一维数组为a[n], 定义方法：*指针变量名 (即*P) 指向二维数组的指针变量 设二维数组为a[m][n], 定义方法：*指针变量名 (即（*P）[n]) “长度”表示二维数组分解为多个一维数组时，一维数组的长度，也就是二维数组的列数。 1234567891011121314151617181920212223242526//数组指针:int a[3][4]=&#123;1,2,3,4,5,6, 7,8,9,10,11,12&#125;;int (*p) [4];p= (int(*) [4])a;for(int i=0;i&lt;3;i++)&#123; for(int j=0;j&lt;4;j++) printf(&quot;&amp;d&quot;,p[i][j]); //或者*(* (p+i) +j)或者* (p[li]+j) printf (&quot;\\n&quot;) ;&#125;//指针数组:int ix=0;int i=0,j=0;int a[3][4]=&#123;1,2,3,4,5,6, 7,8,9,10,11,12);int *p[3] ;for (ix;ix&lt;3;ix++) p[ix]-a[ix];for (i;i&lt;3;i++)&#123; for (j=0;j&lt;4;j++)//注意这里的j要赋值等于0，要不然只能输出第一-行1234, 达不到预期的效果 &#123; printf (&quot;8d&quot;,p[i][j]); //或者 * (* (p+i) +j)或者* (p[i]+j) &#125; printf(&quot;\\n&quot;) ;&#125; 9.3.7 多维数组的指针作为函数参数 一维数组的地址可以作为函数参数传递,多维数组的地址也可以作为函数参数传递 C语言中,对于字符串常量会在内存中开辟一块专门的地址用来存放字符串常量,这段内存是只读的,不可以进行修改 9.5 函数指针和返回指针值的函数 指针变量指向函数,从而可以通过指针来调用所指向的函数 定义: 数据类型标识符 ( * 指针变量名) (形参列表); 指针变量名 = 函数名; //进行赋值,将函数的地址赋值给指针 int *p(int x, int y); 表示这个函数的返回值是指向整型变量的指针,表示定义返回整型指针的函数 int (* p)(int x, int y); 表示p指针指向函数,表示函数指针 9.5.2 把指向函数的指针变量作为函数参数 指向函数的指针变量可以作为参数,从而实现函数地址的传递,也就是将函数地址传递给形参. 用函数指针变量作为形参和实参可以方便的实现调用函数的切换,增强程序的灵活性和扩展性. 9.5.3 返回指针值的函数 一般定义形式: 数据类型 * 函数名(参数列表){…} 在构造子函数时,需要注意局部变量的生命周期,避免因为局部变量被系统回收而造成程序崩溃(特别需要注意返回变量的引用) 9.6 指针数组、指针的指针与main函数参数 指针数组定义: 跳转至该位置 类型标识符 * 数组名[长度] 9.6.3 指针数组作为main函数参数 main函数需要改造一下才可以接受系统传递进来的参数: int main(int argc, char * argv[]) main函数接受两个参数: 第一个参数是整型数据 第二个参数是指针数组(作为函数形参) 9.7 本章小结 指针变量可以指向NULL(空),表示不指向任何有效内容 void * 指针,为万能指针,可以指向任意数据类型 10 结构体与共用体 10.1 结构体变量定义、引用与初始化 10.1.1 结构体类型定义 struct 结构体名 { 成员列表 } 10.1.2 结构变量的定义方法 形式1:定义完结构类型后定义变量 struct 结构体名 变量列表; 形式2:定义结构类型时定义变量 struct 结构体名 { 成员列表 }变量名列表; 形式3:直接定义结构变量 struct { 成员列表 }变量名列表; 说明: 使用结构体,一般需要定义一个结构体类型,在定义结构变量 结构体内可以套结构 结构体内成员名可以和程序中的变量名相同 10.1.3 结构体类型变量的引用 12345// 引用方式:结构体变量.成员名使用指针引用成员类型名 \\*指针名 = &amp;结构体变量.成员名 10.2 结构体数组和结构体指针 10.2.2 结构体指针 定义: struct 结构体类型名 * 指针名; 赋值: 只能指向一个结构体类型的变量,或者结构体类型数组中的某一个元素,不可以指向其中的具体成员 访问结构体变量成员 使用结构体成员运算符“.” 使用结构体成员运算符&quot;-&gt;&quot; 如: struct students stu; struct students *p; p = &amp;stu; (*ps).num = 1; (*的优先级比“.”低) ps -&gt; num =1; 可以使用指向结构体的指针作为函数参数 10.3 共用体、枚举类型与typedef 10.3.1 共用体 共用体和结构体的区别? 共用体的成员会占用同一段内存,而结构体中的成员会占用不同的内存 定义: union 共用体名 { 成员列表 }变量列表; 共用体类型的定义和共用体变量的定义与结构体的定义和结构体变量的定义相似 共用体成员共占一段内存,所以占用内存的大小等于所占用内存最大的成员的大小 每个瞬间只有一个成员起作用,其他成员不起作用 10.3.2 枚举类型 定义枚举类型: enum 枚举类型名 { 值 }变量列表; C语言会自动按照定义时的顺序规定它们的值,并且值是从0开始的. 可以手动在定义枚举类型的时候设置默认的枚举常量的值,后面的枚举常量的值为前一个的值+1 不可以将整数直接赋值给枚举变量,但使用强制类型转换是可以的(enum 枚举类型名); 10.3.3 用typedef定义类型 typedef是用于定义类型名的 typedef 原类型名 新类型名; 习惯上,用typedef定义的类型名用大写字母表示 11 位运算 1个字节是由8个二进制位组成的 &amp; 按位与 | 按位或 ^ 按位异或:两个位相同,返回0,不同为1 ~ 取反 &lt;&lt; 左移 &gt;&gt; 右移 可以使用该代码定义位操作 #define BIT(X) (1&lt;&lt;(X)) 带参数的宏定义 12 文件操作 文本文件中,每个字节存放一个ASCII码,代表一个字符 大端存储与小端存储? 大端存储:低字节存储在高地址,高字节存储在低地址 小端存储:低字节存储在低地址,高字节存储在高地址 如果在文本文件中,以16进制保存数字,保存比较节省空间,但需要人工阅读 12.2 文件的打开、关闭、读写 文件在进行读写操作之前,必须先打开,在读写结束后,必须关闭文件 文件打开: FILE * fp; //FILE为一个结构体,fp是指向结构体的指针(文件指针) fp = fopen(文件名,文件使用方式); 文件使用方式: r 只读 w 只写(文件存在,则清空重写,否则创建文件) a 追加(末尾追加) rb 只读(打开二进制文件) wb 只写(二进制文件) ab 追加(二进制文件) r+ 读写(打开文本文件) w+ 读写(创建文本文件) 文件打开后,会返回一个位置指针(*char),代表当前从文件的哪个位置开始读写. 文件不存在时fopen函数会返回空(NULL) 文件关闭: fclose(文件指针); 文件关闭时,会将缓冲区的数据立即写到磁盘上 文件读写: fputc(ch,fp); //将ch写入磁盘文件中 fgetc(fp); //从磁盘文件中读取一个字符 feof(fp); //判断文件是否结束(结束返回1,否则返回0) 12.3 将结构体写入二进制文件再读出 fwrite(butter, size, count, fp); 向文件写入数据 butter:指针或者地址(将要写入的数据) size:写入文件的字节数 count:要写入多少size的数据项 fp:文件指针 返回值,如果fwrite失败,返回0,否则返回count值 对于要写入的结构体,结构体成员中不要出现指针型成员(因为指针类型成员地址可能失效) 可以使用==#pragma pack(1)设置代码对齐方式为1字节对齐,即不要对齐==,可以避免程序在Linux平台读数据出错 fread(buffer,size,count,fp); 向文件读出数据 butter:指针或者地址(将要写入的数据) size:写入文件的字节数 count:要写入多少size的数据项 fp:文件指针 返回值,如果fwrite失败,返回0,否则返回count值 13 C++基本语言 13.1 语言特性、工程构成与可移植性 C语言是过程式的语言 C++为面向对象的语言,其与面向过程语言的最大区别是:在基于面向对象的程序设计中,额外应用了继承性和多态技术 面向对象的程序设计的优点: 易维护 易扩展 模块化 C++程序的头文件一般以.h居多,此外还有.hpp; hpp文件一般来说就是把定义和实现都包含在一个文件中,可以有效的减少编译次数 C++为编译型语言 在程序执行前,需要一个专门的编译过程,将程序编译成二进制文件,执行的时候不需要重新编译,直接使用编译结果. 13.2 命名空间简介与基本输入输出精解 命名空间就是为了防止名字冲突而引入的一种机制. 定义: namespace 命名空间名 { 其他函数、 } 访问:使用“::”作用域运算符 命名空间名::实体名 命名空间定义可以不连续,可以写在不同的位置,甚至可以写在不同的源文件中 注意不同命名空间中相同的函数在同一个函数中调用,若冲突则: 要么不声明两个命名空间 要么不同命名空间中的函数不要同名 要么调用命名空间中的函数时添加“ 命名空间:: ”表达方式 13.2.2 基本输入输出 C++中输入输出的标准库是iostream库(输入/输出流) std是标准库中的一个命名空间 std::cout 是一个对象,为标准输出 std::cin为基本输入 &lt;&lt; 向左扎,为输出运算符,与std::cout结合表示将内容扎到cout中,表示将&lt;&lt;右侧的内容写到cout屏幕中 std::endl 相当于函数指针.其作用为: 1. 输出换行符 2.刷新输出缓冲区,调用flush函数强制输出缓冲区中所有数据,然后把缓冲区中的数据清除 为什么要有输出缓冲区? 将数据临时保存到输出缓冲区,当缓冲区满了、或者程序执行到main函数的return正常结束时、或者使用std::endl函数(后面会调用flush()函数)等情况,程序一次性将数据写入磁盘,提升速递,降低内存消耗 注意&lt;&lt;符号为右结合性 13.3 auto、头文件防卫、引用与常量 13.3.1 局部变量和初始化 C++中,变量随时定义即可,不必像C语言中需要在函数开头定义 在C++新标准中,可以使用“{}“对变量进行初始化. 例如: int abc{5}; ==在C++中的新标准的好处: int abc = 3.5f; //编译成功,自动进行截断操作 int abc{3.5f}; //编译错误,语法报错 这样做数据不会被截断== 同样也可以使用“()”对变量进行初始化操作 13.3.2 auto关键字简介 auto在C++11中的全新含义:变量的自动推断 变量的自动推断发生在编译期,所以在使用时不会造成程序的效率降低 13.3.3 头文件防卫式声明 为了避免重复定义头文件,在声明头文件时,需要添加头文件防卫式声明: #ifndef 文件名 #define 文件名 代码程序 #endif 在每一个.h文件的#ifdef后面的定义的名字都不一样,不可以重名 13.3.4 引用 引用是为变量起的另一个名字,一般使用&quot; &amp; &quot;符号, 引用和原变量所占的内存是同一段内存(对初学者来说) 定义引用变量时必须进行初始化操作 引用数据类型 &amp; 变量名 = 被引用变量名称; //==(引用变量必须绑定到变量或者对象上,不能绑定到常量上) &amp; 在=左侧表示引用 &amp; 在=右侧表示取地址 13.3.5 常量 const常量 定义变量时,在前面添加const关键字,即为常量 constexpr常量 在C++11中的新关键字,代表一个常量,表示在编译时进行求值,可以提升运行时的性能 在书写constexpr返回类型的函数时,需要格外注意:如 在定义变量时,不可定义未初始化的变量(定义变量必须进行初始化操作) 2.传入constexpr函数的形参对应的实参必须为常量或常量表达式 其中代码需要尽量简单 加了constexpr修饰的函数不但能用在常量表达式中,也能用在常规的函数调用中 常量表达式不可以强制转换得到 13.4 范围for、new内存动态分配与nullptr 13.4.1 范围for语句 范例： int v[]{12，13，14，15，16}； for{auto x:v} //此为范围for语句 { 代码; } 此例多了一个复制的动作，可以使用引用避免复制，提高运行效率 for { auto &amp;x : v} 一般来说，一个容器只要内部支持begin和end成员函数用于返回一个迭代器，能够指向容器的第一个元素和末尾元素的后面，这种容器就饿可以支持范围for语句 13.4.2 动态内存分配问题 C++中内存被分为5块区域： 栈：局部变量创建时存储的位置 堆：使用malloc/new申请，free/delete释放的区域 全局/静态存储区 常量存储区 程序代码区 内存分配和释放必须成对出现 free和delete不可以重复调用 new相较于malloc，new还进行一些额外的初始化工作；delete相较于free，delete还会进行一些额外的清理工作 堆和栈的区别： 栈空间有限，使用便捷；堆空间自由决定分配的内存大小。 malloc和free 在C语言中成对出现，用于在堆中分配内存 一般形式为： void * malloc(int NumBytes); void free(void * Ptr) malloc为向系统申请NumBytes字节的内存空间，分配成功返回被分配内存的指针，否则返回NULL空指针 free为回收指针Ptr对应的内存 strcpy_s:为strcpy的安全版本，能够检测所容纳的元素是否越界。 2. new和delete new和delete为运算符，不是和malloc和free一样的函数 在C++中从堆中分配内存 new的使用方法： 指针变量名 = new 类型标识符； 指针变量名 = new 类型标识符(初始值); 指针变量名 = new 类型标识符[内存单元个数]; 13.4.3 nullptr nullptr为C++11中引入的新关键字，表示“空指针” typeid()函数用于取类型，其中name成员可打印出类型名 ==使用nullptr可以避免在整数和指针之间发生混淆 NULL 其类型为int类型，其实就是0 nullptr表示指针类型 NULL和nullptr会导致调用不同的重载函数 在实际中，对于指针的初始化，能用nullptr尽量使用nullptr 13.5 结构、权限修饰符与类简介 当形参类型使用引用时，在调用函数内所改变的值在主调函数中也会发生相应的改变。实参和形参代表的是同一段内存地址，在传递参数时不存在参数值的复制。 在C++中，结构不仅可以定义成员变量，还可以定义成员函数（方法），可以使用对象名.成员函数名（实参列表）进行调用。 13.5.2 public和private权限修饰符 public为“公共”的，可以被外部访问，类似类的外部接口 private为“私有”的，表示只能被该结构或者类内部定义的成员函数使用 成员函数可以直接访问成员变量（不管成员变量是否为private都可以访问） 默认情况下，struct定义的结构，其内部的成员变量和成员函数都是public 123456struct 结构类型名&#123; public: 成员变量； 成员函数；&#125; 在C++中引入类的概念，使用class定义 结构使用struct定义（与C语言一致） 类的某个变量成为对象，为类的实例化，类中间的成员函数称为方法 类的内部变量默认为private C++中结构的继承默认为public，而类的继承默认为private 13.6 函数新特性、inline内联函数与const详解 13.6.1 函数回顾与后置返回类型 在函数声明中，可以没有形参名 在函数定义中，需要有形参类型和形参名，但若该形参不需要使用，可以不添加函数名，但是在调用是必须给出该位置的实参 后置返回类型： 在函数声明或定义中，把返回类型写在参数列表之后 1auto 函数名(形参列表) -&gt; 函数返回类型; //函数声明 13.6.2 inline内联函数 为避免函数调用消耗系统资源，解决函数体很小，调用频繁的函数消耗系统性能，使用inline关键字 系统尝试将调用该函数的动作替换为函数的本体 内联函数的定义写在头文件中 inline函数应该尽量简单，避免循环、分支、递归调用等 可以将constexpr函数看为更加严格的内联函数（constexpr自带inline属性） 函数特殊写法： 函数只可以被定义一次，但是可以声明很多次 在C++中，更加习惯使用引用类型的形参来代替使用指针类型的形参 函数重载时，const关键字会被同名函数忽略 13.6.4 区别 const char * 、char const * 与char * const三者的区别 const char *p 定义一个常量指针p(p指向的内容不可以通过p来修改) char const *p 等价于const char *p char * const p 定义一个指针常量p(p不可以指向其他内容,但可以修改指向的目标中的内容) 13.6.5 函数形参中带const 如果不希望在函数中修改形参的值,建议形参使用常量引用 可以防止无意中修改了形参的值导致实参值被改变 实参类型可以更加灵活 使用常量引用,不仅仅可以接收普通引用作为实参,还可以接收常量引用作为实参 13.7 string类型 string位于std命名空间中,位于string头文件中 (string为一个对象) 定义和初始化: 123456string s1;string s2 = &quot;I love China&quot;;string s3(&quot;I love China&quot;);string s4 = s2;int num = 6;string s5(num,&#x27;a&#x27;); 常用操作: .empty()方法 :返回布尔量判断是否为空 .size或.length方法 :返回字节数量 s[n] :返回s中的第n个字符 s1+s2 :字符串连接 s1=s2 :字符串对象赋值 s1==s2 :判断两个字符串是否相等 s1 !=s2 :判断两个字符串是否不相等 s.c_str() :返回一个字符串s中的内容指针(==把string对象转换为C中的字符串样式) 范围for语句 :for(auto&amp; x:s1) 13.8 vector类型 代表一个容器、集合、或者动态数组,可以将一堆相同类型的类对象放到vector容器中 vector位于std命名空间中,vector头文件中 定义: 1234567891011121314151617vector &lt;类型&gt; 对象名; //vector为类模版,&lt;&gt;是类模版的一个实例化过程//空vectorvector &lt;string&gt; mystr; //可使用push_back向容器末尾添加数据//vector对象复制vector &lt;string&gt; mystr2(mystr1);vector &lt;string&gt; mystr3 = mystr2;// 使用初始化列表方式初始化vector &lt;string&gt; def = &#123;&quot;aaa&quot;,&quot;bbb&quot;,&quot;ccc&quot;&#125;;// 创建指定数量的元素vector &lt;int&gt; ijihe(15,-200); //创建15个int类型元素的集合,其中每个元素的值都为-200//有元素数量的概念的初始化操作都使用() vector容器不能用来装引用(引用只是一个别名,并不是一个对象) 一般使用()表示与元素数量相关的操作,用{}表示只与元素内容相关的内容 13.8.3 vector对象上的操作 .empty :判断是否为空 .push_back() :向vector末尾添加元素 .size :返回元素数量 .clear :移除所有元素,容器清空 v[n] =,==,!=, 范围for语句,在范围for语句中,不要改变vector的容量,增加、删除元素都不可以 13.9 迭代器精彩演绎、失效分析及弥补、实战 在C中很少通过下标访问string或vector中的元素,通常使用迭代器访问 通过迭代器,可以读取容器中的元素值,修改容器中某个迭代器代表的元素的值,可以像指针一样使用,–等运算符进行元素访问 C++中每种容器都定义了迭代器类型,以vector容器举例: 定义容器: 12vector &lt;int&gt; iv = &#123;100,200,300&#125;;vector &lt;int&gt;::iterator iter; //定义了一个迭代器iter 13.9.3 迭代器begin,end、反向迭代器rbegin,rend操作 迭代器 反向迭代器 rbegin:指向最后一个元素 rend:指向第一个元素前面的位置 123456789// begin成员函数:返回一个迭代器类型iter = iv.begin(); //返回容器的迭代器,指向第一个元素// end成员函数:返回一个迭代器类型// 一般起到一个标志作用,当iter走到了end位置,表示已经遍历完了容器里的所有元素iter = iv.end(); //指向末尾元素的下一个元素// 经典写法:for(vector &lt;int&gt;::iterator iter = iv.begin();iter != iv.end();iter ++)&#123;...&#125; 13.9.4 迭代器运算符 *iter //返回迭代器元素的引用 ++iter,–iter ==,!= 结构成员变量的引用 13.9.5 const_iterator迭代器 类似一个常量指针,若容器对象为常量对象,则必须使用const_iterator迭代器 C++11中引入新的关键字,cbegin与cend返回常量迭代器(不管容器是否为常量容器) 13.9.6 迭代器失效 如果在一个使用了迭代器的循环中插入元素到容器,当插入元素后应立即跳出循环体,不应该继续使用带迭代器操作容器 容器清空: 使用clear方法清除 使用迭代器一个一个清除 1234while(!iv.empty())&#123; auto iter = iv.cbegin(); iv.erase(iter);&#125; 13.10 类型转化:static_cast、reinterpret_cast等 C风格的强制类型转化: (类型)待转换的内容; 类型 (待转换的内容); C++中强制类型转换的通用形式: 强制类型转换名 &lt;type&gt;(express); static_cast :静态转换 与C语言强制类型转换相似 派生类转换为基类 不可用于指针类型之间的转换 dynamic_cast :在转换时会进行类型识别和检查 主要用于父类转换为子类 const_cast: 去除指针或者引用的const属性 注意只能用于原先不是常量,后来转换为常量的变量的去除,(原先是常量的去除为为定义行为) const_cast不可以改变表达式的类型 reinterpret_cast :用来处理无关类型之间的转换 可以将整型转换为指针、一个类型指针转换为另一个类型的指针 可以将一个指针转换为整型 static_cast、reinterpret_cast可以替代C语言风格的类型转换 14 类 14.1 成员函数、对象复制与私有成员 设计类思考的角度: 站在设计和实现者的角度考虑,类的数据存储布局、必要的成员变量和成员函数 站在使用者的角度,可以访问的接口、对外开放仅供内部函数使用的接口 设计父类供子类继承时,如何设计父类 类的成员主要包括:成员变量、成员函数等 访问类成员: 使用“对象名.成员名”访问成员 使用指向这个对象的指针访问: 指针名-&gt;成员名 注意点: public修饰的成员可供外部访问,而private修饰的成员不可以被外部访问 class成员默认为private,而struct默认为public的 建议:没有成员函数只有成员变量的数据结构使用struct;而有成员函数的数据结构一般使用class 14.1.3 成员函数 类可以被定义多次,而全局变量只能被定义一次 在C++中,若类定义和类实现放在不同文件时,其成员函数需要使用==“类名::成员函数名”==表明该成员函数为该类的成员函数(::为作用域运算符) 如： 1234void Time::initTime(int tmphour, int tmpmin, int tmpsec)&#123; 函数代码&#125; 14.1.4 对象复制 可以使用==”=“、”()“、”{}“、”={}“==符号实现对象的复制操作 14.2 构造函数详解、explicit与初始化列表 将成员函数的声明和实现都写在类的内部,称为成员函数的定义 将成员函数的声明写在类的内部,外部的成员函数代码称为:“成员函数的实现” 构造函数:与类名相同,系统会自动调用,目的就是为了初始化类对象的数据成员(成员变量) 构造函数无返回值 构造函数不可以手工调用,会发生程序错误,系统会自动调用 正常情况下,构造函数声明为public 构造函数中含有的参数,在创建对象时需要给定相应的参数 一个类可以存在多个构造函数，必须为该类对象的创建提供多种方法，多个构造函数需要在参数数量或者参数类型上有所不同 对象的复制会调用拷贝构造函数 14.2.4 函数默认参数 任何函数都可以有默认参数，对于传统函数，默认参数一般放在函数声明中，而不放在函数实现中，除非函数只有定义 对于类中的成员函数，默认参数写在类的成员函数声明中，一般写在.h文件中 具有多个参数的函数中指定默认参数，默认参数必须出现在非默认参数的右侧，且默认参数必须给定默认值 14.2.5 隐式转换和explicit 在调用构造函数时，有可能会调用隐式转换。 可以要求构造函数不进行隐式转换，在函数声明中带有explicit（显式），则该构造函数只能用于初始化和显式类型转换 explicit 构造函数名(形参列表); 在类进行实例化调用explicit多参数构造函数时，若带有=号，则隐式类型转换失效（含有等号，表示进行了隐式初始化；省略等号，为显式初始化为直接初始化） 调用explicit单参数构造函数，也只可以使用显式转换 在调用explicit构造函数时，使用{}进行初始化可以避免进行隐式类型转换而出错 14.2.6 构造函数初始化列表 调用构造函数时，可以初始化成员变量的值（为冒号括号逗号式写法），位于构造函数的定义中，（这种写法只用于构造函数中） 例如： Time::Time(int tmphour, int tmpmin, int tmpsec) :Hour(tmphour),Minute(tmpmin) //构造函数初始化列表 在书写带初始化列表的构造函数时，应避免某个成员变量（Minute）的值依赖某个成员变量的值（Hour），不可写成（Minute（Hour）） 使用构造函数初始化列表可以提升初始化效率（避免了调用成员变量相关类的各种特殊成员函数） 14.3 inline、const、mutable、this与static 14.3.1 在类定义中实现成员函数inline 在类的定义中实现的成员函数会被当做inline内联函数处理 跳转至该位置 14.3.2 成员函数末尾的const 在成员函数的末尾添加const为常量成员函数，表示该成员函数不会修改该对象内任何成员变量的值（不可以在该成员函数的实现中修改成员变量的值） 对于成员函数和实现代码分开的成员函数，不但要在成员函数的声明中增加const，也要在实现中增加const 14.3.3 mutable 被mutable修饰的成员变量，永远为可变状态，可被const常量成员函数修改 14.3.4 返回自身对象的引用——this 123456789声明：public： Time&amp; rtnhour(int tmphour); //返回自身的引用 Time&amp; Time::rtnhour(int tmphour)&#123; Hour += tmphour; return *this;&#125; this在成员函数中为一个隐藏的函数参数，表示的时只想本对象的指针，而*this表示该指针指向的对象，即为本对象,*this为调用这个成员函数的对象 编译器内的实际声明： Time&amp; Time::rtnhour(Time * const this, int tmphour){…} 编译器内的实际调用： mytime.rtnhour(&amp;mytime,3); this为一个指针常量，指向这个对象的本身，不可以再指向其他地方 跳转至该位置 this只可以在成员函数（普通成员函数以及特殊的成员函数中使用），不可以在全局函数、静态函数中使用this指针 在普通成员函数中，this是一个非const对象的指针常量 在const成员函数中，this指针是指向一个const对象的指针常量 14.3.5 static成员 跳转至该位置 static成员变量：不属于某个对象而属于整个类 通过对象名修改了static成员变量的值，其他类对象中的相应值也发生改变 普通成员变量在定义类对象时被分配内存，==静态成员变量在 声明：在类内部声明 static 类型 变量名； static 返回类型 函数名(形参列表); 初始化：(一般写在.cpp文件开头) //[]内内容可以省略，初始化时可不给初值,且实现时不需要写static关键字 类型名 类::变量名 [= 值]; 对象名.变量名 [=值]; 类型名 类::静态成员函数名 对象名.静态成员函数名 14.4 类内初始化、默认构造函数、=default、=delete 14.4.1 类相关非成员函数 与类有点关系，但不适合写在类内的函数，这种函数的定义可以放到该类成员函数实现的代码中 14.4.2 类内初始值 在C++11新标准中，可以为新成员提供一个类内的初始值，那么在创建成员的时候，这个初始值就会初始化该成员变量，对于没有初始值的成员变量，系统会默认赋值。 若在构造函数初始化列表或者在构造函数中赋值，该值会覆盖初始值 14.4.3 const成员变量的初始化 对于类的const成员，只能使用初始化列表进行初始化操作（或者在声明该const变量时进行初始化操作），不能在构造函数内部进行赋值操作 构造函数不可以声明为const类型 在const变量完成初始化之后，该变量才具有const属性 14.4.4 默认构造函数 编译器会为一个类生成默认构造函数；若声明了一个构造函数，就不会自动生成其他的默认构造函数 一旦程序员书写了自己的构造函数，那么在创建对象时，必须提供与书写的构造函数形参相符合的实参，才能够成功创建对象 14.4.5 =defalue；和=delete =default 相当于为特殊函数自动生成函数体（等价与空函数体{}） 包括构造函数、拷贝构造函数等 =delete 显式的禁止某个函数 14.5 拷贝构造函数 跳转至该位置 默认情况下：类对象的复制就是每个成员变量的逐个复制 拷贝拷贝构造函数：用于类对象的复制 如果一个类的构造函数的第一个参数为所属类的类引用，若有额外的参数，那么这些额外的参数都有默认值，该构造函数的默认参数必须放在函数声明中（除非该构造函数没有函数声明），那么这个构造函数就是拷贝构造函数。 类名::类名(const 类名&amp; 参数名，[其他形参列表]); const，拷贝构造函数的第一个参数都是带有const的 explicit，（禁止隐式转换） 一般来说单参数的构造函数都声明为explicit以避免参数模糊不清的问题 拷贝构造函数，一般不声明为explicit 如果一个类没有自己的拷贝构造函数，那么编译器会合成一个拷贝构造函数，参考 跳转至该位置 拷贝构造函数的成员变量的赋值操作可以成初始化列表进行 跳转至该位置 调用拷贝构造函数的情况： 将对象作为实参传递给另一个非引用类型的形参（复制构造，效率低） 从函数中返回一个对象(系统会将局部对象(临时对象)return出去,会调用拷贝构造函数) 其他情况 14.6 重载运算符、拷贝赋值运算符与析构函数 14.6.1 重载运算符 运算符(==,!=,&gt;,&gt;=等)想要应用与类对象，需要对这些运算符进行重载（即以这些运算符为成员函数名定义成员函数实现功能） 实现方式：operator关键字后面接这个运算符（本质为函数，需要有返回类型和参数列表） 重载==运算符 12345678bool Time:operator==(Time&amp; t)&#123; if(Hour == t.Hour) &#123; return true; &#125; return false;&#125; 重载=运算符 12345Time&amp; Time:operator=(Time&amp; t)&#123; //.... return *this;&#125; 重载运算符本质上是函数，函数的正式名字是operator关键字后面接这个运算符 如果一个类没有重载赋值，编译器可能会重载一个赋值运算符，可能不会重载运算符，其重载运算符只是简单将对象的成员变量的值复制到新对象对饮的成员变量中即完成赋值 ==运算符，编译器不会默认重载 14.6.2 拷贝赋值运算符(赋值运算符) 给对象赋值，系统会调用一个拷贝构造赋值运算符，若不自己重载运算符，编译器会用默认的对象赋值规则为对象赋值，甚至在必要的情况下重载运算符 编译器重载的赋值运算符功能上只完成一些简单的成员变量赋值以及调用类类型成员变量所对应类中提供的拷贝赋值运算符 123456789101112131415161718// 赋值运算符重载// 类定义Time.h头文件public: Time&amp; operator=(const Time&amp;)// 禁止Time类型对象之间赋值，声明private即可// 类实现文件Time.cpp文件TIme&amp; Time::operator=(const Time&amp; tmpTime)&#123; Hour = tmpTime.hour; Minute = tmpTime.Minute; return * this; // 返回该对象的引用&#125; // 调用myTime6 = myTime5;// 左边的myTime6是operator=运算符的this对象// myTime5是operator=里面的形参// 形参写成了const类型，为了避免误改形参里面的值 14.6.3 析构函数(释放函数) 对象销毁时，会调用析构函数，析构函数没有返回值 在构造函数new了一块内存，一般来说就应该写出自己的析构函数将new出来的内存释放(delete) 一个类只能有一个析构函数 1234// 析构函数的定义~Tmpclass()&#123; // Tmpclass类的析构函数，以~开头，后面跟着类名，没有返回值&#125; 14.6.4 几个话题 构造函数的成员初始化 对于类类型成员变量的初始化，能放在构造函数的初始化列表里进行的，千万不要放在构造函数的函数体里进行，这样可以节省很多次不必要的成员函数调用，从而提高不少程序的执行效率","categories":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/tags/C/"}]},{"title":"矩阵理论","slug":"专业知识相关/矩阵理论","date":"2021-10-20T11:53:06.000Z","updated":"2023-04-09T13:34:00.411Z","comments":true,"path":"2021/10/20/专业知识相关/矩阵理论/","link":"","permalink":"http://jay1060950003.github.io/2021/10/20/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%9B%B8%E5%85%B3/%E7%9F%A9%E9%98%B5%E7%90%86%E8%AE%BA/","excerpt":"引言 本文为硕士课程中矩阵理论的课堂笔记 能力有限,不喜勿喷","text":"引言 本文为硕士课程中矩阵理论的课堂笔记 能力有限,不喜勿喷 矩阵理论 重根的特征向量若不正交，则使用许米正交化方法正交 秩1阵的分解应用 预备知识 AH=AA^H=AAH=A, A为Hermite阵 AH=−AA^H=-AAH=−A, A为斜Hermite阵 Hermite阵的对角线元素为实数 实对称阵是Hermite矩阵 若B为斜Hermite阵，则iB，B/i为Hermite阵，特征根都为虚数或者0(利用B/i为Hermite阵证明) 若A为Hermite阵，则iA为斜Hermite阵 Herimte分解定理：若A为Hermite阵，则存在优阵Q使得A=QDQ−1=Q(λ10⋱0λn)Q−1,且λ1,...λn为实数A =\\mathbf{Q} \\mathbf{D} \\mathbf{Q}^{-1}=\\mathbf{Q} \\left(\\begin{array}{ccc}\\lambda_{1} &amp; &amp; 0 \\\\ &amp; \\ddots &amp; \\\\ 0 &amp; &amp; \\lambda_{n}\\end{array}\\right) \\mathbf{Q}^{-1},且\\lambda_{1} ,...\\lambda_{n}为实数A=QDQ−1=Q⎝⎛​λ1​0​⋱​0λn​​⎠⎞​Q−1,且λ1​,...λn​为实数 Hermite阵A必有n个正交特向 Hermite阵特征根都是实数 AHA=0↔A=0A^HA=0 \\leftrightarrow A=0AHA=0↔A=0(利用秩进行证明,或利用迹公式证明) 迹公式 矩阵模平方(F范数):tr⁡(AHA)=tr⁡(AAH)=∑∣ai,j∣2\\operatorname{tr}\\left(A^{H} A\\right)=\\operatorname{tr}\\left(A A^{H}\\right)=\\sum\\left|a_{i, j}\\right|^{2}tr(AHA)=tr(AAH)=∑∣ai,j​∣2 tr⁡(ABT)=tr⁡(BTA)=∑ai,jbi,j\\operatorname{tr}\\left(A B^{T}\\right)=\\operatorname{tr}\\left(B^{T} A\\right)=\\sum a_{i, j} b_{i, j}tr(ABT)=tr(BTA)=∑ai,j​bi,j​ tr⁡(ABH)=tr⁡(BHA)=∑aijbij‾\\operatorname{tr}\\left(A B^{H}\\right)=\\operatorname{tr}\\left(B^{H} A\\right)=\\sum a_{i j} \\overline{b_{i j}}tr(ABH)=tr(BHA)=∑aij​bij​​ 内积公式 (X,Y)=YHX=tr⁡(XYH)=x1y1‾+⋯+xnyn‾,(X, Y)=Y^{H} X=\\operatorname{tr}\\left(X Y^{H}\\right)=x_{1} \\overline{y_{1}}+\\cdots+x_{n} \\overline{y_{n}}, \\quad(X,Y)=YHX=tr(XYH)=x1​y1​​+⋯+xn​yn​​, for X,Y∈CnX, Y \\in \\mathrm{C}^{\\mathrm{n}}X,Y∈Cn 模长：(X,X)=tr⁡(XXH)=XHX=x1x1‾+⋯+xnxn‾=∣x1∣2+⋯+∣xn∣2=∣X∣2(X, X)=\\operatorname{tr}\\left(X X^{H}\\right)=X^{H} X=x_{1} \\overline{x_{1}}+\\cdots+x_{n} \\overline{x_{n}}=\\left|x_{1}\\right|^{2}+\\cdots+\\left|x_{n}\\right|^{2}=|X|^{2}(X,X)=tr(XXH)=XHX=x1​x1​​+⋯+xn​xn​​=∣x1​∣2+⋯+∣xn​∣2=∣X∣2 复空间矩阵内积： (A,B)=YHX=tr⁡(ABH)=a1b1‾+⋯+anbn‾,(A, B)=Y^{H} X=\\operatorname{tr}\\left(A B^{H}\\right)=a_{1} \\overline{b_{1}}+\\cdots+a_{n} \\overline{b_{n}}, \\quad(A,B)=YHX=tr(ABH)=a1​b1​​+⋯+an​bn​​, for A,B∈Cm∗nA, B \\in \\mathrm{C}^{\\mathrm{m*n}}A,B∈Cm∗n 矩阵模长公式：∥A∥2=tr⁡(AAH)=tr⁡(AHA)=∑∣aij∣2\\|A\\|^{2}=\\operatorname{tr}\\left(A A^{H}\\right)=\\operatorname{tr}\\left(A^{H} A\\right)=\\sum\\left|a_{i j}\\right|^{2}∥A∥2=tr(AAH)=tr(AHA)=∑∣aij​∣2 向量垂直：X⊥Y⇔(Y,X)=0⇔(X,Y)=0X \\perp Y \\Leftrightarrow(Y, X)=0 \\Leftrightarrow(X, Y)=0X⊥Y⇔(Y,X)=0⇔(X,Y)=0 性质：1.满足勾股定理；2.可推广至n个向量互垂直 优阵_预优阵 预优阵：方阵的各列互垂直 预半优阵：矩阵的各列互垂直 引理：A为预优阵(预半优阵)⇔\\Leftrightarrow⇔当且仅当AHAA^{H} AAHA为对角形 优阵：方阵的各列互垂直，且各列的模长为1 半优阵：矩阵的各列互垂直，且各列的模长为1 引理：A为优阵(半优阵)⇔\\Leftrightarrow⇔当且仅当AHA=IA^{H} A = IAHA=I(AAH=IA A^{H} = IAAH=I),则AH=A−1A^{H} = A^{-1}AH=A−1 **性质：A为优阵(半优阵) ∣AX∣2=∣X∣2|AX|^{2} = |X|^{2}∣AX∣2=∣X∣2;保模长 x⊥y⇒Ax⊥Ayx \\perp y \\Rightarrow A x \\perp A yx⊥y⇒Ax⊥Ay;保正交 (Ax,Ay)=(x,y)(A x, A y)=(x, y)(Ax,Ay)=(x,y) 许尔公式 补充公式：设n阶可逆阵P可以按列写成P=(α1,α2,⋯ ,αn)\\mathrm{P}=\\left(\\alpha_{1}, \\alpha_{2}, \\cdots, \\alpha_{n}\\right)P=(α1​,α2​,⋯,αn​)，则P−1α1=e1,P−1α2=e2,⋯ ,P−1αn=en\\mathrm{P}^{-1} \\alpha_{1}=e_{1}, \\mathrm{P}^{-1} \\alpha_{2}=e_{2}, \\cdots, \\mathrm{P}^{-1} \\alpha_{n}=e_{\\mathrm{n}}P−1α1​=e1​,P−1α2​=e2​,⋯,P−1αn​=en​ 二阶许尔公式的引理： 许尔公式：每个方阵A，存在可逆阵P使得P−1AP=D=(λ1…∗⋱⋮0λn)\\mathbf{P}^{-1} \\mathbf{A P}=\\mathbf{D}=\\left(\\begin{array}{ccc}\\lambda_{1} &amp; \\ldots &amp; * \\\\ &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; &amp; \\lambda_{n}\\end{array}\\right)P−1AP=D=⎝⎜⎜⎛​λ1​0​…⋱​∗⋮λn​​⎠⎟⎟⎞​为上三角 优相似三角化(许尔公式2)：每个方阵A，存在优阵Q，使Q−1AQ=D=(λ1…∗⋱⋮0λn)\\mathbf{Q}^{-1} \\mathbf{A Q}=\\mathbf{D}=\\left(\\begin{array}{ccc}\\lambda_{1} &amp; \\ldots &amp; * \\\\ &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; &amp; \\lambda_{n}\\end{array}\\right)Q−1AQ=D=⎝⎜⎜⎛​λ1​0​…⋱​∗⋮λn​​⎠⎟⎟⎞​为上三角 推论：每个方阵都优相似与上三角阵 换位公式 设A=An×p\\mathbf{A}=\\mathbf{A}_{\\mathrm{n} \\times p}A=An×p​，B=Bp×n\\mathbf{B}=\\mathbf{B}_{\\mathrm{p} \\times n}B=Bp×n​，且n≥p\\mathrm{n} \\geq \\mathrm{p}n≥p，则∣λIn−AB∣=λn−p∣λIp−BA∣\\left|\\lambda \\mathbf{I}_{\\mathrm{n}}-\\mathbf{A B}\\right|=\\lambda^{n-p}\\left|\\lambda \\mathbf{I}_{p}-\\mathbf{B} \\mathbf{A}\\right|∣λIn​−AB∣=λn−p∣λIp​−BA∣ AB为n阶方阵，BA为p阶方阵，AB与BA的非0根相同，只相差n-p个0根 且tr⁡(AB)=tr⁡(BA)\\operatorname{tr}\\left(A B\\right)=\\operatorname{tr}\\left(B A\\right)tr(AB)=tr(BA) 行列式降阶公式：∣In+AB∣=∣Ip+BA∣\\left|\\mathbf{I}_{\\mathrm{n}}+\\mathbf{A B}\\right|=\\left|\\mathbf{I}_{\\mathrm{p}}+\\mathbf{B} \\mathbf{A}\\right|∣In​+AB∣=∣Ip​+BA∣ 若n=p，则AB与BA的特征根相同 秩1阵 方阵的秩 rank(A)=1 ，则A叫做秩1阵(比例阵) 特征根为λ(A)={tr⁡(A),0,⋯ ,0}\\lambda(\\mathbf{A})=\\{\\operatorname{tr}(\\mathbf{A}), 0, \\cdots, 0\\}λ(A)={tr(A),0,⋯,0} 设λ1=tr⁡(A)\\lambda_1 = \\operatorname{tr}(\\mathbf{A})λ1​=tr(A),则Aα=λ1αA\\alpha = \\lambda_1 \\alphaAα=λ1​α,且A2=λ1AA^2 = \\lambda_1 AA2=λ1​A 若方阵满足A2=λ1AA^2 = \\lambda_1 AA2=λ1​A，则A中各列都是特征向量 秩1阵必有分解：A=αβ=αn×1β1×n\\mathbf{A}=\\boldsymbol{\\alpha} \\boldsymbol{\\beta}=\\boldsymbol{\\alpha}_{\\mathrm{n} \\times 1} \\boldsymbol{\\beta}_{1 \\times \\mathrm{n}}A=αβ=αn×1​β1×n​，且Aα=λ1αA\\alpha = \\lambda_1 \\alphaAα=λ1​α，λ1=tr⁡(A)\\lambda_1 = \\operatorname{tr}(\\mathbf{A})λ1​=tr(A) 遗传公式 根遗传公式 满足平移公式、倍公式、幂公式、逆公式 向量遗传定理：A的特征向量为X1,X2,...,XnX_1,X_2,...,X_nX1​,X2​,...,Xn​也是f(A)的特征向量 使用平移法求解矩阵的特征值和特征向量 补充定理：若A=A(n∗p)A = A_(n*p)A=A(​n∗p),B=B(p∗n)B = B_(p*n)B=B(​p∗n),且n&gt;p,则∣AB∣=0|A B | = 0∣AB∣=0 秩公式 定理1： 任意复矩阵A,AHAA^HAAHA,AAHAA^HAAH为Hermite阵，且半正定 证明：显然AHAA^H AAHA为Hermite阵，利用二次型XH(AHA)X=(AX)HAX=∣AX∣2≥0X^H (A^H A) X = (AX)^H AX = | AX |^2 \\geq 0XH(AHA)X=(AX)HAX=∣AX∣2≥0,则AHAA^H AAHA为半正定的 定理2： 任意矩阵A，则(AHA)X=0(A^H A)X = 0(AHA)X=0与AX=0AX=0AX=0具有相同解 证明：若(AHA)X=0(A^HA)X = 0(AHA)X=0成立，则∣AX∣2=(AX)HAX=XH(AHA)X=0|AX|^2=(AX)^H AX=X^H (A^H A)X=0∣AX∣2=(AX)HAX=XH(AHA)X=0,→∣AX∣=0→AX=0\\rightarrow |AX|=0 \\rightarrow AX=0→∣AX∣=0→AX=0 定理3：任意m*n矩阵,r(AHA)=r(A)r(A^HA)=r(A)r(AHA)=r(A) 证明：由定理2可知，(AHA)X=0(A^H A)X = 0(AHA)X=0与AX=0AX=0AX=0同解，则r(AHA)=r(A)r(A^HA)=r(A)r(AHA)=r(A) 秩的第二定义：m*n阶矩阵A,r(A)=r的等价条件使A中必有一个r阶子式非0，所有r+1阶子式都为0 r(AHA)=r(A),r(AHA)=r(AH),r(A)=r(AH)=r⁡(Aˉ)r(A^HA) = r(A),r(A^HA)=r(A^H),r(A)=r(A^H)=\\operatorname{r}(\\bar{A})r(AHA)=r(A),r(AHA)=r(AH),r(A)=r(AH)=r(Aˉ) 正规阵 若方阵A满足AHA=AAHA^HA=AA^HAHA=AAH,则A叫正规阵 对角阵必正规 Hermite阵与斜Hermite阵必正规 若A正规，则A与AHA^HAH必有相同特征向量，AX=cX↔AHX=cˉXAX=cX\\leftrightarrow A^HX = \\bar{c}XAX=cX↔AHX=cˉX 若A的特根为λ(A)={λ1,...λn}\\lambda(A)=\\{\\lambda_1,...\\lambda_n\\}λ(A)={λ1​,...λn​}，则λ(AH)={λ1ˉ,...,λnˉ}\\lambda(A^H)=\\{\\bar{\\lambda_1},...,\\bar{\\lambda_n}\\}λ(AH)={λ1​ˉ​,...,λn​ˉ​} 实对称阵与实反对称阵都正规 优阵必正规 已知正规阵，可知正规阵的方法 正规阵的倍数依然正规 正规阵平移后依然正规 优相似定理：正规阵的优相似必正规 多项正规定理：正规阵A的多项式f(A)也正规 三角正规定理：三角正规阵一定是对角形（同时适用于分块矩阵） 严格三角阵不是正规阵 正规分解定理 若方阵A正规，则存在优阵Q(QH=Q−1Q^H=Q^{-1}QH=Q−1),使Q−1AQ=D=(λ10⋱0λn)(对角形),其中λ(A)={λ1,...λn}，\\mathbf{Q}^{-1} \\mathbf{A Q}=\\mathbf{D}=\\left(\\begin{array}{ccc}\\lambda_{1} &amp; &amp; 0 \\\\ &amp; \\ddots &amp; \\\\ 0 &amp; &amp; \\lambda_{n}\\end{array}\\right)(对角形),其中\\lambda(A) = \\{\\lambda_1,...\\lambda_n\\}，Q−1AQ=D=⎝⎛​λ1​0​⋱​0λn​​⎠⎞​(对角形),其中λ(A)={λ1​,...λn​}，由Q−1AQ=D\\mathbf{Q}^{-1} \\mathbf{A Q}=\\mathbf{D}Q−1AQ=D可知，Q中的列都是特向量 推论：正规阵A中恰有n个正交特向，不同特征根对应的特征向量正交（利用内积证明） 正规阵一定优相似与对角形 若A优相似与对角形，则A必正规 分解方法： 求特征根 求正交特征向量X1⊥X2⊥...XnX_1 \\perp X_2 \\perp ...X_nX1​⊥X2​⊥...Xn​ 则Q=(X1∣X1∣,⋯ ,Xn∣Xn∣)Q=\\left(\\frac{X_{1}}{\\left|X_{1}\\right|}, \\cdots, \\frac{X_{n}}{\\left|X_{n}\\right|}\\right)Q=(∣X1​∣X1​​,⋯,∣Xn​∣Xn​​),D=(λ10⋱0λn)\\mathbf{D}=\\left(\\begin{array}{ccc}\\lambda_{1} &amp; &amp; 0 \\\\ &amp; \\ddots &amp; \\\\ 0 &amp; &amp; \\lambda_{n}\\end{array}\\right)D=⎝⎛​λ1​0​⋱​0λn​​⎠⎞​ 结论：A=(0−110),λ(A)={−i,i},X1=(1,i)T,X2=(i,1)TA=\\left(\\begin{array}{cc}0 &amp; -1 \\\\ 1 &amp; 0\\end{array}\\right),\\lambda(A) = \\{-i,i\\},X_1=(1,i)^T,X_2=(i,1)^TA=(01​−10​),λ(A)={−i,i},X1​=(1,i)T,X2​=(i,1)T为正规阵 QR分解 QR公式：若A为列无关(高阵，列满秩，r(A)=列数pr(A)=列数pr(A)=列数p)，则A=QR,Q=Qn∗p为列U阵(QHQ=Ip)，R=(r1…∗⋱⋮0rn)为上三角，对角元为正数A=QR,Q=Q_{n*p}为列U阵(Q^HQ=I_p)，\\mathbf{R}=\\left(\\begin{array}{ccc}r_{1} &amp; \\ldots &amp; * \\\\ &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; &amp; r_{n}\\end{array}\\right)为上三角，对角元为正数A=QR,Q=Qn∗p​为列U阵(QHQ=Ip​)，R=⎝⎜⎜⎛​r1​0​…⋱​∗⋮rn​​⎠⎟⎟⎞​为上三角，对角元为正数，且有公式R=QHAR=Q^HAR=QHA 若A为可逆方阵，则有A=QR,Q=Qn∗n为优阵A=QR,Q=Q_{n*n}为优阵A=QR,Q=Qn∗n​为优阵 许米正交公式： 设3向量α1,α2,α3\\alpha_1,\\alpha_2,\\alpha_3α1​,α2​,α3​线性无关，则令β1=α1,β2=α2−(α2,α1)∣α1∣2α1,β3=α3−(α3,α1)∣α1∣2α1−(α3,β2)∣β2∣2β2\\beta_{1}=\\alpha_{1},\\beta_{2}=\\alpha_{2}-\\frac{\\left(\\alpha_{2}, \\alpha_{1}\\right)}{\\left|\\alpha_{1}\\right|^{2}} \\alpha_{1},\\beta_{3}=\\alpha_{3}-\\frac{\\left(\\alpha_{3}, \\alpha_{1}\\right)}{\\left|\\alpha_{1}\\right|^{2}} \\alpha_{1}-\\frac{\\left(\\alpha_{3}, \\beta_{2}\\right)}{\\left|\\beta_{2}\\right|^{2}} \\beta_{2}β1​=α1​,β2​=α2​−∣α1​∣2(α2​,α1​)​α1​,β3​=α3​−∣α1​∣2(α3​,α1​)​α1​−∣β2​∣2(α3​,β2​)​β2​,则β1,β2,β3\\beta_1,\\beta_2,\\beta_3β1​,β2​,β3​互正交 分解方法 使用许米特公式求解优阵(或半优阵)Q 使用R=QHAR=Q^HAR=QHA求三角阵R 写出分解 满秩分解(高低分解) 设A=Am∗nA=A_{m*n}A=Am∗n​的秩r(A)=r&gt;0r(A)=r&gt;0r(A)=r&gt;0,则有分解A=BCA=BCA=BC,其中B为列满秩(高阵),C为行满秩(低阵) 分解方法： 将A进行行变换化简为简化阶形式，A⟶ 行变换 (Ir∗⋯⋯00),r=r(A)A \\stackrel{\\text { 行变换 }}{\\longrightarrow}\\left(\\begin{array}{cc}I_{r} &amp; * \\\\ \\cdots &amp; \\cdots \\\\ 0 &amp; 0\\end{array}\\right), r=r(A)A⟶ 行变换 ​⎝⎛​Ir​⋯0​∗⋯0​⎠⎞​,r=r(A)，从A中去除前r列即为B，C=(Ir,∗)C=(I_r,*)C=(Ir​,∗) 秩1分解法：若r(A)=1(各列成比例)r(A)=1(各列成比例)r(A)=1(各列成比例)，则A=(a1⋮an)(b1⋯bn)=αβA=\\left(\\begin{array}{c}a_{1} \\\\ \\vdots \\\\ a_{n}\\end{array}\\right)\\left(\\begin{array}{lll}b_{1} &amp; \\cdots &amp; b_{n}\\end{array}\\right)=\\alpha \\betaA=⎝⎜⎜⎛​a1​⋮an​​⎠⎟⎟⎞​(b1​​⋯​bn​​)=αβ 乔利斯分解与平方根公式 乔利斯定理：若A&gt;0(正定),则A=RHRA=R^HRA=RHR,其中R=(b1…∗⋱⋮0bn)\\mathbf{R}=\\left(\\begin{array}{ccc}b_{1} &amp; \\ldots &amp; * \\\\ &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; &amp; b_{n}\\end{array}\\right)R=⎝⎜⎜⎛​b1​0​…⋱​∗⋮bn​​⎠⎟⎟⎞​为上三角，且b1,...bn&gt;0b_1,...b_n&gt;0b1​,...bn​&gt;0 A=RHRA=R^HRA=RHR为乔利斯分解 平方根分解： 若A&gt;0(正定),则有A=B2,B&gt;0(正定)A=B^2,B&gt;0(正定)A=B2,B&gt;0(正定),且矩阵B唯一矩阵B唯一矩阵B唯一,可写B=A,A=(A)2B=\\sqrt{A},A=(\\sqrt{A})^2B=A​,A=(A​)2 若A≥0A\\geq0A≥0半正定，则存在B≥0B\\geq0B≥0半正定，使A=B2A=B^2A=B2,且BH=B,λ(B)={λ1,...,λn}B^H=B,\\lambda(B)=\\{\\sqrt{\\lambda_1},...,\\sqrt{\\lambda_n}\\}BH=B,λ(B)={λ1​​,...,λn​​}全为非负根 补充知识 正定阵：设A是Hermite阵，若f(x)−xHAx&gt;0f(x)-x^HAx&gt;0f(x)−xHAx&gt;0对一切非0向量成立，则A为正定阵(A&gt;0A&gt;0A&gt;0) 等价条件 A为正定 A有分解A=PHP或A=PPHA=P^HP或A=PP^HA=PHP或A=PPH,P可逆 特根λ(A)={λ1&gt;0,...,λn&gt;0}\\lambda(A)=\\{\\lambda_1 &gt;0,...,\\lambda_n &gt;0\\}λ(A)={λ1​&gt;0,...,λn​&gt;0}(可用特商公式λ1=xHAx∣x∣2\\lambda_{1}=\\frac{x^{H} A x}{|x|^{2}}λ1​=∣x∣2xHAx​证明) 半正定阵：设A是Hermite阵，若f(x)−xHAx≥0f(x)-x^HAx \\geq0f(x)−xHAx≥0对一切非0向量成立，则A为正定阵(A≥0A\\geq 0A≥0) 等价条件 A为半正定 A有分解A=PHP或A=PPHA=P^HP或A=PP^HA=PHP或A=PPH 特根λ(A)={λ1≥0,...,λn≥0}\\lambda(A)=\\{\\lambda_1 \\geq 0,...,\\lambda_n \\geq 0\\}λ(A)={λ1​≥0,...,λn​≥0}都非负 定理 设A=Am∗nA=A_{m*n}A=Am∗n​,则AHA,AAHA^HA,AA^HAHA,AAH都半正定，特征根非负(利用二次型证明) 若A=Am∗nA=A_{m*n}A=Am∗n​为高阵，或方阵A可逆，则AHAA^HAAHA正定 Hermite阵的特征根都是实数 奇异值 正奇异值定义:给定 Am∗nA_{m*n}Am∗n​,则 AHA与AAHA^HA与AA^HAHA与AAH 有相同正根λ1≥λ2≥...λr&gt;0,r=r(A)\\lambda_1 \\geq \\lambda_2 \\geq ... \\lambda_r &gt;0,r=r(A)λ1​≥λ2​≥...λr​&gt;0,r=r(A),λ1,...λr\\sqrt{\\lambda_1},...\\sqrt{\\lambda_r}λ1​​,...λr​​叫做A的正奇异值,全体正奇异值记作s+(A)={λ1,...λr}s_+(A)=\\{\\sqrt{\\lambda_1},...\\sqrt{\\lambda_r}\\}s+​(A)={λ1​​,...λr​​},其中λ1\\sqrt{\\lambda_1}λ1​​为A的最大奇异值 奇异值定义:给定 Am∗nA_{m*n}Am∗n​,则 AHA与AAHA^HA与AA^HAHA与AAH 有相同非负根λ1≥λ2≥...λr≥0\\lambda_1 \\geq \\lambda_2 \\geq ... \\lambda_r \\geq 0λ1​≥λ2​≥...λr​≥0,λ1,...λr\\sqrt{\\lambda_1},...\\sqrt{\\lambda_r}λ1​​,...λr​​叫做A的奇异值,全体奇异值记作s(A)={λ1,...λr}s(A)=\\{\\sqrt{\\lambda_1},...\\sqrt{\\lambda_r}\\}s(A)={λ1​​,...λr​​} 奇异值分解 正SVD分解(短SVD分解)：设A=Am∗n,r=r(A)&gt;0A=A_{m*n},r=r(A)&gt;0A=Am∗n​,r=r(A)&gt;0,正奇异值为λ1,λ2,...,λr\\lambda_1,\\lambda_2,...,\\lambda_rλ1​,λ2​,...,λr​,则有分解A=PΔQHA=P\\Delta Q^HA=PΔQH,其中Δ=(λ1⋯0⋮⋱⋮0⋯λr)\\Delta=\\left(\\begin{array}{ccc}\\sqrt{\\lambda_{1}} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\cdots &amp; \\sqrt{\\lambda_{r}}\\end{array}\\right)Δ=⎝⎜⎜⎛​λ1​​⋮0​⋯⋱⋯​0⋮λr​​​⎠⎟⎟⎞​,P,Q为半优阵,PHP=I,QHQ=IP,Q为半优阵,P^HP=I,Q^HQ=IP,Q为半优阵,PHP=I,QHQ=I 将P,Q扩大为U阵W=(P1,P2),V=(Q1,Q2)W=(P_1,P_2),V=(Q_1,Q_2)W=(P1​,P2​),V=(Q1​,Q2​),可验证WDVH=W(Δ000)VH=PΔQH=AW \\mathrm{D} V^{H}=W\\left(\\begin{array}{ll}\\Delta &amp; 0 \\\\ 0 &amp; 0\\end{array}\\right) V^{H}=P \\Delta Q^{H}=AWDVH=W(Δ0​00​)VH=PΔQH=A 奇异分解(SVD)：设A有正奇异值λ1,λ2,...,λr&gt;0\\lambda_1,\\lambda_2,...,\\lambda_r &gt;0λ1​,λ2​,...,λr​&gt;0,则有A=WDVHA=W \\mathrm{D} V^{H}A=WDVH,其中D=(Δ000),W=Wm∗m,V=Vn∗n为两个优阵D = \\left(\\begin{array}{ll}\\Delta &amp; 0 \\\\ 0 &amp; 0\\end{array}\\right),W=W_{m*m},V=V_{n*n}为两个优阵D=(Δ0​00​),W=Wm∗m​,V=Vn∗n​为两个优阵 分解方法： 求AHAA^HAAHA的特征根,正奇值 求特征根对应的正交特向 令列优阵Q=(X1∣X1∣,⋯ ,Xr∣Xr∣);Q=\\left(\\frac{X_{1}}{\\left|X_{1}\\right|}, \\cdots, \\frac{X_{r}}{\\left|X_{r}\\right|}\\right) ; \\quadQ=(∣X1​∣X1​​,⋯,∣Xr​∣Xr​​);与P=(AX1∣AX1∣,⋯ ,AXr∣AXr∣)\\quad P=\\left(\\frac{A X_{1}}{\\left|A X_{1}\\right|}, \\cdots, \\frac{A X_{r}}{\\left|A X_{r}\\right|}\\right)P=(∣AX1​∣AX1​​,⋯,∣AXr​∣AXr​​),正SVD分解A=PΔQHA=P \\Delta Q^{H}A=PΔQH 可用观察扩充法求两个U阵,W=(P,Y),V=(Q,X)W=(P,Y),V=(Q,X)W=(P,Y),V=(Q,X),可得SVD公式A=WDVHA=W D V^{H}A=WDVH,D=(Δ000)D = \\left(\\begin{array}{ll}\\Delta &amp; 0 \\\\ 0 &amp; 0\\end{array}\\right)D=(Δ0​00​) 备注： 对于V=(Q,X)V=(Q,X)V=(Q,X),可解AX=0AX=0AX=0得XXX 对于W=(P,Y)W=(P,Y)W=(P,Y),可解AHY=0A^HY=0AHY=0得YYY 转置法： BH=A=WDVH→B=VDHWHB^H=A=WDV^H \\rightarrow B=VD^HW^HBH=A=WDVH→B=VDHWH 正规阵谱公式 正规分解复习 正规阵谱公式：若A=An∗nA=A_{n*n}A=An∗n​,全体互异根为λ1,...λk\\lambda_{1} ,...\\lambda_{k}λ1​,...λk​,则有A=λ1G1+...+λkGkA=\\lambda_1G_1+...+\\lambda_kG_kA=λ1​G1​+...+λk​Gk​，叫做A的谱分解 G1+G2+...GK=IG_1+G_2+...G_K=IG1​+G2​+...GK​=I G1G2=0,...,GiGj=0G_1G_2=0,...,G_iG_j=0G1​G2​=0,...,Gi​Gj​=0 G12=G1,...,Gk2=GkG_1^2=G_1,...,G_k^2=G_kG12​=G1​,...,Gk2​=Gk​(幂等),G1H=G1,...,GkH=GkG_1^H = G_1,...,G_k^H=G_kG1H​=G1​,...,GkH​=Gk​ AP=λ1PG1+...+λkPGkA^P=\\lambda_1^PG_1+...+\\lambda_k^PG_kAP=λ1P​G1​+...+λkP​Gk​ f(A)=f(λ1)G1+...+f(λk)Gkf(A)=f(\\lambda_1)G_1+...+f(\\lambda_k)G_kf(A)=f(λ1​)G1​+...+f(λk​)Gk​ G1=(A−λ1I)⋯⋯(A−λkI)(λ1−λ1)⋯⋯(λ1−λk)G_{1}=\\frac{\\left(A-\\lambda_{1} I\\right) \\cdots \\cdots\\left(A-\\lambda_{k} I\\right)}{\\left(\\lambda_{1}-\\lambda_{1}\\right) \\cdots \\cdots\\left(\\lambda_{1}-\\lambda_{k}\\right)}G1​=(λ1​−λ1​)⋯⋯(λ1​−λk​)(A−λ1​I)⋯⋯(A−λk​I)​,G2=(A−λ1I)(A−λ2I)⋯⋯(A−λkI)(λ2−λ1)(λ2−λ2)⋯⋯(λ2−λk)G_{2}=\\frac{\\left(A-\\lambda_{1} I\\right)\\left(A-\\lambda_{2} I\\right) \\cdots \\cdots\\left(A-\\lambda_{k} I\\right)}{\\left(\\lambda_{2}-\\lambda_{1}\\right)\\left(\\lambda_{2}-\\lambda_{2}\\right) \\cdots \\cdots\\left(\\lambda_{2}-\\lambda_{k}\\right)}G2​=(λ2​−λ1​)(λ2​−λ2​)⋯⋯(λ2​−λk​)(A−λ1​I)(A−λ2​I)⋯⋯(A−λk​I)​,⋯⋯\\cdots \\cdots⋯⋯,Gk=(A−λ1)⋯⋯(A−λk)(λk−λ1)⋯⋯(λk−λk)G_{k}=\\frac{\\left(A-\\lambda_{1}\\right) \\cdots \\cdots\\left(A-\\lambda_{k}\\right)}{\\left(\\lambda_{k}-\\lambda_{1}\\right) \\cdots \\cdots\\left(\\lambda_{k}-\\lambda_{k}\\right)}Gk​=(λk​−λ1​)⋯⋯(λk​−λk​)(A−λ1​)⋯⋯(A−λk​)​ 若A正规,只有两个不同根,公式G1=(A−λ2)λ1−λ2G_{1}=\\frac{\\left(A-\\lambda_{2}\\right)}{\\lambda_1-\\lambda_2}G1​=λ1​−λ2​(A−λ2​)​,G2=(A−λ1)λ2−λ1G_{2}=\\frac{\\left(A-\\lambda_{1}\\right)}{\\lambda_2-\\lambda_1}G2​=λ2​−λ1​(A−λ1​)​，G1+G2=IG_1+G_2=IG1​+G2​=I 若A正规,有三个不同根,公式G1=(A−λ2)(A−λ3)(λ1−λ2)(λ1−λ3)G_{1}=\\frac{(A-\\lambda_{2})(A-\\lambda_{3})}{(\\lambda_1-\\lambda_2)(\\lambda_1-\\lambda_3)}G1​=(λ1​−λ2​)(λ1​−λ3​)(A−λ2​)(A−λ3​)​,G1=(A−λ1)(A−λ3)(λ2−λ1)(λ2−λ3)G_{1}=\\frac{(A-\\lambda_{1})(A-\\lambda_{3})}{(\\lambda_2-\\lambda_1)(\\lambda_2-\\lambda_3)}G1​=(λ2​−λ1​)(λ2​−λ3​)(A−λ1​)(A−λ3​)​,G3=(A−λ1)(A−λ2)(λ3−λ1)(λ3−λ2)G_{3}=\\frac{(A-\\lambda_{1})(A-\\lambda_{2})}{(\\lambda_3-\\lambda_1)(\\lambda_3-\\lambda_2)}G3​=(λ3​−λ1​)(λ3​−λ2​)(A−λ1​)(A−λ2​)​ AG1=λ1G1,...AGk=λkGkAG_1=\\lambda_1G_1,...AG_k=\\lambda_kG_kAG1​=λ1​G1​,...AGk​=λk​Gk​,G1,G2,...,GkG_1,G_2,...,G_kG1​,G2​,...,Gk​中各列都是A的特征向量 分块法求Ak=(A100A2)k=(A1k00A2k)A^k=(\\begin{array}{ll}A_1 &amp; 0 \\\\ 0 &amp; A_2\\end{array})^k=(\\begin{array}{ll}A_1^k &amp; 0 \\\\ 0 &amp; A_2^k\\end{array})Ak=(A1​0​0A2​​)k=(A1k​0​0A2k​​) 单阵 单阵(单纯阵,可对角阵)定义: 若A=An∗nA=A_{n*n}A=An∗n​相似于对角形，即Q−1DQ=D=(λ10⋱0λn)Q^{-1}DQ=D=\\left(\\begin{array}{ccc}\\lambda_{1} &amp; &amp; 0 \\\\ &amp; \\ddots &amp; \\\\ 0 &amp; &amp; \\lambda_{n}\\end{array}\\right)Q−1DQ=D=⎝⎛​λ1​0​⋱​0λn​​⎠⎞​,称A为单纯阵 正规阵一定是单纯阵 充分条件：设n阶方阵A恰有n个不同根，则A为单阵 单阵的谱公式：若A为单阵，全体不同根为λ1,...,λk\\lambda_1,...,\\lambda_kλ1​,...,λk​,则有A=λ1G1+...+λkGkA=\\lambda_1G_1+...+\\lambda_kG_kA=λ1​G1​+...+λk​Gk​ 单阵的谱阵G1,...GkG_1,...G_kG1​,...Gk​是幂等阵，但是不一定为Hermite阵(正规阵谱分解) 单阵判定法：设λ1,...,λk\\lambda_1,...,\\lambda_kλ1​,...,λk​为A的全体不同根 若(A−λ1I)...(A−λk)I=0(A-\\lambda_1I)...(A-\\lambda_k)I=0(A−λ1​I)...(A−λk​)I=0则A为单阵(相似于对角形) 若(A−λ1I)...(A−λk)I≠0(A-\\lambda_1I)...(A-\\lambda_k)I \\not ={0}(A−λ1​I)...(A−λk​)I=0则A为单阵(相似于对角形) *极小式(0化式) 若λ1,...,λk\\lambda_1,...,\\lambda_kλ1​,...,λk​为不同根,且(A−λ1I)...(A−λk)I=0(A-\\lambda_1I)...(A-\\lambda_k)I=0(A−λ1​I)...(A−λk​)I=0,则A必是单阵,此时**m(x)=(x−λ1)(x−λ2)...(x−λk)m(x)=(x-\\lambda_1)(x-\\lambda_2)...(x-\\lambda_k)m(x)=(x−λ1​)(x−λ2​)...(x−λk​)为A的极小式** 0化式：若多项式f(x)符合f(A)=0,称f(x)为A的0化式 极小式：若多项式m(x)符合m(A)=0且m(x)具有最小次数,称m(x)为A的极小式 特征多项式一定是0化式 极小式鄙视特征式的因式 极小式必为每个0化式f(x)的因子 极小式m(x)的求法： 设∣xI−A∣=(x−a)2(x−b)|xI-A|=(x-a)^2(x-b)∣xI−A∣=(x−a)2(x−b)验(A−aI)(A−bI)=0是否成立(A-aI)(A-bI)=0是否成立(A−aI)(A−bI)=0是否成立，若成立则m(x)=(x−a)(x−b)m(x)=(x-a)(x-b)m(x)=(x−a)(x−b)，否则为m(x)=(x−a)2(x−b)2m(x)=(x-a)^2(x-b)^2m(x)=(x−a)2(x−b)2 |xI-A|=(x-a)(x-b)(x-c),则极小式为m(x)=(x−a)(x−b)(x−c)m(x)=(x-a)(x-b)(x-c)m(x)=(x−a)(x−b)(x−c) 补充验单法 已知n阶方阵A 若每个k&gt;1重根λ1\\lambda_1λ1​使得rank(A−λ1)=n−krank(A-\\lambda_1) = n-krank(A−λ1​)=n−k,则A为单阵 若有k&gt;1重根λ1\\lambda_1λ1​使得rank(A−λ1)≠n−krank(A-\\lambda_1) \\not ={n-k}rank(A−λ1​)=n−k,则A非单阵 补充引理 若(A−λ1I)P=0(A-\\lambda_1I)P=0(A−λ1​I)P=0,则P中非0列都是λ1\\lambda_1λ1​的特向 镜面阵 3个矩阵函数 常见解析函数f(x)与矩阵函数A,其中A为方阵 ex=1+x+12!x2+⋯+1k!xk+⋯⋯e^{x}=1+x+\\frac{1}{2 !} x^{2}+\\cdots+\\frac{1}{k !} x^{k}+\\cdots \\cdotsex=1+x+2!1​x2+⋯+k!1​xk+⋯⋯,则eA=1+A+12!A2+⋯+1k!Ak+⋯⋯e^{A}=1+A+\\frac{1}{2 !} A^{2}+\\cdots+\\frac{1}{k !} A^{k}+\\cdots \\cdotseA=1+A+2!1​A2+⋯+k!1​Ak+⋯⋯ 记eA=∑k=0∞1k!Ake^{\\mathbf{A}}=\\sum_{k=0}^{\\infty} \\frac{1}{k !} \\mathbf{A}^{k}eA=∑k=0∞​k!1​Ak sin⁡x=x−x33!+x55!−x77!+⋯⋯\\sin x=x-\\frac{x^{3}}{3 !}+\\frac{x^{5}}{5 !}-\\frac{x^{7}}{7 !}+\\cdots \\cdotssinx=x−3!x3​+5!x5​−7!x7​+⋯⋯,则sin⁡A=A−A33!+A55!−A77!+⋯⋯\\sin A=A-\\frac{A^{3}}{3 !}+\\frac{A^{5}}{5 !}-\\frac{A^{7}}{7 !}+\\cdots \\cdotssinA=A−3!A3​+5!A5​−7!A7​+⋯⋯ 记sin⁡A=∑k=0∞(−1)kA2k+1(2k+1)!\\sin \\mathbf{A}=\\sum_{\\mathrm{k}=0}^{\\infty}(-1)^{k} \\frac{\\mathbf{A}^{2 k+1}}{(2 k+1) !}sinA=∑k=0∞​(−1)k(2k+1)!A2k+1​ cos⁡x=x−x22!+x44!−x66!+⋯⋯\\cos x=x-\\frac{x^{2}}{2 !}+\\frac{x^{4}}{4 !}-\\frac{x^{6}}{6 !}+\\cdots \\cdotscosx=x−2!x2​+4!x4​−6!x6​+⋯⋯,则cos⁡A=A−A22!+A44!−A66!+⋯⋯\\cos A=A-\\frac{A^{2}}{2 !}+\\frac{A^{4}}{4 !}-\\frac{A^{6}}{6 !}+\\cdots \\cdotscosA=A−2!A2​+4!A4​−6!A6​+⋯⋯ 记cos⁡A=∑k=0∞(−1)kA2k(2k)!\\cos \\mathbf{A}=\\sum_{\\mathrm{k}=0}^{\\infty}(-1)^{k} \\frac{\\mathbf{A}^{2 k}}{(2 k) !}cosA=∑k=0∞​(−1)k(2k)!A2k​ 为了方便应用引入参数t etA=1+tA+12!tA2+⋯+1k!tAk+⋯⋯e^{tA}=1+tA+\\frac{1}{2 !} tA^{2}+\\cdots+\\frac{1}{k !} tA^{k}+\\cdots \\cdotsetA=1+tA+2!1​tA2+⋯+k!1​tAk+⋯⋯ sin⁡tA=tA−tA33!+tA55!−tA77!+⋯⋯\\sin tA=tA-\\frac{tA^{3}}{3 !}+\\frac{tA^{5}}{5 !}-\\frac{tA^{7}}{7 !}+\\cdots \\cdotssintA=tA−3!tA3​+5!tA5​−7!tA7​+⋯⋯ cos⁡tA=tA−tA22!+tA44!−tA66!+⋯⋯\\cos tA=tA-\\frac{tA^{2}}{2 !}+\\frac{tA^{4}}{4 !}-\\frac{tA^{6}}{6 !}+\\cdots \\cdotscostA=tA−2!tA2​+4!tA4​−6!tA6​+⋯⋯ 性质： e0=I,sin0=0,cos0=0e^0=I,sin0=0,cos0=0e0=I,sin0=0,cos0=0 cos(−A)=A,sin(−A)=−sin(A)cos(-A)=A,sin(-A)=-sin(A)cos(−A)=A,sin(−A)=−sin(A) eiA=cosA+isinAe^{iA}=cosA+isinAeiA=cosA+isinA,cos⁡A=12(eiA+e−iA)\\cos A=\\frac{1}{2}\\left(e^{i A}+e^{-i A}\\right)cosA=21​(eiA+e−iA),sin⁡A=12i(eiA−e−iA)\\sin A=\\frac{1}{2 i}\\left(e^{i A}-e^{-i A}\\right)sinA=2i1​(eiA−e−iA),eitA=costA+isintAe^{itA}=costA+isintAeitA=costA+isintA 交换公式，若AB=BAAB=BAAB=BA,则eAeB=eA+B=eBeAe^Ae^B=e^{A+B}=e^Be^AeAeB=eA+B=eBeA 特别公式:eAe−A=e−AeA=Ie^Ae^{-A}=e^{-A}e^A=IeAe−A=e−AeA=I 可逆公式:(eA)−1=e−A(e^A)^{-1}=e^{-A}(eA)−1=e−A 推论：令n方阵A=(ai,j)A=(a_{i,j})A=(ai,j​),则f(A)=eAf(A)=e^Af(A)=eA的行列式为det(eA)=∣eA∣=etr(A)det(e^A)=|e^A|=e^{tr(A)}det(eA)=∣eA∣=etr(A) 对幂等阵,若A2=AA^2=AA2=A,则etA=I+(et−1)Ae^{tA}=I+(e^t-1)AetA=I+(et−1)A 幂零阵 Ak=0A^k=0Ak=0,A称为幂零阵 幂零阵公式1：若Ak=0A^k=0Ak=0,f(x)为任一解析式,则f(A)=f(0)I+f′(0)A+f′′(0)2!A2+⋯+fk−1(0)(k−1)!Ak−1f(A)=f(0) I+f^{\\prime}(0) A+\\frac{f^{\\prime \\prime}(0)}{2 !} A^{2}+\\cdots+\\frac{f^{k-1}(0)}{(k-1) !} A^{k-1}f(A)=f(0)I+f′(0)A+2!f′′(0)​A2+⋯+(k−1)!fk−1(0)​Ak−1 幂零阵公式0：若(A−aI)k=0(A-aI)^k=0(A−aI)k=0,f(x)为任一解析式,则f(A)=f(a)I+f′(a)(A−a)+f′′(a)2!(A−a)2+⋯+fk−1(a)(k−1)!(A−a)k−1f(A)=f(a) I+f^{\\prime}(a) (A-a)+\\frac{f^{\\prime \\prime}(a)}{2 !} (A-a)^{2}+\\cdots+\\frac{f^{k-1}(a)}{(k-1) !} (A-a)^{k-1}f(A)=f(a)I+f′(a)(A−a)+2!f′′(a)​(A−a)2+⋯+(k−1)!fk−1(a)​(A−a)k−1 备注1:若Ak=0A^k=0Ak=0为幂零阵,则A的全体根λ(A)=0,0,...,0\\lambda(A)={0,0,...,0}λ(A)=0,0,...,0 备注2:若(A−aI)k=0(A-aI)^k=0(A−aI)k=0为幂零阵,则A的全体根λ(A)=a,a,...,a\\lambda(A)={a,a,...,a}λ(A)=a,a,...,a Jordan块 n阶上三角A=(a10a1⋱⋱⋱1a)n,nA=\\left(\\begin{array}{lllll}a &amp; 1 &amp; &amp; &amp; 0 \\\\ &amp; a &amp; 1 &amp; &amp; \\\\ &amp; &amp; \\ddots &amp; \\ddots &amp; \\\\ &amp; &amp; &amp; \\ddots &amp; 1 \\\\ &amp; &amp; &amp; &amp; a\\end{array}\\right)_{n, n}A=⎝⎜⎜⎜⎜⎜⎛​a​1a​1⋱​⋱⋱​01a​⎠⎟⎟⎟⎟⎟⎞​n,n​叫n阶Jordan块 可知λ=a\\lambda=aλ=a为n重根 若a=0,可得n阶0根Jordan块,A=(01001⋱⋱⋱10)n,n=(0,e1,e2,...,en−1A=\\left(\\begin{array}{lllll}0&amp; 1 &amp; &amp; &amp; 0 \\\\ &amp; 0 &amp; 1 &amp; &amp; \\\\ &amp; &amp; \\ddots &amp; \\ddots &amp; \\\\ &amp; &amp; &amp; \\ddots &amp; 1 \\\\ &amp; &amp; &amp; &amp; 0\\end{array}\\right)_{n, n}=(0,e_1,e_2,...,e_{n-1}A=⎝⎜⎜⎜⎜⎜⎛​0​10​1⋱​⋱⋱​010​⎠⎟⎟⎟⎟⎟⎞​n,n​=(0,e1​,e2​,...,en−1​,eje_{j}ej​为单位阵I的各列 Dn+1=0D^{n+1}=0Dn+1=0 定理:n阶Jordan块A=(a10a1⋱⋱⋱1a)n,nA=\\left(\\begin{array}{lllll}a &amp; 1 &amp; &amp; &amp; 0 \\\\ &amp; a &amp; 1 &amp; &amp; \\\\ &amp; &amp; \\ddots &amp; \\ddots &amp; \\\\ &amp; &amp; &amp; \\ddots &amp; 1 \\\\ &amp; &amp; &amp; &amp; a\\end{array}\\right)_{n, n}A=⎝⎜⎜⎜⎜⎜⎛​a​1a​1⋱​⋱⋱​01a​⎠⎟⎟⎟⎟⎟⎞​n,n​对任一解析式f(x)有公式:f(A)=(f(a)f′(a)12!f′′(a)⋯1(n−1)!f(n−1)(a)f(a)f′(a)⋯⋮⋱⋱12!f′′(a)f(a)f′(a)f(a))f(A)=\\left(\\begin{array}{ccccc}f(a) &amp; f^{\\prime}(a) &amp; \\frac{1}{2 !} f^{\\prime \\prime}(a) &amp; \\cdots &amp; \\frac{1}{(n-1) !} f^{(n-1)}(a) \\\\ &amp; f(a) &amp; f^{\\prime}(a) &amp; \\cdots &amp; \\vdots \\\\ &amp; &amp; \\ddots &amp; \\ddots &amp; \\frac{1}{2 !} f^{\\prime \\prime}(a) \\\\ &amp; &amp; &amp; f(a) &amp; f^{\\prime}(a) \\\\ &amp; &amp; &amp; &amp; f(a)\\end{array}\\right)f(A)=⎝⎜⎜⎜⎜⎜⎜⎛​f(a)​f′(a)f(a)​2!1​f′′(a)f′(a)⋱​⋯⋯⋱f(a)​(n−1)!1​f(n−1)(a)⋮2!1​f′′(a)f′(a)f(a)​⎠⎟⎟⎟⎟⎟⎟⎞​ 广谱公式:非单阵的f(A)公式 若A满足(A−aI)2(A−bI)=0,a≥b(A-aI)^2(A-bI)=0,a \\geq b(A−aI)2(A−bI)=0,a≥b,即A有0化式(x−a)2(x−b)(x-a)^2(x-b)(x−a)2(x−b),则有广谱公式f(A)=f(a)G1+f(b)G2+f′(a)D1,G1+G2=If(A)=f(a)G_1+f(b)G_2+f^{&#x27;}(a)D_1,G_1+G_2=If(A)=f(a)G1​+f(b)G2​+f′(a)D1​,G1​+G2​=I,其中G1,G2,D1为固定矩阵(广谱阵)G_1,G_2,D_1为固定矩阵(广谱阵)G1​,G2​,D1​为固定矩阵(广谱阵) 张量积 定义:设A=(ai,j)m∗n,B=(bi,j)p∗qA=(a_{i,j})_{m*n},B=(b_{i,j})_{p*q}A=(ai,j​)m∗n​,B=(bi,j​)p∗q​,称下面的分块矩阵为A与B的直积(张量积),(a11Ba12B⋯⋯a1nBa21Ba22B⋯⋯a2nB⋯⋯⋯⋯am1Bam2B⋯⋯amnB)mp×nq\\left(\\begin{array}{llll}a_{11} B &amp; a_{12} B \\cdots \\cdots &amp; a_{1 n} B \\\\ a_{21} B &amp; a_{22} B \\cdots \\cdots &amp; a_{2 n} B \\\\ \\cdots \\cdots \\cdots \\cdots &amp; &amp; \\\\ a_{m 1} B &amp; a_{m 2} B \\cdots \\cdots &amp; a_{m n} B\\end{array}\\right)_{m p \\times n q}⎝⎜⎜⎜⎛​a11​Ba21​B⋯⋯⋯⋯am1​B​a12​B⋯⋯a22​B⋯⋯am2​B⋯⋯​a1n​Ba2n​Bamn​B​⎠⎟⎟⎟⎞​mp×nq​,记作A⊗B=(aijB)mp×nqA \\otimes B=\\left(a_{i j} B\\right)_{m p \\times n q}A⊗B=(aij​B)mp×nq​ 定理1： 两个上三角阵的直积意识上三角阵 两个对角阵的直积仍是对角阵 In⊗Im=Im⊗In=Im∗nI_n \\otimes I_m = I_m \\otimes I_n = I_{m*n}In​⊗Im​=Im​⊗In​=Im∗n​ 推论1:设A=(α1,...,αt)n∗t,b=(β1,...,βt)p∗q(按列分块)A=(\\alpha_1,...,\\alpha_t)_{n*t},b=(\\beta_1,...,\\beta_t)_{p*q}(按列分块)A=(α1​,...,αt​)n∗t​,b=(β1​,...,βt​)p∗q​(按列分块),则A⊗B=(α1⊗β1,...,αt⊗βp)np∗tqA \\otimes B=(\\alpha_1\\otimes\\beta_1,...,\\alpha_t\\otimes\\beta_p)_{np*tq}A⊗B=(α1​⊗β1​,...,αt​⊗βp​)np∗tq​,记为A⊗B=(全列αi⊗βj)−−按字典次序A\\otimes B = (全列\\alpha_i\\otimes\\beta_j)--按字典次序A⊗B=(全列αi​⊗βj​)−−按字典次序 性质: 直积满足分配律,结合律,倍数关系 吸收律:(A⊗B)(C⊗D)=(AC)⊗(BD)(A\\otimes B)(C \\otimes D)=(AC)\\otimes(BD)(A⊗B)(C⊗D)=(AC)⊗(BD) 转置公式:(A⊗B)T=AT⊗BT,(A⊗B)H=AH⊗BH(A\\otimes B)^T = A^T \\otimes B^T,(A \\otimes B)^H=A^H \\otimes B^H(A⊗B)T=AT⊗BT,(A⊗B)H=AH⊗BH (A⊗B)−1=A−1⊗B−1(A \\otimes B)^{-1}=A^{-1} \\otimes B^{-1}(A⊗B)−1=A−1⊗B−1 秩公式:rank(A⊗B)=(rankA)(rankB)rank(A \\otimes B) = (rankA)(rankB)rank(A⊗B)=(rankA)(rankB) 设A为m阶方阵,B为n阶方阵,则tr(A⊗B)=trA∗trB,det(A⊗B)=(detA)n(detB)mtr(A \\otimes B) =trA*trB,det(A \\otimes B)=(detA)^n(detB)^mtr(A⊗B)=trA∗trB,det(A⊗B)=(detA)n(detB)m 推论2:若A为m阶方阵,B为n阶方阵,则 (A⊗B)k=Ak⊗Bk(A\\otimes B)^k=A^k \\otimes B^k(A⊗B)k=Ak⊗Bk (A⊗In)(Im⊗B)=(Im⊗B)(A⊗In)=A⊗B(A \\otimes I_n)(I_m \\otimes B)=(I_m \\otimes B)(A \\otimes I_n) = A \\otimes B(A⊗In​)(Im​⊗B)=(Im​⊗B)(A⊗In​)=A⊗B 推论3:若A,B为优阵,则A⊗BA \\otimes BA⊗B为优阵 推论4:设X1,...,XpX_1,...,X_pX1​,...,Xp​式p个线性无关的列向量,Y1,...,YqY_1,...,Y_qY1​,...,Yq​式q个线性无关的列向量,则全体pq个向量Xi⊗YjX_i \\otimes Y_jXi​⊗Yj​线性无关 张量积与特征值 定理1:设m阶方阵A的特征根为λ1,...λm\\lambda_1,...\\lambda_mλ1​,...λm​,n阶方阵B的特征根为t1,...,tnt_1,...,t_nt1​,...,tn​,则A⊗BA \\otimes BA⊗B的全体特征根恰为mn个λktj\\lambda_k t_jλk​tj​ 定理2:设m阶方阵A的特征根为λ1,...λm\\lambda_1,...\\lambda_mλ1​,...λm​,n阶方阵B的特征根为t1,...,tnt_1,...,t_nt1​,...,tn​ A⊗In+Im⊗BA \\otimes I_n + I_m \\otimes BA⊗In​+Im​⊗B的全体特征根恰为mn个λk+tj\\lambda_k +t_jλk​+tj​ A⊗In−Im⊗BA \\otimes I_n - I_m \\otimes BA⊗In​−Im​⊗B的全体特征根恰为mn个λk−tj\\lambda_k -t_jλk​−tj​ **矩阵的拉直 按行拉直为一个列向量,A⃗=(a11,a12,⋯ ,a1n,a21,a22,⋯ ,a2n,⋯ ,am1,am2,⋯ ,amn)T\\vec{A}=\\left(a_{11}, a_{12}, \\cdots, a_{1 n}, a_{21}, a_{22}, \\cdots, a_{2 n}, \\cdots, a_{m 1}, a_{m 2}, \\cdots, a_{m n}\\right)^{T}A=(a11​,a12​,⋯,a1n​,a21​,a22​,⋯,a2n​,⋯,am1​,am2​,⋯,amn​)T 性质: 线性公式A+b⃗=A⃗+B⃗\\vec{A+b}=\\vec{A}+\\vec{B}A+b​=A+B,kA⃗=kA⃗\\vec{kA}=k\\vec{A}kA=kA 拉直公式:ABC⃗=(A⊗CT)B⃗\\vec{ABC} = (A \\otimes C^T)\\vec{B}ABC=(A⊗CT)B 推论: AX⃗=(A⊗In)X⃗\\vec{AX} = (A \\otimes I_n)\\vec{X}AX=(A⊗In​)X XB⃗=(Im⊗BT)X⃗\\vec{XB} = (I_m \\otimes B^T)\\vec{X}XB=(Im​⊗BT)X AX+XB⃗=(A⊗In+Im⊗BT)X⃗\\vec{AX+XB} = (A \\otimes I_n + I_m \\otimes B^T)\\vec{X}AX+XB​=(A⊗In​+Im​⊗BT)X 方程求解 AX+XB=CAX+XB=CAX+XB=C:,利用拉直公式AX+XB⃗=(A⊗In+Im⊗BT)X⃗\\vec{AX+XB} = (A \\otimes I_n + I_m \\otimes B^T)\\vec{X}AX+XB​=(A⊗In​+Im​⊗BT)X将方程拉直为(A⊗In+Im⊗BT)X⃗=C⃗(A \\otimes I_n + I_m \\otimes B^T)\\vec{X} = \\vec{C}(A⊗In​+Im​⊗BT)X=C 广义逆 A+A^+A+定义:若m*n矩阵A与n*m矩阵适合四个条件,则X叫A的加号逆(伪逆,广义逆),即为X=A+X=A^+X=A+ AXA=A XAX=X (AX)H=AX(AX)^H=AX(AX)H=AX (XA)H=XA(XA)^H=XA(XA)H=XA A+A^+A+唯一定理:矩阵A存在A+A^+A+且唯一 性质 AA+A=AAA^+A=AAA+A=A A+AA+=A+A^+AA^+=A^+A+AA+=A+ (AA+)H=AA+(AA^+)^H=AA^+(AA+)H=AA+ (A+A)H=A+A(A^+A)^H=A^+A(A+A)H=A+A 幂等公式:(AA+)2=AA+,(A+A)2=A+A(AA^+)^2=AA^+,(A^+A)^2=A^+A(AA+)2=AA+,(A+A)2=A+A 例题 若A为优阵,则A+=AH=A−1A^+=A^H=A^{-1}A+=AH=A−1(假设A+=AHA^+=A^HA+=AH,验证四个条件) 若A为半优阵,则A+=AHA^+=A^HA+=AH(假设A+=AHA^+=A^HA+=AH,验证四个条件) 引理1(半优公式): 若A为列优阵AHA=IA^HA=IAHA=I,则A+=AHA^+=A^HA+=AH 若AHA^HAH为列优阵AAH=IAA^H=IAAH=I(A为行优阵),则A+=AHA^+=A^HA+=AH A+A^+A+第一公式:若A=Am∗nA=A_{m*n}A=Am∗n​有正SVD,A=PΔQH,(P,Q为半优阵)A=P\\Delta Q^H,(P,Q为半优阵)A=PΔQH,(P,Q为半优阵)，则有公式A+=QΔ−1PH,Δ+=Δ−1A^+=Q\\Delta^{-1}P^H,\\Delta^+=\\Delta^{-1}A+=QΔ−1PH,Δ+=Δ−1 A+A^+A+秩1公式:若r(A)=1,各列成比例r(A)=1,各列成比例r(A)=1,各列成比例,则A+=1∑∣aij∣2AH=1tr(AHA)AHA^{+}=\\frac{1}{\\sum\\left|a_{i j}\\right|^{2}} A^{H}=\\frac{1}{tr(A^HA)} A^HA+=∑∣aij​∣21​AH=tr(AHA)1​AH 分块公式:A=(A100A2)m⁡×nA=\\left(\\begin{array}{cc}A_{1} &amp; 0 \\\\ 0 &amp; A_{2}\\end{array}\\right)_{\\operatorname{m} \\times n}A=(A1​0​0A2​​)m×n​,则A+=(A1+00A2+)m⁡×nA^+=\\left(\\begin{array}{cc}A_{1}^+ &amp; 0 \\\\ 0 &amp; A_{2}^+\\end{array}\\right)_{\\operatorname{m} \\times n}A+=(A1+​0​0A2+​​)m×n​ 特注: 一般情况下A+A≠I,AA+≠I,A+A≠AA+A^+A \\not ={I},AA^+ \\not ={I},A^+A \\not ={AA^+}A+A=I,AA+=I,A+A=AA+ 一般情况下(AB)+≠A+B+(AB)^+ \\not ={A^+B^+}(AB)+=A+B+ 一般情况下(AB)+≠B+A+(AB)^+ \\not ={B^+A^+}(AB)+=B+A+,只有满秩分解时成立 引理2(优分解公式):设P,Q为优阵,则(PDQ)+=QHD+PH=Q+D+P+(PDQ)^+=Q^HD^+P^H=Q^+D^+P^+(PDQ)+=QHD+PH=Q+D+P+ 引理3:设D为对角形,则D+D=DD+D^+D=DD^+D+D=DD+ 定理:若A正规,则A+A=AA+A^+A=AA^+A+A=AA+,且(A+)k=(Ak)+(A^+)^k=(A^k)^+(A+)k=(Ak)+ QR公式:设A为高阵,且有QR分解,A=QR,Q为列优阵,则A+=R−1QHA^+=R^{-1}Q^HA+=R−1QH A+A^+A+的谱分解公式:A+=λ1+G1+⋯+λk+GkA^{+}=\\lambda_{1}^{+} G_{1}+\\cdots+\\lambda_{k}^{+} G_{k}A+=λ1+​G1​+⋯+λk+​Gk​,A+A^+A+非正规时不一定成立,A为单阵且可逆时一定成立 推论:若A正规,则A+A=AA+,(A+)p=(Ap)+A^+A=AA^+,(A^+)^p=(A^p)^+A+A=AA+,(A+)p=(Ap)+ 推论:若A正规,则A+正规,且(A+)p=(Ap)+A^+正规,且(A^+)^p=(A^p)^+A+正规,且(A+)p=(Ap)+ 补充A+A^+A+公式: A+=(AHA)+AHA^+=(A^HA)^+A^HA+=(AHA)+AH A+=AH(AAH)+A^+=A^H(AA^H)^+A+=AH(AAH)+ 高低阵引理: 若B为高阵(列满秩),则存在左逆阵BLB_LBL​使得BLB=IB_LB=IBL​B=I,其中BL=(BHB)−1BHB_L=(B^HB)^{-1}B^HBL​=(BHB)−1BH 若C为低阵(行满秩),则存在右逆阵CRC_RCR​使得CCR=ICC_R=ICCR​=I,其中CR=CH(CCH)−1C_R=C^H(CC^H)^{-1}CR​=CH(CCH)−1 高低广逆公式: 若A为高阵(列满秩),加号逆A+=(AHA)−1AHA^+=(A^HA)^{-1}A^HA+=(AHA)−1AH 若A为低阵(行满秩),加号逆A+=AH(AAH)−1A^+=A^H(AA^H)^{-1}A+=AH(AAH)−1 A+A^+A+第二公式:若有高低分解A=BC(满秩分解),则有公式A+=C+B+A^+=C^+B^+A+=C+B+,其中C+=CH(CCH)−1C^+=C^H(CC^H)^{-1}C+=CH(CCH)−1,B+=(BHB)−1BHB^+=(B^HB)^{-1}B^HB+=(BHB)−1BH,B+B=I,CC+=IB^+B=I,CC^+=IB+B=I,CC+=I A+A^+A+第三公式:A+=(AHA)+AHA^+=(A^HA)^+A^HA+=(AHA)+AH 张量的广逆公式:(A⊗B)+=A+⊗B+(A \\otimes B)^+=A^+ \\otimes B^+(A⊗B)+=A+⊗B+ 常见分块公式: (A100A2)+=(A1+00A2+)\\left(\\begin{array}{cc}A_{1} &amp; 0 \\\\ 0 &amp; A_{2}\\end{array}\\right)^{+}=\\left(\\begin{array}{cc}A_{1}^{+} &amp; 0 \\\\ 0 &amp; A_{2}^{+}\\end{array}\\right)(A1​0​0A2​​)+=(A1+​0​0A2+​​) (0A1A20)+=(0A2+A1+0)\\left(\\begin{array}{cc}0 &amp; A_{1} \\\\ A_{2} &amp; 0\\end{array}\\right)^{+}=\\left(\\begin{array}{cc}0 &amp; A_{2}^{+} \\\\ A_{1}^{+} &amp; 0\\end{array}\\right)(0A2​​A1​0​)+=(0A1+​​A2+​0​) 正规方程 AHAx=AHbA^HAx=A^HbAHAx=AHb叫Ax=bAx=bAx=b的正规方程 正规方程AHAx=AHbA^HAx=A^HbAHAx=AHb必有特解x0=A+bx_0=A^+bx0​=A+b,使AHAx0=AHbA^HAx_0=A^HbAHAx0​=AHb 推论:正规方程AHAx=AHbA^HAx=A^HbAHAx=AHb必有解,方程Ax=bAx=bAx=b可能无解 特解定理:若Ax=bAx=bAx=b有解(相容),则必有特解x0=A+bx_0=A^+bx0​=A+b 无解定理:若x0=A+b使Ax0≠bx_0=A^+b使Ax_0 \\not ={b}x0​=A+b使Ax0​=b,则Ax=bAx=bAx=b无解(不相容) 子空间 子空间定义:设W⊂Cn(非空集合)W \\subset \\mathrm{C}^{\\mathrm{n}}(非空集合)W⊂Cn(非空集合),若对∀α,β∈W\\forall \\boldsymbol{\\alpha}, \\boldsymbol{\\beta} \\in W∀α,β∈W, 有 α+β∈W\\boldsymbol{\\alpha}+\\boldsymbol{\\beta} \\in Wα+β∈W(对加法封闭),对∀α∈W,k∈C\\forall \\boldsymbol{\\alpha} \\in W, \\boldsymbol{k} \\in C∀α∈W,k∈C, 有 kα∈W\\boldsymbol{k\\alpha} \\in Wkα∈W(对数乘封闭),称W为CnC^nCn中的子空间(简称空间) 推论1:子空间W一定含有0⃗∈W\\vec{0} \\in W0∈W,且子空间对线性组合封闭 推论2:子空间W一定含有0⃗∈W\\vec{0} \\in W0∈W;若W不含0向量,则W不是子空间 生成子空间:设α1,...αm∈Cn,W=x=k1α1+...+kmαm∣kj∈C,j=1,...,m\\alpha_1,...\\alpha_m \\in C^n,W={x=k_1\\alpha_1+...+k_m\\alpha_m|k_j \\in C,j=1,...,m}α1​,...αm​∈Cn,W=x=k1​α1​+...+km​αm​∣kj​∈C,j=1,...,m,称W为由α1,...αm\\alpha_1,...\\alpha_mα1​,...αm​生成的子空间,记为W=L(α1,...,αm)W=L(\\alpha_1,...,\\alpha_m)W=L(α1​,...,αm​) 基定义:若子空间W中有r个向量α1,...,αr\\alpha_1,...,\\alpha_rα1​,...,αr​线性无关,W中任一α\\alphaα可由α1,...,αr\\alpha_1,...,\\alpha_rα1​,...,αr​表示，称[α1,...,αr][\\alpha_1,...,\\alpha_r][α1​,...,αr​]为W的一个基,r叫做W的维数,记作dimW=rdim W =rdimW=r 基性质1:设W是r维子空间(dim W=r),则W中任r+1个向量必线性相关 基性质2:W的基[α1,...,αr][\\alpha_1,...,\\alpha_r][α1​,...,αr​]必是向量组W的一个极大无关组 基性质3:若dim W=r,则W中任取r个线性无关向量都是W的基 备注:矩阵A=Am∗n∈Cm∗nA=A_{m*n} \\in C^{m*n}A=Am∗n​∈Cm∗n产生两个子空间:值域R(A)⊂CmR(A) \\subset C^mR(A)⊂Cm,核空间N(A)⊂Cn\\mathrm{N}(A) \\subset \\mathrm{C}^{\\mathrm{n}}N(A)⊂Cn A=Am,nA=A_{m,n}A=Am,n​的值域为R(A)=y=AX∣X∈Cn⊂CmR(A)={y=AX|X \\in C^n} \\subset C^mR(A)=y=AX∣X∈Cn⊂Cm也叫列空间,令A=(α1,...αn)A=(\\alpha_1,...\\alpha_n)A=(α1​,...αn​),可写R(A)=L(α1,...,αn)R(A)=L(\\alpha_1,...,\\alpha_n)R(A)=L(α1​,...,αn​) 维数=秩数:dimR(A)=rank(A)dim R(A) = rank(A)dimR(A)=rank(A) 值域可以用CmC^mCm中过原点的一个平面表示 A=Am,nA=A_{m,n}A=Am,n​的核空间为N(A)=X∈Cm∣AX=0⊂CnN(A)={X \\in C^m | AX=0} \\subset C^nN(A)=X∈Cm∣AX=0⊂Cn 维数公式:dimN(A)=n−rank(A)dim N(A) = n- rank(A)dimN(A)=n−rank(A) 核空间可以用CmC^mCm中过原点的一个平面表示 维数公式:dim N(A) + dim R(A) = n 正交引理1: CnC^nCn中正交引理:任取向量b∈Cnb \\in C^nb∈Cn,令x0=A+b∈Cnx_0=A^+b \\in C^nx0​=A+b∈Cn,则有x0⊥N(A)x_{0} \\perp \\mathrm{N}(A)x0​⊥N(A),即x0⊥x,∀x∈N(A)=x∣Ax=0x_{0} \\perp x ,\\forall x \\in N(A)={x|Ax=0}x0​⊥x,∀x∈N(A)=x∣Ax=0 推论1:若x0=A+b,则∣x0+x∣2=∣x0∣2+∣x∣2≥∣X0∣2(∣x0∣2最小)x_0=A^+b,则|x_0+x|^2=|x_0|^2+|x|^2 \\geq |X_0|^2(|x_0|^2最小)x0​=A+b,则∣x0​+x∣2=∣x0​∣2+∣x∣2≥∣X0​∣2(∣x0​∣2最小) 推论2:若Ax=bAx=bAx=b有特解x0x_0x0​,则通解公式为x=x0+w,∀w∈N(A)x=x_0+w,\\forall w \\in N(A)x=x0​+w,∀w∈N(A) 最小范数解定理:若Ax=bAx=bAx=b有解(相容),则x0=A+bx_0=A^+bx0​=A+b为最小范数解 正交引理2: CmC^mCm中正交引理:任取向量b∈Cmb \\in C^mb∈Cm,令x0=A+b∈Cnx_0=A^+b \\in C^nx0​=A+b∈Cn,则有(b−Ax0)⊥R(A)(b-Ax_{0}) \\perp \\mathrm{R}(A)(b−Ax0​)⊥R(A) 推论1:若x0=A+b,则∣Ax−b∣2≥∣Ax0−b∣2(为最小)x_0=A^+b,则|Ax-b|^2 \\geq |Ax_0-b|^2(为最小)x0​=A+b,则∣Ax−b∣2≥∣Ax0​−b∣2(为最小) 结论:仅当A(x−x0)=0A(x-x_0)=0A(x−x0​)=0时∣Ax−b∣2|Ax-b|^2∣Ax−b∣2取到最小值∣Ax−b∣2=∣Ax0−b∣2|Ax-b|^2 = |Ax_0-b|^2∣Ax−b∣2=∣Ax0​−b∣2 最小二乘解 定义:若∣Ax0−b∣2\\left|A x_{0}-b\\right|^{2}∣Ax0​−b∣2取到最小:∣Ax0−b∣2=min⁡{∣Ax−b∣2∣x∈Cn}\\left|A x_{0}-b\\right|^{2}=\\min \\left\\{|A x-b|^{2} \\mid x \\in C^{n}\\right\\}∣Ax0​−b∣2=min{∣Ax−b∣2∣x∈Cn}最小值,则x0x_0x0​叫Ax=bAx=bAx=b的一个最小二乘解(极小二乘解), 简称“小二解” 定理1:若Ax=b无解(不相容)Ax=b无解(不相容)Ax=b无解(不相容),则x0=A+bx_0=A^+bx0​=A+b恰是一个最小二乘解,且全体最小二乘解公式为x=x0+w,w∈N(A)x=x_0+w,w \\in N(A)x=x0​+w,w∈N(A),即x=x0+w=x0+(t1Y1+...+tkYk),w=t1Y1+...+tkYk,k=n−r(A),其中Y1,...,Yk为Ax=0的基本解x=x_0+w=x_0+(t_1Y_1+...+t_kY_k),w=t_1Y_1+...+t_kY_k,k=n-r(A),其中Y_1,...,Y_k为Ax=0的基本解x=x0​+w=x0​+(t1​Y1​+...+tk​Yk​),w=t1​Y1​+...+tk​Yk​,k=n−r(A),其中Y1​,...,Yk​为Ax=0的基本解 定理2:若Ax=b无解(不相容)Ax=b无解(不相容)Ax=b无解(不相容),则x0=A+bx_0=A^+bx0​=A+b是最小范数的最小二乘解(最佳小二解) 备注: 若A=Am∗nA=A_{m*n}A=Am∗n​列满秩(高阵),则有N(A)=0⃗N(A)={\\vec{0}}N(A)=0,即AX=0AX=0AX=0只有零解X=0⃗X=\\vec{0}X=0 若Ax=bAx=bAx=b不相容,且A为高阵,则x0=A+bx_0=A^+bx0​=A+b时唯一最小二乘解(也是最佳二乘解) **其他通解公式 定理1:齐次方程Ax=0Ax=0Ax=0必有通解公式x=(In−A+A)y,∀y∈Cnx=(I_n-A^+A)y, \\forall y \\in C^nx=(In​−A+A)y,∀y∈Cn 备注:可写核空间公式N(A)=w=(In−A+A)y∣y∈CnN(A)={w=(I_n-A^+A)y|y \\in C^n}N(A)=w=(In​−A+A)y∣y∈Cn 定理2:非齐次方程Ax=bAx=bAx=b必有解,则有通解公式x=(A+b)+(In−A+A)y,∀y∈Cnx=(A^+b)+(I_n-A^+A)y, \\forall y \\in C^nx=(A+b)+(In​−A+A)y,∀y∈Cn 定理3:Ax=bAx=bAx=b的全体小二解公式为x=x0+w,w∈N(A),x0=A+b,x=(A+b)+(In−A+A)yx=x_0+w,w \\in N(A),x_0=A^+b,x=(A^+b)+(I_n-A^+A)yx=x0​+w,w∈N(A),x0​=A+b,x=(A+b)+(In​−A+A)y 引理:A=Am∗n,b∈CmA=A_{m*n},b \\in C^mA=Am∗n​,b∈Cm,则x0=A+bx_0=A^+bx0​=A+b适合AHAx0−AHb=0A^HAx_0-A^Hb=0AHAx0​−AHb=0 推论:∀A=Am∗n,∀binCm,→AHAx=AHb\\forall A=A_{m*n}, \\forall b in C^m,\\rightarrow A^HAx=A^Hb∀A=Am∗n​,∀binCm,→AHAx=AHb必有解 广逆补充** 定理1:若矩阵方程AXB=DAXB=DAXB=D有解(相容),则有特解x0=A+DB+x_0=A^+DB^+x0​=A+DB+ 推论(无解定理):若x0=A+DB+x_0=A^+DB^+x0​=A+DB+使得AX0B≠DAX_0B \\not ={D}AX0​B=D,则无解(不相容) 备注1:齐次方程AXB=0AXB=0AXB=0必有通解公式X=Y−A+AYBB+X=Y-A^+AYBB^+X=Y−A+AYBB+,Y是适当阶数的任一矩阵 定理2:若AXB=DAXB=DAXB=D有解,令X0=A+DB+X_0=A^+DB^+X0​=A+DB+,必有通解公式X=X0+(Y−A+AYBB+)X=X_0+(Y-A^+AYBB^+)X=X0​+(Y−A+AYBB+) 特别结论矩阵方程AXA=AAXA=AAXA=A必有解,且特解x0=A+AA+=A+x_0=A^+AA^+=A^+x0​=A+AA+=A+,且有通解X=X0+(Y−A+AYAA+)X=X_0+(Y-A^+AYAA^+)X=X0​+(Y−A+AYAA+) 其他广逆简介 1号逆或减号逆定义:若AXA=A,则称X为A的一个减号逆,记作A−或A(1)A^-或A^(1)A−或A(1) 减号逆满足AA−A=AAA^-A=AAA−A=A 求法:任意矩阵的全体减号逆通解公式为A−=X=A++(Y−A+AYAA+)A^-=X=A^++(Y-A^+AYAA^+)A−=X=A++(Y−A+AYAA+) 引理1:若A=(Ir000)m,nA=\\left(\\begin{array}{cc}I_{r} &amp; 0 \\\\ 0 &amp; 0\\end{array}\\right)_{m, n}A=(Ir​0​00​)m,n​为标准行,则全体A−=(IrBCD)n,mA^{-}=\\left(\\begin{array}{ll}I_{r} &amp; B \\\\ C &amp; D\\end{array}\\right)_{n, m}A−=(Ir​C​BD​)n,m​ 补充公式1:若PAQ=(Ir000)m,nP A Q=\\left(\\begin{array}{ll}I_{r} &amp; 0 \\\\ 0 &amp; 0\\end{array}\\right)_{m, n}PAQ=(Ir​0​00​)m,n​,则全体A−=Q(IrBCD)n,mPA^{-}=Q\\left(\\begin{array}{ll}I_{r} &amp; B \\\\ C &amp; D\\end{array}\\right)_{n, m} PA−=Q(Ir​C​BD​)n,m​P 补充定理2:N(A)或AY=0N(A)或AY=0N(A)或AY=0的通解为Y=(I−A−A)y,∀y∈CnY=(I-A^-A)y,\\forall y \\in C^nY=(I−A−A)y,∀y∈Cn 补充定理3:若Ax=bAx=bAx=b有解,令x0=A−bx_0=A^-bx0​=A−b,则有通解公式x=x0+(In−A−A)y,∀y∈Cnx=x_0+(I_n-A^-A)y,\\forall y \\in C^nx=x0​+(In​−A−A)y,∀y∈Cn 性质: (A−A)2=A−A(A^-A)^2=A^-A(A−A)2=A−A (AA−)2=AA−(AA^-)^2=AA^-(AA−)2=AA− rank(AA−)=rank(A)rank(AA^-)=rank(A)rank(AA−)=rank(A) rank(A−A)=rank(A)rank(A^-A)=rank(A)rank(A−A)=rank(A) 定义1:A(1,3)=x∣AXA=A,(AX)H=AXA^{(1,3)}={x|AXA=A,(AX)^H=AX}A(1,3)=x∣AXA=A,(AX)H=AX 定义2:A(1,4)=x∣AXA=A,(XA)H=XAA^{(1,4)}={x|AXA=A,(XA)^H=XA}A(1,4)=x∣AXA=A,(XA)H=XA 引理1:A(1,3)=x∣AHAX=AHA^{(1,3)}={x|A^HAX=A^H}A(1,3)=x∣AHAX=AH 引理2:A(1,4)=x∣XAAH=AHA^{(1,4)}={x|XAA^H=A^H}A(1,4)=x∣XAAH=AH 引理3:A(1,3)=x∣AX=AA+A^{(1,3)}={x|AX=AA^+}A(1,3)=x∣AX=AA+,A(1,4)=x∣XA=A+AA^{(1,4)}={x|XA=A^+A}A(1,4)=x∣XA=A+A 矩阵函数求导公式 设A(x)=(ai,j(x))m∗nA(x)=(a_{i,j}(x))_{m*n}A(x)=(ai,j​(x))m∗n​的元素都是x的可导函数,定义A(x)A(x)A(x)关于x的求导为A′(x)=ddxA(x)=(ddxaij(x))m×nA^{\\prime}(x)=\\frac{d}{d x} A(x)=\\left(\\frac{d}{d x} a_{i j}(x)\\right)_{m \\times n}A′(x)=dxd​A(x)=(dxd​aij​(x))m×n​,同理可得积分式 常见三个矩阵函数 f(At)=etA,cos(tA),sin(tA)f(At)=e^{tA},cos(tA),sin(tA)f(At)=etA,cos(tA),sin(tA) 定理:设方阵A∈Cn∗nA \\in C^{n*n}A∈Cn∗n,则 ddxeAt=AeAt=eAtA\\frac{d}{d x} e^{At} = Ae^{At}= e^{At}Adxd​eAt=AeAt=eAtA ddxsinAt=AcosAt=cosAtA\\frac{d}{d x} sin{At} = Acos{At}= cos{At}Adxd​sinAt=AcosAt=cosAtA ddxcosAt=−AsinAt=−(sinAt)A\\frac{d}{d x} cos{At} = -Asin{At}= -(sinAt)Adxd​cosAt=−AsinAt=−(sinAt)A 备注 公式ddxeAt=AeAt=eAtA\\frac{d}{d x} e^{At} = Ae^{At}= e^{At}Adxd​eAt=AeAt=eAtA用-A替换A可得ddxe−At=−Ae−At\\frac{d}{d x} e^{-At} = -Ae^{-At}dxd​e−At=−Ae−At ddt(e−ttX(t))=−Ae−tAX(t)+e−tAX′(t)=e−tA(X′(t)−AX(t))\\frac{d}{d \\mathrm{t}}\\left(e^{-t t} \\mathrm{X}(\\mathrm{t})\\right)=-A e^{-t A} \\mathrm{X}(\\mathrm{t})+e^{-t A} \\mathrm{X}^{\\prime}(\\mathrm{t})=e^{-t A}\\left(\\mathrm{X}^{\\prime}(\\mathrm{t})-A \\mathrm{X}(\\mathrm{t})\\right)dtd​(e−ttX(t))=−Ae−tAX(t)+e−tAX′(t)=e−tA(X′(t)−AX(t)) 求解微分方程 定理1:齐次方程dxdt=Ax,x(0)=c⃗\\frac{dx}{d t}= Ax,x(0)= \\vec{c}dtdx​=Ax,x(0)=c,其中x=(x1(t),...,xn(t))T,A=An∗nx=(x_1(t),...,x_n(t))^T,A=A_{n*n}x=(x1​(t),...,xn​(t))T,A=An∗n​为常数矩阵,有唯一解公式x=eAtc⃗,即x=eAtx(0)x=e^{At}\\vec{c},即x=e^{At}x(0)x=eAtc,即x=eAtx(0) 定理2:齐次方程dYdt=AY+YB,Y(0)=D,Y=(yij(t))n×p,A=An,n,B=Bp,p\\frac{d Y}{d t}=A Y+Y B, Y(0)=D, Y=\\left(y_{i j}(t)\\right)_{n \\times p}, A=A_{n, n}, B=B_{p, p}dtdY​=AY+YB,Y(0)=D,Y=(yij​(t))n×p​,A=An,n​,B=Bp,p​有唯一解公式Y=e(At)De(Bt)Y=e^(At)De^(Bt)Y=e(At)De(Bt),即Y=eAtY(0)eBtY=e^{At}Y(0)e^{Bt}Y=eAtY(0)eBt 备注:非齐次方程{dx(t)dt=Ax(t)+f(t),x(t0)=c⃗( 初始条件 )\\left\\{\\begin{array}{l}\\frac{d x(t)}{d t}=\\mathrm{A} x(t)+f(t), \\\\ x\\left(t_{0}\\right)=\\vec{c}(\\text { 初始条件 })\\end{array}\\right.{dtdx(t)​=Ax(t)+f(t),x(t0​)=c( 初始条件 )​有唯一解x(t)=eA(t−t0)c⃗+eAt∫t0te−Auf(u)dux(t)=e^{A\\left(t-t_{0}\\right)} \\vec{c}+e^{A t} \\int_{t_{0}}^{t} \\mathrm{e}^{-A u} f(u) d ux(t)=eA(t−t0​)c+eAt∫t0​t​e−Auf(u)du 备注公式: 设A=(01−10)A=\\left(\\begin{array}{cc}0 &amp; 1 \\\\ -1 &amp; 0\\end{array}\\right)A=(0−1​10​) 则有 etA=(cos⁡tsin⁡t−sin⁡tcos⁡t)e^{tA}=\\left(\\begin{array}{cc}\\cos t &amp; \\sin t \\\\ -\\sin t &amp; \\cos t\\end{array}\\right)etA=(cost−sint​sintcost​) e(0at−at0)=(cos⁡atsin⁡at−sin⁡atcos⁡at)e^{\\left(\\begin{array}{cc}0 &amp; a t \\\\ -a t &amp; 0\\end{array}\\right)}=\\left(\\begin{array}{cc}\\cos a t &amp; \\sin a t \\\\ -\\sin a t &amp; \\cos a t\\end{array}\\right)e(0−at​at0​)=(cosat−sinat​sinatcosat​) 范数理论 谱半径定义:称ρ(A)=max⁡{∣λ1∣,∣λ2∣,⋯ ,∣λn∣}\\rho(A)=\\max \\left\\{\\left|\\lambda_{1}\\right|,\\left|\\lambda_{2}\\right|, \\cdots,\\left|\\lambda_{n}\\right|\\right\\}ρ(A)=max{∣λ1​∣,∣λ2​∣,⋯,∣λn​∣}为方阵的谱半径,其中方阵A的特征根λ(A)={λ1,...,λn}\\lambda(A)=\\{\\lambda_1,...,\\lambda_n\\}λ(A)={λ1​,...,λn​} 备注:任一方阵A=An∗nA=A_{n*n}A=An∗n​,必有ρ(A)≥0(非负性)\\rho(A) \\geq 0 (非负性)ρ(A)≥0(非负性) 谱半径性质:(齐次公式)ρ(kA)=∣k∣ρ(A)\\rho (kA) =|k| \\rho (A)ρ(kA)=∣k∣ρ(A) 幂公式:ρ(Ak)=∣k∣ρ(A)\\rho(A^k)=|k| \\rho(A)ρ(Ak)=∣k∣ρ(A) 谱范不等式:ρ(A)≤∣∣A∣∣\\rho(A) \\leq ||A||ρ(A)≤∣∣A∣∣,对一起矩阵范数||A||成立 向量范数 向量空间CnC^nCn中的模长公式:∣x∣=(x,x)=xHx=tr(xHx)=∣x1∣2+...+∣xn∣2|x|=\\sqrt{(x,x)}=\\sqrt{x^Hx}=\\sqrt{tr(x^Hx)}=\\sqrt{|x_1|^2+...+|x_n|^2}∣x∣=(x,x)​=xHx​=tr(xHx)​=∣x1​∣2+...+∣xn​∣2​ 性质:正性,齐性,三角性 线性空间(向量空间)中范数定义 定义1:设V是数域F(实数或复数域)上线性空间,若对于任一x∈Vx \\in Vx∈V,对应一个非负数,记为∣∣x∣∣||x||∣∣x∣∣,满足一下3个条件,则称∣∣x∣∣||x||∣∣x∣∣为空间V上一个向量范数:1.正性,2.齐次性,3.三角不等式 备注:空间V上一个向量范数就是V上一个非负函数ϕ(x)=∣∣x∣∣,x∈V\\phi(x)=||x||,x \\in Vϕ(x)=∣∣x∣∣,x∈V满足三个条件:1.正性,2.齐次性,3.三角不等式 定义2:若线性空间V上有一个函数ϕ(x),x∈V\\phi (x),x \\in Vϕ(x),x∈V适合1.正性,2.齐次性,3.三角不等式,则称ϕ(x)\\phi (x)ϕ(x)为V上的一个范数,记作ϕ(x)=∣∣x∣∣\\phi (x) = ||x||ϕ(x)=∣∣x∣∣ 常用范数,令向量x=(x1,...,xn)T∈Cnx=(x_1,...,x_n)^T \\in C^nx=(x1​,...,xn​)T∈Cn 1 范数: ∥x∥1=∑∣xj∣=∣x1∣+⋯+∣xn∣\\|\\mathrm{x}\\|_{1}=\\sum\\left|x_{j}\\right|=\\left|x_{1}\\right|+\\cdots+\\left|x_{n}\\right|∥x∥1​=∑∣xj​∣=∣x1​∣+⋯+∣xn​∣ 2 范数: ∥x∥2=∣x∣=(x,x)=∣x1∣2+⋯+∣xn∣2\\|\\mathrm{x}\\|_{2}=|\\mathrm{x}|=\\sqrt{(\\mathrm{x}, \\mathrm{x})}=\\sqrt{\\left|x_{1}\\right|^{2}+\\cdots+\\left|x_{n}\\right|^{2}}∥x∥2​=∣x∣=(x,x)​=∣x1​∣2+⋯+∣xn​∣2​ ∞\\infty∞ 范数: ∥x∥∞=max⁡{∣x1∣,⋯ ,∣xn∣}\\|\\mathrm{x}\\|_{\\infty}=\\max \\left\\{\\left|x_{1}\\right|, \\cdots,\\left|x_{n}\\right|\\right\\}∥x∥∞​=max{∣x1​∣,⋯,∣xn​∣} ppp-范数: ∥x∥p=(∑i=1n∣xi∣p)1p,p≥1;\\|\\mathrm{x}\\|_{p}=\\left(\\sum_{i=1}^{n}\\left|x_{i}\\right|^{p}\\right)^{\\frac{1}{p}}, \\quad p \\geq 1 ;∥x∥p​=(∑i=1n​∣xi​∣p)p1​,p≥1; 向量范数的性质: 单位化公式 ∣∣−x∣∣=−∣∣x∣∣||-x||=-||x||∣∣−x∣∣=−∣∣x∣∣ ∣∣x−y∣∣≥∣∣x∣∣−∣∣y∣∣||x-y|| \\geq ||x||-||y||∣∣x−y∣∣≥∣∣x∣∣−∣∣y∣∣ CnC^nCn上范数等价性: 定理CnC^nCn上任两个范数∣∣x∣∣a,∣∣x∣∣b||x||_a,||x||_b∣∣x∣∣a​,∣∣x∣∣b​存在任意正数k1&gt;0,k2&gt;0k_1&gt;0,k_2&gt;0k1​&gt;0,k2​&gt;0使k_{1}|\\mathrm{x}|{b} \\leq|\\mathrm{x}|{a} \\leq k_{2}|\\mathrm{x}|_{b}对一切x成立,简称这两个范数等价 收敛定义:设CnC^nCn中向量序列x(k)=(x1(k),...,xn(k)),α=(α1,...,αn)Tx^{(k)}=(x_1^{(k)},...,x_n^{(k)}),\\alpha=(\\alpha_1,...,\\alpha_n)^Tx(k)=(x1(k)​,...,xn(k)​),α=(α1​,...,αn​)T,若 x1(k)→a1,x2(k)→a2,⋯ ,xn(k)→an,(k→∞)x_{1}^{(k)} \\rightarrow a_{1}, x_{2}^{(k)} \\rightarrow a_{2}, \\cdots, x_{n}^{(k)} \\rightarrow a_{n},(k \\rightarrow \\infty)x1(k)​→a1​,x2(k)​→a2​,⋯,xn(k)​→an​,(k→∞),称 x(k)→α(k→∞),x^{(k)} \\rightarrow \\alpha(k \\rightarrow \\infty), \\quadx(k)→α(k→∞), 或 lim⁡x(k)=α\\lim x^{(k)}=\\alphalimx(k)=α 收敛引理:x(k)→α↔∣∣x(k)−a∣∣→0x^{(k)} \\rightarrow \\alpha \\leftrightarrow ||x^{(k)}-a|| \\rightarrow 0x(k)→α↔∣∣x(k)−a∣∣→0 矩阵范数 矩阵范数定义1:对于任意方阵A,矩阵范数∣∣A∣∣||A||∣∣A∣∣表示按某个法则与A对应的非负函数ϕ(A)\\phi (A)ϕ(A)满足四个条件:正性,齐性,三角性,相容性(次乘性),满足四个条件的矩阵范数∣∣A∣∣||A||∣∣A∣∣叫做相容范数 常用矩阵范数: 列范数 (最大列和): ∥A∥1=max⁡j∑i=1n∣aij∣（j=1,2,⋯ ,n;\\|\\mathbf{A}\\|_{1}=\\max_{j} \\sum_{i=1}^{n}\\left|a_{i j}\\right| （ j=1,2, \\cdots, n ;∥A∥1​=maxj​∑i=1n​∣aij​∣（j=1,2,⋯,n; 行范数 (最大行和): ∥A∥∞=max⁡i∑j=1n∣aij∣(i=1,2,,⋯ ,n)\\|\\mathbf{A}\\|_{\\infty}=\\max_{i} \\sum_{j=1}^{n}\\left|a_{i j}\\right|(i=1,2,, \\cdots, n)∥A∥∞​=maxi​∑j=1n​∣aij​∣(i=1,2,,⋯,n); 谱范数: ∥A∥2=(λ1(AHA))1/2,λ1(AHA)\\|\\mathbf{A}\\|_{2}=\\left(\\lambda_{1}\\left(\\mathbf{A}^{H} \\mathbf{A}\\right)\\right)^{1 / 2}, \\lambda_{1}\\left(\\mathbf{A}^{H} \\mathbf{A}\\right)∥A∥2​=(λ1​(AHA))1/2,λ1​(AHA) 表示 AHA\\mathbf{A}^{H} \\mathbf{A}AHA 的最大特征值,即 ∥A∥2\\|\\mathbf{A}\\|_{2}∥A∥2​ 是 A\\mathbf{A}A 的最大奇异值; 总和范数 (求总和): ∥A∥M=∑∣aij∣\\|\\mathbf{A}\\|_{M}=\\sum\\left|a_{i j}\\right|∥A∥M​=∑∣aij​∣; F−\\mathrm{F}-F− 范数: ∥A∥F=(∑∣aij∣2)12=tr⁡(AHA)\\|\\mathbf{A}\\|_{\\mathrm{F}}=\\left(\\sum\\left|a_{i j}\\right|^{2}\\right)^{\\frac{1}{2}}=\\sqrt{\\operatorname{tr}\\left(\\mathbf{A}^{H} \\mathbf{A}\\right)}∥A∥F​=(∑∣aij​∣2)21​=tr(AHA)​; GGG-范数: ∥A∥G=n⋅max⁡i,j{\\|\\mathbf{A}\\|_{G}=n \\cdot \\max_{i, j}\\left\\{\\right.∥A∥G​=n⋅maxi,j​{ 最大的 ∣aij∣}\\left.\\left|a_{i j}\\right|\\right\\}∣aij​∣} 备注 以上6个范数满足矩阵范数的4个条件 任两个范数都是等价的 可用如下记号: ∞\\infty∞ 范数: ∥A∥∞=max⁡{∥A1∥1,∥A2∥1,⋯ ,∥An∥1}\\|A\\|_{\\infty}=\\max \\left\\{\\left\\|A_{1}\\right\\|_{1},\\left\\|A_{2}\\right\\|_{1}, \\cdots,\\left\\|A_{n}\\right\\|_{1}\\right\\} \\quad∥A∥∞​=max{∥A1​∥1​,∥A2​∥1​,⋯,∥An​∥1​} (行范数) 1 范数: ∥A∥1=max⁡{∥α1∥1,∥α2∥1,⋯ ,∥αn∥1}\\|A\\|_{1}=\\max \\left\\{\\left\\|\\alpha_{1}\\right\\|_{1},\\left\\|\\alpha_{2}\\right\\|_{1}, \\cdots,\\left\\|\\alpha_{n}\\right\\|_{1}\\right\\} \\quad∥A∥1​=max{∥α1​∥1​,∥α2​∥1​,⋯,∥αn​∥1​} (列范数) 2 范数(谱范数): ∥A∥2= 最大的 λ1(AHA)=λ1\\|A\\|_{2}=\\sqrt{\\text { 最大的 } \\lambda_{1}\\left(A^{H} A\\right)}=\\sqrt{\\lambda_{1}}∥A∥2​= 最大的 λ1​(AHA)​=λ1​​ (最大奇异值) 都有 (1)正性; (2)齐性; (3)三角性; (4)相容性: ∥AB∥≤∥A∥⋅∥B∥\\|A B\\| \\leq\\|A\\| \\cdot\\|B\\|∥AB∥≤∥A∥⋅∥B∥ 备注*(公式): ∥A∥∞=∥AH∥1\\|A\\|_{\\infty}=\\left\\|A^{H}\\right\\|_{1}∥A∥∞​=∥∥∥​AH∥∥∥​1​ ∥A∥1=∥AH∥∞\\|A\\|_{1}=\\left\\|A^{H}\\right\\|_{\\infty}∥A∥1​=∥∥∥​AH∥∥∥​∞​ ∥A∥2=∥AH∥2\\|A\\|_{2}=\\left\\|A^{H}\\right\\|_{2}∥A∥2​=∥∥∥​AH∥∥∥​2​ ∣A∥F=∥AH∥F=(tr(AHA))1/2|\\mathbf{A}\\|_{\\mathrm{F}}=\\left\\|\\mathbf{A}^{\\mathrm{H}}\\right\\|_{\\mathrm{F}}=\\left(\\mathrm{tr}\\left(\\mathbf{A}^{H} \\mathbf{A}\\right)\\right)^{1 / 2}∣A∥F​=∥∥∥​AH∥∥∥​F​=(tr(AHA))1/2 补充定理 U,VU, VU,V 为西阵, 则 ∥UA∥F=∥AV∥F=∥UAV∥F=∥A∥F\\|\\mathrm{UA}\\|_{\\mathrm{F}}=\\|\\mathbf{A} \\mathrm{V}\\|_{\\mathrm{F}}=\\|\\mathrm{UAV}\\|_{\\mathrm{F}}=\\|\\mathbf{A}\\|_{\\mathrm{F}}∥UA∥F​=∥AV∥F​=∥UAV∥F​=∥A∥F​ A∈v∈Cn×n,x∈Cn,\\mathbf{A} \\in \\mathbb{v} \\in \\mathbb{C}^{\\mathrm{n} \\times n}, \\mathrm{x} \\in \\mathrm{C}^{\\mathrm{n}}, \\quadA∈v∈Cn×n,x∈Cn, 则 ∥Ax∥2≤∥A∥F∥x∥2\\|\\mathbf{A x}\\|_{2} \\leq\\|\\mathbf{A}\\|_{\\mathrm{F}}\\|\\mathrm{x}\\|_{2}∥Ax∥2​≤∥A∥F​∥x∥2​ 新范数公式: 已知Cn∗nC^{n*n}Cn∗n上一个矩阵范数∣∣.∣∣||.||∣∣.∣∣,P是可逆阵,令φ(A)=∥P−1AP∥\\varphi(\\mathbf{A})=\\left\\|P^{-1} \\mathbf{A} P\\right\\|φ(A)=∥∥∥​P−1AP∥∥∥​,或φ(A)=∥PAP−1∥,A∈Cn×n\\varphi(\\mathbf{A})=\\left\\|P \\mathbf{A} P^{-1}\\right\\|, \\mathbf{A} \\in \\mathrm{C}^{\\mathrm{n} \\times n}φ(A)=∥∥∥​PAP−1∥∥∥​,A∈Cn×n,可记这个新矩阵范数为φ(A)=∣∣A∣∣p(与P有关)\\varphi(A)=||A||_p(与P有关)φ(A)=∣∣A∣∣p​(与P有关) 备注 ∥A±B∥≤∥A∥+∥B∥\\|A \\pm B\\| \\leq\\|A\\|+\\|B\\|∥A±B∥≤∥A∥+∥B∥, 推广有 ∥A1±A2±⋯±Ak∥≤∥A1∥+∥A2∥+⋯+∥Ak∥\\left\\|A_{1} \\pm A_{2} \\pm \\cdots \\pm A_{k}\\right\\| \\leq\\left\\|A_{1}\\right\\|+\\left\\|A_{2}\\right\\|+\\cdots+\\left\\|A_{k}\\right\\|∥A1​±A2​±⋯±Ak​∥≤∥A1​∥+∥A2​∥+⋯+∥Ak​∥ ∥AB∥≤∥A∥⋅∥B∥\\|A B\\| \\leq\\|A\\| \\cdot\\|B\\|∥AB∥≤∥A∥⋅∥B∥ 推广有 ∥A1A2⋯⋯⋅Ak∥≤∥A1∥⋅∥A2∥⋯⋯⋅∥Ak∥\\left\\|A_{1} A_{2} \\cdots \\cdots \\cdot A_{k}\\right\\| \\leq\\left\\|A_{1}\\right\\| \\cdot\\left\\|A_{2}\\right\\| \\cdots \\cdots \\cdot\\left\\|A_{k}\\right\\|∥A1​A2​⋯⋯⋅Ak​∥≤∥A1​∥⋅∥A2​∥⋯⋯⋅∥Ak​∥ 幂公式: ∥Ak∥≤∥A∥k(k=1,2,3⋯⋯ )\\left\\|A^{k}\\right\\| \\leq\\|A\\|^{k} \\quad(k=1,2,3 \\cdots \\cdots)∥∥∥​Ak∥∥∥​≤∥A∥k(k=1,2,3⋯⋯) 幕公式: ρ(Ak)=[ρ(A)]k,k=1,2,3⋯⋯\\rho\\left(A^{k}\\right)=[\\rho(A)]^{k}, k=1,2,3 \\cdots \\cdotsρ(Ak)=[ρ(A)]k,k=1,2,3⋯⋯ 矩阵范数产生向量范数 定理1:Cn∗nC^{n*n}Cn∗n上任一矩阵范数∣∣.∣∣||.||∣∣.∣∣都产生一个向量范数Φ(X)=∣∣X∣∣V\\varPhi(X) = ||X||_VΦ(X)=∣∣X∣∣V​,使φ(AX)≤∥A∥φ(X), 即 ∥AX∥V≤∥A∥∥X∥V,∀A∈Cn,n,∀X∈Cn\\varphi(A X) \\leq\\|A\\| \\varphi(X),\\text { 即 }\\|A X\\|_{\\mathrm{V}} \\leq\\|A\\|\\|X\\|_{\\mathrm{V}}, \\quad \\forall A \\in \\mathrm{C}^{\\mathrm{n}, \\mathrm{n}}, \\forall X \\in \\mathrm{C}^{\\mathrm{n}}φ(AX)≤∥A∥φ(X), 即 ∥AX∥V​≤∥A∥∥X∥V​,∀A∈Cn,n,∀X∈Cn 备注(定义):若矩阵范数∣∣A∣∣m||A||_m∣∣A∣∣m​与向量范数∣∣x∣∣v||x||_v∣∣x∣∣v​适合∥AX∥V≤∥A∥m∥X∥V\\|A X\\|_{\\mathrm{V}} \\leq\\|A\\|_m\\|X\\|_{\\mathrm{V}}∥AX∥V​≤∥A∥m​∥X∥V​,则说∣∣A∣∣m与∣∣x∣∣v相容||A||_m与||x||_v相容∣∣A∣∣m​与∣∣x∣∣v​相容 向量范数生成公式:Cn×n\\mathrm{C}^{n \\times n}Cn×n 上任一矩阵范数 ∥A∥\\|A\\|∥A∥ 产生一个向量范数公式:φ(X)=∥X∥v≜∥(x10⋯0⋮⋮⋱⋮xn0⋯0)∥,X=(x1⋮xn)∈Cn\\varphi(X)=\\|X\\|_{\\mathrm{v}} \\triangleq\\left\\|\\left(\\begin{array}{cccc}x_{1} &amp; 0 &amp; \\cdots &amp; 0 \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\x_{n} &amp; 0 &amp; \\cdots &amp; 0\\end{array}\\right)\\right\\|, X=\\left(\\begin{array}{c}x_{1} \\\\\\vdots \\\\x_{n}\\end{array}\\right) \\in \\mathrm{C}^{\\mathrm{n}}φ(X)=∥X∥v​≜∥∥∥∥∥∥∥∥​⎝⎜⎜⎛​x1​⋮xn​​0⋮0​⋯⋱⋯​0⋮0​⎠⎟⎟⎞​∥∥∥∥∥∥∥∥​,X=⎝⎜⎜⎛​x1​⋮xn​​⎠⎟⎟⎞​∈Cn,且∥X∥v\\|X\\|_{\\mathrm{v}}∥X∥v​满足相容性:∥AX∥v≤∥A∥∥X∥v,A∈Cn,n,X∈Cn\\quad\\|A X\\|_{\\mathrm{v}} \\leq\\|A\\|\\|X\\|_{\\mathrm{v}}, \\quad A \\in \\mathrm{C}^{\\mathrm{n}, \\mathrm{n}}, X \\in \\mathrm{C}^{\\mathrm{n}}∥AX∥v​≤∥A∥∥X∥v​,A∈Cn,n,X∈Cn 小范数定理:设 A∈Cn×n\\mathbf{A} \\in \\mathrm{C}^{\\mathrm{n} \\times n}A∈Cn×n 固定, 任取很小正数 ε&gt;0\\varepsilon&gt;0ε&gt;0, 则有矩阵范数 ∥(∙)∥ε\\|(\\bullet)\\|_{\\varepsilon}∥(∙)∥ε​ 使得 St:∥A∥ε≤ρ(A)+ε\\mathrm{St}:\\|\\mathbf{A}\\|_{\\varepsilon} \\leq \\rho(\\mathbf{A})+\\varepsilonSt:∥A∥ε​≤ρ(A)+ε 特别推论:若ρ(A)&lt;1\\rho (A) &lt; 1ρ(A)&lt;1,则有某个范数∣∣A∣∣ε&lt;1||A||_{\\varepsilon} &lt; 1∣∣A∣∣ε​&lt;1 收敛阵 定义:若方阵A满足Ak→0A^k \\rightarrow 0Ak→0,即lim(k→∞)Ak=0lim_{(k \\rightarrow \\infin)} A^k=0lim(k→∞)​Ak=0,称A为收敛阵 推论1:lim(k→∞)Ak=0↔∣∣Ak∣∣→0lim_{(k \\rightarrow \\infin)} A^k=0 \\leftrightarrow ||A^k|| \\rightarrow 0lim(k→∞)​Ak=0↔∣∣Ak∣∣→0 定理1： ρ(A)&lt;1⇔∥Ak∥→0(k→∞)⇔Ak→0(k→∞)\\rho(A)&lt;1 \\Leftrightarrow\\left\\|A^{k}\\right\\| \\rightarrow 0(k \\rightarrow \\infty) \\Leftrightarrow A^{k} \\rightarrow 0(k \\rightarrow \\infty)ρ(A)&lt;1⇔∥∥∥​Ak∥∥∥​→0(k→∞)⇔Ak→0(k→∞) 某一范数 ∥A∥&lt;1⇒∥Ak∥→0(k→∞)\\|A\\|&lt;1 \\Rightarrow\\left\\|A^{k}\\right\\| \\rightarrow 0(k \\rightarrow \\infty)∥A∥&lt;1⇒∥∥∥​Ak∥∥∥​→0(k→∞) 牛曼公式(收敛公式): 若 ρ(A)&lt;1\\rho(A)&lt;1ρ(A)&lt;1, 则 I+A+A2+⋯+Ak+⋯=(I−A)−1I+A+A^{2}+\\cdots+A^{k}+\\cdots=(I-A)^{-1}I+A+A2+⋯+Ak+⋯=(I−A)−1 若某范数 ∥A∥&lt;1\\|A\\|&lt;1∥A∥&lt;1, 则 I+A+A2+⋯+Ak+⋯=(I−A)−1I+A+A^{2}+\\cdots+A^{k}+\\cdots=(I-A)^{-1}I+A+A2+⋯+Ak+⋯=(I−A)−1 若 ρ(A)≥1\\rho(A) \\geq 1ρ(A)≥1, 则 I+A+A2+⋯+Ak+⋯发散I+A+A^{2}+\\cdots+A^{k}+\\cdots发散I+A+A2+⋯+Ak+⋯发散 谱半径估计 定义:称A∈Cn∗nA \\in C^{n*n}A∈Cn∗n,称A的n个特征值的模的最大者为A的谱半径,即为p(A)p(A)p(A) 定理:设A∈Cn∗nA \\in C^{n*n}A∈Cn∗n,则ρ(A)\\rho (A)ρ(A)不大于A的任一矩阵范数,即为ρ(A)≤∣∣A∣∣\\rho(A) \\leq ||A||ρ(A)≤∣∣A∣∣ 特别:ρ(A)≤∣∣A∣∣∞\\rho(A) \\leq ||A||_{\\infty}ρ(A)≤∣∣A∣∣∞​,且ρ(A)≤∣∣A∣∣1\\rho(A) \\leq ||A||_{1}ρ(A)≤∣∣A∣∣1​,即ρ(A)≤∣∣AT∣∣∞\\rho (A) \\leq ||A^T||_\\inftyρ(A)≤∣∣AT∣∣∞​ 正矩阵定义1:一个实矩阵A=(aij)∈Rm∗nA=(a_{ij}) \\in R^{m*n}A=(aij​)∈Rm∗n 若每个元素aij≥0a_{ij} \\geq 0aij​≥0,称A为非负矩阵,记作A≥0A \\geq 0A≥0 若每个元素aij&gt;0a_{ij} &gt; 0aij​&gt;0,称A为正矩阵,记作A&gt;0A &gt; 0A&gt;0 正矩阵定理:设非负阵A=(aij)n∗n≥0A=(a_{ij})_{n*n} \\geq 0A=(aij​)n∗n​≥0,令h=(A的最小行和),l=(A的最小列和)h=(A的最小行和),l=(A的最小列和)h=(A的最小行和),l=(A的最小列和),则 h≤ρ(A)≤∣∣A∣∣∞(A的最大行和)h \\leq \\rho(A) \\leq ||A||_\\infty(A的最大行和)h≤ρ(A)≤∣∣A∣∣∞​(A的最大行和) l≤ρ(A)≤∣∣A∣∣1(A的最大列和)l \\leq \\rho(A) \\leq ||A||_1(A的最大列和)l≤ρ(A)≤∣∣A∣∣1​(A的最大列和) 特别,若A=An∗n&gt;0A=A_{n*n} &gt; 0A=An∗n​&gt;0为正矩阵,且h&lt;∣∣A∣∣∞或l&lt;∣∣A∣∣1h&lt;||A||_\\infty或l&lt;||A||_1h&lt;∣∣A∣∣∞​或l&lt;∣∣A∣∣1​ h&lt;ρ(A)&lt;∣∣A∣∣∞h &lt; \\rho(A) &lt; ||A||_\\inftyh&lt;ρ(A)&lt;∣∣A∣∣∞​ l&lt;ρ(A)&lt;∣∣A∣∣1l &lt; \\rho(A) &lt; ||A||_1l&lt;ρ(A)&lt;∣∣A∣∣1​ 盖尔圆估计 圆盘定理1:方阵A的全体特征根都在A的n个Ger圆的并集中 定义:若A的k个Ger圆相连在一起,且与其他n-k个圆分离,称此k个圆盘为一个连通分支,简称分支 圆盘定理2:设A的k个Ger圆构成一个连通分支D,则在D中恰有k个特征根(含重复),特别一个孤立圆中恰有一个根 由于A与转置ATA^TAT有相同特征根,可用ATA^TAT的Ger半径代替A的半径,可得A的列(圆盘定理) 注:实矩阵A的n个Ger圆中心都在x轴上 复习定理 实系数方程的虚根一定在共轭出现 实矩阵A的虚特征根必成对出现,实矩阵A的孤立圆中恰有一个实根 推论1:对方阵A,若原点O∉⋃i=1nGiO \\notin \\bigcup_{i=1}^{n} G_{i}O∈/⋃i=1n​Gi​,则A为可逆阵 推论2:若A行对角占优:∣ajj∣&gt;Rj|a_{jj}|&gt;R_j∣ajj​∣&gt;Rj​,则A为可逆阵 推论3:若A的n个Ger圆互相分离(都是孤立圆),则A是单阵(可对角化).特别,若实矩阵A的n个Ger圆互相分离，则特征根全为实数 其他推论: 推论1:对A∈Cn∗nA \\in C^{n*n}A∈Cn∗n,n个盖尔圆盘G1,...GnG_1,...G_nG1​,...Gn​,若原点O∉⋃i=1nGiO \\notin \\bigcup_{i=1}^{n} G_{i}O∈/⋃i=1n​Gi​,则A为非奇异阵 推论2: A=(aij)∈Cn×nA=\\left(a_{i j}\\right) \\in \\mathbb{C}^{n \\times n}A=(aij​)∈Cn×n. 若A对角占优, 即 ∣aij∣&gt;∑j=1j≠in∣aij∣(i=1,2,⋯ ,n)\\left|a_{i j}\\right|&gt;\\sum_{j=1 \\atop j \\neq i}^{n}\\left|a_{i j}\\right|(i=1,2, \\cdots, n)∣aij​∣&gt;∑j=ij=1​n​∣aij​∣(i=1,2,⋯,n) (行对角占优)或∣aij∣&gt;∑j=1j≠in∣aji∣(i=1,2,⋯ ,n)\\left|a_{i j}\\right|&gt;\\sum_{j=1 \\atop j \\neq i}^{n}\\left|a_{j i}\\right|(i=1,2, \\cdots, n)∣aij​∣&gt;∑j=ij=1​n​∣aji​∣(i=1,2,⋯,n) (列对角占优), 则A为非奇异阵","categories":[{"name":"Study","slug":"Study","permalink":"http://jay1060950003.github.io/categories/Study/"}],"tags":[{"name":"Study","slug":"Study","permalink":"http://jay1060950003.github.io/tags/Study/"}]},{"title":"高等光学","slug":"专业知识相关/高等光学","date":"2021-10-20T11:53:06.000Z","updated":"2023-04-16T12:15:50.187Z","comments":true,"path":"2021/10/20/专业知识相关/高等光学/","link":"","permalink":"http://jay1060950003.github.io/2021/10/20/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%9B%B8%E5%85%B3/%E9%AB%98%E7%AD%89%E5%85%89%E5%AD%A6/","excerpt":"引言 本文为硕士课程中高等光学的课堂笔记 能力有限,不喜勿喷","text":"引言 本文为硕士课程中高等光学的课堂笔记 能力有限,不喜勿喷 1 电磁理论基础 1.1 场论基础 场的概念:指带有某种物理量的空间 数学语言描述:如果空间或部分空间中每一点对应于某一量的值，则这样的空间称为场 方向导数:∂u∂l=lim⁡P→Pu(P1)−u(P)P1P‾\\frac{\\partial u}{\\partial l}=\\lim _{P \\rightarrow P} \\frac{u\\left(P_{1}\\right)-u(P)}{\\overline{P_{1} P}}∂l∂u​=limP→P​P1​P​u(P1​)−u(P)​存在,为场u(P)在P点沿l⃗\\vec{l}l方向的方向导数,记为∂u∂l\\frac{\\partial u}{\\partial l}∂l∂u​ 梯度∇U\\nabla U∇U: 方向为使u(P)u(P)u(P)在P点方向导数最大的方向(与等值面法线平行) 模为方向导数最大方向上的方向导数 哈密顿算符’del’:∇=∂∂xi⃗+∂∂yj⃗+∂∂zk⃗\\nabla=\\frac{\\partial}{\\partial x} \\vec{i}+\\frac{\\partial}{\\partial y} \\vec{j}+\\frac{\\partial}{\\partial z} \\vec{k}∇=∂x∂​i+∂y∂​j​+∂z∂​k 散度∇⋅A⃗\\nabla \\cdot \\vec{A}∇⋅A: 流量:对任意矢量场A⃗(P)\\vec{A}(P)A(P), 称式∮sA⃗∙ds=∮sA⃗∙N⃗ds\\oint_{s} \\vec{A}\\bullet d s=\\oint_{s}\\vec{A} \\bullet \\vec{N} ds∮s​A∙ds=∮s​A∙Nds为通过封闭曲面SSS的流量 =0 S内无源也无沟 &gt;0 S内有源 &lt;0 S内有沟 ∮sA⃗∙dsV\\frac{\\oint_s \\vec{A} \\bullet ds}{V}V∮s​A∙ds​单位体积内的源发出的液量大小,V中源的平均强度 散度:∇⋅A⃗=limD(V)→0∮sA⃗∙dsV\\nabla \\cdot \\vec{A}=lim_{D(V) \\rightarrow 0} \\frac{\\oint_s \\vec{A} \\bullet ds}{V}∇⋅A=limD(V)→0​V∮s​A∙ds​,P点处源的平均强度,称矢量A⃗\\vec{A}A在P点的散度 物理意义:表示矢量场中某点通量源的密度 若散度为0,表示无散场 若散度为ρ(源密度)\\rho(源密度)ρ(源密度),表示有散场 计算: div⁡A⃗(r⃗)=∂Ax∂x+∂Ay∂y+∂Az∂z\\operatorname{div} \\vec{A}(\\vec{r})=\\frac{\\partial A_{x}}{\\partial x}+\\frac{\\partial A_{y}}{\\partial y}+\\frac{\\partial A_{z}}{\\partial z}divA(r)=∂x∂Ax​​+∂y∂Ay​​+∂z∂Az​​ ∇⋅A⃗=1r∂(rAr)∂r+1r∂Aφ∂φ+∂Az∂z\\nabla \\cdot \\vec{A}=\\frac{1}{r} \\frac{\\partial\\left(r A_{r}\\right)}{\\partial r}+\\frac{1}{r} \\frac{\\partial A_{\\varphi}}{\\partial \\varphi}+\\frac{\\partial A_{z}}{\\partial z}∇⋅A=r1​∂r∂(rAr​)​+r1​∂φ∂Aφ​​+∂z∂Az​​ ∇⋅A⃗=1r2∂∂r(r2Ar)+1rsin⁡θ∂∂θ(sin⁡θAθ)+1rsin⁡θ∂Aφ∂φ\\nabla \\cdot \\vec{A}=\\frac{1}{r^{2}} \\frac{\\partial}{\\partial r}\\left(r^{2} A_{r}\\right)+\\frac{1}{r \\sin \\theta} \\frac{\\partial}{\\partial \\theta}\\left(\\sin \\theta A_{\\theta}\\right)+\\frac{1}{r \\sin \\theta} \\frac{\\partial A_{\\varphi}}{\\partial \\varphi}∇⋅A=r21​∂r∂​(r2Ar​)+rsinθ1​∂θ∂​(sinθAθ​)+rsinθ1​∂φ∂Aφ​​ 性质: ∇⋅(αA⃗+βB⃗)=α∇⋅A⃗+β∇⋅B⃗\\nabla \\cdot(\\alpha \\vec{A}+\\beta \\vec{B})=\\alpha \\nabla \\cdot \\vec{A}+\\beta \\nabla \\cdot \\vec{B}∇⋅(αA+βB)=α∇⋅A+β∇⋅B ∇⋅(uA⃗)=u∇⋅A⃗+A⃗⋅∇u(u\\nabla \\cdot(u \\vec{A})=u \\nabla \\cdot \\vec{A}+\\vec{A} \\cdot \\nabla u \\quad(u∇⋅(uA)=u∇⋅A+A⋅∇u(u 散度定理(矢量场中的高斯定理):∫V∇⋅A⃗dV=∮sA⃗⋅dS⃗\\int_{V} \\nabla \\cdot \\vec{A} d V=\\oint_{s} \\vec{A} \\cdot d \\vec{S}∫V​∇⋅AdV=∮s​A⋅dS 物理意义:矢量场A⃗\\vec{A}A的散度在体积V内的体积分等于矢量场穿过包围该体积的闭合边界面S的面积分 体积V内通量为:Ψ=∫V∇⋅A⃗dV\\Psi=\\int_{V} \\nabla \\cdot \\vec{A} d VΨ=∫V​∇⋅AdV 旋度∇×A⃗\\nabla \\times \\vec{A}∇×A: 环流: 矢量场A⃗(P)\\vec{A}(P)A(P)中,沿封闭曲线Γ\\GammaΓ的线积分∮ΓA⃗⋅dl⃗\\oint_{\\Gamma} \\vec{A} \\cdot d \\vec{l}∮Γ​A⋅dl 物理意义:若矢量场环流不为0,则说明场中有在矢量场的漩涡源,不能显示源的分布情况 环流密度:Wn(P)=lim⁡D(s)→0∮ΓA⃗⋅dl⃗SW_{n} (P)=\\lim_{D(s) \\rightarrow 0} \\frac{\\oint_{\\Gamma} \\vec{A} \\cdot d \\vec{l}}{S}Wn​(P)=limD(s)→0​S∮Γ​A⋅dl​ 环流面密度:空间某点M处沿单位面元边界闭合曲线的环流称为矢量场F(r⃗)⃗\\vec{F(\\vec{r})}F(r)​在M点处沿en⃗\\vec{e_n}en​​方向的环流面密度 rot⁡F⃗=n⃗lim⁡ΔS→0∮cF⃗⋅dl⃗ΔS\\operatorname{rot} \\vec{F}=\\vec{n} \\lim _{\\Delta S \\rightarrow 0} \\frac{\\oint_{c} \\vec{F} \\cdot d \\vec{l}}{\\Delta S}rotF=nlimΔS→0​ΔS∮c​F⋅dl​ 旋度:矢量场在M点的旋度为该点处的最大环流面密度，其方向为环流面密度取得最大值的面元法线方向 rot⁡F⃗=n⃗lim⁡ΔS→0∮cF⃗⋅dl⃗ΔS∣max⁡\\operatorname{rot} \\vec{F}=\\left.\\vec{n} \\lim _{\\Delta S \\rightarrow 0} \\frac{\\oint_{c} \\vec{F} \\cdot d \\vec{l}}{\\Delta S}\\right|_{\\max }rotF=nlimΔS→0​ΔS∮c​F⋅dl​∣∣∣∣∣​max​ 物理意义:矢量场的旋度表征了矢量场在空间某点处的漩涡源密度 计算:rot⁡A⃗=∇×A⃗=∣i⃗j⃗k⃗∂∂x∂∂y∂∂zAxAyAz∣\\operatorname{rot} \\vec{A}=\\nabla \\times \\vec{A}=\\left|\\begin{array}{ccc}\\vec{i} &amp; \\vec{j} &amp; \\vec{k} \\\\ \\frac{\\partial}{\\partial x} &amp; \\frac{\\partial}{\\partial y} &amp; \\frac{\\partial}{\\partial z} \\\\ A_{x} &amp; A_{y} &amp; A_{z}\\end{array}\\right|rotA=∇×A=∣∣∣∣∣∣∣​i∂x∂​Ax​​j​∂y∂​Ay​​k∂z∂​Az​​∣∣∣∣∣∣∣​ 斯托克斯定理:矢量场的旋度在曲面S上的面积分等于该矢量场沿限定该曲面的闭合路径C上的线积分 ∮CF⃗⋅dl⃗=∫S∇×F⃗⋅dS⃗\\oint_{C} \\vec{F} \\cdot \\mathrm{d} \\vec{l}=\\int_{S} \\nabla \\times \\vec{F} \\cdot \\mathrm{d} \\vec{S}∮C​F⋅dl=∫S​∇×F⋅dS 势函数,势量场(保守场),矢势 对矢量场Ap⃗\\vec{A_p}Ap​​存在单值函数u(P)u(P)u(P),使A⃗=∇u\\vec{A} = \\nabla uA=∇u,称A⃗(p)\\vec{A}(p)A(p)为势量场,u(p)u(p)u(p)为势量场A⃗(p)\\vec{A}_(p)A(​p)的势函数. 保守场: 无旋∇×∇u≡0\\nabla \\times \\nabla u \\equiv 0∇×∇u≡0 回路积分为0 例如:重力场,静电场 对无旋场A⃗\\vec{A}A势函数uuu为标量,uuu为势量场的标势 矢势: 对无源场存在矢势A⃗\\vec{A}A使B⃗≡∇×A⃗\\vec{B} \\equiv \\nabla \\times \\vec{A}B≡∇×A(无源势必存在矢势∇∙(∇×A⃗)\\nabla \\bullet(\\nabla \\times \\vec{A})∇∙(∇×A) 有散无旋场(有势场,保守场):标量位函数uuu的梯度表征矢量场∇×(∇∙A⃗)≡0\\nabla \\times(\\nabla \\bullet \\vec{A}) \\equiv 0∇×(∇∙A)≡0 无散有旋场(管形场):引入矢量位函数AAA的旋度,表示无散场,恒磁场∇∙B≡0→B⃗=∇×A\\nabla \\bullet B \\equiv 0 \\rightarrow \\vec{B} = \\nabla \\times A∇∙B≡0→B=∇×A 静电场 静磁场 高斯定理 无旋场 安培环路定律 磁通连续性定律 1.2 静电场,静磁场基本定律 1.2.1 静电场 库伦定理:F12=q1q24πε0R122e^R=q1q24πε0R123R12\\mathbf{F}_{12}=\\frac{q_{1} q_{2}}{4 \\pi \\varepsilon_{0} R_{12}^{2}} \\hat{\\mathbf{e}}_{R}=\\frac{q_{1} q_{2}}{4 \\pi \\varepsilon_{0} R_{12}^{3}} \\mathbf{R}_{12}F12​=4πε0​R122​q1​q2​​e^R​=4πε0​R123​q1​q2​​R12​ ε0≈(36π)−1×10−9 F/m=8.8542×10−12 F/m\\varepsilon_{0} \\approx(36 \\pi)^{-1} \\times 10^{-9} \\mathrm{~F} / \\mathrm{m}=8.8542 \\times 10^{-12} \\mathrm{~F} / \\mathrm{m}ε0​≈(36π)−1×10−9 F/m=8.8542×10−12 F/m 电场强度:E=lim⁡q0→0Fq0=q4πε0R3R⃗\\mathbf{E}=\\lim _{q_{0} \\rightarrow 0} \\frac{\\mathbf{F}}{q_{0}}=\\frac{q}{4 \\pi \\varepsilon_{0} R^3} \\vec{R}E=limq0​→0​q0​F​=4πε0​R3q​R 高斯定理: ∮SE(r)⋅dS=1ε0∑iqi=Qε0\\oint_{S} \\mathbf{E}(\\mathbf{r}) \\cdot \\mathrm{d} \\mathbf{S}=\\frac{1}{\\varepsilon_{0}} \\sum_{i} q_{i}=\\frac{Q}{\\varepsilon_{0}}∮S​E(r)⋅dS=ε0​1​∑i​qi​=ε0​Q​ ∇⋅E(r)=ρ(r)ε0\\nabla \\cdot \\mathbf{E}(\\mathbf{r})=\\frac{\\rho(\\mathbf{r})}{\\varepsilon_{0}}∇⋅E(r)=ε0​ρ(r)​ 物理意义: 静电场穿过闭合面𝐒的通量只与闭合面内所围电荷量有关 静电场是有源场，静电荷是其散度源 静电场环路定律 ∮CE⋅dl=0\\oint_{C} \\mathbf{E} \\cdot \\mathrm{d} \\mathbf{l}=0∮C​E⋅dl=0 ∇×E(r)=0\\nabla \\times \\mathbf{E}(\\mathbf{r})=0∇×E(r)=0 物理意义:静电场为无旋场(保守场)(电场力不做功——闭合环路) 静电场为有源无旋场,恒有∇×E=0⇒∇×(∇φ)≡0⇒E=−∇φ\\nabla \\times \\mathbf{E}=0 \\Rightarrow \\nabla \\times(\\nabla \\varphi) \\equiv 0 \\quad \\Rightarrow \\quad \\mathbf{E}=-\\nabla \\varphi∇×E=0⇒∇×(∇φ)≡0⇒E=−∇φ,静电场可由势函数的梯度表示 均匀介质中,∇⋅E=ρεE=∇(−u)}\\left.\\begin{array}{l}\\nabla \\cdot \\mathbf{E}=\\frac{\\rho}{\\varepsilon} \\\\ \\mathbf{E}=\\nabla(-u)\\end{array}\\right\\}∇⋅E=ερ​E=∇(−u)​} 故电势的标量泊松方程∇2u=−ρε\\nabla^{2} u=-\\frac{\\rho}{\\varepsilon}∇2u=−ερ​ 无源区域ρ=0\\rho =0ρ=0,拉普拉斯方程∇2u=0\\nabla^{2} u=0∇2u=0 1.2.2 静磁场 体电流密度:J=lim⁡Δt→0ΔiΔSe^n=di dSe^n=ρv\\mathbf{J}=\\lim _{\\Delta t \\rightarrow 0} \\frac{\\Delta i}{\\Delta S} \\hat{\\mathbf{e}}_{n}=\\frac{\\mathrm{d} i}{\\mathrm{~d} S} \\hat{\\mathbf{e}}_{n}=\\rho \\mathbf{v}J=limΔt→0​ΔSΔi​e^n​= dSdi​e^n​=ρv,单位C/(s∗cm2)C/(s*cm^2)C/(s∗cm2)或A/cm2A/cm^2A/cm2 电流强度:单位时间内通过垂直穿过任意截面积 𝐒 的电量 I=∫SJ⋅dS=∫SJ⋅n^dSI=\\int_{S} \\mathbf{J} \\cdot \\mathrm{d} \\mathbf{S}=\\int_{S} \\mathbf{J} \\cdot \\widehat{\\mathbf{n}} \\mathrm{d} SI=∫S​J⋅dS=∫S​J⋅ndS 电流连续性方程 ∮SJ⋅dS=−dq dt=∫V−∂ρ∂t dV\\oint_{S} \\mathbf{J} \\cdot \\mathrm{d} \\mathbf{S}=-\\frac{\\mathrm{d} q}{\\mathrm{~d} t}=\\int_{V}-\\frac{\\partial \\rho}{\\partial t} \\mathrm{~d} V∮S​J⋅dS=− dtdq​=∫V​−∂t∂ρ​ dV ∇⋅J+∂ρ∂t=0\\nabla \\cdot \\mathbf{J}+\\frac{\\partial \\rho}{\\partial t}=0∇⋅J+∂t∂ρ​=0 单位时间内从体积𝑉中减少的电荷量等于流出该体积总电流 导电介质中的欧姆定律(微分形式):Jc=σE\\mathbf{J}_{c}=\\sigma \\mathbf{E}Jc​=σE 安培力公式:F12=μ04π∮C2I2 dl2⃗×∮C1I1dl1⃗×eR⃗R122\\mathbf{F}_{12}=\\frac{\\mu_{0}}{4 \\pi} \\oint_{C_{2}} I_{2} \\mathrm{~d} \\vec{\\mathbf{l}_{2}} \\times \\oint_{C_{1}} \\frac{I_{1} \\vec{\\mathrm{dl}_{1}} \\times \\vec{\\mathbf{e}_{R}}}{R_{12}^{2}}F12​=4πμ0​​∮C2​​I2​ dl2​​×∮C1​​R122​I1​dl1​​×eR​​​ 毕奥－萨伐尔定律:B⃗(r)=μ04π∮CI dl′⃗×R⃗R3\\vec{B}(\\mathbf{r})=\\frac{\\mu_{0}}{4 \\pi} \\oint_{C} \\frac{I \\mathrm{~d} \\vec{\\mathbf{l}^{\\prime}} \\times \\vec{\\mathbf{R}}}{R^{3}}B(r)=4πμ0​​∮C​R3I dl′×R​,单位T,W/m2T,W/m^2T,W/m2 磁通连续性原理: ∮SB⃗⋅dS⃗=0\\oint_{\\mathbf{S}} \\vec{\\mathbf{B}} \\cdot \\mathrm{d} \\vec{S}=0∮S​B⋅dS=0 ∇⋅B⃗=0\\nabla \\cdot \\vec{B}=0∇⋅B=0 恒定磁场中，磁感应强度矢量穿过任意闭合面的磁通量为零 恒定磁场无散度源,磁力线是闭合连续的 安培环路定律: ∮CB⃗(r)⋅dl⃗=μ0∑kIk=μ0I\\oint_{C} \\vec{B}(\\mathbf{r}) \\cdot \\mathrm{d} \\vec{l}=\\mu_{0} \\sum_{k} I_{k}=\\mu_{0} I∮C​B(r)⋅dl=μ0​∑k​Ik​=μ0​I ∇×B⃗(r)=μ0⃗(r)J\\nabla \\times \\vec{B}(\\mathbf{r})=\\vec{\\mu_{0}}(\\mathbf{r}) \\mathbf{J}∇×B(r)=μ0​​(r)J 在恒定磁场中，磁感应强度在任意闭合回路𝐿上的环流等于穿过回路𝐿所围面积𝑆内电流的代数和与μ0\\mu_0μ0​的乘积 静磁场有旋场，涡流源是恒定电流 1.3 时变电磁场 电磁感应定律: ∮CE⋅dl=−∫S∂B∂t⋅dS\\oint_{C} \\mathbf{E} \\cdot \\mathrm{d} \\mathbf{l}=-\\int_{S} \\frac{\\partial \\mathbf{B}}{\\partial t} \\cdot \\mathrm{d} \\mathbf{S}∮C​E⋅dl=−∫S​∂t∂B​⋅dS ∇×E=−∂B∂t\\nabla \\times \\mathbf{E}=-\\frac{\\partial \\mathbf{B}}{\\partial t}∇×E=−∂t∂B​ 当穿过导体回路所围面积的磁通量发生改变时,回路中将产生感应电动势， 其大小等于回路磁通量的时间变化率 物理意义:随时间变化的磁场将产生电场 涡旋电场:时变电磁场的主要区别之一:与静电场不同，当磁场为时变的情况时，电场的旋度不再为零,而是涡旋电场 全电流定律: ∇×B=μ0J+μ0∂D∂t\\nabla \\times \\mathbf{B}=\\mu_{0} \\mathbf{J}+\\mu_{0} \\frac{\\partial \\mathbf{D}}{\\partial t}∇×B=μ0​J+μ0​∂t∂D​ 物理意义:磁场的激发源不仅仅是传导电流，还可以是变化的电场 位移电流:在时变场空间中,存在着因变化的电场而形成的位移电流,位移电流与自由电流共同形成全电流 理想介质中,无传导电流,但可能有位移电流 理想导体中,无位移电流,但可能有传导电流 导电介质中,既可能有传导电流,又可能有位移电流 时变电磁场 库伦定理 电场强度与真空中的静电场 ∇⋅E=ρε0\\nabla\\cdot \\mathbf{E}=\\frac{\\rho}{\\varepsilon_{0}}∇⋅E=ε0​ρ​ 高斯定律 物理基础 法拉电感定理 ∇×E=−∂B∂t\\nabla \\times \\mathbf{E}=-\\frac{\\partial \\mathbf{B}}{\\partial t}∇×E=−∂t∂B​ 电磁感应定律 物理基础 位移电流假说/安培环路定律 ∇×B=μ0J+μ0∂D∂t\\nabla \\times \\mathbf{B}=\\mu_{0} \\mathbf{J}+\\mu_{0} \\frac{\\partial \\mathbf{D}}{\\partial t}∇×B=μ0​J+μ0​∂t∂D​ 全电流定律 安培定理 磁感应强度与真空中的静磁场 ∇⋅B=0\\nabla \\cdot \\mathbf{B}=0∇⋅B=0 磁通连续性原理 1.4 真空中的麦克斯韦方程组 真空中麦克斯韦方程组 ∇⋅E=ρε0\\nabla\\cdot \\mathbf{E}=\\frac{\\rho}{\\varepsilon_{0}}∇⋅E=ε0​ρ​ ∮SE⋅dS=∫Vρε0 dV=Qε0\\oint_{S} \\mathbf{E} \\cdot \\mathrm{d} \\mathbf{S}=\\int_{V} \\frac{\\rho}{\\varepsilon_{0}} \\mathrm{~d} V=\\frac{Q}{\\varepsilon_{0}}∮S​E⋅dS=∫V​ε0​ρ​ dV=ε0​Q​ 电场为有源场 ∇×E=−∂B∂t\\nabla \\times \\mathbf{E}=-\\frac{\\partial \\mathbf{B}}{\\partial t}∇×E=−∂t∂B​ ∮CE⋅dl=−∫S∂B∂t⋅dS\\oint_{C} \\mathbf{E} \\cdot \\mathrm{d} \\mathbf{l}=-\\int_{S} \\frac{\\partial \\mathbf{B}}{\\partial t} \\cdot \\mathrm{d} \\mathbf{S}∮C​E⋅dl=−∫S​∂t∂B​⋅dS 变化的磁场产生涡旋电场 ∇×B=μ0J+μ0∂D∂t\\nabla \\times \\mathbf{B}=\\mu_{0} \\mathbf{J}+\\mu_{0} \\frac{\\partial \\mathbf{D}}{\\partial t}∇×B=μ0​J+μ0​∂t∂D​ ∮CB⋅dl=∫Sμ0(J+∂D∂t)⋅dS\\oint_{C} \\mathbf{B} \\cdot \\mathrm{d} \\mathbf{l}=\\int_{S} \\mu_{0}\\left(\\mathbf{J}+\\frac{\\partial \\mathbf{D}}{\\partial t}\\right) \\cdot \\mathrm{d} \\mathbf{S}∮C​B⋅dl=∫S​μ0​(J+∂t∂D​)⋅dS 稳恒电流及变化电场产生涡旋磁场 ∇⋅B=0\\nabla \\cdot \\mathbf{B}=0∇⋅B=0 ∮SB⋅dS=0\\oint_{S} \\mathbf{B} \\cdot \\mathrm{d} \\mathbf{S}=0∮S​B⋅dS=0 磁场为无源场 1.5 介质中的麦克斯韦方程组 真空本构方程 D=ε0ED = \\varepsilon_0ED=ε0​E B=μ0H\\mathbf{B} =\\mu_{0} \\mathbf{H}B=μ0​H J=σE\\mathrm{J} =\\sigma \\mathrm{E}J=σE 极化 电介质:指导线性能较差的为u之 电偶极子:由两个相距很近且带等量异号电量的点电荷所组成的电荷系统,用电偶极矩描述,p⃗=qd⃗\\vec{p} = q \\vec{d}p​=qd 无极分子:电偶极矩为0,正负电荷中心重合((外加电场后,无极分子位移极化) 有极分子:电偶极矩不为0,正负电荷中心不重合(外加电场后,有极分子取向极化) 极化过程:外加电场使电介质极化,产生极化电荷;极化电荷又形成极化电场,两者相互制约并达到平衡状态 极化强度矢量:极化强度矢量是描述介质极化程度的物理量P=(∑pi)ΔVΔV=np\\mathbf{P}=\\frac{\\left(\\sum \\mathbf{p}_{i}\\right)_{\\Delta V}}{\\Delta V}=n \\mathbf{p}P=ΔV(∑pi​)ΔV​​=np 物理意义:单位体积内分子电偶极矩的矢量和 极化电荷体密度: 极化电荷数:qP=−∫VρPdV=∮SP⋅dS=∫V∇⋅PdVq_{\\mathrm{P}}=-\\int_{V} \\rho_{\\mathrm{P}} \\mathrm{d} V=\\oint_{S} \\mathbf{P} \\cdot \\mathrm{d} \\mathbf{S}=\\int_{V} \\nabla \\cdot \\mathbf{P} \\mathrm{d} VqP​=−∫V​ρP​dV=∮S​P⋅dS=∫V​∇⋅PdV 极化电荷体密度:ρP=−∇⋅P\\rho_{\\mathrm{P}}=-\\nabla \\cdot \\mathbf{P}ρP​=−∇⋅P 极化电荷面密度:ρsp=P⋅en\\rho_{\\mathrm{sp}}=\\mathbf{P} \\cdot \\mathbf{e}_{\\mathrm{n}}ρsp​=P⋅en​ 极化电流(密度):JP=∂P∂t\\mathbf{J}_{\\mathrm{P}}=\\frac{\\partial \\mathbf{P}}{\\partial t}JP​=∂t∂P​ 电介质中的高斯定理: 电位移矢量:D=ε0E+PD=\\varepsilon_0E+PD=ε0​E+P ∇⋅D=ρf\\nabla \\cdot D = \\rho_f∇⋅D=ρf​ ∫sDdS=Qf\\int_{s} D dS=Q_f∫s​DdS=Qf​ 本构关系:D=ε0(1+ϰe)E=ε0εrE=εED=\\varepsilon_0(1+\\varkappa_e)E=\\varepsilon_0\\varepsilon_r E = \\varepsilon ED=ε0​(1+ϰe​)E=ε0​εr​E=εE εr=1+ϰe\\varepsilon_r =1+\\varkappa_eεr​=1+ϰe​相对介电常数 ε=ε0εr\\varepsilon = \\varepsilon_0\\varepsilon_rε=ε0​εr​绝对介电常数 磁化 分子电流:电子绕原子核运动形成&quot;分子电流&quot; 磁偶极矩:分子电流产生磁偶极矩m⃗=ia⃗\\vec{m}=i\\vec{a}m=ia 磁介质的磁化 外加磁场时:大量磁偶极矩的取向与外加磁场趋于一致,宏观上表现出磁特性,这一过程称为磁化 磁化强度矢量:单位体积内的磁偶极矩的磁化强度矢量 M=(∑mi)ΔVΔV=nm\\mathbf{M}=\\frac{\\left(\\sum \\mathbf{m}_{i}\\right)_{\\Delta V}}{\\Delta V}=n \\mathbf{m}M=ΔV(∑mi​)ΔV​​=nm 磁化电流:磁介质被磁化后,在其内部和表面将出现宏观磁化电流 磁化电流密度:JM=∇×M\\mathbf{J}_{\\mathrm{M}}=\\nabla \\times \\mathbf{M}JM​=∇×M 磁介质中安培环路定律: 磁场强度矢量H⃗=B⃗μ0−M⃗\\vec{H}=\\frac{\\vec{B}}{\\mu_0} - \\vec{M}H=μ0​B​−M ∇×H=Jf+∂D∂t\\nabla \\times \\mathbf{H}=\\mathbf{J}_{\\mathrm{f}}+\\frac{\\partial \\mathbf{D}}{\\partial t}∇×H=Jf​+∂t∂D​ ∫CH⋅dl=∫S(Jf+∂D∂t)⋅dS\\int_{C} \\mathbf{H} \\cdot \\mathrm{d} \\mathbf{l}=\\int_{S}\\left(\\mathbf{J}_{\\mathrm{f}}+\\frac{\\partial \\mathbf{D}}{\\partial t}\\right) \\cdot \\mathrm{d} \\mathbf{S}∫C​H⋅dl=∫S​(Jf​+∂t∂D​)⋅dS 磁介质本构关系: B=μ0(1+χm)H=μ0μrH=μH\\mathbf{B}=\\mu_{0}\\left(1+\\chi_{\\mathrm{m}}\\right) \\mathbf{H}=\\mu_{0} \\mu_{\\mathrm{r}} \\mathbf{H}=\\mu \\mathbf{H}B=μ0​(1+χm​)H=μ0​μr​H=μH 介质中麦克斯韦方程组 ∇⋅D=ρ\\nabla\\cdot \\mathbf{D}=\\rho∇⋅D=ρ ∮SD⋅dS=Q\\oint_{S} \\mathbf{D} \\cdot \\mathrm{d} \\mathbf{S} = Q∮S​D⋅dS=Q 电荷产生静电场,电力线不闭合 ∇×E=−∂B∂t\\nabla \\times \\mathbf{E}=-\\frac{\\partial \\mathbf{B}}{\\partial t}∇×E=−∂t∂B​ ∮CE⋅dl=−∫S∂B∂t⋅dS\\oint_{C} \\mathbf{E} \\cdot \\mathrm{d} \\mathbf{l}=-\\int_{S} \\frac{\\partial \\mathbf{B}}{\\partial t} \\cdot \\mathrm{d} \\mathbf{S}∮C​E⋅dl=−∫S​∂t∂B​⋅dS 时变磁场产生时变电场 ∇×H=J+∂D∂t\\nabla \\times \\mathbf{H}= \\mathbf{J}+ \\frac{\\partial \\mathbf{D}}{\\partial t}∇×H=J+∂t∂D​ ∮CH⋅dl=∫S(J+∂D∂t)⋅dS\\oint_{C} \\mathbf{H} \\cdot \\mathrm{d} \\mathbf{l}=\\int_{S} (\\mathbf{J}+\\frac{\\partial \\mathbf{D}}{\\partial t}) \\cdot \\mathrm{d} \\mathbf{S}∮C​H⋅dl=∫S​(J+∂t∂D​)⋅dS 自由电荷和变化的电场都能产生磁场 ∇⋅B=0\\nabla \\cdot \\mathbf{B}=0∇⋅B=0 ∮SB⋅dS=0\\oint_{S} \\mathbf{B} \\cdot \\mathrm{d} \\mathbf{S}=0∮S​B⋅dS=0 磁场为无源场,磁感线总是闭合曲线 真空本构方程 D=εE=ε0E+PD = \\varepsilon E =\\varepsilon_0 E +PD=εE=ε0​E+P B=μH=μ0(H+M)\\mathbf{B} =\\mu \\mathbf{H} = \\mu_0(H+M)B=μH=μ0​(H+M) J=σE\\mathrm{J} =\\sigma \\mathrm{E}J=σE 电磁场的源:电流和电荷;时变的电场和时变的磁场 无源空间中的两个旋度方程为: ∇×H=∂D∂t\\nabla \\times \\mathbf{H}= \\frac{\\partial \\mathbf{D}}{\\partial t}∇×H=∂t∂D​ ∇×E=−∂B∂t\\nabla \\times \\mathbf{E}=-\\frac{\\partial \\mathbf{B}}{\\partial t}∇×E=−∂t∂B​ 在离开辐射源(如天线)的无源空间中,电荷密度和电流密度矢量为零,电场和磁场相互激发,从而在空间形成电磁振荡并传播,这就是电磁波时变磁场 时变电磁场中，电场和磁场相互关联，构成一个整体。静场只是时变场的一种特殊情况 麦克斯韦方程组的物理含义: 时变电场的激发源除电荷以外,还有变化的磁场 时变磁场的激发源除传导电流以外,还有变化的电场 电场和磁场可互为激发源 静电场,静磁场 在静态情况下𝐄和𝐃与静磁场中的𝐁和𝐇是相互独立的矢量对,它们互不相关 时变电磁场 变化的电场可以激励出时变的磁场,而时变的磁场又可激励出时变电场 电场,极化 磁场,磁化 电偶极矩 p=qlp=qlp=ql 磁偶极矩 m=iam=iam=ia 极化强度 P=(∑pi)ΔVΔV\\mathbf{P}=\\frac{\\left(\\sum \\mathbf{p}_{i}\\right)_{\\Delta V}}{\\Delta V}P=ΔV(∑pi​)ΔV​​ 磁化强度 M=(∑mi)ΔVΔV\\mathbf{M}=\\frac{\\left(\\sum \\mathbf{m}_{i}\\right)_{\\Delta V}}{\\Delta V}M=ΔV(∑mi​)ΔV​​ 线性关系 P=ε0ϰeEP = \\varepsilon_0 \\varkappa_e EP=ε0​ϰe​E 磁偶极矩 M=ϰmHM=\\varkappa_m HM=ϰm​H 电极化率 ϰe\\varkappa_eϰe​ 磁偶极矩 ϰm\\varkappa_mϰm​ 电位移矢量 D=εED=\\varepsilon ED=εE 磁偶极矩 B=μHB=\\mu HB=μH 相对介电常数 εr=1+ϰe\\varepsilon_r=1+\\varkappa_eεr​=1+ϰe​ 磁偶极矩 μr=1+ϰm\\mu_r=1+\\varkappa_mμr​=1+ϰm​ 1.6 电磁场的边界条件 电场强度E的边界条件: ∮CE⋅dl=−∫S∂B∂t⋅dS\\oint_{C} \\mathbf{E} \\cdot \\mathrm{d} \\mathbf{l}=-\\int_{S} \\frac{\\partial \\mathbf{B}}{\\partial t} \\cdot \\mathrm{d} \\mathbf{S}∮C​E⋅dl=−∫S​∂t∂B​⋅dS Δh→0,⇒n⃗×(E2⃗−E1⃗)=0\\Delta h\\rightarrow 0,\\Rightarrow \\vec{n} \\times (\\vec{E_2}-\\vec{E_1})=0Δh→0,⇒n×(E2​​−E1​​)=0 (E2t⃗−E1t⃗)=0(\\vec{E_{2t}}-\\vec{E_{1t}})=0(E2t​​−E1t​​)=0 在分界面上电场强度矢量的切向分量连续 磁场强度H的边界条件: ∮CH⋅dl=∫S(J+∂D∂t)⋅dS\\oint_{C} \\mathbf{H} \\cdot \\mathrm{d} \\mathbf{l}=\\int_{S} (\\mathbf{J}+\\frac{\\partial \\mathbf{D}}{\\partial t}) \\cdot \\mathrm{d} \\mathbf{S}∮C​H⋅dl=∫S​(J+∂t∂D​)⋅dS Δh→0,⇒n⃗×(H2⃗−H1⃗)=Js⃗\\Delta h\\rightarrow 0,\\Rightarrow \\vec{n} \\times (\\vec{H_2}-\\vec{H_1})=\\vec{J_s}Δh→0,⇒n×(H2​​−H1​​)=Js​​ (H2t⃗−H1t⃗)=Js⃗(\\vec{H_{2t}}-\\vec{H_{1t}})=\\vec{J_s}(H2t​​−H1t​​)=Js​​ 在分界面上磁场矢量的切向分量与界面处自由面电流相关 当界面处自由面电流为0时,磁场强度矢量切向分量在界面处连续 电位移矢量D的边界条件: ∮SD⋅dS=Q\\oint_{S} \\mathbf{D} \\cdot \\mathrm{d} \\mathbf{S} = Q∮S​D⋅dS=Q Δh→0,⇒n⃗⋅(D2⃗−D1⃗)=ρs\\Delta h\\rightarrow 0,\\Rightarrow \\vec{n} \\cdot (\\vec{D_2}-\\vec{D_1})=\\rho_sΔh→0,⇒n⋅(D2​​−D1​​)=ρs​ (D2n⃗−D1n⃗)=ρs(\\vec{D_{2n}}-\\vec{D_{1n}})=\\rho_s(D2n​​−D1n​​)=ρs​ 在介质界面上电位移矢量的法向分量与界面处自由面电荷相关 当界面处自由面电荷为0时,电位移矢量法向分量在界面处连续 磁感应矢量B的边界条件: ∮SB⋅dS=0\\oint_{S} \\mathbf{B} \\cdot \\mathrm{d} \\mathbf{S} = 0∮S​B⋅dS=0 Δh→0,⇒n⃗⋅(B2⃗−B1⃗)=0\\Delta h\\rightarrow 0,\\Rightarrow \\vec{n} \\cdot (\\vec{B_2}-\\vec{B_1})=0Δh→0,⇒n⋅(B2​​−B1​​)=0 (B2n⃗−B1n⃗)=0(\\vec{B_{2n}}-\\vec{B_{1n}})=0(B2n​​−B1n​​)=0 在介质界面上磁感应强度矢量法向分量连续 边界条件 两种电介质(Js=0,ρs=0J_s=0,\\rho_s=0Js​=0,ρs​=0) 电介质与理想导体(E1,H1,D1,B1=0E_1,H_1,D_1,B_1=0E1​,H1​,D1​,B1​=0) 电介质与实际导体 n⃗×(E2⃗−E1⃗)=0\\vec{n} \\times (\\vec{E_2}-\\vec{E_1})=0n×(E2​​−E1​​)=0 E1t=E2tE_{1t} = E_{2t}E1t​=E2t​ E2t=0E_{2t}=0E2t​=0 E1t=E2tE_{1t} = E_{2t}E1t​=E2t​ n⃗×(H2⃗−H1⃗)=Js⃗\\vec{n} \\times (\\vec{H_2}-\\vec{H_1})=\\vec{J_s}n×(H2​​−H1​​)=Js​​ H1t=H2tH_{1t} = H_{2t}H1t​=H2t​ H2t=JsH_{2t}=J_sH2t​=Js​ H1t=H2tH_{1t} = H_{2t}H1t​=H2t​ n⃗⋅(D2⃗−D1⃗)=ρs\\vec{n} \\cdot (\\vec{D_2}-\\vec{D_1})=\\rho_sn⋅(D2​​−D1​​)=ρs​ D1n=D2nD_{1n} = D_{2n}D1n​=D2n​ D2n=ρsD_{2n}=\\rho_sD2n​=ρs​ D1n=D2nD_{1n} = D_{2n}D1n​=D2n​ n⃗⋅(B2⃗−B1⃗)=0\\vec{n} \\cdot (\\vec{B_2}-\\vec{B_1})=0n⋅(B2​​−B1​​)=0 B1n=B2nB_{1n} = B_{2n}B1n​=B2n​ B2n=0B_{2n}=0B2n​=0 B1n=B2nB_{1n} = B_{2n}B1n​=B2n​ 1.7 无源波动方程 无源波动方程的一般形式 推导过程: 矢量恒等式:∇×∇×A=∇(∇⋅A)−∇2A\\nabla \\times \\nabla \\times \\mathbf{A}=\\nabla(\\nabla \\cdot \\mathbf{A})-\\nabla^{2} \\mathbf{A}∇×∇×A=∇(∇⋅A)−∇2A 无源均匀简单介质,J=0,ρ=0,D=εE,B=μHJ=0,\\rho=0,D=\\varepsilon E,B=\\mu HJ=0,ρ=0,D=εE,B=μH 由∇×E=−∂B∂t\\nabla \\times \\mathbf{E}=-\\frac{\\partial \\mathbf{B}}{\\partial t}∇×E=−∂t∂B​,取散度可得,∇×∇×E=∇×(−μ∂H∂t)\\nabla \\times \\nabla \\times \\mathbf{E}=\\nabla \\times (-\\mu \\frac{\\partial \\mathbf{H}}{\\partial t})∇×∇×E=∇×(−μ∂t∂H​),利用恒等式,且∇⋅D=0\\nabla\\cdot \\mathbf{D}=0∇⋅D=0,可得∇2E−με∂2E∂t2=0\\nabla^{2} \\mathbf{E}-\\mu \\varepsilon \\frac{\\partial^{2} \\mathbf{E}}{\\partial t^{2}}=0∇2E−με∂t2∂2E​=0 波动方程: ∇2E−με∂2E∂t2=0\\nabla^{2} \\mathbf{E}-\\mu \\varepsilon \\frac{\\partial^{2} \\mathbf{E}}{\\partial t^{2}}=0∇2E−με∂t2∂2E​=0,∇2H−με∂2H∂t2=0\\nabla^{2} \\mathbf{H}-\\mu \\varepsilon \\frac{\\partial^{2} \\mathbf{H}}{\\partial t^{2}}=0∇2H−με∂t2∂2H​=0 令v=1εμv=\\frac{1}{\\sqrt{\\varepsilon \\mu}}v=εμ​1​为介质中电磁波传播速度,n=εrμrn=\\sqrt{\\varepsilon_r \\mu_r}n=εr​μr​​ ∇2E−1v2∂2E∂t2=0\\nabla^{2} \\mathbf{E}-\\frac{1}{v^2} \\frac{\\partial^{2} \\mathbf{E}}{\\partial t^{2}}=0∇2E−v21​∂t2∂2E​=0,∇2H−1v2∂2H∂t2=0\\nabla^{2} \\mathbf{H}-\\frac{1}{v^2} \\frac{\\partial^{2} \\mathbf{H}}{\\partial t^{2}}=0∇2H−v21​∂t2∂2H​=0 结论: 电磁场具有波动性，以波的形式向外传播 电磁波的传播速度为𝑣,𝑣取决于传播介质 时谐电磁场,定态波动方程 电场表示为复振幅形式E(r,t)=E(r)eiwtE(r,t)=E(r)e^{iwt}E(r,t)=E(r)eiwt 代入波动方程可得:∇2E+w2μεE=0\\nabla^{2}E+ w^2 \\mu \\varepsilon E=0∇2E+w2μεE=0 波数:k=wμε=2πλk=w\\sqrt{\\mu \\varepsilon} = \\frac{2\\pi}{\\lambda}k=wμε​=λ2π​ 定态波动方程–亥姆赫兹方程 ∇2E+k2E=0\\nabla^{2}E+ k^2 E=0∇2E+k2E=0 ∇2H+k2H=0\\nabla^{2}H+ k^2 H=0∇2H+k2H=0 非均匀介质中波动方程(无源非均匀介质) Js=0,ρs=0，D(r)=ε(r)E(r),B(r)=μ0H(r)J_s=0,\\rho_s=0，D(r)=\\varepsilon(r)E(r),B(r)=\\mu_0H(r)Js​=0,ρs​=0，D(r)=ε(r)E(r),B(r)=μ0​H(r) 故可推导电场波动方程,磁场波动方程 1.9 电磁场的能量 带电粒子或系统在电磁场中所受的力:洛伦兹力 电场力:F⃗=qE⃗\\vec{F}=q\\vec{E}F=qE 磁场力:F⃗=qv⃗×B⃗\\vec{F} = q\\vec{v} \\times \\vec{B}F=qv×B 能量密度:场内单位体积内电磁场的能量 能流密度:(坡印廷矢量),表示电磁场传输的功率面密度(W/m2W/m^2W/m2) 方向为能量传输方向,数值等于单位时间内垂直流过单位横截面积的能量 坡印廷定理:−∇⋅S=f⋅v+∂w∂t-\\nabla \\cdot \\mathbf{S}=\\mathbf{f} \\cdot \\mathbf{v}+\\frac{\\partial w}{\\partial t}−∇⋅S=f⋅v+∂t∂w​ 能量密度及能流密度的表达式 电磁场对电荷所作的功:f⃗⋅c⃗=ρE⃗⋅v⃗+(J⃗×B⃗)⋅v⃗\\vec{f} \\cdot \\vec{c} = \\rho \\vec{E} \\cdot \\vec{v}+ (\\vec{J} \\times \\vec{B}) \\cdot \\vec{v}f​⋅c=ρE⋅v+(J×B)⋅v 将J⃗=ρ⋅v⃗\\vec{J} = \\rho \\cdot \\vec{v}J=ρ⋅v代入可得f⃗⋅c⃗=E⃗⋅J⃗\\vec{f} \\cdot \\vec{c} = \\vec{E} \\cdot \\vec{J}f​⋅c=E⋅J 由坡印廷定理可得:−∇⋅S−∂w∂t=f⋅v=E⋅J-\\nabla \\cdot \\mathbf{S} -\\frac{\\partial w}{\\partial t}=\\mathbf{f} \\cdot \\mathbf{v}=E \\cdot J−∇⋅S−∂t∂w​=f⋅v=E⋅J 由∇×H=J+∂D∂t\\nabla \\times H = J + \\frac{\\partial D}{\\partial t}∇×H=J+∂t∂D​,得J=∇×H−∂D∂tJ =\\nabla \\times H - \\frac{\\partial D}{\\partial t}J=∇×H−∂t∂D​ 而E⋅J=E⋅(∇×H−∂D∂t)E \\cdot J = E \\cdot (\\nabla \\times H - \\frac{\\partial D}{\\partial t})E⋅J=E⋅(∇×H−∂t∂D​) E⋅(∇×H)=−∇⋅(E×H)+H⋅(∇×E)=−∇⋅(E×H)−H⋅∂B∂t\\mathbf{E} \\cdot(\\nabla \\times \\mathbf{H})=-\\nabla \\cdot(\\mathbf{E} \\times \\mathbf{H})+\\mathbf{H} \\cdot(\\nabla \\times \\mathbf{E})=-\\nabla \\cdot(\\mathbf{E} \\times \\mathbf{H})-\\mathbf{H} \\cdot \\frac{\\partial \\mathbf{B}}{\\partial t}E⋅(∇×H)=−∇⋅(E×H)+H⋅(∇×E)=−∇⋅(E×H)−H⋅∂t∂B​ E⋅J=−∇⋅(E×H)−(E⋅∂D∂t+H⋅∂B∂t)\\mathbf{E} \\cdot \\mathbf{J}=-\\nabla \\cdot(\\mathbf{E} \\times \\mathbf{H})-\\left(\\mathbf{E} \\cdot \\frac{\\partial \\mathbf{D}}{\\partial t}+\\mathbf{H} \\cdot \\frac{\\partial \\mathbf{B}}{\\partial t}\\right)E⋅J=−∇⋅(E×H)−(E⋅∂t∂D​+H⋅∂t∂B​) 故由坡印廷定理得:−∇⋅S−∂w∂t=E⋅J=−∇⋅(E×H)−(E⋅∂D∂t+H⋅∂B∂t)-\\nabla \\cdot \\mathbf{S} -\\frac{\\partial w}{\\partial t}=E \\cdot J = -\\nabla \\cdot(\\mathbf{E} \\times \\mathbf{H})-\\left(\\mathbf{E} \\cdot \\frac{\\partial \\mathbf{D}}{\\partial t}+\\mathbf{H} \\cdot \\frac{\\partial \\mathbf{B}}{\\partial t}\\right)−∇⋅S−∂t∂w​=E⋅J=−∇⋅(E×H)−(E⋅∂t∂D​+H⋅∂t∂B​) 故S=E×H,∂w∂t=E⋅∂D∂t+H⋅∂B∂tS=E \\times H,\\frac{\\partial w}{\\partial t} = \\mathbf{E} \\cdot \\frac{\\partial \\mathbf{D}}{\\partial t}+\\mathbf{H} \\cdot \\frac{\\partial \\mathbf{B}}{\\partial t}S=E×H,∂t∂w​=E⋅∂t∂D​+H⋅∂t∂B​ 电磁能量的传输 电磁场在传输过程中其能量是以场的形式在传播 传输的总功率为坡印廷矢量在传输空间的截面上的积分:P=∫ΣS⋅dσ=∫Σ(E×H)⋅dσP=\\int_{\\Sigma} \\mathbf{S} \\cdot \\mathrm{d} \\boldsymbol{\\sigma}=\\int_{\\Sigma}(\\mathbf{E} \\times \\mathbf{H}) \\cdot \\mathrm{d} \\boldsymbol{\\sigma}P=∫Σ​S⋅dσ=∫Σ​(E×H)⋅dσ 2 电磁场在无限大均匀介质中的传播 2.1 无限大均匀介质中的平面波解 无源波动方程:∇2E−με∂2E∂t2=0\\nabla^{2} \\mathbf{E}-\\mu \\varepsilon \\frac{\\partial^{2} \\mathbf{E}}{\\partial t^{2}}=0∇2E−με∂t2∂2E​=0 将时谐电磁场Ei=Ui(r)eiwtE_i= U_i(r)e^{iwt}Ei​=Ui​(r)eiwt代入,可得亥姆霍兹方程∇2Ui(r)+k2Ui(r)=0\\nabla^{2} U_i(r)+k^2U_i(r)=0∇2Ui​(r)+k2Ui​(r)=0 可得通解:Ui(r)=ai+e−ik⋅r+ai−eik⋅rU_i(r)=a_i^+e^{-ik \\cdot r}+a_i^-e^{ik \\cdot r}Ui​(r)=ai+​e−ik⋅r+ai−​eik⋅r 位相共轭波,当正反向传播的波的复振幅互为复数共轭,则称这一对波为位相共轭波 2.2 无限大均匀介质中的球面波解 ∇2=1r2∂∂r(r2∂∂r)+1r2sin⁡θ∂∂θ(sin⁡θ∂∂θ)+1r2sin⁡θ2∂2∂φ2\\nabla^{2}=\\frac{1}{r^{2}} \\frac{\\partial}{\\partial r}\\left(r^{2} \\frac{\\partial}{\\partial r}\\right)+\\frac{1}{r^{2} \\sin \\theta} \\frac{\\partial}{\\partial \\theta}\\left(\\sin \\theta \\frac{\\partial}{\\partial \\theta}\\right)+\\frac{1}{r^{2} \\sin \\theta^{2}} \\frac{\\partial^{2}}{\\partial \\varphi^{2}}∇2=r21​∂r∂​(r2∂r∂​)+r2sinθ1​∂θ∂​(sinθ∂θ∂​)+r2sinθ21​∂φ2∂2​ 由亥姆霍兹方程可得:1r∂2∂r2[rU(r)]+k2U(r)=0\\frac{1}{r} \\frac{\\partial^{2}}{\\partial r^{2}}[r \\mathbf{U}(r)]+k^{2} \\mathbf{U}(r)=0r1​∂r2∂2​[rU(r)]+k2U(r)=0 可得解: 发散球面波:E+(r,t)=a+rei(wt−kr)E^+(r,t)=\\frac{a^+}{r}e^{i(wt-kr)}E+(r,t)=ra+​ei(wt−kr) 会聚球面波:E−(r,t)=a−rei(wt+kr)E^-(r,t)=\\frac{a^-}{r}e^{i(wt+kr)}E−(r,t)=ra−​ei(wt+kr) 球面单色波: E⃗(r,t)=arcos(wt+Kr)\\vec{E}(r,t) = \\frac{a}{r}cos(wt+Kr)E(r,t)=ra​cos(wt+Kr) E⃗(r,t)=arei(wt+Kr)\\vec{E}(r,t) = \\frac{a}{r}e^{i(wt+Kr)}E(r,t)=ra​ei(wt+Kr) 2.3 无限大均匀介质中柱坐标系下的高斯光束基模解 ∇2=∇t2+∂2∂z2=∂2∂r2+1r∂∂r+∂2∂z2\\nabla^{2}=\\nabla_{\\mathrm{t}}^{2}+\\frac{\\partial^{2}}{\\partial z^{2}}=\\frac{\\partial^{2}}{\\partial r^{2}}+\\frac{1}{r} \\frac{\\partial}{\\partial r}+\\frac{\\partial^{2}}{\\partial z^{2}}∇2=∇t2​+∂z2∂2​=∂r2∂2​+r1​∂r∂​+∂z2∂2​ 由亥姆霍兹方程可得:∇t2U(r)+∂2U(r)∂z2+k2U(r)=0\\nabla_{\\mathrm{t}}^{2} \\mathbf{U}(\\mathbf{r})+\\frac{\\partial^{2} \\mathbf{U}(\\mathbf{r})}{\\partial z^{2}}+k^{2} \\mathbf{U}(\\mathbf{r})=0∇t2​U(r)+∂z2∂2U(r)​+k2U(r)=0 能流主要沿Z轴传播的近似平面波:U(r)=A(r)e−ikzU(r)=A(r)e^{-ikz}U(r)=A(r)e−ikz 利用近似平面波方程,振幅沿Z轴缓慢变化,忽略∂2A(r)∂2z\\frac{\\partial^2 \\mathbf{A(r)}}{\\partial^2 z}∂2z∂2A(r)​,可得傍轴方程∇t2A(r)−2ik∂A(r)∂z=0\\nabla_{\\mathrm{t}}^{2} A(\\mathbf{r})-2 \\mathrm{i} k \\frac{\\partial A(\\mathbf{r})}{\\partial z}=0∇t2​A(r)−2ik∂z∂A(r)​=0 介质均匀n(r)=n0n(r)=n_0n(r)=n0​,考察的场矢量在垂直于zzz轴平面上rrr方向上等同,利用∇t2=∂2∂r2+1r∂∂r\\nabla_{\\mathrm{t}}^{2}=\\frac{\\partial^{2}}{\\partial r^{2}}+\\frac{1}{r} \\frac{\\partial}{\\partial r}∇t2​=∂r2∂2​+r1​∂r∂​,可得∂2A(r,z)∂r2+1r∂A(r,z)∂r−2ik∂A(r,z)∂z=0\\frac{\\partial^{2} A(r, z)}{\\partial r^{2}}+\\frac{1}{r} \\frac{\\partial A(r, z)}{\\partial r}-2 \\mathrm{i} k \\frac{\\partial A(r, z)}{\\partial z}=0∂r2∂2A(r,z)​+r1​∂r∂A(r,z)​−2ik∂z∂A(r,z)​=0 解上面的方程:U(r,z)=A0w0w(z)exp⁡[−r2w2(z)]exp⁡{−i[kz+kr22R(z)−φ(z)]}U(r, z)=A_{0} \\frac{w_{0}}{w(z)} \\exp \\left[-\\frac{r^{2}}{w^{2}(z)}\\right] \\exp \\left\\{-\\mathrm{i}\\left[k z+\\frac{k r^{2}}{2 R(z)}-\\varphi(z)\\right]\\right\\}U(r,z)=A0​w(z)w0​​exp[−w2(z)r2​]exp{−i[kz+2R(z)kr2​−φ(z)]} 激光光学中的基模高斯光束,是波动方程的一个特解,基模解 高斯光束的等相面曲率半径:R(z)=z(1+z02z2)R(z)=z\\left(1+\\frac{z_{0}^{2}}{z^{2}}\\right)R(z)=z(1+z2z02​​) 高斯光束的光斑半径:w(z)=w01+z2z02w(z)=w_{0} \\sqrt{1+\\frac{z^{2}}{z_{0}^{2}}}w(z)=w0​1+z02​z2​​ 高斯光束的附加相位因子:φ(z)=arctan⁡(zz0)\\varphi(z)=\\arctan \\left(\\frac{z}{z_{0}}\\right)φ(z)=arctan(z0​z​) 高斯光束的共焦参数:z0=πw02n0λ,z=z0z_{0}=\\frac{\\pi w_{0}^{2} n_{0}}{\\lambda},\\quad z=z_{0}z0​=λπw02​n0​​,z=z0​ 时, w(z)=2w0w(z)=\\sqrt{2} w_{0}w(z)=2​w0​ 高斯球面波的性质: 光斑半径w(z)w(z)w(z):在光束界面内,自光轴轴线到振幅的大小下降至轴线的1/e1/e1/e点的距离 w2(z)w02−z2z02=1\\frac{w^2(z)}{w_0^2}-\\frac{z^2}{z_0^2} = 1w02​w2(z)​−z02​z2​=1 等相面:相位相同的点的轨迹 等相面是球面,曲率半径R(z)R(z)R(z)不恒定,是z的函数 R(z)=z(1+z02z2)R(z)=z\\left(1+\\frac{z_{0}^{2}}{z^{2}}\\right)R(z)=z(1+z2z02​​) 当z=z0z=z_0z=z0​,R(z)R(z)R(z)最小,等于2z02z_02z0​;在束腰和无穷远处为平面 等相面的曲率中心随着光束的传输而移动,不是固定的点 总相移:光束在点处相对于原点的相位差 ϕ(z)=k[z+r22R(z)]−φ(z)\\phi(z)=k\\left[z+\\frac{r^{2}}{2 R(z)}\\right]-\\varphi(z)ϕ(z)=k[z+2R(z)r2​]−φ(z) 瑞利长度z0z_0z0​(共焦参数) z0=12kw02=πw02λz_{0}=\\frac{1}{2} k w_{0}^{2}=\\frac{\\pi w_{0}^{2}}{\\lambda}z0​=21​kw02​=λπw02​​ 当∣z∣=z0|z| = z_0∣z∣=z0​时,w(z0)=2w0w(z_0)=\\sqrt{2}w_0w(z0​)=2​w0​ 当∣z∣≤z0|z| \\leq z_0∣z∣≤z0​时,对应于准直范围,高斯光束近似平行 瑞利长度越长,高斯光束的准直范围越大 远场发散角θ0\\theta_0θ0​:数值上等于以束宽w0w_0w0​为半径的光束的衍射角 θ0=lim⁡z→∞w(z)z=λπw0\\theta_{0}=\\lim_{z \\rightarrow \\infty} \\frac{w(z)}{z}=\\frac{\\lambda}{\\pi w_{0}}θ0​=limz→∞​zw(z)​=πw0​λ​ 高斯光束在其传输轴线附近,可近似堪称一种非均匀球面波,曲率中心随传输过程而不断改变,振幅和强度在横截面内始终保持高斯分布特性,等相面始终保持为球面,光强集中在轴线及其附近 2.4 单色平面波的基本性质 单色平面波的特点 具有空间周期性和时间周期性 时间和空间上是无限的 若任何时间和空间周期的破坏都意味着单色性遭到破坏.平面波的振幅或位相若受到时间或空间的调制,它的单色性和平面性都受到破坏 E和K的关系E和K的关系E和K的关系 ∇⋅E=0\\nabla \\cdot E = 0∇⋅E=0将E=E0exp[i(wt−k⋅r)]E=E_0 exp[i(wt-k \\cdot r)]E=E0​exp[i(wt−k⋅r)]代入可得∇⋅E=−ik⋅E=0⇒k⊥E\\nabla \\cdot E = -i k \\cdot E = 0 \\Rightarrow k \\perp E∇⋅E=−ik⋅E=0⇒k⊥E 单色平面波是横电磁波 E与B的关系E与B的关系E与B的关系 ∇×E=−iωμH=−iωB\\nabla \\times \\mathbf{E}=-\\mathrm{i} \\omega \\mu \\mathbf{H}=-\\mathrm{i} \\omega \\mathbf{B}∇×E=−iωμH=−iωB &amp; e^k\\hat{\\mathbf{e}}_{\\mathbf{k}}e^k​ B=iω∇×E=iω∇×{E0exp⁡[i(ωt−k⋅r)]}=1ωk×E=μϵe^k×E\\mathbf{B}=\\frac{\\mathrm{i}}{\\omega} \\nabla \\times \\mathbf{E}=\\frac{\\mathrm{i}}{\\omega} \\nabla \\times\\left\\{\\mathbf{E}_{0} \\exp [\\mathrm{i}(\\omega t-\\mathbf{k} \\cdot \\mathbf{r})]\\right\\}=\\frac{1}{\\omega} \\mathbf{k} \\times \\mathbf{E}=\\sqrt{\\mu \\epsilon} \\hat{\\mathbf{e}}_{\\mathbf{k}} \\times \\mathbf{E}B=ωi​∇×E=ωi​∇×{E0​exp[i(ωt−k⋅r)]}=ω1​k×E=μϵ​e^k​×E 故B⊥k,B⊥EB \\perp k,B \\perp EB⊥k,B⊥E E,B,k三者互相垂直 波阻抗 真空中波阻抗:η0=∣EH∣=μ0ε0=4π×10−78.85×10−12=120π≈377(Ω)\\eta_{0}=\\left|\\frac{\\mathbf{E}}{\\mathbf{H}}\\right|=\\sqrt{\\frac{\\mu_{0}}{\\varepsilon_{0}}}=\\sqrt{\\frac{4 \\pi \\times 10^{-7}}{8.85 \\times 10^{-12}}}=120 \\pi \\approx 377(\\Omega)η0​=∣∣∣​HE​∣∣∣​=ε0​μ0​​​=8.85×10−124π×10−7​​=120π≈377(Ω) 波阻抗:η=∣EH∣=με\\eta=\\left|\\frac{\\mathbf{E}}{\\mathbf{H}}\\right|=\\sqrt{\\frac{\\mu}{\\varepsilon}}η=∣∣∣​HE​∣∣∣​=εμ​​ 2.5 平面波的能量和能流密度 平面波的能量密度: 瞬时能量密度:w=12(E⋅D+H⋅B)=12(εE2+1μB2)=1μB2w=\\frac{1}{2}(E \\cdot D+ H \\cdot B) = \\frac{1}{2}(\\varepsilon E^2+ \\frac{1}{\\mu}B^2)=\\frac{1}{\\mu}B^2w=21​(E⋅D+H⋅B)=21​(εE2+μ1​B2)=μ1​B2 时间平均能量密度:&lt;w&gt;=12εE02&lt; w &gt;= \\frac{1}{2} \\varepsilon E_0^2&lt;w&gt;=21​εE02​ 平面波的能流密度(坡印廷矢量): 平面电磁波情况: B=μεek×EB=\\sqrt{\\mu \\varepsilon} e_k \\times EB=με​ek​×E 瞬时能流密度S=E×H=1μεwek=vϕwekS = E\\times H=\\frac{1}{\\sqrt{\\mu \\varepsilon}}we_k=v_\\phi w e_kS=E×H=με​1​wek​=vϕ​wek​ 平均能流密度:&lt;S&gt;=12εμE02ek&lt; S &gt;=\\frac{1}{2}\\sqrt{\\frac{\\varepsilon}{\\mu}} E_0^2 e_k&lt;S&gt;=21​με​​E02​ek​ 能流密度大小=能量密度×相速度 能流密度方向为波矢量的方向 光学中,通常将时间平均能量密度成为光强 2.6 准单色光波 准单色光波的物理意义 单色波是理想化的波,不可能实际存在 根据傅里叶定理,任何波都可以看成不同频率波的叠加 当Δωω0(Δλλ0,Δγγ0)≪1\\frac{\\Delta \\omega}{\\omega_{0}}\\left(\\frac{\\Delta \\lambda}{\\lambda_{0}}, \\frac{\\Delta \\gamma}{\\gamma_{0}}\\right) \\ll 1ω0​Δω​(λ0​Δλ​,γ0​Δγ​)≪1时,称之为准单色波 相应的波列长度c⋅δtc\\cdot \\delta tc⋅δt很小 光谱线宽度极小,所包含的频率分布在一个极小的频谱范围之内,单色性很好 不像理想单色光那样只含有一种频率 准单色波可以看作时由分布在光谱线宽度极小范围内的所有各单色分量的叠加 又被称为波包 波包和群速度 任何非单色光波都可以利用傅里叶逆变换的方法分解为许多不同频率分量的单色光波的叠加,基元函数代表了不同频率从而不同波数的单色波;振幅即为相应频率单色波分量的大小 若频率分量满足ωˉ−12Δω≤ω≤ωˉ+12Δω\\bar{\\omega}-\\frac{1}{2} \\Delta \\omega \\leq \\omega \\leq \\bar{\\omega}+\\frac{1}{2} \\Delta \\omega \\quadωˉ−21​Δω≤ω≤ωˉ+21​Δω 且 Δωωˉ≪1\\quad \\frac{\\Delta \\omega}{\\bar{\\omega}} \\ll 1ωˉΔω​≪1,即为准单色波或波包 相速度:高频振荡波等相面的传输速度vp=wkv_p=\\frac{w}{k}vp​=kw​ 群速度:等振幅面的传播速度,等于低频调制波的传输速度vg=dwdkv_g=\\frac{dw}{dk}vg​=dkdw​ 表示由振幅函数保罗的波群的传输速度,群速度一般代表了能量传播的速度 相速度与群速度的关系:vg=vp−λdvpdλv_g=v_p-\\lambda \\frac{dv_p}{d\\lambda}vg​=vp​−λdλdvp​​ vg&lt;vpv_g &lt; v_pvg​&lt;vp​,正常色散 vg=vpv_g = v_pvg​=vp​,无色散 vg&gt;vpv_g &gt; v_pvg​&gt;vp​,反常色散 群折射率:ng=cvg=n1+λndn dλ≈n−λdn dλn_{\\mathrm{g}}=\\frac{c}{v_{\\mathrm{g}}}=\\frac{n}{1+\\frac{\\lambda}{n} \\frac{\\mathrm{d} n}{\\mathrm{~d} \\lambda}} \\approx n-\\lambda \\frac{\\mathrm{d} n}{\\mathrm{~d} \\lambda}ng​=vg​c​=1+nλ​ dλdn​n​≈n−λ dλdn​ 如何改变光的传播速度: 由群速度公式可以推导出vg=cngv_{g}=\\frac{c}{n_{g}}vg​=ng​c​,或vs=cn(ω)+ωdndav_{s}=\\frac{c}{n(\\omega)+\\omega \\frac{d n}{d a}}vs​=n(ω)+ωdadn​c​ 故ng≫1,vg≪cn_{g} \\gg 1,v_{g} \\ll cng​≫1,vg​≪c 快光:群速大于光速 慢光:群速小于光速 2.7 任意简谐波及相速度 可以由任意简谐波的标量波动方程推导得出其相速度为vp=n^⋅drdt=ω∣∇g(r)∣v_{\\mathrm{p}}=\\frac{\\hat{\\mathbf{n}} \\cdot \\mathrm{d} \\mathbf{r}}{\\mathrm{d} t}=\\frac{\\omega}{|\\nabla g(\\mathbf{r})|}vp​=dtn^⋅dr​=∣∇g(r)∣ω​ 例如平面波或球面波的相速度: ωt−kr+ϕ0=\\omega t-k r+\\phi_{0}=ωt−kr+ϕ0​= const ⇒g(r)=kr−ϕ0∇g(r)=∇(kr)=k⇒vp=ω∣∇g(r)∣=ωk\\Rightarrow \\begin{aligned}&amp;g(\\mathbf{r})=k r-\\phi_{0} \\\\&amp;\\nabla g(\\mathbf{r})=\\nabla(k r)=k\\end{aligned} \\Rightarrow v_{\\mathrm{p}}=\\frac{\\omega}{|\\nabla g(\\mathbf{r})|}=\\frac{\\omega}{k}⇒​g(r)=kr−ϕ0​∇g(r)=∇(kr)=k​⇒vp​=∣∇g(r)∣ω​=kω​ 并且可以得出标量波动方程和亥姆霍兹方程 2.8 光波的偏振 偏振的概念 偏振是指用一个场矢量来描述空间中某一固定点所观测的矢量波随时间变化的特征 在自由空间中传播的电磁波是一种纯粹的横波,光波中沿横向振动着的物理量是电场矢量和磁场矢量,一般以电矢量作为光波中振动矢量的代表 波动的复数表示和相位关系: 约定+w+w+w方向为逆时针旋转方向,或认为www矢量为垂直纸面向外 δ=ϕb−ϕa\\delta=\\phi_b-\\phi_aδ=ϕb​−ϕa​,当ϕb−ϕa&gt;0\\phi_b-\\phi_a &gt;0ϕb​−ϕa​&gt;0表示b相位超前a,或者a相位滞后b 单色平面波的偏振 两个单色平面波(频率相同,传播方向相同,振动方向相互垂直)叠加,叠加后 新主轴长度为 a2=Ax2cos⁡2ψ+Ay2sin⁡2ψ+AxAycos⁡δsin⁡(2ψ)a^{2}=A_{x}^{2} \\cos ^{2} \\psi+A_{y}^{2} \\sin ^{2} \\psi+A_{x} A_{y} \\cos \\delta \\sin (2 \\psi)a2=Ax2​cos2ψ+Ay2​sin2ψ+Ax​Ay​cosδsin(2ψ) b2=Ax2sin⁡2ψ+Ay2cos⁡2ψ−AxAycos⁡δsin⁡(2ψ)b^{2}=A_{x}^{2} \\sin ^{2} \\psi+A_{y}^{2} \\cos ^{2} \\psi-A_{x} A_{y} \\cos \\delta \\sin (2 \\psi)b2=Ax2​sin2ψ+Ay2​cos2ψ−Ax​Ay​cosδsin(2ψ) 且:tan⁡(2ψ)=2AxAyAx2−Ay2cos⁡δ\\tan (2 \\psi)=\\frac{2 A_{x} A_{y}}{A_{x}^{2}-A_{y}^{2}} \\cos \\deltatan(2ψ)=Ax2​−Ay2​2Ax​Ay​​cosδ 完全偏振光的三种形态 线偏振光 圆偏振光:Ex=Acos(wt),Ey=Acos(wt±π2)E_x=Acos(wt),E_y=Acos(wt±\\frac{\\pi}{2})Ex​=Acos(wt),Ey​=Acos(wt±2π​),右旋对正号,左旋对应负号 椭圆偏振光 3 电磁波在分层介质中的传播 3.1 平面电磁波在两介质界面上的反射和折射 复习:电磁场的边界条件 在没有传导电流和自由电荷的介质中 磁感应强度B和电感强度D的法向分量在界面上连续 电场强度E和磁场强度H的切向分量在界面上连续 折反射定理: 利用入射波,反射波和折射波的复数振幅表达式和电磁场的边界条件进行推导可得矢量形式的折反射定律(kr⃗−ki⃗)⋅r⃗=0,(kt⃗−ki⃗)⋅r⃗=0(\\vec{k^r} -\\vec{k^i}) \\cdot \\vec{r} = 0,(\\vec{k^t} -\\vec{k^i}) \\cdot \\vec{r} = 0(kr−ki)⋅r=0,(kt−ki)⋅r=0 电磁波的时间频率是入射波的固有属性,不随介质的改变而改变 对波矢进行分解可得波矢守恒方程kxi=kxr=kxtk_x^i=k_x^r=k_x^tkxi​=kxr​=kxt​ 故可得到 反射定理:kxi=kxr⇒ωμ1ε1sin⁡θi=ωμ1ε1sin⁡θr⇒θi=θrk_{x}^{\\mathrm{i}}=k_{x}^{\\mathrm{r}} \\Rightarrow \\omega \\sqrt{\\mu_{1} \\varepsilon_{1}} \\sin \\theta_{\\mathrm{i}}=\\omega \\sqrt{\\mu_{1} \\varepsilon_{1}} \\sin \\theta_{\\mathrm{r}} \\Rightarrow \\theta_{\\mathrm{i}}=\\theta_{\\mathrm{r}}kxi​=kxr​⇒ωμ1​ε1​​sinθi​=ωμ1​ε1​​sinθr​⇒θi​=θr​ 折射定律:kxi=kxt⇒ωμ1ε1sin⁡θi=ωμ2ε2sin⁡θt⇒μ1ε1sin⁡θi=μ2ε2sin⁡θtk_{x}^{\\mathrm{i}}=k_{x}^{\\mathrm{t}} \\Rightarrow \\omega \\sqrt{\\mu_{1} \\varepsilon_{1}} \\sin \\theta_{\\mathrm{i}}=\\omega \\sqrt{\\mu_{2} \\varepsilon_{2}} \\sin \\theta_{\\mathrm{t}}\\Rightarrow \\sqrt{\\mu_{1} \\varepsilon_{1}} \\sin \\theta_{\\mathrm{i}}=\\sqrt{\\mu_{2} \\varepsilon_{2}} \\sin \\theta_{\\mathrm{t}}kxi​=kxt​⇒ωμ1​ε1​​sinθi​=ωμ2​ε2​​sinθt​⇒μ1​ε1​​sinθi​=μ2​ε2​​sinθt​ 菲涅尔公式: 反射波,折射波与入射波的振幅和位相关系 rs=n1cos⁡θ1−n2cos⁡θ2n1cos⁡θ1+n2cos⁡θ2=−sin⁡(θ1−θ2)sin⁡(θ1+θ2)r_{\\mathrm{s}}=\\frac{n_{1} \\cos \\theta_{1}-n_{2} \\cos \\theta_{2}}{n_{1} \\cos \\theta_{1}+n_{2} \\cos \\theta_{2}}=-\\frac{\\sin \\left(\\theta_{1}-\\theta_{2}\\right)}{\\sin \\left(\\theta_{1}+\\theta_{2}\\right)}rs​=n1​cosθ1​+n2​cosθ2​n1​cosθ1​−n2​cosθ2​​=−sin(θ1​+θ2​)sin(θ1​−θ2​)​ ts=2n1cos⁡θ1n1cos⁡θ1+n2cos⁡θ2=2cos⁡θ1sin⁡θ2sin⁡(θ1+θ2)t_{\\mathrm{s}}=\\frac{2 n_{1} \\cos \\theta_{1}}{n_{1} \\cos \\theta_{1}+n_{2} \\cos \\theta_{2}}=\\frac{2 \\cos \\theta_{1} \\sin \\theta_{2}}{\\sin \\left(\\theta_{1}+\\theta_{2}\\right)}ts​=n1​cosθ1​+n2​cosθ2​2n1​cosθ1​​=sin(θ1​+θ2​)2cosθ1​sinθ2​​ rp=n2cos⁡θ1−n1cos⁡θ2n2cos⁡θ1+n1cos⁡θ2=tan⁡(θ1−θ2)tan⁡(θ1+θ2)r_{\\mathrm{p}}=\\frac{n_{2} \\cos \\theta_{1}-n_{1} \\cos \\theta_{2}}{n_{2} \\cos \\theta_{1}+n_{1} \\cos \\theta_{2}}=\\frac{\\tan \\left(\\theta_{1}-\\theta_{2}\\right)}{\\tan \\left(\\theta_{1}+\\theta_{2}\\right)}rp​=n2​cosθ1​+n1​cosθ2​n2​cosθ1​−n1​cosθ2​​=tan(θ1​+θ2​)tan(θ1​−θ2​)​ tp=2n1cos⁡θ1n2cos⁡θ1+n1cos⁡θ2=2cos⁡θ1sin⁡θ2sin⁡(θ1+θ2)cos⁡(θ1−θ2)t_{\\mathrm{p}}=\\frac{2 n_{1} \\cos \\theta_{1}}{n_{2} \\cos \\theta_{1}+n_{1} \\cos \\theta_{2}}=\\frac{2 \\cos \\theta_{1} \\sin \\theta_{2}}{\\sin \\left(\\theta_{1}+\\theta_{2}\\right) \\cos \\left(\\theta_{1}-\\theta_{2}\\right)}tp​=n2​cosθ1​+n1​cosθ2​2n1​cosθ1​​=sin(θ1​+θ2​)cos(θ1​−θ2​)2cosθ1​sinθ2​​ 当θ1=0,m=n2n1\\theta_1=0,m=\\frac{n_2}{n_1}θ1​=0,m=n1​n2​​ rs=−m−1m+1r_s=-\\frac{m-1}{m+1}rs​=−m+1m−1​ rp=m−1m+1r_p=\\frac{m-1}{m+1}rp​=m+1m−1​ ts=2m+1t_s=\\frac{2}{m+1}ts​=m+12​ tp=2m+1t_p=\\frac{2}{m+1}tp​=m+12​ 反射光波与透射光波的性质(光疏-光密) 振幅变化 折射波,P与S波均单调减小,保持正值,不发生相位变化 反射波,S波负值,幅度单调增加,P波正值先减到0后负向增加 Rs=IsrIsi=n1∣Esr∣2n1∣Esi∣2=∣rs∣2Rp=IprIpi=n1∣Epr∣2n1∣Epi∣2=∣rp∣2Ts=IstIsi=n2∣Est∣2n1∣Esi∣2=n2n1∣ts∣2Tp=IptIpi=n2∣Ept∣2n1∣Epi∣2=n2n1∣tp∣2\\begin{array}{ll}R_{\\mathrm{s}}=\\frac{I_{\\mathrm{s}}^{\\mathrm{r}}}{I_{\\mathrm{s}}^{\\mathrm{i}}}=\\frac{n_{1}\\left|E_{\\mathrm{s}}^{\\mathrm{r}}\\right|^{2}}{n_{1}\\left|E_{\\mathrm{s}}^{\\mathrm{i}}\\right|^{2}}=\\left|r_{\\mathrm{s}}\\right|^{2} &amp; R_{\\mathrm{p}}=\\frac{I_{\\mathrm{p}}^{\\mathrm{r}}}{I_{\\mathrm{p}}^{\\mathrm{i}}}=\\frac{n_{1}\\left|E_{\\mathrm{p}}^{\\mathrm{r}}\\right|^{2}}{n_{1}\\left|E_{\\mathrm{p}}^{\\mathrm{i}}\\right|^{2}}=\\left|r_{\\mathrm{p}}\\right|^{2} \\\\ T_{\\mathrm{s}}=\\frac{I_{\\mathrm{s}}^{\\mathrm{t}}}{I_{\\mathrm{s}}^{\\mathrm{i}}}=\\frac{n_{2}\\left|E_{\\mathrm{s}}^{\\mathrm{t}}\\right|^{2}}{n_{1}\\left|E_{\\mathrm{s}}^{\\mathrm{i}}\\right|^{2}}=\\frac{n_{2}}{n_{1}}\\left|t_{\\mathrm{s}}\\right|^{2} &amp; T_{\\mathrm{p}}=\\frac{I_{\\mathrm{p}}^{\\mathrm{t}}}{I_{\\mathrm{p}}^{\\mathrm{i}}}=\\frac{n_{2}\\left|E_{\\mathrm{p}}^{\\mathrm{t}}\\right|^{2}}{n_{1}\\left|E_{\\mathrm{p}}^{\\mathrm{i}}\\right|^{2}}=\\frac{n_{2}}{n_{1}}\\left|t_{\\mathrm{p}}\\right|^{2}\\end{array}Rs​=Isi​Isr​​=n1​∣Esi​∣2n1​∣Esr​∣2​=∣rs​∣2Ts​=Isi​Ist​​=n1​∣Esi​∣2n2​∣Est​∣2​=n1​n2​​∣ts​∣2​Rp​=Ipi​Ipr​​=n1​∣Epi​∣2n1​∣Epr​∣2​=∣rp​∣2Tp​=Ipi​Ipt​​=n1​∣Epi​∣2n2​∣Ept​∣2​=n1​n2​​∣tp​∣2​ 偏振性质和布儒斯特角 分量振幅改变,极化 rp=0,θ1+θ2=π2r_p=0,\\theta_1+\\theta_2=\\frac{\\pi}{2}rp​=0,θ1​+θ2​=2π​ 布儒斯特定律(p波)tanθ1=n2n1,θ1tan \\theta_1=\\frac{n_2}{n_1},\\theta_1tanθ1​=n1​n2​​,θ1​为布儒斯特角 位相变化 折射波ts&gt;0,tp&gt;0t_s&gt;0,t_p&gt;0ts​&gt;0,tp​&gt;0,反射波rs&lt;0,rp&gt;0→rp&lt;0r_s&lt;0,r_p&gt;0\\rightarrow r_p&lt;0rs​&lt;0,rp​&gt;0→rp​&lt;0 位相突变,半波损失 折射波,不发生位相变化 全反射(光密-光疏) θ1&gt;θc→(sin⁡θc=n2n1)\\theta_{1}&gt;\\theta_{c} \\rightarrow\\left(\\sin \\theta_{c}=\\frac{n_{2}}{n_{1}}\\right)θ1​&gt;θc​→(sinθc​=n1​n2​​)时,不存在折射角,此时没有折射光,在界面上的光全部反射会介质1,即发生全反射,θc\\theta_cθc​为临界角 位相变化:S 波和 P 波分量相位跃变,引起偏振态变化 δrs=−2arctan⁡(n2An1cos⁡θ1)δrp=π−2arctan⁡(n1An2cos⁡θ1)\\begin{gathered}\\delta_{\\mathrm{rs}}=-2 \\arctan \\left(\\frac{n_{2} A}{n_{1} \\cos \\theta_{1}}\\right) \\\\ \\delta_{\\mathrm{rp}}=\\pi-2 \\arctan \\left(\\frac{n_{1} A}{n_{2} \\cos \\theta_{1}}\\right)\\end{gathered}δrs​=−2arctan(n1​cosθ1​n2​A​)δrp​=π−2arctan(n2​cosθ1​n1​A​)​ s波和P波分量相位跃变:δrs−δrp=2arccot⁡(n2Acos⁡θ1n1sin⁡2θ1)\\delta_{\\mathrm{rs}}-\\delta_{\\mathrm{rp}}=2 \\operatorname{arccot}\\left(\\frac{n_{2} A \\cos \\theta_{1}}{n_{1} \\sin ^{2} \\theta_{1}}\\right)δrs​−δrp​=2arccot(n1​sin2θ1​n2​Acosθ1​​) 倏逝波 虽然入射波能量被全部反射回n1n_1n1​介质，但在介质n2n_2n2​中的界面附近极薄一层中仍存在表面波，即称倏逝波 穿透深度:在距离界面z=zmz=z_mz=zm​处,振幅衰减为e−1e^{-1}e−1,zm=1k1sin2θ1−n212z_m=\\frac{1}{k_1 \\sqrt{sin^2 \\theta_1 - n_{21}^2}}zm​=k1​sin2θ1​−n212​​1​ 𝑧方向上振幅衰减是指沿𝑥方向传播的波在𝑧方向上振幅的分布不是均匀的，是不等振幅,等相面和等幅面不重合,非均匀波 能流密度:在媒介界面方向(x方向)传播,平均能流密度不为0,瞬时能流密度不为0;在与界面垂直的方向上(z方向)平均能流密度为0 应用: 牛顿实验:全反射时无干扰,亮光斑;透镜4𝜆距离时就可以观察到光强变化;无接触时，中心也是黑的;光通过倏逝波耦合到透镜里去了 全反射，由于倏逝波的存在使得一部分椭圆形区域感光 古斯汉森位移: 有限光束在界面上发生全反射时,光束在界面上有一侧向位移 光带I在银层上全反射,由于银层的高吸收,使光波的穿透深 度小于倏逝波,造成出射光的明显错位 3.4 电磁波在分层介质上的反射和折射 为什么镜头呈现蓝紫色? 目视仪器的增透膜为黄绿色,增透膜的反射光呈现器互补色","categories":[{"name":"Study","slug":"Study","permalink":"http://jay1060950003.github.io/categories/Study/"}],"tags":[{"name":"Study","slug":"Study","permalink":"http://jay1060950003.github.io/tags/Study/"}]}],"categories":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/categories/Tools/"},{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/categories/Interview/"},{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/categories/deeplearning/"},{"name":"ISP","slug":"ISP","permalink":"http://jay1060950003.github.io/categories/ISP/"},{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/categories/C/"},{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/categories/Basic/"},{"name":"Misc","slug":"Misc","permalink":"http://jay1060950003.github.io/categories/Misc/"},{"name":"Java","slug":"Java","permalink":"http://jay1060950003.github.io/categories/Java/"},{"name":"Study","slug":"Study","permalink":"http://jay1060950003.github.io/categories/Study/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://jay1060950003.github.io/tags/Tools/"},{"name":"Interview","slug":"Interview","permalink":"http://jay1060950003.github.io/tags/Interview/"},{"name":"deeplearning","slug":"deeplearning","permalink":"http://jay1060950003.github.io/tags/deeplearning/"},{"name":"ISP","slug":"ISP","permalink":"http://jay1060950003.github.io/tags/ISP/"},{"name":"C++","slug":"C","permalink":"http://jay1060950003.github.io/tags/C/"},{"name":"Basic","slug":"Basic","permalink":"http://jay1060950003.github.io/tags/Basic/"},{"name":"Misc","slug":"Misc","permalink":"http://jay1060950003.github.io/tags/Misc/"},{"name":"Java","slug":"Java","permalink":"http://jay1060950003.github.io/tags/Java/"},{"name":"Study","slug":"Study","permalink":"http://jay1060950003.github.io/tags/Study/"}]}